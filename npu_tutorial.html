<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Neural Processing Unit (NPU) 设计教程</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'PingFang SC', 'Microsoft YaHei', sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: #f5f5f5;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }

        header {
            background: linear-gradient(135deg, #2c3e50 0%, #3498db 100%);
            color: white;
            padding: 40px 0;
            text-align: center;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }

        header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
        }

        nav {
            background: #34495e;
            padding: 15px 0;
            position: sticky;
            top: 0;
            z-index: 100;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }

        nav ul {
            list-style: none;
            display: flex;
            flex-wrap: wrap;
            justify-content: center;
            max-width: 1200px;
            margin: 0 auto;
        }

        nav li {
            margin: 5px 15px;
        }

        nav a {
            color: white;
            text-decoration: none;
            padding: 5px 10px;
            border-radius: 4px;
            transition: background 0.3s;
        }

        nav a:hover {
            background: #2c3e50;
        }

        .chapter {
            background: white;
            margin: 20px 0;
            padding: 30px;
            border-radius: 8px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }

        .chapter h2 {
            color: #2c3e50;
            font-size: 2em;
            margin-bottom: 20px;
            padding-bottom: 10px;
            border-bottom: 3px solid #3498db;
        }

        .chapter h3 {
            color: #34495e;
            font-size: 1.5em;
            margin: 25px 0 15px 0;
        }

        .chapter h4 {
            color: #7f8c8d;
            font-size: 1.2em;
            margin: 20px 0 10px 0;
        }

        .code-block {
            background: #2c3e50;
            color: #ecf0f1;
            padding: 20px;
            border-radius: 5px;
            margin: 15px 0;
            overflow-x: auto;
            font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
            font-size: 14px;
            line-height: 1.5;
        }

        .exercise {
            background: #ecf0f1;
            padding: 20px;
            border-radius: 5px;
            margin: 20px 0;
            border-left: 5px solid #3498db;
        }

        .exercise h4 {
            color: #2c3e50;
            margin-bottom: 10px;
        }

        .question {
            margin: 15px 0;
            padding: 15px;
            background: white;
            border-radius: 5px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
        }

        .answer {
            margin-top: 10px;
            padding: 15px;
            background: #e8f5e9;
            border-radius: 5px;
            display: none;
            border-left: 4px solid #4caf50;
        }

        .answer.show {
            display: block;
        }

        .toggle-answer {
            background: #3498db;
            color: white;
            border: none;
            padding: 8px 15px;
            border-radius: 4px;
            cursor: pointer;
            font-size: 14px;
            margin-top: 10px;
            transition: background 0.3s;
        }

        .toggle-answer:hover {
            background: #2980b9;
        }

        .figure {
            text-align: center;
            margin: 20px 0;
        }

        .figure img {
            max-width: 100%;
            height: auto;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }

        .figure-caption {
            color: #7f8c8d;
            font-size: 0.9em;
            margin-top: 10px;
        }

        .table-wrapper {
            overflow-x: auto;
            margin: 20px 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }

        th, td {
            padding: 12px;
            text-align: left;
            border-bottom: 1px solid #ddd;
        }

        th {
            background: #34495e;
            color: white;
            font-weight: bold;
        }

        tr:hover {
            background: #f5f5f5;
        }

        .highlight {
            background: #fff3cd;
            padding: 2px 5px;
            border-radius: 3px;
        }

        .info-box {
            background: #e3f2fd;
            border-left: 5px solid #2196f3;
            padding: 15px;
            margin: 20px 0;
            border-radius: 5px;
        }

        .warning-box {
            background: #fff3cd;
            border-left: 5px solid #ff9800;
            padding: 15px;
            margin: 20px 0;
            border-radius: 5px;
        }

        @media (max-width: 768px) {
            .container {
                padding: 10px;
            }
            
            header h1 {
                font-size: 1.8em;
            }
            
            .chapter {
                padding: 20px;
            }
            
            nav ul {
                flex-direction: column;
                align-items: center;
            }
        }
    </style>
</head>
<body>
    <header>
        <h1>Neural Processing Unit (NPU) 设计教程</h1>
        <p>从基础到高级的完整NPU芯片设计指南</p>
    </header>

    <nav>
        <ul>
            <li><a href="#intro">课程介绍</a></li>
            <li><a href="#chapter1">1. NPU简介</a></li>
            <li><a href="#chapter2">2. 神经网络基础</a></li>
            <li><a href="#chapter3">3. NPU架构</a></li>
            <li><a href="#chapter4">4. 计算核心</a></li>
            <li><a href="#chapter5">5. 存储系统</a></li>
            <li><a href="#chapter6">6. RTL设计</a></li>
            <li><a href="#chapter7">7. 验证方法</a></li>
            <li><a href="#chapter8">8. 物理设计</a></li>
            <li><a href="#chapter9">9. 先进工艺</a></li>
            <li><a href="#chapter10">10. 软硬件协同</a></li>
            <li><a href="#chapter11">11. 性能优化</a></li>
            <li><a href="#chapter12">12. 实战项目</a></li>
        </ul>
    </nav>

    <div class="container">
        <div id="intro" class="chapter">
            <h2>课程介绍</h2>
            <p>欢迎来到Neural Processing Unit (NPU)设计教程！本教程将带您从零开始，逐步深入了解NPU的设计原理和实现技术。</p>
            
            <h3>课程目标</h3>
            <ul>
                <li>理解NPU的基本原理和架构</li>
                <li>掌握NPU前端设计技术（RTL设计和验证）</li>
                <li>学习NPU后端设计流程（综合、布局布线）</li>
                <li>了解软硬件协同设计方法</li>
                <li>通过实战项目巩固所学知识</li>
            </ul>

            <h3>学习建议</h3>
            <div class="info-box">
                <p><strong>提示：</strong>本教程采用渐进式学习方式，建议按章节顺序学习。每章都包含理论讲解、代码示例和练习题，请确保完成每章的练习题后再进入下一章。</p>
            </div>

            <h3>先修知识</h3>
            <ul>
                <li>数字电路基础</li>
                <li>Verilog/SystemVerilog编程基础</li>
                <li>计算机体系结构基础</li>
                <li>基本的深度学习概念</li>
            </ul>
        </div>

        <div id="chapter1" class="chapter">
            <h2>第1章：NPU简介与发展历程</h2>
            
            <h3>1.1 什么是NPU</h3>
            <p>Neural Processing Unit (NPU) 是一种专门为加速人工智能和机器学习工作负载而设计的处理器。与传统的CPU和GPU不同，NPU针对神经网络计算进行了特殊优化，能够高效执行矩阵运算、卷积运算等AI相关操作。</p>
            
            <div class="info-box">
                <p><strong>关键特征：</strong></p>
                <ul>
                    <li>专用硬件加速器，优化神经网络推理和训练</li>
                    <li>高效的矩阵运算单元（MAC阵列）</li>
                    <li>专门的数据流架构，减少内存访问开销</li>
                    <li>支持低精度计算（INT8, INT4等）以提高效率</li>
                </ul>
            </div>

            <h3>1.2 NPU vs CPU vs GPU</h3>
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>特性</th>
                            <th>CPU</th>
                            <th>GPU</th>
                            <th>NPU</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>设计目标</td>
                            <td>通用计算</td>
                            <td>并行图形/计算</td>
                            <td>AI/ML专用</td>
                        </tr>
                        <tr>
                            <td>架构特点</td>
                            <td>少量复杂核心</td>
                            <td>大量简单核心</td>
                            <td>专用MAC阵列</td>
                        </tr>
                        <tr>
                            <td>内存层次</td>
                            <td>多级缓存</td>
                            <td>高带宽显存</td>
                            <td>片上SRAM为主</td>
                        </tr>
                        <tr>
                            <td>功耗效率</td>
                            <td>中等</td>
                            <td>较低</td>
                            <td>高</td>
                        </tr>
                        <tr>
                            <td>编程模型</td>
                            <td>串行为主</td>
                            <td>SIMD/SIMT</td>
                            <td>数据流</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h3>1.3 NPU的应用场景</h3>
            <h4>边缘端应用</h4>
            <ul>
                <li><strong>智能手机：</strong>人脸识别、语音助手、拍照优化</li>
                <li><strong>智能摄像头：</strong>实时物体检测、行为分析</li>
                <li><strong>自动驾驶：</strong>感知融合、路径规划</li>
                <li><strong>IoT设备：</strong>语音唤醒、异常检测</li>
            </ul>

            <h4>数据中心应用</h4>
            <ul>
                <li><strong>推理服务器：</strong>大规模AI服务部署</li>
                <li><strong>训练加速：</strong>分布式训练加速卡</li>
                <li><strong>推荐系统：</strong>实时推荐计算</li>
            </ul>

            <h3>1.4 主流NPU架构概览</h3>
            
            <h4>1.4.1 Google TPU</h4>
            <div class="code-block">
// TPU v1 架构特点
- 脉动阵列（Systolic Array）：256x256 MACs
- 片上缓存：24MB Unified Buffer
- 主频：700MHz
- 峰值性能：92 TOPS (INT8)
- 内存带宽：34 GB/s
            </div>

            <h4>1.4.2 华为Ascend</h4>
            <div class="code-block">
// Ascend 910 架构特点
- 达芬奇架构：Cube计算单元
- 片上缓存：多级缓存体系
- 峰值性能：256 TFLOPS (FP16)
- HBM内存：32GB
- 互联：高速片间互联
            </div>

            <h4>1.4.3 寒武纪MLU</h4>
            <div class="code-block">
// MLU 290 架构特点
- MLUv02架构
- 16个MLU Core
- 片上缓存：48MB
- 内存：32GB LPDDR4x
- 峰值性能：1024 TOPS (INT4)
            </div>

            <div class="exercise">
                <h4>练习题集 1</h4>
                
                <div class="question">
                    <p><strong>题目1.1：</strong>简述NPU相比GPU在AI推理任务上的三个主要优势。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <ol>
                            <li><strong>功耗效率更高：</strong>NPU采用专用硬件设计，去除了GPU中用于图形渲染的部分，并针对神经网络运算进行优化，在相同性能下功耗可降低50%以上。</li>
                            <li><strong>推理延迟更低：</strong>NPU的数据流架构和片上存储设计减少了内存访问延迟，批处理大小为1时性能优势明显。</li>
                            <li><strong>支持低精度计算：</strong>NPU原生支持INT8、INT4等低精度格式，可在保持精度的同时大幅提升吞吐量。</li>
                        </ol>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目1.2：</strong>解释什么是脉动阵列（Systolic Array），以及它为什么适合神经网络计算？</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p>脉动阵列是一种规则的处理单元阵列，数据像心脏跳动一样有节奏地在阵列中流动。其特点包括：</p>
                        <ul>
                            <li><strong>数据复用：</strong>输入数据在多个PE间传递，减少内存访问</li>
                            <li><strong>规则结构：</strong>易于实现和扩展，面积利用率高</li>
                            <li><strong>高并行度：</strong>可同时执行大量MAC运算</li>
                        </ul>
                        <p>适合神经网络的原因：</p>
                        <ol>
                            <li>神经网络主要是矩阵乘法运算，与脉动阵列的计算模式匹配</li>
                            <li>权重可以预加载并保持静止，提高数据复用率</li>
                            <li>规则的计算模式便于流水线设计</li>
                        </ol>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目1.3：</strong>某NPU的MAC阵列为16x16，主频为1GHz，每个周期每个MAC可完成2次INT8运算。计算该NPU的理论峰值性能（TOPS）。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p>计算步骤：</p>
                        <ol>
                            <li>MAC单元总数 = 16 × 16 = 256</li>
                            <li>每秒周期数 = 1GHz = 10^9 cycles/s</li>
                            <li>每周期运算次数 = 256 × 2 = 512 ops/cycle</li>
                            <li>峰值性能 = 10^9 × 512 = 512 × 10^9 ops/s = 512 GOPS = 0.512 TOPS</li>
                        </ol>
                        <p><strong>答案：0.512 TOPS</strong></p>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目1.4：</strong>设计一个简单的4x4脉动阵列，用Verilog描述其中一个PE（Processing Element）的基本结构。PE需要支持乘累加操作。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module PE #(
    parameter DATA_WIDTH = 8,
    parameter ACC_WIDTH = 32
)(
    input wire clk,
    input wire rst_n,
    input wire en,
    
    // 数据输入
    input wire [DATA_WIDTH-1:0] data_in,    // 从左边PE传入
    input wire [DATA_WIDTH-1:0] weight_in,  // 从上边PE传入
    
    // 数据输出
    output reg [DATA_WIDTH-1:0] data_out,   // 传给右边PE
    output reg [DATA_WIDTH-1:0] weight_out, // 传给下边PE
    
    // 部分和
    input wire [ACC_WIDTH-1:0] psum_in,     // 从上边PE传入
    output reg [ACC_WIDTH-1:0] psum_out     // 传给下边PE
);

    // 内部寄存器
    reg [DATA_WIDTH-1:0] weight_reg;
    wire [2*DATA_WIDTH-1:0] mult_result;
    wire [ACC_WIDTH-1:0] acc_result;
    
    // 乘法器
    assign mult_result = data_in * weight_reg;
    
    // 加法器
    assign acc_result = psum_in + {{(ACC_WIDTH-2*DATA_WIDTH){mult_result[2*DATA_WIDTH-1]}}, mult_result};
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            data_out <= 0;
            weight_out <= 0;
            psum_out <= 0;
            weight_reg <= 0;
        end else if (en) begin
            // 数据向右传递
            data_out <= data_in;
            
            // 权重向下传递并保存
            weight_out <= weight_in;
            weight_reg <= weight_in;
            
            // 累加结果向下传递
            psum_out <= acc_result;
        end
    end
endmodule
                        </div>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目1.5：</strong>分析边缘端NPU和云端NPU在设计上的主要差异，至少列举4个方面。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <table>
                            <tr>
                                <th>设计方面</th>
                                <th>边缘端NPU</th>
                                <th>云端NPU</th>
                            </tr>
                            <tr>
                                <td>功耗预算</td>
                                <td>通常&lt;5W，需要极致的功耗优化</td>
                                <td>可达100W以上，更关注性能</td>
                            </tr>
                            <tr>
                                <td>内存系统</td>
                                <td>小容量片上SRAM，有限的外部带宽</td>
                                <td>大容量HBM/GDDR，高带宽</td>
                            </tr>
                            <tr>
                                <td>计算精度</td>
                                <td>主要INT8/INT4，追求高压缩比</td>
                                <td>FP16/FP32/INT8混合精度</td>
                            </tr>
                            <tr>
                                <td>芯片面积</td>
                                <td>&lt;50mm²，成本敏感</td>
                                <td>可达800mm²，性能优先</td>
                            </tr>
                            <tr>
                                <td>应用场景</td>
                                <td>推理为主，实时性要求高</td>
                                <td>训练和推理，吞吐量优先</td>
                            </tr>
                        </table>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目1.6：</strong>计算题：某手机NPU需要实时处理1080p@30fps的视频流进行物体检测。假设每帧需要100M次MAC运算，计算所需的最小算力（GOPS）。如果NPU效率为70%，实际需要多少GOPS的峰值性能？</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p>计算步骤：</p>
                        <ol>
                            <li>每秒帧数：30 fps</li>
                            <li>每帧运算量：100M = 10^8 ops</li>
                            <li>每秒运算量：30 × 10^8 = 3 × 10^9 ops = 3 GOPS</li>
                            <li>考虑70%效率，实际需要：3 ÷ 0.7 ≈ 4.29 GOPS</li>
                        </ol>
                        <p><strong>答案：最小算力需求为3 GOPS，考虑效率后需要4.29 GOPS的峰值性能。</strong></p>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目1.7：</strong>编程题：用Python实现一个简单的脉动阵列模拟器，计算两个4x4矩阵的乘法。要求展示数据在阵列中的流动过程。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
import numpy as np

class SystolicArray:
    def __init__(self, size=4):
        self.size = size
        self.array = [[{'a': 0, 'b': 0, 'c': 0} for _ in range(size)] for _ in range(size)]
        self.cycle = 0
        
    def reset(self):
        """重置脉动阵列"""
        self.array = [[{'a': 0, 'b': 0, 'c': 0} for _ in range(size)] for _ in range(size)]
        self.cycle = 0
    
    def step(self, a_inputs, b_inputs):
        """执行一个时钟周期"""
        # 创建新的阵列状态
        new_array = [[{'a': 0, 'b': 0, 'c': 0} for _ in range(self.size)] for _ in range(self.size)]
        
        # 更新每个PE
        for i in range(self.size):
            for j in range(self.size):
                # 获取输入
                if j == 0:
                    a_in = a_inputs[i] if i < len(a_inputs) else 0
                else:
                    a_in = self.array[i][j-1]['a']
                    
                if i == 0:
                    b_in = b_inputs[j] if j < len(b_inputs) else 0
                else:
                    b_in = self.array[i-1][j]['b']
                
                # 计算MAC
                new_array[i][j]['c'] = self.array[i][j]['c'] + a_in * b_in
                
                # 传递数据
                new_array[i][j]['a'] = a_in
                new_array[i][j]['b'] = b_in
        
        self.array = new_array
        self.cycle += 1
        
    def get_result(self):
        """获取计算结果"""
        result = np.zeros((self.size, self.size))
        for i in range(self.size):
            for j in range(self.size):
                result[i][j] = self.array[i][j]['c']
        return result
    
    def print_state(self):
        """打印当前状态"""
        print(f"\n周期 {self.cycle}:")
        for i in range(self.size):
            for j in range(self.size):
                pe = self.array[i][j]
                print(f"({pe['a']},{pe['b']},{pe['c']:3})", end=" ")
            print()

# 使用示例
def matrix_multiply_systolic(A, B):
    """使用脉动阵列计算矩阵乘法"""
    size = len(A)
    sa = SystolicArray(size)
    
    # 准备输入数据（需要错开时序）
    a_streams = []
    b_streams = []
    
    for i in range(size):
        # A矩阵的行需要错开输入
        a_stream = [0] * i + list(A[i]) + [0] * (size - 1)
        a_streams.append(a_stream)
        
        # B矩阵的列需要错开输入
        b_stream = [0] * i + [B[j][i] for j in range(size)] + [0] * (size - 1)
        b_streams.append(b_stream)
    
    # 执行计算
    max_cycles = 3 * size - 2  # 完成计算需要的周期数
    
    for cycle in range(max_cycles):
        # 准备这个周期的输入
        a_inputs = []
        b_inputs = []
        
        for i in range(size):
            if cycle < len(a_streams[i]):
                a_inputs.append(a_streams[i][cycle])
            else:
                a_inputs.append(0)
                
            if cycle < len(b_streams[i]):
                b_inputs.append(b_streams[i][cycle])
            else:
                b_inputs.append(0)
        
        sa.step(a_inputs[:size], b_inputs[:size])
        sa.print_state()
    
    return sa.get_result()

# 测试
if __name__ == "__main__":
    A = np.array([[1, 2, 3, 4],
                  [5, 6, 7, 8],
                  [9, 10, 11, 12],
                  [13, 14, 15, 16]])
    
    B = np.array([[1, 0, 0, 0],
                  [0, 1, 0, 0],
                  [0, 0, 1, 0],
                  [0, 0, 0, 1]])
    
    print("矩阵A:")
    print(A)
    print("\n矩阵B:")
    print(B)
    
    result = matrix_multiply_systolic(A, B)
    print("\n脉动阵列计算结果:")
    print(result)
    
    print("\nNumPy验证结果:")
    print(np.matmul(A, B))
                        </div>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目1.8：</strong>分析题：为什么大多数NPU采用INT8而不是FP32进行推理？从硬件实现角度分析其优势。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p>NPU采用INT8进行推理的硬件优势：</p>
                        <ol>
                            <li><strong>硬件面积：</strong>
                                <ul>
                                    <li>INT8乘法器面积约为FP32的1/8</li>
                                    <li>INT8加法器面积约为FP32的1/4</li>
                                    <li>相同面积可集成4-8倍的计算单元</li>
                                </ul>
                            </li>
                            <li><strong>功耗效率：</strong>
                                <ul>
                                    <li>INT8运算功耗约为FP32的1/4</li>
                                    <li>数据位宽减少，总线功耗降低75%</li>
                                </ul>
                            </li>
                            <li><strong>内存带宽：</strong>
                                <ul>
                                    <li>数据量减少4倍，缓解内存瓶颈</li>
                                    <li>片上缓存可存储更多数据</li>
                                </ul>
                            </li>
                            <li><strong>时序优化：</strong>
                                <ul>
                                    <li>INT8运算延迟更低，便于提高主频</li>
                                    <li>流水线级数减少，控制逻辑简化</li>
                                </ul>
                            </li>
                        </ol>
                        <p><strong>实际应用中通过量化感知训练，INT8精度损失通常小于1%，是性能功耗比的最佳选择。</strong></p>
                    </div>
                </div>
            </div>
        </div>

        <div id="chapter2" class="chapter">
            <h2>第2章：神经网络计算基础</h2>
            
            <h3>2.1 神经网络基本运算</h3>
            
            <h4>2.1.1 神经元计算模型</h4>
            <p>神经元是神经网络的基本计算单元，其数学模型为：</p>
            <div class="code-block">
y = f(Σ(wi * xi) + b)

其中：
- wi * xi：加权输入 (Weighted Input)
- Σ(...)：求和 (Summation)  
- b：偏置 (Bias)
- f(...)：激活函数 (Activation Function)
            </div>
            
            <div class="info-box">
                <p><strong>硬件视角：</strong>神经元的核心运算是乘累加（MAC），这是NPU设计的基础。一个神经元的计算可以分解为：</p>
                <ol>
                    <li>多个乘法运算：wi * xi</li>
                    <li>累加运算：Σ(wi * xi)</li>
                    <li>加偏置：+ b</li>
                    <li>激活函数：f(...)</li>
                </ol>
            </div>

            <h4>2.1.2 激活函数的硬件实现</h4>
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>激活函数</th>
                            <th>公式</th>
                            <th>硬件实现方式</th>
                            <th>硬件成本</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>ReLU</td>
                            <td>max(0, x)</td>
                            <td>比较器 + 选择器</td>
                            <td>极低</td>
                        </tr>
                        <tr>
                            <td>Leaky ReLU</td>
                            <td>max(αx, x)</td>
                            <td>乘法器 + 比较器 + 选择器</td>
                            <td>低</td>
                        </tr>
                        <tr>
                            <td>Sigmoid</td>
                            <td>1/(1+e^(-x))</td>
                            <td>查找表(LUT) / 分段线性逼近</td>
                            <td>高</td>
                        </tr>
                        <tr>
                            <td>Tanh</td>
                            <td>(e^x - e^(-x))/(e^x + e^(-x))</td>
                            <td>查找表(LUT) / 分段线性逼近</td>
                            <td>高</td>
                        </tr>
                        <tr>
                            <td>GeLU</td>
                            <td>x * Φ(x)</td>
                            <td>多级查找表 + 插值</td>
                            <td>很高</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h3>2.2 矩阵乘法与卷积运算</h3>
            
            <h4>2.2.1 通用矩阵乘法（GEMM）</h4>
            <p>全连接层的本质是矩阵乘法：<code>Y = XW + B</code></p>
            
            <div class="code-block">
// 矩阵乘法的基本实现
for (int i = 0; i < M; i++) {
    for (int j = 0; j < N; j++) {
        float sum = 0;
        for (int k = 0; k < K; k++) {
            sum += A[i][k] * B[k][j];  // MAC运算
        }
        C[i][j] = sum;
    }
}

// 硬件视角的优化考虑：
// 1. 内层循环是MAC运算，适合并行化
// 2. 数据复用：A的每一行被复用N次，B的每一列被复用M次
// 3. 访存模式：顺序访问A，跳跃访问B（缓存不友好）
            </div>

            <h4>2.2.2 卷积运算的实现方式</h4>
            
            <div class="warning-box">
                <p><strong>核心挑战：</strong>卷积运算涉及多维数据和复杂的访存模式，如何高效地映射到硬件是NPU设计的关键。</p>
            </div>

            <p><strong>方法1：Im2Col + GEMM</strong></p>
            <div class="code-block">
// Im2Col转换示例
// 输入: [H, W, C_in]
// 卷积核: [K_h, K_w, C_in, C_out]
// 输出: [H_out, W_out, C_out]

// Step 1: Im2Col展开
// 将每个卷积窗口展开成一列
// 展开后矩阵大小: [K_h * K_w * C_in, H_out * W_out]

// Step 2: 矩阵乘法
// 权重矩阵: [C_out, K_h * K_w * C_in]
// 结果 = 权重矩阵 × Im2Col矩阵

// 优点：可以复用高效的GEMM硬件
// 缺点：内存开销大，数据冗余严重
            </div>

            <p><strong>方法2：直接卷积</strong></p>
            <div class="code-block">
// 直接卷积的硬件实现
module ConvolutionEngine #(
    parameter IN_WIDTH = 8,
    parameter WEIGHT_WIDTH = 8,
    parameter OUT_WIDTH = 32
)(
    input clk,
    input rst_n,
    input [IN_WIDTH-1:0] pixel_in,
    input [WEIGHT_WIDTH-1:0] weight,
    input valid_in,
    output [OUT_WIDTH-1:0] conv_out,
    output valid_out
);
    // Line Buffer用于缓存输入行
    // Window Buffer用于提取卷积窗口
    // MAC阵列执行并行乘累加
endmodule
            </div>

            <h3>2.3 数据流与并行计算</h3>
            
            <h4>2.3.1 数据流架构</h4>
            <p>NPU的数据流设计决定了如何在计算单元间移动和复用数据，直接影响性能和功耗。</p>
            
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>数据流类型</th>
                            <th>固定数据</th>
                            <th>移动数据</th>
                            <th>优势</th>
                            <th>适用场景</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>权重固定(WS)</td>
                            <td>权重</td>
                            <td>输入、部分和</td>
                            <td>权重复用率高</td>
                            <td>权重大、批处理小</td>
                        </tr>
                        <tr>
                            <td>输出固定(OS)</td>
                            <td>部分和</td>
                            <td>权重、输入</td>
                            <td>减少部分和读写</td>
                            <td>输出通道多</td>
                        </tr>
                        <tr>
                            <td>输入固定(IS)</td>
                            <td>输入</td>
                            <td>权重、部分和</td>
                            <td>输入复用率高</td>
                            <td>输入大、权重小</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h4>2.3.2 并行计算维度</h4>
            <div class="code-block">
// 卷积运算的7个循环维度
for (n = 0; n < N; n++)         // Batch
  for (k = 0; k < K; k++)       // 输出通道
    for (c = 0; c < C; c++)     // 输入通道
      for (y = 0; y < Y; y++)   // 输出高度
        for (x = 0; x < X; x++) // 输出宽度
          for (fy = 0; fy < FY; fy++)   // 卷积核高度
            for (fx = 0; fx < FX; fx++) // 卷积核宽度
              out[n][k][y][x] += in[n][c][y+fy][x+fx] * w[k][c][fy][fx]

// NPU可以选择在不同维度上并行化：
// 1. 空间并行：在Y、X维度展开
// 2. 通道并行：在K、C维度展开
// 3. 批处理并行：在N维度展开
            </div>

            <h3>2.4 量化与数据格式</h3>
            
            <h4>2.4.1 量化原理</h4>
            <p>量化是将高精度浮点数转换为低精度定点数的过程，是NPU提升效率的关键技术。</p>
            
            <div class="code-block">
// 对称量化
int8_value = round(fp32_value / scale)
fp32_value = int8_value * scale

// 非对称量化
int8_value = round(fp32_value / scale) + zero_point
fp32_value = (int8_value - zero_point) * scale

// 量化参数计算
scale = (max_val - min_val) / (2^bits - 1)
zero_point = round(-min_val / scale)
            </div>

            <h4>2.4.2 不同精度的硬件开销对比</h4>
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>数据类型</th>
                            <th>位宽</th>
                            <th>乘法器面积</th>
                            <th>加法器面积</th>
                            <th>功耗比例</th>
                            <th>内存带宽</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>FP32</td>
                            <td>32-bit</td>
                            <td>1.0x</td>
                            <td>1.0x</td>
                            <td>1.0x</td>
                            <td>1.0x</td>
                        </tr>
                        <tr>
                            <td>FP16</td>
                            <td>16-bit</td>
                            <td>~0.25x</td>
                            <td>~0.5x</td>
                            <td>~0.4x</td>
                            <td>0.5x</td>
                        </tr>
                        <tr>
                            <td>INT8</td>
                            <td>8-bit</td>
                            <td>~0.125x</td>
                            <td>~0.25x</td>
                            <td>~0.25x</td>
                            <td>0.25x</td>
                        </tr>
                        <tr>
                            <td>INT4</td>
                            <td>4-bit</td>
                            <td>~0.06x</td>
                            <td>~0.125x</td>
                            <td>~0.1x</td>
                            <td>0.125x</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <div class="exercise">
                <h4>练习题集 2</h4>
                
                <div class="question">
                    <p><strong>题目2.1：</strong>某NPU的MAC阵列大小为32×32，计算一个[512, 1024] × [1024, 2048]的矩阵乘法需要多少个计算周期？假设每个周期可以完成阵列大小的MAC运算。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p>矩阵分块计算：</p>
                        <ol>
                            <li>结果矩阵大小：[512, 2048]</li>
                            <li>总MAC运算次数：512 × 1024 × 2048 = 1,073,741,824</li>
                            <li>MAC阵列每周期运算次数：32 × 32 = 1,024</li>
                            <li>分块数量：
                                <ul>
                                    <li>M维度分块：⌈512/32⌉ = 16</li>
                                    <li>N维度分块：⌈2048/32⌉ = 64</li>
                                    <li>K维度分块：⌈1024/32⌉ = 32</li>
                                </ul>
                            </li>
                            <li>总周期数：16 × 64 × 32 = 32,768 周期</li>
                        </ol>
                        <p><strong>验证：</strong>32,768 × 1,024 = 33,554,432 ≈ 1,073,741,824 / 32（考虑边界填充）</p>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目2.2：</strong>设计一个支持ReLU和Sigmoid激活函数的硬件模块。对于Sigmoid，使用4段分段线性逼近。给出RTL设计框架。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module ActivationUnit #(
    parameter DATA_WIDTH = 16,
    parameter FRAC_WIDTH = 8
)(
    input wire clk,
    input wire rst_n,
    input wire [DATA_WIDTH-1:0] data_in,
    input wire [1:0] act_type,  // 00: bypass, 01: ReLU, 10: Sigmoid
    input wire valid_in,
    output reg [DATA_WIDTH-1:0] data_out,
    output reg valid_out
);

    // Sigmoid分段线性逼近参数（4段）
    // 区间: [-8, -2.5], [-2.5, 0], [0, 2.5], [2.5, 8]
    localparam signed [DATA_WIDTH-1:0] SIGMOID_X1 = -16'd2048;  // -8 (Q8.8)
    localparam signed [DATA_WIDTH-1:0] SIGMOID_X2 = -16'd640;   // -2.5
    localparam signed [DATA_WIDTH-1:0] SIGMOID_X3 = 16'd0;      // 0
    localparam signed [DATA_WIDTH-1:0] SIGMOID_X4 = 16'd640;    // 2.5
    localparam signed [DATA_WIDTH-1:0] SIGMOID_X5 = 16'd2048;   // 8
    
    // 斜率和截距（根据Sigmoid曲线拟合得出）
    localparam [DATA_WIDTH-1:0] SLOPE1 = 16'd13;    // 0.05
    localparam [DATA_WIDTH-1:0] SLOPE2 = 16'd51;    // 0.2
    localparam [DATA_WIDTH-1:0] SLOPE3 = 16'd64;    // 0.25
    localparam [DATA_WIDTH-1:0] SLOPE4 = 16'd51;    // 0.2
    
    wire signed [DATA_WIDTH-1:0] data_in_signed;
    reg [DATA_WIDTH-1:0] relu_out;
    reg [DATA_WIDTH-1:0] sigmoid_out;
    reg [2*DATA_WIDTH-1:0] mult_result;
    
    assign data_in_signed = data_in;
    
    // ReLU实现
    always @(*) begin
        if (data_in_signed < 0)
            relu_out = 0;
        else
            relu_out = data_in;
    end
    
    // Sigmoid分段线性逼近
    always @(*) begin
        if (data_in_signed <= SIGMOID_X1) begin
            sigmoid_out = 16'd0;  // 0
        end else if (data_in_signed <= SIGMOID_X2) begin
            mult_result = (data_in_signed - SIGMOID_X1) * SLOPE1;
            sigmoid_out = mult_result[DATA_WIDTH+FRAC_WIDTH-1:FRAC_WIDTH];
        end else if (data_in_signed <= SIGMOID_X3) begin
            mult_result = (data_in_signed - SIGMOID_X2) * SLOPE2;
            sigmoid_out = 16'd26 + mult_result[DATA_WIDTH+FRAC_WIDTH-1:FRAC_WIDTH];  // 0.1 + ...
        end else if (data_in_signed <= SIGMOID_X4) begin
            mult_result = data_in_signed * SLOPE3;
            sigmoid_out = 16'd128 + mult_result[DATA_WIDTH+FRAC_WIDTH-1:FRAC_WIDTH];  // 0.5 + ...
        end else if (data_in_signed <= SIGMOID_X5) begin
            mult_result = (data_in_signed - SIGMOID_X4) * SLOPE4;
            sigmoid_out = 16'd230 + mult_result[DATA_WIDTH+FRAC_WIDTH-1:FRAC_WIDTH];  // 0.9 + ...
        end else begin
            sigmoid_out = 16'd256;  // 1.0
        end
    end
    
    // 输出选择
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            data_out <= 0;
            valid_out <= 0;
        end else if (valid_in) begin
            case (act_type)
                2'b00: data_out <= data_in;      // Bypass
                2'b01: data_out <= relu_out;     // ReLU
                2'b10: data_out <= sigmoid_out;  // Sigmoid
                default: data_out <= data_in;
            endcase
            valid_out <= 1;
        end else begin
            valid_out <= 0;
        end
    end
endmodule
                        </div>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目2.3：</strong>比较Im2Col+GEMM和直接卷积两种实现方式。对于一个输入[224,224,3]、卷积核[3,3,3,64]的卷积层，计算Im2Col的内存开销。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p><strong>1. Im2Col内存开销计算：</strong></p>
                        <ol>
                            <li>输出特征图大小（假设stride=1, padding=1）：[224, 224, 64]</li>
                            <li>Im2Col展开后每个位置：3×3×3 = 27个元素</li>
                            <li>总位置数：224×224 = 50,176</li>
                            <li>Im2Col矩阵大小：[27, 50,176]</li>
                            <li>内存占用（FP32）：27 × 50,176 × 4 bytes = 5.42 MB</li>
                            <li>原始输入大小：224 × 224 × 3 × 4 bytes = 0.60 MB</li>
                            <li><strong>内存扩展比例：9.0倍</strong></li>
                        </ol>
                        
                        <p><strong>2. 两种方式对比：</strong></p>
                        <table>
                            <tr>
                                <th>特性</th>
                                <th>Im2Col + GEMM</th>
                                <th>直接卷积</th>
                            </tr>
                            <tr>
                                <td>内存开销</td>
                                <td>高（9倍扩展）</td>
                                <td>低（仅需Line Buffer）</td>
                            </tr>
                            <tr>
                                <td>计算效率</td>
                                <td>高（复用GEMM优化）</td>
                                <td>中等</td>
                            </tr>
                            <tr>
                                <td>硬件复杂度</td>
                                <td>简单（复用GEMM单元）</td>
                                <td>复杂（需要专用控制）</td>
                            </tr>
                            <tr>
                                <td>适用场景</td>
                                <td>大卷积核、服务器端</td>
                                <td>小卷积核、边缘设备</td>
                            </tr>
                        </table>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目2.4：</strong>设计一个简单的脉动阵列数据流控制器，支持权重固定（Weight Stationary）模式。要求能够处理8×8的MAC阵列。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module WeightStationaryController #(
    parameter ARRAY_SIZE = 8,
    parameter DATA_WIDTH = 8,
    parameter ADDR_WIDTH = 16
)(
    input wire clk,
    input wire rst_n,
    input wire start,
    
    // 配置接口
    input wire [ADDR_WIDTH-1:0] input_base_addr,
    input wire [ADDR_WIDTH-1:0] weight_base_addr,
    input wire [ADDR_WIDTH-1:0] output_base_addr,
    input wire [15:0] M, N, K,  // 矩阵维度
    
    // SRAM接口
    output reg [ADDR_WIDTH-1:0] input_addr,
    output reg input_rd_en,
    input wire [DATA_WIDTH*ARRAY_SIZE-1:0] input_data,
    
    output reg [ADDR_WIDTH-1:0] weight_addr,
    output reg weight_rd_en,
    input wire [DATA_WIDTH*ARRAY_SIZE-1:0] weight_data,
    
    output reg [ADDR_WIDTH-1:0] output_addr,
    output reg output_wr_en,
    output reg [DATA_WIDTH*ARRAY_SIZE-1:0] output_data,
    
    // MAC阵列接口
    output reg [DATA_WIDTH-1:0] input_to_array [0:ARRAY_SIZE-1],
    output reg [DATA_WIDTH-1:0] weight_to_array [0:ARRAY_SIZE-1][0:ARRAY_SIZE-1],
    output reg weight_load,
    output reg compute_en,
    input wire [DATA_WIDTH-1:0] output_from_array [0:ARRAY_SIZE-1],
    
    // 状态输出
    output reg busy,
    output reg done
);

    // 状态机定义
    localparam IDLE = 3'd0;
    localparam LOAD_WEIGHT = 3'd1;
    localparam COMPUTE = 3'd2;
    localparam STORE_OUTPUT = 3'd3;
    localparam NEXT_TILE = 3'd4;
    
    reg [2:0] state, next_state;
    reg [15:0] tile_m, tile_n, tile_k;  // 当前处理的分块索引
    reg [15:0] cycle_cnt;                // 周期计数器
    reg [15:0] k_iter;                   // K维度迭代计数
    
    // 计算分块数量
    wire [15:0] num_tile_m = (M + ARRAY_SIZE - 1) / ARRAY_SIZE;
    wire [15:0] num_tile_n = (N + ARRAY_SIZE - 1) / ARRAY_SIZE;
    wire [15:0] num_tile_k = (K + ARRAY_SIZE - 1) / ARRAY_SIZE;
    
    // 状态机
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n)
            state <= IDLE;
        else
            state <= next_state;
    end
    
    // 状态转换逻辑
    always @(*) begin
        next_state = state;
        case (state)
            IDLE: begin
                if (start)
                    next_state = LOAD_WEIGHT;
            end
            
            LOAD_WEIGHT: begin
                if (cycle_cnt == ARRAY_SIZE - 1)
                    next_state = COMPUTE;
            end
            
            COMPUTE: begin
                if (k_iter == K - 1)
                    next_state = STORE_OUTPUT;
            end
            
            STORE_OUTPUT: begin
                if (cycle_cnt == ARRAY_SIZE - 1)
                    next_state = NEXT_TILE;
            end
            
            NEXT_TILE: begin
                if (tile_n == num_tile_n - 1 && 
                    tile_m == num_tile_m - 1)
                    next_state = IDLE;
                else
                    next_state = LOAD_WEIGHT;
            end
        endcase
    end
    
    // 控制逻辑
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            tile_m <= 0;
            tile_n <= 0;
            tile_k <= 0;
            cycle_cnt <= 0;
            k_iter <= 0;
            weight_load <= 0;
            compute_en <= 0;
            busy <= 0;
            done <= 0;
        end else begin
            case (state)
                IDLE: begin
                    if (start) begin
                        tile_m <= 0;
                        tile_n <= 0;
                        tile_k <= 0;
                        busy <= 1;
                        done <= 0;
                    end
                end
                
                LOAD_WEIGHT: begin
                    // 加载权重到阵列
                    weight_load <= 1;
                    weight_rd_en <= 1;
                    weight_addr <= weight_base_addr + 
                                  (tile_n * ARRAY_SIZE + cycle_cnt) * K + 
                                  tile_k * ARRAY_SIZE;
                    
                    // 将权重数据分配到阵列
                    for (int i = 0; i < ARRAY_SIZE; i++) begin
                        for (int j = 0; j < ARRAY_SIZE; j++) begin
                            weight_to_array[i][j] <= weight_data[j*DATA_WIDTH +: DATA_WIDTH];
                        end
                    end
                    
                    cycle_cnt <= cycle_cnt + 1;
                    if (cycle_cnt == ARRAY_SIZE - 1) begin
                        cycle_cnt <= 0;
                        weight_load <= 0;
                        weight_rd_en <= 0;
                    end
                end
                
                COMPUTE: begin
                    // 启动计算
                    compute_en <= 1;
                    input_rd_en <= 1;
                    
                    // 读取输入数据
                    input_addr <= input_base_addr + 
                                 (tile_m * ARRAY_SIZE) * K + 
                                 k_iter;
                    
                    // 将输入数据送入阵列
                    for (int i = 0; i < ARRAY_SIZE; i++) begin
                        input_to_array[i] <= input_data[i*DATA_WIDTH +: DATA_WIDTH];
                    end
                    
                    k_iter <= k_iter + 1;
                    if (k_iter == K - 1) begin
                        k_iter <= 0;
                        compute_en <= 0;
                        input_rd_en <= 0;
                    end
                end
                
                STORE_OUTPUT: begin
                    // 存储输出结果
                    output_wr_en <= 1;
                    output_addr <= output_base_addr + 
                                  (tile_m * ARRAY_SIZE + cycle_cnt) * N + 
                                  tile_n * ARRAY_SIZE;
                    
                    // 从阵列收集输出
                    for (int i = 0; i < ARRAY_SIZE; i++) begin
                        output_data[i*DATA_WIDTH +: DATA_WIDTH] <= output_from_array[i];
                    end
                    
                    cycle_cnt <= cycle_cnt + 1;
                    if (cycle_cnt == ARRAY_SIZE - 1) begin
                        cycle_cnt <= 0;
                        output_wr_en <= 0;
                    end
                end
                
                NEXT_TILE: begin
                    // 移动到下一个分块
                    if (tile_n < num_tile_n - 1) begin
                        tile_n <= tile_n + 1;
                    end else begin
                        tile_n <= 0;
                        tile_m <= tile_m + 1;
                    end
                    
                    if (tile_n == num_tile_n - 1 && 
                        tile_m == num_tile_m - 1) begin
                        busy <= 0;
                        done <= 1;
                    end
                end
            endcase
        end
    end
endmodule
                        </div>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目2.5：</strong>分析深度可分离卷积（Depthwise Separable Convolution）的计算特点，说明为什么它对NPU的内存带宽要求更高。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p><strong>深度可分离卷积分解为两步：</strong></p>
                        <ol>
                            <li><strong>Depthwise Convolution：</strong>每个输入通道独立卷积
                                <ul>
                                    <li>计算量：H×W×C×K×K</li>
                                    <li>参数量：C×K×K</li>
                                </ul>
                            </li>
                            <li><strong>Pointwise Convolution (1×1卷积)：</strong>跨通道混合
                                <ul>
                                    <li>计算量：H×W×C×M</li>
                                    <li>参数量：C×M</li>
                                </ul>
                            </li>
                        </ol>
                        
                        <p><strong>计算强度分析（Compute-to-Memory Ratio）：</strong></p>
                        <table>
                            <tr>
                                <th>卷积类型</th>
                                <th>计算量</th>
                                <th>内存访问量</th>
                                <th>计算强度</th>
                            </tr>
                            <tr>
                                <td>标准卷积</td>
                                <td>H×W×C×M×K×K</td>
                                <td>H×W×(C+M) + C×M×K×K</td>
                                <td>O(K×K)</td>
                            </tr>
                            <tr>
                                <td>Depthwise</td>
                                <td>H×W×C×K×K</td>
                                <td>H×W×C×2 + C×K×K</td>
                                <td>O(1)</td>
                            </tr>
                            <tr>
                                <td>Pointwise</td>
                                <td>H×W×C×M</td>
                                <td>H×W×(C+M) + C×M</td>
                                <td>O(1)</td>
                            </tr>
                        </table>
                        
                        <p><strong>为什么内存带宽要求更高：</strong></p>
                        <ol>
                            <li><strong>计算强度低：</strong>Depthwise卷积的计算强度为O(1)，而标准卷积为O(K²)。这意味着每次内存访问只能支撑很少的计算。</li>
                            <li><strong>数据复用率低：</strong>
                                <ul>
                                    <li>标准卷积中，每个输入被M个输出通道复用</li>
                                    <li>Depthwise中，每个输入只被1个输出通道使用</li>
                                </ul>
                            </li>
                            <li><strong>Memory Bound：</strong>NPU的计算单元经常处于空闲状态，等待数据从内存加载。</li>
                        </ol>
                        
                        <p><strong>优化策略：</strong></p>
                        <ul>
                            <li>增加片上缓存容量</li>
                            <li>使用更宽的内存接口</li>
                            <li>将Depthwise和Pointwise融合执行，减少中间结果的存储</li>
                            <li>使用专门的DMA引擎进行数据预取</li>
                        </ul>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目2.6：</strong>实现一个简单的INT8量化模块，支持对称量化和非对称量化两种模式。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module Quantizer #(
    parameter IN_WIDTH = 32,    // FP32输入
    parameter OUT_WIDTH = 8,    // INT8输出
    parameter SCALE_WIDTH = 16  // 定点scale表示
)(
    input wire clk,
    input wire rst_n,
    input wire [IN_WIDTH-1:0] fp_in,      // 浮点输入
    input wire [SCALE_WIDTH-1:0] scale,   // 量化尺度
    input wire [OUT_WIDTH-1:0] zero_point,// 零点（非对称量化）
    input wire symmetric_mode,            // 0: 非对称, 1: 对称
    input wire valid_in,
    
    output reg signed [OUT_WIDTH-1:0] int_out,  // 量化输出
    output reg valid_out
);

    // 内部信号
    reg [IN_WIDTH+SCALE_WIDTH-1:0] scaled_value;
    reg signed [IN_WIDTH-1:0] rounded_value;
    reg signed [IN_WIDTH-1:0] shifted_value;
    wire signed [OUT_WIDTH-1:0] saturated_value;
    
    // 饱和边界
    localparam signed [IN_WIDTH-1:0] MAX_INT8 = 127;
    localparam signed [IN_WIDTH-1:0] MIN_INT8 = -128;
    
    // Step 1: 缩放
    always @(*) begin
        // 假设scale是定点表示 (Q8.8格式)
        // 实际硬件中需要浮点转定点单元
        scaled_value = fp_in * scale;
    end
    
    // Step 2: 四舍五入
    always @(*) begin
        // 简化的四舍五入：加0.5后截断
        rounded_value = scaled_value[IN_WIDTH+SCALE_WIDTH-1:SCALE_WIDTH] + 
                       (scaled_value[SCALE_WIDTH-1] ? 1 : 0);
    end
    
    // Step 3: 加零点（非对称量化）
    always @(*) begin
        if (symmetric_mode)
            shifted_value = rounded_value;
        else
            shifted_value = rounded_value + {{(IN_WIDTH-OUT_WIDTH){1'b0}}, zero_point};
    end
    
    // Step 4: 饱和处理
    assign saturated_value = (shifted_value > MAX_INT8) ? MAX_INT8 :
                            (shifted_value < MIN_INT8) ? MIN_INT8 :
                            shifted_value[OUT_WIDTH-1:0];
    
    // 输出寄存
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            int_out <= 0;
            valid_out <= 0;
        end else if (valid_in) begin
            int_out <= saturated_value;
            valid_out <= 1;
        end else begin
            valid_out <= 0;
        end
    end
endmodule

// 反量化模块
module Dequantizer #(
    parameter IN_WIDTH = 8,     // INT8输入
    parameter OUT_WIDTH = 32,   // FP32输出
    parameter SCALE_WIDTH = 16
)(
    input wire clk,
    input wire rst_n,
    input wire signed [IN_WIDTH-1:0] int_in,
    input wire [SCALE_WIDTH-1:0] scale,
    input wire [IN_WIDTH-1:0] zero_point,
    input wire symmetric_mode,
    input wire valid_in,
    
    output reg [OUT_WIDTH-1:0] fp_out,
    output reg valid_out
);

    // 内部信号
    reg signed [OUT_WIDTH-1:0] shifted_value;
    reg [OUT_WIDTH+SCALE_WIDTH-1:0] scaled_value;
    
    // Step 1: 减去零点
    always @(*) begin
        if (symmetric_mode)
            shifted_value = {{(OUT_WIDTH-IN_WIDTH){int_in[IN_WIDTH-1]}}, int_in};
        else
            shifted_value = {{(OUT_WIDTH-IN_WIDTH){int_in[IN_WIDTH-1]}}, int_in} - 
                           {{(OUT_WIDTH-IN_WIDTH){1'b0}}, zero_point};
    end
    
    // Step 2: 乘以scale
    always @(*) begin
        scaled_value = shifted_value * scale;
    end
    
    // 输出寄存
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            fp_out <= 0;
            valid_out <= 0;
        end else if (valid_in) begin
            // 提取定点结果的整数部分
            fp_out <= scaled_value[OUT_WIDTH+SCALE_WIDTH-1:SCALE_WIDTH];
            valid_out <= 1;
        end else begin
            valid_out <= 0;
        end
    end
endmodule
                        </div>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目2.7：</strong>计算并比较不同批处理大小（batch size）对NPU效率的影响。假设处理一个ResNet50的第一个卷积层，输入[N,224,224,3]，卷积核[7,7,3,64]。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p><strong>不同batch size的影响分析：</strong></p>
                        
                        <table>
                            <tr>
                                <th>Batch Size</th>
                                <th>计算量(GFLOPs)</th>
                                <th>内存占用(MB)</th>
                                <th>并行度</th>
                                <th>数据复用率</th>
                            </tr>
                            <tr>
                                <td>1</td>
                                <td>0.118</td>
                                <td>输入: 0.6<br>输出: 3.2</td>
                                <td>低</td>
                                <td>权重复用率: 1x</td>
                            </tr>
                            <tr>
                                <td>8</td>
                                <td>0.944</td>
                                <td>输入: 4.8<br>输出: 25.6</td>
                                <td>中</td>
                                <td>权重复用率: 8x</td>
                            </tr>
                            <tr>
                                <td>32</td>
                                <td>3.776</td>
                                <td>输入: 19.2<br>输出: 102.4</td>
                                <td>高</td>
                                <td>权重复用率: 32x</td>
                            </tr>
                            <tr>
                                <td>128</td>
                                <td>15.104</td>
                                <td>输入: 76.8<br>输出: 409.6</td>
                                <td>很高</td>
                                <td>权重复用率: 128x</td>
                            </tr>
                        </table>
                        
                        <p><strong>计算过程：</strong></p>
                        <ol>
                            <li>输出大小：(224-7+2*3)/2+1 = 112，即[N,112,112,64]</li>
                            <li>每个输出像素的计算量：7×7×3×2 = 294 FLOPs</li>
                            <li>总计算量：N×112×112×64×294</li>
                        </ol>
                        
                        <p><strong>NPU效率影响：</strong></p>
                        <ol>
                            <li><strong>小batch size (1-8)：</strong>
                                <ul>
                                    <li>权重复用率低，需要频繁重新加载权重</li>
                                    <li>MAC阵列利用率低，很多PE空闲</li>
                                    <li>适合边缘设备，响应延迟低</li>
                                </ul>
                            </li>
                            <li><strong>中等batch size (16-32)：</strong>
                                <ul>
                                    <li>权重复用率适中</li>
                                    <li>MAC阵列利用率较好</li>
                                    <li>内存占用在可接受范围</li>
                                </ul>
                            </li>
                            <li><strong>大batch size (64-128)：</strong>
                                <ul>
                                    <li>权重复用率高，摊销权重加载开销</li>
                                    <li>MAC阵列充分利用</li>
                                    <li>可能受限于片上SRAM容量</li>
                                    <li>适合云端训练场景</li>
                                </ul>
                            </li>
                        </ol>
                        
                        <p><strong>优化建议：</strong></p>
                        <ul>
                            <li>边缘NPU：优化batch=1的性能，采用权重固定数据流</li>
                            <li>云端NPU：支持大batch，增加片上SRAM容量</li>
                            <li>动态批处理：根据负载自适应调整batch size</li>
                        </ul>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目2.8：</strong>设计一个简单的稀疏计算单元，能够跳过零值计算。给出零检测和地址生成的RTL框架。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module SparseComputeUnit #(
    parameter DATA_WIDTH = 8,
    parameter ADDR_WIDTH = 16,
    parameter PE_NUM = 16       // 并行PE数量
)(
    input wire clk,
    input wire rst_n,
    
    // 输入数据和索引
    input wire [DATA_WIDTH-1:0] activation_data [0:PE_NUM-1],
    input wire [DATA_WIDTH-1:0] weight_data [0:PE_NUM-1],
    input wire [PE_NUM-1:0] activation_valid,  // 非零标志
    input wire [PE_NUM-1:0] weight_valid,      // 非零标志
    input wire data_valid,
    
    // 稀疏索引
    input wire [ADDR_WIDTH-1:0] activation_indices [0:PE_NUM-1],
    input wire [ADDR_WIDTH-1:0] weight_indices [0:PE_NUM-1],
    
    // 输出接口
    output reg [2*DATA_WIDTH-1:0] result_data [0:PE_NUM-1],
    output reg [ADDR_WIDTH-1:0] result_indices [0:PE_NUM-1],
    output reg [PE_NUM-1:0] result_valid,
    output reg output_valid
);

    // 内部信号
    reg [PE_NUM-1:0] compute_mask;
    wire [2*DATA_WIDTH-1:0] mult_results [0:PE_NUM-1];
    reg [4:0] valid_count;
    reg [4:0] compact_indices [0:PE_NUM-1];
    
    // 生成计算掩码（只有当激活值和权重都非零时才计算）
    always @(*) begin
        compute_mask = activation_valid & weight_valid;
    end
    
    // 并行乘法器
    genvar i;
    generate
        for (i = 0; i < PE_NUM; i = i + 1) begin : mult_gen
            assign mult_results[i] = activation_data[i] * weight_data[i];
        end
    endgenerate
    
    // 计算有效结果数量
    always @(*) begin
        valid_count = 0;
        for (int j = 0; j < PE_NUM; j = j + 1) begin
            if (compute_mask[j])
                valid_count = valid_count + 1;
        end
    end
    
    // 压缩有效结果（去除零值结果）
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            output_valid <= 0;
            result_valid <= 0;
        end else if (data_valid) begin
            int compact_idx = 0;
            
            // 压缩非零结果
            for (int j = 0; j < PE_NUM; j = j + 1) begin
                if (compute_mask[j]) begin
                    result_data[compact_idx] <= mult_results[j];
                    result_indices[compact_idx] <= activation_indices[j];
                    result_valid[compact_idx] <= 1'b1;
                    compact_idx = compact_idx + 1;
                end
            end
            
            // 清空未使用的输出
            for (int j = compact_idx; j < PE_NUM; j = j + 1) begin
                result_data[j] <= 0;
                result_indices[j] <= 0;
                result_valid[j] <= 1'b0;
            end
            
            output_valid <= 1;
        end else begin
            output_valid <= 0;
        end
    end
endmodule

// 稀疏数据加载器
module SparseDataLoader #(
    parameter DATA_WIDTH = 8,
    parameter ADDR_WIDTH = 16,
    parameter SPARSE_FORMAT = "CSR"  // CSR或COO格式
)(
    input wire clk,
    input wire rst_n,
    
    // 内存接口
    output reg [ADDR_WIDTH-1:0] mem_addr,
    output reg mem_rd_en,
    input wire [31:0] mem_data,
    
    // 稀疏数据输出
    output reg [DATA_WIDTH-1:0] value_out,
    output reg [ADDR_WIDTH-1:0] row_idx_out,
    output reg [ADDR_WIDTH-1:0] col_idx_out,
    output reg data_valid_out,
    
    // 控制接口
    input wire start,
    input wire [ADDR_WIDTH-1:0] base_addr,
    input wire [15:0] nnz,  // 非零元素数量
    output reg done
);

    // CSR格式存储结构
    // values[nnz]: 非零值数组
    // col_indices[nnz]: 列索引数组
    // row_ptrs[rows+1]: 行指针数组
    
    reg [15:0] element_cnt;
    reg [2:0] load_state;
    
    localparam IDLE = 3'd0;
    localparam LOAD_VALUE = 3'd1;
    localparam LOAD_COL_IDX = 3'd2;
    localparam OUTPUT = 3'd3;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            load_state <= IDLE;
            element_cnt <= 0;
            done <= 0;
            mem_rd_en <= 0;
            data_valid_out <= 0;
        end else begin
            case (load_state)
                IDLE: begin
                    if (start) begin
                        element_cnt <= 0;
                        load_state <= LOAD_VALUE;
                        done <= 0;
                    end
                end
                
                LOAD_VALUE: begin
                    mem_rd_en <= 1;
                    mem_addr <= base_addr + element_cnt;
                    load_state <= LOAD_COL_IDX;
                end
                
                LOAD_COL_IDX: begin
                    value_out <= mem_data[DATA_WIDTH-1:0];
                    mem_addr <= base_addr + nnz + element_cnt;
                    load_state <= OUTPUT;
                end
                
                OUTPUT: begin
                    col_idx_out <= mem_data[ADDR_WIDTH-1:0];
                    data_valid_out <= 1;
                    mem_rd_en <= 0;
                    
                    element_cnt <= element_cnt + 1;
                    if (element_cnt == nnz - 1) begin
                        load_state <= IDLE;
                        done <= 1;
                    end else begin
                        load_state <= LOAD_VALUE;
                    end
                end
            endcase
        end
    end
endmodule
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div id="chapter3" class="chapter">
            <h2>第3章：NPU系统架构</h2>
            
            <h3>3.1 整体架构设计</h3>
            
            <h4>3.1.1 NPU系统组成</h4>
            <p>现代NPU系统通常包含以下核心组件：</p>
            
            <div class="code-block">
NPU系统架构层次：
┌─────────────────────────────────────────┐
│          Host Interface (PCIe/AXI)       │
├─────────────────────────────────────────┤
│         Command Processor & Scheduler    │
├─────────────────────────────────────────┤
│  ┌─────────┐  ┌─────────┐  ┌─────────┐ │
│  │ Compute │  │ Memory  │  │  DMA    │ │
│  │ Cluster │  │ System  │  │ Engine  │ │
│  └─────────┘  └─────────┘  └─────────┘ │
├─────────────────────────────────────────┤
│         On-chip Interconnect (NoC)      │
├─────────────────────────────────────────┤
│         External Memory Interface        │
└─────────────────────────────────────────┘
            </div>

            <h4>3.1.2 设计考虑因素</h4>
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>设计维度</th>
                            <th>关键指标</th>
                            <th>架构影响</th>
                            <th>优化方向</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>算力</td>
                            <td>TOPS/TFLOPS</td>
                            <td>MAC阵列规模</td>
                            <td>增加PE数量、提高频率</td>
                        </tr>
                        <tr>
                            <td>能效</td>
                            <td>TOPS/W</td>
                            <td>数据复用、电压调节</td>
                            <td>减少数据移动、低功耗设计</td>
                        </tr>
                        <tr>
                            <td>灵活性</td>
                            <td>支持的算子类型</td>
                            <td>可编程性</td>
                            <td>VLIW/SIMD混合架构</td>
                        </tr>
                        <tr>
                            <td>成本</td>
                            <td>$/TOPS</td>
                            <td>芯片面积</td>
                            <td>架构简化、工艺选择</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h3>3.2 计算单元设计</h3>
            
            <h4>3.2.1 计算集群架构</h4>
            <p>NPU的计算能力主要来自于大规模并行的计算集群：</p>
            
            <div class="code-block">
// 典型的计算集群组织
Compute Cluster
├── MAC Array (脉动阵列或其他拓扑)
│   ├── PE[0][0] ... PE[0][N-1]
│   ├── PE[1][0] ... PE[1][N-1]
│   └── PE[M-1][0] ... PE[M-1][N-1]
├── Vector Unit (向量处理单元)
│   ├── SIMD ALU
│   ├── Special Function Unit
│   └── Reduction Unit
├── Local Memory
│   ├── Weight Buffer
│   ├── Input Buffer
│   └── Output Buffer
└── Control Unit
    ├── Instruction Decoder
    ├── Address Generator
    └── Synchronization Logic
            </div>

            <h4>3.2.2 处理单元(PE)设计</h4>
            <div class="info-box">
                <p><strong>PE设计原则：</strong></p>
                <ul>
                    <li>面积效率：最大化MAC密度</li>
                    <li>功耗优化：时钟门控、操作数隔离</li>
                    <li>数据通路：支持多种精度(INT8/16, FP16/32)</li>
                    <li>流水线：平衡延迟和吞吐量</li>
                </ul>
            </div>

            <h3>3.3 存储层次结构</h3>
            
            <h4>3.3.1 存储层次设计</h4>
            <div class="code-block">
存储层次（从快到慢）：
1. Register File (RF)
   - 容量: ~1KB per PE
   - 延迟: 1 cycle
   - 带宽: 极高
   
2. L1 Buffer (私有)
   - 容量: 16-64KB per cluster
   - 延迟: 2-4 cycles
   - 用途: 权重/激活值缓存

3. L2 Buffer (共享)
   - 容量: 256KB-2MB
   - 延迟: 8-16 cycles
   - 用途: 跨cluster数据共享

4. Global Buffer
   - 容量: 4-32MB
   - 延迟: 20-40 cycles
   - 用途: 大型特征图存储

5. External Memory (DDR/HBM)
   - 容量: GB级别
   - 延迟: 100+ cycles
   - 带宽: 受限（关键瓶颈）
            </div>

            <h4>3.3.2 内存访问优化</h4>
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>优化技术</th>
                            <th>原理</th>
                            <th>硬件支持</th>
                            <th>效果</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>数据预取</td>
                            <td>提前加载数据到片上</td>
                            <td>硬件预取器</td>
                            <td>隐藏内存延迟</td>
                        </tr>
                        <tr>
                            <td>双缓冲</td>
                            <td>计算与数据传输重叠</td>
                            <td>乒乓Buffer</td>
                            <td>提高利用率</td>
                        </tr>
                        <tr>
                            <td>数据压缩</td>
                            <td>减少传输数据量</td>
                            <td>压缩/解压单元</td>
                            <td>节省带宽</td>
                        </tr>
                        <tr>
                            <td>地址映射</td>
                            <td>优化数据布局</td>
                            <td>可编程DMA</td>
                            <td>提高局部性</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h3>3.4 互连网络设计</h3>
            
            <h4>3.4.1 片上网络拓扑</h4>
            <div class="code-block">
常见的NoC拓扑结构：

1. Mesh (网格)
   优点：规则、可扩展
   缺点：跳数多、延迟大
   
   [R]--[R]--[R]--[R]
    |    |    |    |
   [R]--[R]--[R]--[R]
    |    |    |    |
   [R]--[R]--[R]--[R]

2. Torus (环面)
   优点：降低平均跳数
   缺点：布线复杂
   
3. Tree (树形)
   优点：层次化、易于广播
   缺点：根节点瓶颈

4. Crossbar (交叉开关)
   优点：单跳连接
   缺点：面积O(N²)，不可扩展
            </div>

            <h4>3.4.2 数据通信模式</h4>
            <p>NPU中的典型通信模式：</p>
            <ul>
                <li><strong>单播(Unicast)：</strong>点对点数据传输</li>
                <li><strong>多播(Multicast)：</strong>权重广播到多个PE</li>
                <li><strong>归约(Reduction)：</strong>部分和累加</li>
                <li><strong>全局同步：</strong>barrier同步</li>
            </ul>

            <div class="warning-box">
                <p><strong>设计挑战：</strong>如何在保证高带宽的同时控制功耗和面积开销是NoC设计的核心挑战。</p>
            </div>

            <div class="exercise">
                <h4>练习题集 3</h4>
                
                <div class="question">
                    <p><strong>题目3.1：</strong>设计一个NPU的存储层次结构。给定：MAC阵列32×32，主频1GHz，外部内存带宽100GB/s。计算各级存储的容量和带宽需求。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p><strong>1. 计算MAC阵列带宽需求：</strong></p>
                        <ul>
                            <li>MAC阵列规模：32×32 = 1024个MAC</li>
                            <li>每个MAC每周期需要：2个输入(weight, activation) + 1个输出</li>
                            <li>假设INT8精度：每个数据1字节</li>
                            <li>总带宽需求：1024 × 3 × 1B × 1GHz = 3.072 TB/s</li>
                        </ul>
                        
                        <p><strong>2. 存储层次设计：</strong></p>
                        <table>
                            <tr>
                                <th>存储级别</th>
                                <th>容量</th>
                                <th>带宽</th>
                                <th>设计理由</th>
                            </tr>
                            <tr>
                                <td>L0 (Register)</td>
                                <td>1KB/PE</td>
                                <td>3TB/s</td>
                                <td>直接供给MAC运算</td>
                            </tr>
                            <tr>
                                <td>L1 Buffer</td>
                                <td>64KB</td>
                                <td>1TB/s</td>
                                <td>存储当前tile的数据</td>
                            </tr>
                            <tr>
                                <td>L2 Buffer</td>
                                <td>2MB</td>
                                <td>400GB/s</td>
                                <td>预取下一个tile</td>
                            </tr>
                            <tr>
                                <td>Global Buffer</td>
                                <td>16MB</td>
                                <td>200GB/s</td>
                                <td>存储整层的部分数据</td>
                            </tr>
                            <tr>
                                <td>External Mem</td>
                                <td>16GB</td>
                                <td>100GB/s</td>
                                <td>给定约束</td>
                            </tr>
                        </table>
                        
                        <p><strong>3. 带宽逐级递减原理：</strong></p>
                        <ul>
                            <li>数据复用降低上级需求</li>
                            <li>时分复用共享带宽</li>
                            <li>预取隐藏延迟</li>
                        </ul>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目3.2：</strong>比较Weight Stationary、Output Stationary和Row Stationary三种数据流的优缺点，并给出适用场景。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <table>
                            <tr>
                                <th>数据流</th>
                                <th>固定数据</th>
                                <th>优点</th>
                                <th>缺点</th>
                                <th>适用场景</th>
                            </tr>
                            <tr>
                                <td>Weight Stationary (WS)</td>
                                <td>权重</td>
                                <td>• 权重复用最大化<br>• 减少权重读取能耗<br>• 实现简单</td>
                                <td>• 输入/输出需要大量移动<br>• 对大feature map不友好</td>
                                <td>• 全连接层<br>• 小batch推理<br>• 权重>>激活值</td>
                            </tr>
                            <tr>
                                <td>Output Stationary (OS)</td>
                                <td>部分和</td>
                                <td>• 减少部分和读写<br>• 累加在PE本地完成<br>• 适合深度网络</td>
                                <td>• 权重和输入都需移动<br>• 控制复杂度高</td>
                                <td>• 深度卷积<br>• 输出通道数多<br>• ResNet类结构</td>
                            </tr>
                            <tr>
                                <td>Row Stationary (RS)</td>
                                <td>卷积行</td>
                                <td>• 所有数据类型都有复用<br>• 能量效率最优<br>• 适应性强</td>
                                <td>• 实现最复杂<br>• 需要复杂的控制器<br>• 面积开销大</td>
                                <td>• 通用场景<br>• 各种卷积层<br>• 需要灵活性</td>
                            </tr>
                        </table>
                        
                        <p><strong>具体例子：</strong></p>
                        <p>对于1×1卷积（Pointwise）：</p>
                        <ul>
                            <li>WS最优：因为没有空间维度的复用</li>
                            <li>RS退化为WS</li>
                        </ul>
                        <p>对于3×3卷积：</p>
                        <ul>
                            <li>RS最优：可以复用所有维度的数据</li>
                            <li>OS次优：如果输出通道很多</li>
                        </ul>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目3.3：</strong>设计一个4×4 Mesh NoC的路由器。要求支持XY路由算法，包含5个端口（东南西北+本地）。给出RTL框架。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module MeshRouter #(
    parameter DATA_WIDTH = 32,
    parameter ADDR_WIDTH = 8,
    parameter X_COORD = 0,
    parameter Y_COORD = 0,
    parameter FIFO_DEPTH = 4
)(
    input wire clk,
    input wire rst_n,
    
    // 5个输入端口 (North, South, East, West, Local)
    input wire [DATA_WIDTH-1:0] data_in_n, data_in_s, data_in_e, data_in_w, data_in_l,
    input wire valid_in_n, valid_in_s, valid_in_e, valid_in_w, valid_in_l,
    output wire ready_out_n, ready_out_s, ready_out_e, ready_out_w, ready_out_l,
    
    // 5个输出端口
    output wire [DATA_WIDTH-1:0] data_out_n, data_out_s, data_out_e, data_out_w, data_out_l,
    output wire valid_out_n, valid_out_s, valid_out_e, valid_out_w, valid_out_l,
    input wire ready_in_n, ready_in_s, ready_in_e, ready_in_w, ready_in_l
);

    // 数据包格式：[DATA | SRC_Y | SRC_X | DST_Y | DST_X]
    localparam DST_X_START = 0;
    localparam DST_X_END = 3;
    localparam DST_Y_START = 4;
    localparam DST_Y_END = 7;
    
    // 内部信号
    wire [4:0] route_req_n, route_req_s, route_req_e, route_req_w, route_req_l;
    wire [4:0] grant_n, grant_s, grant_e, grant_w, grant_l;
    
    // 输入FIFO
    wire [DATA_WIDTH-1:0] fifo_data_n, fifo_data_s, fifo_data_e, fifo_data_w, fifo_data_l;
    wire fifo_empty_n, fifo_empty_s, fifo_empty_e, fifo_empty_w, fifo_empty_l;
    wire fifo_rd_en_n, fifo_rd_en_s, fifo_rd_en_e, fifo_rd_en_w, fifo_rd_en_l;
    
    // FIFO实例化（每个输入端口一个）
    genvar i;
    generate
        // North port FIFO
        FIFO #(.WIDTH(DATA_WIDTH), .DEPTH(FIFO_DEPTH)) fifo_n (
            .clk(clk), .rst_n(rst_n),
            .wr_en(valid_in_n), .wr_data(data_in_n),
            .rd_en(fifo_rd_en_n), .rd_data(fifo_data_n),
            .empty(fifo_empty_n), .full(~ready_out_n)
        );
        // 类似地实例化其他4个FIFO...
    endgenerate
    
    // XY路由计算模块
    XYRouteCompute route_comp_n (
        .current_x(X_COORD), .current_y(Y_COORD),
        .dest_x(fifo_data_n[DST_X_END:DST_X_START]),
        .dest_y(fifo_data_n[DST_Y_END:DST_Y_START]),
        .valid(!fifo_empty_n),
        .route_request(route_req_n)  // 5-bit one-hot
    );
    // 为其他端口实例化路由计算...
    
    // 5×5交叉开关仲裁器
    SwitchAllocator allocator (
        .clk(clk), .rst_n(rst_n),
        // 来自5个输入端口的请求
        .req_n(route_req_n), .req_s(route_req_s), 
        .req_e(route_req_e), .req_w(route_req_w), .req_l(route_req_l),
        // 授权信号
        .grant_n(grant_n), .grant_s(grant_s),
        .grant_e(grant_e), .grant_w(grant_w), .grant_l(grant_l)
    );
    
    // 交叉开关矩阵
    Crossbar5x5 xbar (
        // 输入数据
        .data_in({fifo_data_l, fifo_data_w, fifo_data_e, fifo_data_s, fifo_data_n}),
        // 控制信号
        .sel_n(grant_n), .sel_s(grant_s), 
        .sel_e(grant_e), .sel_w(grant_w), .sel_l(grant_l),
        // 输出数据
        .data_out_n(data_out_n), .data_out_s(data_out_s),
        .data_out_e(data_out_e), .data_out_w(data_out_w), .data_out_l(data_out_l)
    );
    
    // 输出valid信号生成
    assign valid_out_n = |grant_n & ready_in_n;
    assign valid_out_s = |grant_s & ready_in_s;
    assign valid_out_e = |grant_e & ready_in_e;
    assign valid_out_w = |grant_w & ready_in_w;
    assign valid_out_l = |grant_l & ready_in_l;
    
    // FIFO读使能
    assign fifo_rd_en_n = |(grant_n & {ready_in_l, ready_in_w, ready_in_e, ready_in_s, ready_in_n});
    // 类似处理其他端口...

endmodule

// XY路由计算模块
module XYRouteCompute #(
    parameter COORD_WIDTH = 4
)(
    input [COORD_WIDTH-1:0] current_x, current_y,
    input [COORD_WIDTH-1:0] dest_x, dest_y,
    input valid,
    output reg [4:0] route_request  // [Local, West, East, South, North]
);
    always @(*) begin
        route_request = 5'b00000;
        if (valid) begin
            if (dest_x == current_x && dest_y == current_y) begin
                route_request[4] = 1'b1;  // Local
            end else if (dest_x < current_x) begin
                route_request[3] = 1'b1;  // West
            end else if (dest_x > current_x) begin
                route_request[2] = 1'b1;  // East
            end else if (dest_y < current_y) begin
                route_request[1] = 1'b1;  // South
            end else begin
                route_request[0] = 1'b1;  // North
            end
        end
    end
endmodule
                        </div>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目3.4：</strong>计算一个NPU执行ResNet50一个残差块所需的片上存储容量。假设特征图大小为56×56×256，使用3×3卷积。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p><strong>ResNet50残差块结构：</strong></p>
                        <pre>
Input (56×56×256)
    │
    ├─────────────────────┐
    │                     │
    ▼                     │
Conv1 (1×1, 64)          │
    │                     │
    ▼                     │
Conv2 (3×3, 64)          │
    │                     │
    ▼                     │
Conv3 (1×1, 256)         │
    │                     │
    ▼                     │
    + ←──────────────────┘
    │
Output (56×56×256)
                        </pre>
                        
                        <p><strong>存储需求计算（INT8）：</strong></p>
                        <table>
                            <tr>
                                <th>数据类型</th>
                                <th>尺寸</th>
                                <th>容量(KB)</th>
                                <th>说明</th>
                            </tr>
                            <tr>
                                <td>输入特征图</td>
                                <td>56×56×256</td>
                                <td>784</td>
                                <td>需要保存用于残差连接</td>
                            </tr>
                            <tr>
                                <td>Conv1权重</td>
                                <td>1×1×256×64</td>
                                <td>16</td>
                                <td>Pointwise卷积</td>
                            </tr>
                            <tr>
                                <td>Conv1输出</td>
                                <td>56×56×64</td>
                                <td>196</td>
                                <td>中间特征图</td>
                            </tr>
                            <tr>
                                <td>Conv2权重</td>
                                <td>3×3×64×64</td>
                                <td>36</td>
                                <td>Depthwise卷积</td>
                            </tr>
                            <tr>
                                <td>Conv2输出</td>
                                <td>56×56×64</td>
                                <td>196</td>
                                <td>中间特征图</td>
                            </tr>
                            <tr>
                                <td>Conv3权重</td>
                                <td>1×1×64×256</td>
                                <td>16</td>
                                <td>Pointwise卷积</td>
                            </tr>
                            <tr>
                                <td>Conv3输出</td>
                                <td>56×56×256</td>
                                <td>784</td>
                                <td>用于残差加法</td>
                            </tr>
                            <tr>
                                <td><strong>总计</strong></td>
                                <td>-</td>
                                <td><strong>2028</strong></td>
                                <td>约2MB</td>
                            </tr>
                        </table>
                        
                        <p><strong>优化策略：</strong></p>
                        <ol>
                            <li><strong>层融合：</strong>将Conv1输出直接送入Conv2，节省196KB</li>
                            <li><strong>流水线执行：</strong>分块处理，每块只需存储部分特征图</li>
                            <li><strong>权重压缩：</strong>使用稀疏或量化技术减少权重存储</li>
                            <li><strong>双缓冲：</strong>计算当前块时预取下一块数据</li>
                        </ol>
                        
                        <p><strong>实际需求：</strong>考虑优化后，片上存储约需1MB即可高效执行。</p>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目3.5：</strong>设计一个DMA控制器，支持2D数据传输和简单的数据重排。要求支持stride访问模式。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module DMA2D #(
    parameter ADDR_WIDTH = 32,
    parameter DATA_WIDTH = 128,  // 128-bit宽接口
    parameter BURST_LEN = 16     // 最大突发长度
)(
    input wire clk,
    input wire rst_n,
    
    // 配置接口
    input wire [ADDR_WIDTH-1:0] src_addr,      // 源地址
    input wire [ADDR_WIDTH-1:0] dst_addr,      // 目标地址
    input wire [15:0] width,                   // 2D传输宽度（字节）
    input wire [15:0] height,                  // 2D传输高度
    input wire [15:0] src_stride,              // 源跨步（字节）
    input wire [15:0] dst_stride,              // 目标跨步（字节）
    input wire [2:0] transfer_mode,            // 传输模式
    input wire start,
    output reg done,
    output reg busy,
    
    // 源内存接口（AXI-like）
    output reg [ADDR_WIDTH-1:0] src_araddr,
    output reg src_arvalid,
    input wire src_arready,
    input wire [DATA_WIDTH-1:0] src_rdata,
    input wire src_rvalid,
    output reg src_rready,
    
    // 目标内存接口
    output reg [ADDR_WIDTH-1:0] dst_awaddr,
    output reg dst_awvalid,
    input wire dst_awready,
    output reg [DATA_WIDTH-1:0] dst_wdata,
    output reg dst_wvalid,
    input wire dst_wready,
    input wire dst_bvalid,
    output reg dst_bready
);

    // 传输模式定义
    localparam MODE_LINEAR = 3'd0;      // 线性传输
    localparam MODE_2D_BLOCK = 3'd1;    // 2D块传输
    localparam MODE_TRANSPOSE = 3'd2;   // 转置
    localparam MODE_INTERLEAVE = 3'd3;  // 交织
    
    // 状态机
    localparam IDLE = 3'd0;
    localparam CALC_ADDR = 3'd1;
    localparam READ_REQ = 3'd2;
    localparam READ_DATA = 3'd3;
    localparam WRITE_REQ = 3'd4;
    localparam WRITE_DATA = 3'd5;
    localparam WRITE_RESP = 3'd6;
    localparam NEXT_LINE = 3'd7;
    
    reg [2:0] state, next_state;
    
    // 内部计数器
    reg [15:0] row_cnt, col_cnt;
    reg [15:0] burst_cnt;
    reg [ADDR_WIDTH-1:0] current_src_addr, current_dst_addr;
    
    // 数据缓冲（支持突发传输）
    reg [DATA_WIDTH-1:0] data_buffer [0:BURST_LEN-1];
    reg [4:0] buffer_wr_ptr, buffer_rd_ptr;
    reg [4:0] buffer_count;
    
    // 地址计算单元
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            current_src_addr <= 0;
            current_dst_addr <= 0;
        end else if (state == CALC_ADDR) begin
            case (transfer_mode)
                MODE_LINEAR: begin
                    current_src_addr <= src_addr + (row_cnt * src_stride) + col_cnt;
                    current_dst_addr <= dst_addr + (row_cnt * dst_stride) + col_cnt;
                end
                MODE_2D_BLOCK: begin
                    current_src_addr <= src_addr + (row_cnt * src_stride) + col_cnt;
                    current_dst_addr <= dst_addr + (row_cnt * dst_stride) + col_cnt;
                end
                MODE_TRANSPOSE: begin
                    // 转置：源按行读，目标按列写
                    current_src_addr <= src_addr + (row_cnt * src_stride) + col_cnt;
                    current_dst_addr <= dst_addr + (col_cnt * dst_stride) + row_cnt * (DATA_WIDTH/8);
                end
                MODE_INTERLEAVE: begin
                    // 交织模式：用于通道重排
                    // 实现NCHW -> NHWC转换等
                    current_src_addr <= src_addr + calculate_interleave_src(row_cnt, col_cnt);
                    current_dst_addr <= dst_addr + calculate_interleave_dst(row_cnt, col_cnt);
                end
            endcase
        end
    end
    
    // 状态机控制
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n)
            state <= IDLE;
        else
            state <= next_state;
    end
    
    always @(*) begin
        next_state = state;
        case (state)
            IDLE: begin
                if (start)
                    next_state = CALC_ADDR;
            end
            
            CALC_ADDR: begin
                next_state = READ_REQ;
            end
            
            READ_REQ: begin
                if (src_arready)
                    next_state = READ_DATA;
            end
            
            READ_DATA: begin
                if (src_rvalid && burst_cnt == calculate_burst_len() - 1)
                    next_state = WRITE_REQ;
            end
            
            WRITE_REQ: begin
                if (dst_awready)
                    next_state = WRITE_DATA;
            end
            
            WRITE_DATA: begin
                if (dst_wready && buffer_rd_ptr == buffer_wr_ptr - 1)
                    next_state = WRITE_RESP;
            end
            
            WRITE_RESP: begin
                if (dst_bvalid)
                    next_state = NEXT_LINE;
            end
            
            NEXT_LINE: begin
                if (row_cnt == height - 1 && col_cnt >= width - (DATA_WIDTH/8))
                    next_state = IDLE;
                else
                    next_state = CALC_ADDR;
            end
        endcase
    end
    
    // 数据路径控制
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            row_cnt <= 0;
            col_cnt <= 0;
            burst_cnt <= 0;
            buffer_wr_ptr <= 0;
            buffer_rd_ptr <= 0;
            done <= 0;
            busy <= 0;
        end else begin
            case (state)
                IDLE: begin
                    done <= 0;
                    if (start) begin
                        row_cnt <= 0;
                        col_cnt <= 0;
                        busy <= 1;
                    end
                end
                
                READ_DATA: begin
                    if (src_rvalid) begin
                        data_buffer[buffer_wr_ptr] <= apply_transform(src_rdata);
                        buffer_wr_ptr <= buffer_wr_ptr + 1;
                        burst_cnt <= burst_cnt + 1;
                    end
                end
                
                WRITE_DATA: begin
                    if (dst_wready) begin
                        buffer_rd_ptr <= buffer_rd_ptr + 1;
                    end
                end
                
                NEXT_LINE: begin
                    col_cnt <= col_cnt + (DATA_WIDTH/8) * calculate_burst_len();
                    if (col_cnt >= width - (DATA_WIDTH/8)) begin
                        col_cnt <= 0;
                        row_cnt <= row_cnt + 1;
                        if (row_cnt == height - 1) begin
                            done <= 1;
                            busy <= 0;
                        end
                    end
                    burst_cnt <= 0;
                    buffer_wr_ptr <= 0;
                    buffer_rd_ptr <= 0;
                end
            endcase
        end
    end
    
    // AXI接口信号
    always @(*) begin
        // 默认值
        src_arvalid = 0;
        src_rready = 0;
        dst_awvalid = 0;
        dst_wvalid = 0;
        dst_bready = 0;
        
        case (state)
            READ_REQ: begin
                src_araddr = current_src_addr;
                src_arvalid = 1;
            end
            
            READ_DATA: begin
                src_rready = 1;
            end
            
            WRITE_REQ: begin
                dst_awaddr = current_dst_addr;
                dst_awvalid = 1;
            end
            
            WRITE_DATA: begin
                dst_wdata = data_buffer[buffer_rd_ptr];
                dst_wvalid = 1;
            end
            
            WRITE_RESP: begin
                dst_bready = 1;
            end
        endcase
    end
    
    // 辅助函数
    function [4:0] calculate_burst_len;
        begin
            // 根据剩余数据量计算突发长度
            if (width - col_cnt >= BURST_LEN * (DATA_WIDTH/8))
                calculate_burst_len = BURST_LEN;
            else
                calculate_burst_len = (width - col_cnt) / (DATA_WIDTH/8);
        end
    endfunction
    
    function [DATA_WIDTH-1:0] apply_transform;
        input [DATA_WIDTH-1:0] data;
        begin
            // 根据模式应用数据变换（如字节序转换等）
            case (transfer_mode)
                MODE_LINEAR, MODE_2D_BLOCK: 
                    apply_transform = data;
                MODE_TRANSPOSE:
                    apply_transform = transpose_bytes(data);
                MODE_INTERLEAVE:
                    apply_transform = interleave_channels(data);
                default:
                    apply_transform = data;
            endcase
        end
    endfunction

endmodule
                        </div>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目3.6：</strong>分析Tensor Core架构相比传统MAC阵列的优势，并计算其理论性能提升。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p><strong>1. 架构对比：</strong></p>
                        <table>
                            <tr>
                                <th>特性</th>
                                <th>传统MAC阵列</th>
                                <th>Tensor Core</th>
                            </tr>
                            <tr>
                                <td>基本运算</td>
                                <td>标量MAC: c += a × b</td>
                                <td>矩阵MAC: D = A×B + C</td>
                            </tr>
                            <tr>
                                <td>运算粒度</td>
                                <td>1×1</td>
                                <td>4×4×4 (或更大)</td>
                            </tr>
                            <tr>
                                <td>每周期运算量</td>
                                <td>2 ops (乘+加)</td>
                                <td>128 ops (4×4×4×2)</td>
                            </tr>
                            <tr>
                                <td>数据复用</td>
                                <td>有限</td>
                                <td>矩阵级复用</td>
                            </tr>
                        </table>
                        
                        <p><strong>2. Tensor Core工作原理：</strong></p>
                        <div class="code-block">
// Tensor Core执行的运算
D[4×4] = A[4×4] × B[4×4] + C[4×4]

// 分解为标量运算：
for i in 0..3:
    for j in 0..3:
        sum = 0
        for k in 0..3:
            sum += A[i][k] * B[k][j]
        D[i][j] = sum + C[i][j]

// 总运算数：4×4×4 = 64次乘法，48次加法，16次加法
// 共128 ops
                        </div>
                        
                        <p><strong>3. 性能提升计算：</strong></p>
                        <p>假设：</p>
                        <ul>
                            <li>传统MAC阵列：16×16 = 256个MAC单元</li>
                            <li>Tensor Core阵列：4×4 = 16个Tensor Core</li>
                            <li>相同的总硬件面积</li>
                        </ul>
                        
                        <p>性能对比：</p>
                        <ul>
                            <li>传统MAC：256 × 2 = 512 ops/cycle</li>
                            <li>Tensor Core：16 × 128 = 2048 ops/cycle</li>
                            <li><strong>理论加速比：4×</strong></li>
                        </ul>
                        
                        <p><strong>4. 优势分析：</strong></p>
                        <ol>
                            <li><strong>更高的计算密度：</strong>相同面积下提供更多运算</li>
                            <li><strong>更好的数据复用：</strong>矩阵运算天然具有数据复用</li>
                            <li><strong>减少控制开销：</strong>一条指令完成更多运算</li>
                            <li><strong>更适合深度学习：</strong>直接匹配GEMM运算模式</li>
                        </ol>
                        
                        <p><strong>5. 限制条件：</strong></p>
                        <ul>
                            <li>需要对齐到4×4块大小</li>
                            <li>不适合稀疏或不规则运算</li>
                            <li>精度限制（通常是混合精度）</li>
                            <li>编程模型相对复杂</li>
                        </ul>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目3.7：</strong>设计一个简单的NPU指令集架构(ISA)，包含计算、数据传输和控制指令。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p><strong>NPU ISA设计：</strong></p>
                        
                        <p><strong>1. 指令格式（32-bit）：</strong></p>
                        <div class="code-block">
[31:28] | [27:24] | [23:16] | [15:8] | [7:0]
OPCODE  | FLAGS   | DEST    | SRC1   | SRC2/IMM

OPCODE: 4-bit 操作码
FLAGS:  4-bit 标志位（精度、饱和模式等）
DEST:   8-bit 目标寄存器/地址
SRC1:   8-bit 源操作数1
SRC2:   8-bit 源操作数2或立即数
                        </div>
                        
                        <p><strong>2. 指令集分类：</strong></p>
                        
                        <p><strong>A. 计算指令：</strong></p>
                        <table>
                            <tr>
                                <th>助记符</th>
                                <th>操作码</th>
                                <th>功能</th>
                                <th>示例</th>
                            </tr>
                            <tr>
                                <td>MMUL</td>
                                <td>0x0</td>
                                <td>矩阵乘法</td>
                                <td>MMUL R0, M1, M2</td>
                            </tr>
                            <tr>
                                <td>CONV</td>
                                <td>0x1</td>
                                <td>卷积运算</td>
                                <td>CONV R0, I1, W1</td>
                            </tr>
                            <tr>
                                <td>MADD</td>
                                <td>0x2</td>
                                <td>矩阵加法</td>
                                <td>MADD R0, M1, M2</td>
                            </tr>
                            <tr>
                                <td>ACTV</td>
                                <td>0x3</td>
                                <td>激活函数</td>
                                <td>ACTV.RELU R0, R1</td>
                            </tr>
                            <tr>
                                <td>POOL</td>
                                <td>0x4</td>
                                <td>池化操作</td>
                                <td>POOL.MAX R0, I1</td>
                            </tr>
                        </table>
                        
                        <p><strong>B. 数据传输指令：</strong></p>
                        <table>
                            <tr>
                                <th>助记符</th>
                                <th>操作码</th>
                                <th>功能</th>
                                <th>示例</th>
                            </tr>
                            <tr>
                                <td>LOAD</td>
                                <td>0x8</td>
                                <td>从内存加载</td>
                                <td>LOAD R0, [ADDR]</td>
                            </tr>
                            <tr>
                                <td>STORE</td>
                                <td>0x9</td>
                                <td>存储到内存</td>
                                <td>STORE [ADDR], R0</td>
                            </tr>
                            <tr>
                                <td>DMA</td>
                                <td>0xA</td>
                                <td>DMA传输</td>
                                <td>DMA DST, SRC, LEN</td>
                            </tr>
                            <tr>
                                <td>BCAST</td>
                                <td>0xB</td>
                                <td>广播数据</td>
                                <td>BCAST R0, VAL</td>
                            </tr>
                        </table>
                        
                        <p><strong>C. 控制指令：</strong></p>
                        <table>
                            <tr>
                                <th>助记符</th>
                                <th>操作码</th>
                                <th>功能</th>
                                <th>示例</th>
                            </tr>
                            <tr>
                                <td>SYNC</td>
                                <td>0xC</td>
                                <td>同步屏障</td>
                                <td>SYNC</td>
                            </tr>
                            <tr>
                                <td>LOOP</td>
                                <td>0xD</td>
                                <td>循环控制</td>
                                <td>LOOP CNT, LABEL</td>
                            </tr>
                            <tr>
                                <td>JUMP</td>
                                <td>0xE</td>
                                <td>跳转</td>
                                <td>JUMP LABEL</td>
                            </tr>
                            <tr>
                                <td>HALT</td>
                                <td>0xF</td>
                                <td>停止执行</td>
                                <td>HALT</td>
                            </tr>
                        </table>
                        
                        <p><strong>3. 寄存器组织：</strong></p>
                        <div class="code-block">
// 通用寄存器
R0-R31: 32个通用寄存器（标量）
M0-M15: 16个矩阵寄存器（每个可存储32×32矩阵）
V0-V15: 16个向量寄存器（每个256元素）

// 特殊寄存器
PC:     程序计数器
SP:     栈指针
STATUS: 状态寄存器
CONFIG: 配置寄存器（精度模式等）
                        </div>
                        
                        <p><strong>4. 示例程序（卷积层）：</strong></p>
                        <div class="code-block">
// 执行一个3×3卷积层
// 输入: I0, 权重: W0, 输出: O0

    // 配置卷积参数
    LOAD  R0, #3        // 卷积核大小
    LOAD  R1, #1        // stride
    LOAD  R2, #1        // padding
    
    // 加载数据
    DMA   M0, [input_addr], #input_size
    DMA   M1, [weight_addr], #weight_size
    
    // 执行卷积
    CONV  M2, M0, M1    // 使用配置的参数
    
    // 应用激活函数
    ACTV.RELU M3, M2
    
    // 存储结果
    DMA   [output_addr], M3, #output_size
    
    // 同步确保完成
    SYNC
    HALT
                        </div>
                        
                        <p><strong>5. ISA特点：</strong></p>
                        <ul>
                            <li><strong>CISC风格：</strong>单条指令完成复杂操作</li>
                            <li><strong>数据并行：</strong>原生支持矩阵/向量操作</li>
                            <li><strong>内存层次感知：</strong>显式DMA管理</li>
                            <li><strong>灵活精度：</strong>通过FLAGS支持多精度</li>
                            <li><strong>硬件加速：</strong>直接映射到硬件单元</li>
                        </ul>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目3.8：</strong>评估不同的功耗优化技术对NPU的影响。给定一个100 TOPS的NPU，分析各种技术的节能潜力。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p><strong>基准NPU规格：</strong></p>
                        <ul>
                            <li>峰值性能：100 TOPS (INT8)</li>
                            <li>功耗：50W (2 TOPS/W)</li>
                            <li>工艺：7nm</li>
                            <li>频率：1GHz</li>
                        </ul>
                        
                        <p><strong>功耗优化技术分析：</strong></p>
                        <table>
                            <tr>
                                <th>优化技术</th>
                                <th>原理</th>
                                <th>节能潜力</th>
                                <th>性能影响</th>
                                <th>实现复杂度</th>
                            </tr>
                            <tr>
                                <td>时钟门控</td>
                                <td>关闭空闲单元时钟</td>
                                <td>10-20%</td>
                                <td>无</td>
                                <td>低</td>
                            </tr>
                            <tr>
                                <td>电源门控</td>
                                <td>关闭空闲单元电源</td>
                                <td>20-30%</td>
                                <td>唤醒延迟</td>
                                <td>中</td>
                            </tr>
                            <tr>
                                <td>DVFS</td>
                                <td>动态调节电压频率</td>
                                <td>30-40%</td>
                                <td>性能下降</td>
                                <td>中</td>
                            </tr>
                            <tr>
                                <td>近阈值计算</td>
                                <td>降低工作电压</td>
                                <td>50-70%</td>
                                <td>频率降低</td>
                                <td>高</td>
                            </tr>
                            <tr>
                                <td>数据压缩</td>
                                <td>减少数据传输</td>
                                <td>15-25%</td>
                                <td>轻微</td>
                                <td>中</td>
                            </tr>
                            <tr>
                                <td>稀疏计算</td>
                                <td>跳过零值运算</td>
                                <td>20-60%</td>
                                <td>依赖稀疏度</td>
                                <td>高</td>
                            </tr>
                            <tr>
                                <td>精度缩放</td>
                                <td>动态调整精度</td>
                                <td>25-40%</td>
                                <td>精度损失</td>
                                <td>中</td>
                            </tr>
                        </table>
                        
                        <p><strong>功耗分解（50W总功耗）：</strong></p>
                        <div class="code-block">
计算单元：    20W (40%)
├── MAC阵列： 15W
└── 向量单元： 5W

存储系统：    15W (30%)
├── SRAM：    10W
└── 接口：     5W

互连网络：     8W (16%)

控制逻辑：     4W (8%)

IO接口：       3W (6%)
                        </div>
                        
                        <p><strong>组合优化方案：</strong></p>
                        <ol>
                            <li><strong>方案A（保守型）：</strong>
                                <ul>
                                    <li>时钟门控 + 基础DVFS</li>
                                    <li>预期节能：25%</li>
                                    <li>功耗降至：37.5W</li>
                                    <li>能效提升至：2.67 TOPS/W</li>
                                </ul>
                            </li>
                            <li><strong>方案B（平衡型）：</strong>
                                <ul>
                                    <li>时钟/电源门控 + DVFS + 数据压缩</li>
                                    <li>预期节能：45%</li>
                                    <li>功耗降至：27.5W</li>
                                    <li>能效提升至：3.64 TOPS/W</li>
                                </ul>
                            </li>
                            <li><strong>方案C（激进型）：</strong>
                                <ul>
                                    <li>全部技术组合 + 近阈值计算</li>
                                    <li>预期节能：70%</li>
                                    <li>功耗降至：15W（但性能降至70 TOPS）</li>
                                    <li>能效提升至：4.67 TOPS/W</li>
                                </ul>
                            </li>
                        </ol>
                        
                        <p><strong>实施建议：</strong></p>
                        <ul>
                            <li>优先实施低复杂度高收益技术（时钟门控）</li>
                            <li>根据应用场景选择DVFS策略</li>
                            <li>稀疏计算需要软硬件协同优化</li>
                            <li>考虑功耗-性能-面积(PPA)平衡</li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>

        <div id="chapter4" class="chapter">
            <h2>第4章：计算核心设计</h2>
            
            <h3>4.1 MAC阵列设计</h3>
            
            <h4>4.1.1 基础MAC单元</h4>
            <p>MAC (Multiply-Accumulate) 是NPU的基本计算单元，执行 <code>C = C + A × B</code> 运算。</p>
            
            <div class="code-block">
module MAC_Unit #(
    parameter DATA_WIDTH = 8,      // 输入数据位宽(INT8)
    parameter ACC_WIDTH = 32       // 累加器位宽(防止溢出)
)(
    input wire clk,
    input wire rst_n,
    input wire enable,
    
    // 输入接口
    input wire signed [DATA_WIDTH-1:0] a_in,      // 激活值
    input wire signed [DATA_WIDTH-1:0] b_in,      // 权重
    input wire signed [ACC_WIDTH-1:0] c_in,       // 部分和输入
    
    // 输出接口
    output reg signed [ACC_WIDTH-1:0] c_out,      // 累加结果
    output reg valid_out
);

    // 内部信号
    wire signed [2*DATA_WIDTH-1:0] mult_result;
    wire signed [ACC_WIDTH-1:0] add_result;
    
    // 乘法器
    assign mult_result = a_in * b_in;
    
    // 加法器（扩展乘法结果位宽后相加）
    assign add_result = c_in + {{(ACC_WIDTH-2*DATA_WIDTH){mult_result[2*DATA_WIDTH-1]}}, mult_result};
    
    // 寄存输出
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            c_out <= 0;
            valid_out <= 0;
        end else if (enable) begin
            c_out <= add_result;
            valid_out <= 1;
        end else begin
            valid_out <= 0;
        end
    end
endmodule
            </div>

            <h4>4.1.2 多精度MAC设计</h4>
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>数据类型</th>
                            <th>乘法器面积</th>
                            <th>功耗</th>
                            <th>延迟</th>
                            <th>应用场景</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>INT4</td>
                            <td>16 gates</td>
                            <td>0.1x</td>
                            <td>1 cycle</td>
                            <td>极低功耗推理</td>
                        </tr>
                        <tr>
                            <td>INT8</td>
                            <td>64 gates</td>
                            <td>0.25x</td>
                            <td>1 cycle</td>
                            <td>主流推理</td>
                        </tr>
                        <tr>
                            <td>FP16</td>
                            <td>~400 gates</td>
                            <td>0.4x</td>
                            <td>2 cycles</td>
                            <td>训练/高精度推理</td>
                        </tr>
                        <tr>
                            <td>FP32</td>
                            <td>~1600 gates</td>
                            <td>1.0x</td>
                            <td>3 cycles</td>
                            <td>科学计算/训练</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h4>4.1.3 MAC阵列组织</h4>
            <div class="code-block">
// 二维MAC阵列组织示例 (8x8)
module MAC_Array_8x8 #(
    parameter DATA_WIDTH = 8,
    parameter ACC_WIDTH = 32,
    parameter ARRAY_SIZE = 8
)(
    input wire clk,
    input wire rst_n,
    input wire enable,
    
    // 输入数据广播
    input wire [DATA_WIDTH-1:0] act_broadcast [0:ARRAY_SIZE-1],  // 激活值广播
    input wire [DATA_WIDTH-1:0] weight_array [0:ARRAY_SIZE-1][0:ARRAY_SIZE-1],  // 权重
    
    // 部分和累加
    output wire [ACC_WIDTH-1:0] psum_out [0:ARRAY_SIZE-1][0:ARRAY_SIZE-1]
);

    // MAC单元阵列
    genvar i, j;
    generate
        for (i = 0; i < ARRAY_SIZE; i = i + 1) begin : row
            for (j = 0; j < ARRAY_SIZE; j = j + 1) begin : col
                MAC_Unit #(
                    .DATA_WIDTH(DATA_WIDTH),
                    .ACC_WIDTH(ACC_WIDTH)
                ) mac_inst (
                    .clk(clk),
                    .rst_n(rst_n),
                    .enable(enable),
                    .a_in(act_broadcast[i]),              // 行广播
                    .b_in(weight_array[i][j]),            // 本地权重
                    .c_in(/* 根据数据流选择 */),
                    .c_out(psum_out[i][j])
                );
            end
        end
    endgenerate
endmodule
            </div>

            <h3>4.2 脉动阵列架构</h3>
            
            <h4>4.2.1 脉动阵列原理</h4>
            <p>脉动阵列通过数据在PE间的有节奏流动，实现高效的数据复用和规则的计算模式。</p>
            
            <div class="info-box">
                <p><strong>核心优势：</strong></p>
                <ul>
                    <li>数据复用率高：每个数据被多个PE使用</li>
                    <li>通信局部化：只需要邻近PE间通信</li>
                    <li>控制简单：规则的数据流动模式</li>
                    <li>易于扩展：模块化设计便于增加阵列规模</li>
                </ul>
            </div>

            <h4>4.2.2 Weight Stationary脉动阵列实现</h4>
            <div class="code-block">
// 权重固定型脉动阵列PE
module SystolicPE_WS #(
    parameter DATA_WIDTH = 8,
    parameter ACC_WIDTH = 32
)(
    input wire clk,
    input wire rst_n,
    
    // 控制信号
    input wire weight_load,      // 权重加载使能
    input wire compute_en,       // 计算使能
    
    // 数据输入
    input wire [DATA_WIDTH-1:0] act_in,      // 激活值输入（从上方）
    input wire [DATA_WIDTH-1:0] weight_in,   // 权重输入（加载时）
    input wire [ACC_WIDTH-1:0] psum_in,      // 部分和输入（从左侧）
    
    // 数据输出
    output reg [DATA_WIDTH-1:0] act_out,     // 激活值输出（向下方）
    output reg [ACC_WIDTH-1:0] psum_out      // 部分和输出（向右侧）
);

    // 内部寄存器
    reg [DATA_WIDTH-1:0] weight_reg;         // 存储的权重
    reg [DATA_WIDTH-1:0] act_reg;            // 激活值寄存器
    
    // MAC运算
    wire [2*DATA_WIDTH-1:0] mult_result;
    wire [ACC_WIDTH-1:0] mac_result;
    
    assign mult_result = act_reg * weight_reg;
    assign mac_result = psum_in + {{(ACC_WIDTH-2*DATA_WIDTH){mult_result[2*DATA_WIDTH-1]}}, mult_result};
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            weight_reg <= 0;
            act_reg <= 0;
            act_out <= 0;
            psum_out <= 0;
        end else begin
            // 权重加载
            if (weight_load) begin
                weight_reg <= weight_in;
            end
            
            // 计算模式
            if (compute_en) begin
                // 激活值向下传递
                act_reg <= act_in;
                act_out <= act_reg;
                
                // MAC结果向右传递
                psum_out <= mac_result;
            end
        end
    end
endmodule

// 4x4 Weight Stationary脉动阵列
module SystolicArray_4x4_WS #(
    parameter DATA_WIDTH = 8,
    parameter ACC_WIDTH = 32,
    parameter ARRAY_DIM = 4
)(
    input wire clk,
    input wire rst_n,
    input wire weight_load,
    input wire compute_en,
    
    // 激活值输入（从顶部进入）
    input wire [DATA_WIDTH-1:0] act_in [0:ARRAY_DIM-1],
    
    // 权重加载接口
    input wire [DATA_WIDTH-1:0] weight_in [0:ARRAY_DIM-1][0:ARRAY_DIM-1],
    
    // 结果输出（从右侧输出）
    output wire [ACC_WIDTH-1:0] result_out [0:ARRAY_DIM-1]
);

    // PE间的连接线
    wire [DATA_WIDTH-1:0] act_h [0:ARRAY_DIM][0:ARRAY_DIM-1];  // 垂直连接
    wire [ACC_WIDTH-1:0] psum_h [0:ARRAY_DIM-1][0:ARRAY_DIM];  // 水平连接
    
    // 初始化边界
    genvar i, j;
    generate
        // 左边界部分和为0
        for (i = 0; i < ARRAY_DIM; i = i + 1) begin
            assign psum_h[i][0] = 0;
        end
        
        // 顶部输入激活值
        for (j = 0; j < ARRAY_DIM; j = j + 1) begin
            assign act_h[0][j] = act_in[j];
        end
    endgenerate
    
    // PE阵列实例化
    generate
        for (i = 0; i < ARRAY_DIM; i = i + 1) begin : pe_row
            for (j = 0; j < ARRAY_DIM; j = j + 1) begin : pe_col
                SystolicPE_WS #(
                    .DATA_WIDTH(DATA_WIDTH),
                    .ACC_WIDTH(ACC_WIDTH)
                ) pe_inst (
                    .clk(clk),
                    .rst_n(rst_n),
                    .weight_load(weight_load),
                    .compute_en(compute_en),
                    .act_in(act_h[i][j]),
                    .weight_in(weight_in[i][j]),
                    .psum_in(psum_h[i][j]),
                    .act_out(act_h[i+1][j]),
                    .psum_out(psum_h[i][j+1])
                );
            end
        end
    endgenerate
    
    // 输出连接
    generate
        for (i = 0; i < ARRAY_DIM; i = i + 1) begin
            assign result_out[i] = psum_h[i][ARRAY_DIM];
        end
    endgenerate
endmodule
            </div>

            <h4>4.2.3 脉动阵列数据流动示例</h4>
            <p>以2×2矩阵乘法为例，展示数据在脉动阵列中的流动过程：</p>
            <div class="code-block">
矩阵A = [a00 a01]    矩阵B = [b00 b01]    结果C = A×B
        [a10 a11]            [b10 b11]

时刻0: 权重加载
PE[0][0] <- b00    PE[0][1] <- b01
PE[1][0] <- b10    PE[1][1] <- b11

时刻1: 
输入: a00, a10 (错开一个周期)
      ↓
    [b00]--[b01]    a00×b00 → PE[0][0]
      ↓
    [b10]--[b11]    

时刻2:
输入: a01, a11
    a00  ↓
    [b00]--[b01]    a00×b01 → PE[0][1], a10×b00 → PE[1][0]
    a10  ↓
    [b10]--[b11]

时刻3:
    a01  a00
    [b00]--[b01]→c00   a01×b10 → PE[0][0], a10×b01 → PE[1][1]
    a11  a10
    [b10]--[b11]

时刻4:
         a01
    [b00]--[b01]→c01   a01×b11 → PE[0][1], a11×b10 → PE[1][0]
         a11
    [b10]--[b11]→c10

时刻5:
    [b00]--[b01]       a11×b11 → PE[1][1]
    [b10]--[b11]→c11
            </div>

            <h3>4.3 向量处理单元</h3>
            
            <h4>4.3.1 SIMD架构设计</h4>
            <p>向量处理单元采用SIMD架构，支持非线性激活、池化等操作。</p>
            
            <div class="code-block">
module VectorProcessingUnit #(
    parameter VECTOR_WIDTH = 16,    // 向量宽度（并行度）
    parameter DATA_WIDTH = 8,       // 数据位宽
    parameter OPCODE_WIDTH = 5      // 操作码宽度
)(
    input wire clk,
    input wire rst_n,
    
    // 指令接口
    input wire [OPCODE_WIDTH-1:0] opcode,
    input wire execute,
    
    // 向量输入
    input wire [DATA_WIDTH-1:0] vec_a [0:VECTOR_WIDTH-1],
    input wire [DATA_WIDTH-1:0] vec_b [0:VECTOR_WIDTH-1],
    
    // 向量输出
    output reg [DATA_WIDTH-1:0] vec_result [0:VECTOR_WIDTH-1],
    output reg done
);

    // 操作码定义
    localparam OP_ADD  = 5'b00001;
    localparam OP_SUB  = 5'b00010;
    localparam OP_MUL  = 5'b00011;
    localparam OP_MAX  = 5'b00100;
    localparam OP_MIN  = 5'b00101;
    localparam OP_RELU = 5'b00110;
    localparam OP_SIGM = 5'b00111;
    localparam OP_TANH = 5'b01000;
    
    // 功能单元输出
    wire [DATA_WIDTH-1:0] alu_out [0:VECTOR_WIDTH-1];
    wire [DATA_WIDTH-1:0] act_out [0:VECTOR_WIDTH-1];
    
    // SIMD ALU阵列
    genvar i;
    generate
        for (i = 0; i < VECTOR_WIDTH; i = i + 1) begin : simd_lane
            // 算术逻辑单元
            VectorALU #(.DATA_WIDTH(DATA_WIDTH)) alu_inst (
                .a(vec_a[i]),
                .b(vec_b[i]),
                .op(opcode[2:0]),
                .result(alu_out[i])
            );
            
            // 激活函数单元
            ActivationUnit #(.DATA_WIDTH(DATA_WIDTH)) act_inst (
                .data_in(vec_a[i]),
                .func_sel(opcode[4:3]),
                .data_out(act_out[i])
            );
        end
    endgenerate
    
    // 结果选择和流水线控制
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            done <= 0;
        end else if (execute) begin
            case (opcode)
                OP_ADD, OP_SUB, OP_MUL, OP_MAX, OP_MIN: begin
                    for (int j = 0; j < VECTOR_WIDTH; j = j + 1) begin
                        vec_result[j] <= alu_out[j];
                    end
                end
                OP_RELU, OP_SIGM, OP_TANH: begin
                    for (int j = 0; j < VECTOR_WIDTH; j = j + 1) begin
                        vec_result[j] <= act_out[j];
                    end
                end
            endcase
            done <= 1;
        end else begin
            done <= 0;
        end
    end
endmodule
            </div>

            <h4>4.3.2 特殊功能单元</h4>
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>功能单元</th>
                            <th>操作</th>
                            <th>实现方式</th>
                            <th>硬件成本</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>ReLU单元</td>
                            <td>max(0, x)</td>
                            <td>比较器+选择器</td>
                            <td>极低</td>
                        </tr>
                        <tr>
                            <td>池化单元</td>
                            <td>max/avg pooling</td>
                            <td>比较树/加法树</td>
                            <td>低</td>
                        </tr>
                        <tr>
                            <td>LUT单元</td>
                            <td>sigmoid/tanh</td>
                            <td>查找表+插值</td>
                            <td>中等</td>
                        </tr>
                        <tr>
                            <td>归一化单元</td>
                            <td>batch/layer norm</td>
                            <td>乘法器+移位器</td>
                            <td>高</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h3>4.4 特殊计算单元</h3>
            
            <h4>4.4.1 Tensor Core设计</h4>
            <p>Tensor Core是一种执行小矩阵乘法的专用单元，提供更高的计算密度。</p>
            
            <div class="code-block">
// 4x4x4 Tensor Core实现
// 计算 D = A×B + C，其中A、B、C、D都是4×4矩阵
module TensorCore_4x4x4 #(
    parameter DATA_WIDTH = 8,
    parameter ACC_WIDTH = 32
)(
    input wire clk,
    input wire rst_n,
    input wire enable,
    
    // 输入矩阵（扁平化表示）
    input wire [DATA_WIDTH-1:0] mat_a [0:15],  // 4x4矩阵A
    input wire [DATA_WIDTH-1:0] mat_b [0:15],  // 4x4矩阵B
    input wire [ACC_WIDTH-1:0] mat_c [0:15],   // 4x4矩阵C（累加）
    
    // 输出矩阵
    output reg [ACC_WIDTH-1:0] mat_d [0:15],   // 4x4结果矩阵D
    output reg valid
);

    // 内部信号
    wire [ACC_WIDTH-1:0] dot_products [0:15];
    
    // 生成16个点积计算单元
    genvar i, j, k;
    generate
        for (i = 0; i < 4; i = i + 1) begin : row
            for (j = 0; j < 4; j = j + 1) begin : col
                // 计算D[i][j] = sum(A[i][k] * B[k][j]) + C[i][j]
                wire [2*DATA_WIDTH-1:0] products [0:3];
                wire [ACC_WIDTH-1:0] sum;
                
                // 4个并行乘法器
                for (k = 0; k < 4; k = k + 1) begin : mult
                    assign products[k] = mat_a[i*4+k] * mat_b[k*4+j];
                end
                
                // 加法树
                assign sum = mat_c[i*4+j] + 
                           {{(ACC_WIDTH-2*DATA_WIDTH){products[0][2*DATA_WIDTH-1]}}, products[0]} +
                           {{(ACC_WIDTH-2*DATA_WIDTH){products[1][2*DATA_WIDTH-1]}}, products[1]} +
                           {{(ACC_WIDTH-2*DATA_WIDTH){products[2][2*DATA_WIDTH-1]}}, products[2]} +
                           {{(ACC_WIDTH-2*DATA_WIDTH){products[3][2*DATA_WIDTH-1]}}, products[3]};
                
                assign dot_products[i*4+j] = sum;
            end
        end
    endgenerate
    
    // 寄存输出
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            valid <= 0;
        end else if (enable) begin
            for (int idx = 0; idx < 16; idx = idx + 1) begin
                mat_d[idx] <= dot_products[idx];
            end
            valid <= 1;
        end else begin
            valid <= 0;
        end
    end
endmodule
            </div>

            <h4>4.4.2 稀疏计算支持</h4>
            <p>支持结构化稀疏（如2:4稀疏）可以显著提升有效计算吞吐量。</p>
            
            <div class="code-block">
// 2:4结构化稀疏MAC单元
// 每4个权重中有2个非零值
module SparseMACUnit_2in4 #(
    parameter DATA_WIDTH = 8,
    parameter ACC_WIDTH = 32
)(
    input wire clk,
    input wire rst_n,
    input wire enable,
    
    // 稀疏权重输入（2个非零值）
    input wire [DATA_WIDTH-1:0] weight_values [0:1],  // 非零权重值
    input wire [1:0] weight_indices [0:1],            // 权重位置索引(0-3)
    
    // 4个激活值输入
    input wire [DATA_WIDTH-1:0] activations [0:3],
    
    // 累加输入输出
    input wire [ACC_WIDTH-1:0] psum_in,
    output reg [ACC_WIDTH-1:0] psum_out,
    output reg valid
);

    // 选择对应的激活值并计算
    wire [DATA_WIDTH-1:0] selected_acts [0:1];
    wire [2*DATA_WIDTH-1:0] products [0:1];
    wire [ACC_WIDTH-1:0] sum;
    
    // 根据索引选择激活值
    assign selected_acts[0] = activations[weight_indices[0]];
    assign selected_acts[1] = activations[weight_indices[1]];
    
    // 计算两个乘积
    assign products[0] = selected_acts[0] * weight_values[0];
    assign products[1] = selected_acts[1] * weight_values[1];
    
    // 累加
    assign sum = psum_in + 
                {{(ACC_WIDTH-2*DATA_WIDTH){products[0][2*DATA_WIDTH-1]}}, products[0]} +
                {{(ACC_WIDTH-2*DATA_WIDTH){products[1][2*DATA_WIDTH-1]}}, products[1]};
    
    // 寄存输出
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            psum_out <= 0;
            valid <= 0;
        end else if (enable) begin
            psum_out <= sum;
            valid <= 1;
        end else begin
            valid <= 0;
        end
    end
endmodule
            </div>

            <div class="exercise">
                <h4>练习题集 4</h4>
                
                <div class="question">
                    <p><strong>题目4.1：</strong>设计一个支持INT8/INT16混合精度的MAC单元。要求能够处理不同精度的输入组合。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module MixedPrecisionMAC #(
    parameter MAX_WIDTH = 16,      // 最大数据宽度
    parameter ACC_WIDTH = 48       // 累加器宽度（支持INT16×INT16）
)(
    input wire clk,
    input wire rst_n,
    input wire enable,
    
    // 输入数据和精度控制
    input wire [MAX_WIDTH-1:0] a_in,
    input wire [MAX_WIDTH-1:0] b_in,
    input wire [1:0] precision_mode,  // 00: INT8×INT8, 01: INT8×INT16, 10: INT16×INT8, 11: INT16×INT16
    input wire [ACC_WIDTH-1:0] c_in,
    
    // 输出
    output reg [ACC_WIDTH-1:0] c_out,
    output reg valid_out
);

    // 内部信号
    reg signed [MAX_WIDTH-1:0] a_ext, b_ext;
    wire signed [2*MAX_WIDTH-1:0] mult_result;
    wire signed [ACC_WIDTH-1:0] add_result;
    
    // 根据精度模式进行符号扩展
    always @(*) begin
        case (precision_mode)
            2'b00: begin  // INT8 × INT8
                a_ext = {{8{a_in[7]}}, a_in[7:0]};
                b_ext = {{8{b_in[7]}}, b_in[7:0]};
            end
            2'b01: begin  // INT8 × INT16
                a_ext = {{8{a_in[7]}}, a_in[7:0]};
                b_ext = b_in;
            end
            2'b10: begin  // INT16 × INT8
                a_ext = a_in;
                b_ext = {{8{b_in[7]}}, b_in[7:0]};
            end
            2'b11: begin  // INT16 × INT16
                a_ext = a_in;
                b_ext = b_in;
            end
        endcase
    end
    
    // 乘法器（支持最大精度）
    assign mult_result = a_ext * b_ext;
    
    // 累加器
    assign add_result = c_in + {{(ACC_WIDTH-2*MAX_WIDTH){mult_result[2*MAX_WIDTH-1]}}, mult_result};
    
    // 输出寄存
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            c_out <= 0;
            valid_out <= 0;
        end else if (enable) begin
            c_out <= add_result;
            valid_out <= 1;
        end else begin
            valid_out <= 0;
        end
    end
    
    // 功耗优化：根据精度模式门控高位逻辑
    // 实际实现中可以添加时钟门控逻辑
endmodule
                        </div>
                        <p><strong>设计要点：</strong></p>
                        <ul>
                            <li>使用参数化的最大位宽支持多种精度</li>
                            <li>根据精度模式进行正确的符号扩展</li>
                            <li>累加器位宽需要足够大以防止溢出</li>
                            <li>可以通过时钟门控优化低精度模式的功耗</li>
                        </ul>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目4.2：</strong>分析脉动阵列的三种数据流（WS/OS/RS）在执行1×1卷积时的效率差异。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p><strong>1×1卷积特点：</strong></p>
                        <ul>
                            <li>没有空间维度的滑动窗口</li>
                            <li>本质上是通道间的线性组合</li>
                            <li>可以完全转化为矩阵乘法</li>
                        </ul>
                        
                        <table>
                            <tr>
                                <th>数据流</th>
                                <th>数据复用</th>
                                <th>带宽需求</th>
                                <th>控制复杂度</th>
                                <th>1×1卷积效率</th>
                            </tr>
                            <tr>
                                <td>Weight Stationary (WS)</td>
                                <td>权重100%复用<br>激活值无复用</td>
                                <td>低（权重预加载）</td>
                                <td>简单</td>
                                <td><strong>最优</strong></td>
                            </tr>
                            <tr>
                                <td>Output Stationary (OS)</td>
                                <td>部分和本地累加<br>权重和激活都需流动</td>
                                <td>高</td>
                                <td>中等</td>
                                <td>较差</td>
                            </tr>
                            <tr>
                                <td>Row Stationary (RS)</td>
                                <td>退化为WS模式</td>
                                <td>低</td>
                                <td>复杂（但退化后简化）</td>
                                <td>等同于WS</td>
                            </tr>
                        </table>
                        
                        <p><strong>定量分析（假设计算1×1×256×256卷积）：</strong></p>
                        <ul>
                            <li><strong>WS模式：</strong>
                                <ul>
                                    <li>权重读取：256×256 = 65,536次（仅一次）</li>
                                    <li>激活值读取：取决于输入特征图大小</li>
                                    <li>部分和写回：每个输出位置一次</li>
                                </ul>
                            </li>
                            <li><strong>OS模式：</strong>
                                <ul>
                                    <li>权重读取：每个空间位置都需要读取所有权重</li>
                                    <li>带宽需求增加H×W倍</li>
                                </ul>
                            </li>
                        </ul>
                        
                        <p><strong>结论：</strong>对于1×1卷积，WS数据流最优，因为可以充分利用权重复用，而没有空间维度的复用需求。</p>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目4.3：</strong>设计一个8×8脉动阵列的控制器，支持矩阵分块计算。输入矩阵可能大于8×8。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module SystolicArrayController #(
    parameter ARRAY_DIM = 8,
    parameter DATA_WIDTH = 8,
    parameter ADDR_WIDTH = 32,
    parameter ACC_WIDTH = 32
)(
    input wire clk,
    input wire rst_n,
    
    // 配置接口
    input wire [31:0] M, N, K,              // 矩阵维度
    input wire [ADDR_WIDTH-1:0] addr_a,    // 矩阵A基地址
    input wire [ADDR_WIDTH-1:0] addr_b,    // 矩阵B基地址
    input wire [ADDR_WIDTH-1:0] addr_c,    // 矩阵C基地址
    input wire start,
    output reg done,
    
    // 内存接口
    output reg [ADDR_WIDTH-1:0] mem_addr_a,
    output reg [ADDR_WIDTH-1:0] mem_addr_b,
    output reg [ADDR_WIDTH-1:0] mem_addr_c,
    output reg mem_rd_a, mem_rd_b,
    output reg mem_wr_c,
    input wire [DATA_WIDTH*ARRAY_DIM-1:0] mem_data_a,
    input wire [DATA_WIDTH*ARRAY_DIM-1:0] mem_data_b,
    output reg [ACC_WIDTH*ARRAY_DIM-1:0] mem_data_c,
    
    // 脉动阵列接口
    output reg sa_weight_load,
    output reg sa_compute_en,
    output reg [DATA_WIDTH-1:0] sa_act_in [0:ARRAY_DIM-1],
    output reg [DATA_WIDTH-1:0] sa_weight_in [0:ARRAY_DIM-1][0:ARRAY_DIM-1],
    input wire [ACC_WIDTH-1:0] sa_result_out [0:ARRAY_DIM-1]
);

    // 状态机定义
    typedef enum logic [3:0] {
        IDLE,
        CALC_TILES,
        LOAD_WEIGHT,
        INIT_COMPUTE,
        COMPUTE,
        DRAIN,
        STORE_RESULT,
        NEXT_TILE
    } state_t;
    
    state_t state, next_state;
    
    // 分块计算控制
    reg [31:0] tile_m, tile_n, tile_k;     // 当前分块索引
    reg [31:0] num_tiles_m, num_tiles_n, num_tiles_k;
    reg [31:0] compute_cycles;              // 计算周期计数
    reg [31:0] row_offset, col_offset;     // 数据输入偏移
    
    // 计算分块数量
    always @(posedge clk) begin
        if (start) begin
            num_tiles_m <= (M + ARRAY_DIM - 1) / ARRAY_DIM;
            num_tiles_n <= (N + ARRAY_DIM - 1) / ARRAY_DIM;
            num_tiles_k <= (K + ARRAY_DIM - 1) / ARRAY_DIM;
        end
    end
    
    // 状态转换
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n)
            state <= IDLE;
        else
            state <= next_state;
    end
    
    always @(*) begin
        next_state = state;
        case (state)
            IDLE: begin
                if (start)
                    next_state = CALC_TILES;
            end
            
            CALC_TILES: begin
                next_state = LOAD_WEIGHT;
            end
            
            LOAD_WEIGHT: begin
                if (compute_cycles == ARRAY_DIM - 1)
                    next_state = INIT_COMPUTE;
            end
            
            INIT_COMPUTE: begin
                next_state = COMPUTE;
            end
            
            COMPUTE: begin
                // 需要K个周期完成一个K维的点积
                if (compute_cycles == K - 1)
                    next_state = DRAIN;
            end
            
            DRAIN: begin
                // 等待最后的结果流出
                if (compute_cycles == ARRAY_DIM - 1)
                    next_state = STORE_RESULT;
            end
            
            STORE_RESULT: begin
                if (compute_cycles == ARRAY_DIM - 1)
                    next_state = NEXT_TILE;
            end
            
            NEXT_TILE: begin
                if (tile_k < num_tiles_k - 1) begin
                    // 同一输出块的下一个K分块
                    next_state = LOAD_WEIGHT;
                end else if (tile_n < num_tiles_n - 1 || tile_m < num_tiles_m - 1) begin
                    // 下一个输出块
                    next_state = LOAD_WEIGHT;
                end else begin
                    // 完成所有计算
                    next_state = IDLE;
                end
            end
        endcase
    end
    
    // 数据路径控制
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            tile_m <= 0;
            tile_n <= 0;
            tile_k <= 0;
            compute_cycles <= 0;
            done <= 0;
            sa_weight_load <= 0;
            sa_compute_en <= 0;
            mem_rd_a <= 0;
            mem_rd_b <= 0;
            mem_wr_c <= 0;
        end else begin
            case (state)
                IDLE: begin
                    done <= 0;
                    if (start) begin
                        tile_m <= 0;
                        tile_n <= 0;
                        tile_k <= 0;
                    end
                end
                
                LOAD_WEIGHT: begin
                    // 加载权重矩阵B的一个tile
                    sa_weight_load <= 1;
                    mem_rd_b <= 1;
                    mem_addr_b <= addr_b + 
                                 (tile_n * ARRAY_DIM * K + tile_k * ARRAY_DIM) * DATA_WIDTH/8;
                    
                    // 将权重数据分配到阵列
                    // 简化处理：假设数据已正确排列
                    for (int i = 0; i < ARRAY_DIM; i++) begin
                        for (int j = 0; j < ARRAY_DIM; j++) begin
                            sa_weight_in[i][j] <= mem_data_b[(i*ARRAY_DIM+j)*DATA_WIDTH +: DATA_WIDTH];
                        end
                    end
                    
                    compute_cycles <= compute_cycles + 1;
                    if (compute_cycles == ARRAY_DIM - 1) begin
                        compute_cycles <= 0;
                        sa_weight_load <= 0;
                        mem_rd_b <= 0;
                    end
                end
                
                COMPUTE: begin
                    // 流式输入激活值
                    sa_compute_en <= 1;
                    mem_rd_a <= 1;
                    
                    // 计算当前输入地址
                    mem_addr_a <= addr_a + 
                                 ((tile_m * ARRAY_DIM + row_offset) * K + 
                                  tile_k * ARRAY_DIM + col_offset) * DATA_WIDTH/8;
                    
                    // 错开输入时序（脉动阵列需要）
                    for (int i = 0; i < ARRAY_DIM; i++) begin
                        if (compute_cycles >= i && compute_cycles - i < K) begin
                            sa_act_in[i] <= mem_data_a[i*DATA_WIDTH +: DATA_WIDTH];
                        end else begin
                            sa_act_in[i] <= 0;
                        end
                    end
                    
                    compute_cycles <= compute_cycles + 1;
                    col_offset <= col_offset + 1;
                    
                    if (col_offset == ARRAY_DIM - 1) begin
                        col_offset <= 0;
                        row_offset <= row_offset + 1;
                    end
                    
                    if (compute_cycles == K - 1) begin
                        compute_cycles <= 0;
                        row_offset <= 0;
                        col_offset <= 0;
                        sa_compute_en <= 0;
                        mem_rd_a <= 0;
                    end
                end
                
                STORE_RESULT: begin
                    // 存储计算结果
                    mem_wr_c <= 1;
                    mem_addr_c <= addr_c + 
                                 ((tile_m * ARRAY_DIM + compute_cycles) * N + 
                                  tile_n * ARRAY_DIM) * ACC_WIDTH/8;
                    
                    // 收集结果
                    for (int i = 0; i < ARRAY_DIM; i++) begin
                        mem_data_c[i*ACC_WIDTH +: ACC_WIDTH] <= sa_result_out[i];
                    end
                    
                    compute_cycles <= compute_cycles + 1;
                    if (compute_cycles == ARRAY_DIM - 1) begin
                        compute_cycles <= 0;
                        mem_wr_c <= 0;
                    end
                end
                
                NEXT_TILE: begin
                    if (tile_k < num_tiles_k - 1) begin
                        tile_k <= tile_k + 1;
                    end else begin
                        tile_k <= 0;
                        if (tile_n < num_tiles_n - 1) begin
                            tile_n <= tile_n + 1;
                        end else begin
                            tile_n <= 0;
                            tile_m <= tile_m + 1;
                        end
                    end
                    
                    if (tile_m == num_tiles_m - 1 && 
                        tile_n == num_tiles_n - 1 && 
                        tile_k == num_tiles_k - 1) begin
                        done <= 1;
                    end
                end
            endcase
        end
    end
endmodule
                        </div>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目4.4：</strong>设计一个高效的激活函数单元，支持ReLU、Leaky ReLU和Swish。考虑面积和延迟的权衡。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module EfficientActivationUnit #(
    parameter DATA_WIDTH = 16,
    parameter FRAC_WIDTH = 8    // 小数位宽（定点数）
)(
    input wire clk,
    input wire rst_n,
    input wire enable,
    
    // 输入数据
    input wire signed [DATA_WIDTH-1:0] data_in,
    
    // 功能选择和参数
    input wire [1:0] func_sel,  // 00: ReLU, 01: LeakyReLU, 10: Swish
    input wire [DATA_WIDTH-1:0] alpha,  // LeakyReLU的斜率（定点表示）
    
    // 输出
    output reg signed [DATA_WIDTH-1:0] data_out,
    output reg valid
);

    // 内部信号
    wire is_negative;
    wire signed [DATA_WIDTH-1:0] relu_out;
    wire signed [DATA_WIDTH-1:0] leaky_relu_out;
    wire signed [DATA_WIDTH-1:0] swish_out;
    
    // 负数检测
    assign is_negative = data_in[DATA_WIDTH-1];
    
    // ReLU: max(0, x)
    assign relu_out = is_negative ? {DATA_WIDTH{1'b0}} : data_in;
    
    // Leaky ReLU: x if x > 0, else alpha * x
    wire signed [2*DATA_WIDTH-1:0] alpha_mult;
    assign alpha_mult = data_in * alpha;
    assign leaky_relu_out = is_negative ? 
                           alpha_mult[DATA_WIDTH+FRAC_WIDTH-1:FRAC_WIDTH] : 
                           data_in;
    
    // Swish: x * sigmoid(x)
    // 使用分段线性逼近sigmoid
    wire signed [DATA_WIDTH-1:0] sigmoid_approx;
    SwishLUT #(
        .DATA_WIDTH(DATA_WIDTH),
        .FRAC_WIDTH(FRAC_WIDTH)
    ) swish_lut (
        .x(data_in),
        .sigmoid_x(sigmoid_approx)
    );
    
    wire signed [2*DATA_WIDTH-1:0] swish_mult;
    assign swish_mult = data_in * sigmoid_approx;
    assign swish_out = swish_mult[DATA_WIDTH+FRAC_WIDTH-1:FRAC_WIDTH];
    
    // 输出选择（组合逻辑，最小化延迟）
    always @(*) begin
        case (func_sel)
            2'b00: data_out = relu_out;
            2'b01: data_out = leaky_relu_out;
            2'b10: data_out = swish_out;
            default: data_out = data_in;  // 直通
        endcase
    end
    
    // 有效信号生成
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            valid <= 0;
        end else begin
            valid <= enable;
        end
    end
endmodule

// Swish激活函数的LUT实现
module SwishLUT #(
    parameter DATA_WIDTH = 16,
    parameter FRAC_WIDTH = 8,
    parameter LUT_DEPTH = 256  // LUT条目数
)(
    input wire signed [DATA_WIDTH-1:0] x,
    output reg signed [DATA_WIDTH-1:0] sigmoid_x
);

    // 定义查找表（实际中由工具生成）
    reg signed [DATA_WIDTH-1:0] lut_table [0:LUT_DEPTH-1];
    
    // LUT初始化（sigmoid函数的采样点）
    initial begin
        // 覆盖范围 [-8, 8]，均匀采样
        for (int i = 0; i < LUT_DEPTH; i++) begin
            real x_real = -8.0 + 16.0 * i / (LUT_DEPTH - 1);
            real sigmoid_real = 1.0 / (1.0 + $exp(-x_real));
            lut_table[i] = sigmoid_real * (1 << FRAC_WIDTH);
        end
    end
    
    // 地址计算和查表
    wire [7:0] lut_addr;
    wire signed [DATA_WIDTH-1:0] x_saturated;
    
    // 饱和到[-8, 8]范围
    assign x_saturated = (x > (8 << FRAC_WIDTH)) ? (8 << FRAC_WIDTH) :
                        (x < (-8 << FRAC_WIDTH)) ? (-8 << FRAC_WIDTH) : x;
    
    // 映射到LUT地址
    assign lut_addr = ((x_saturated + (8 << FRAC_WIDTH)) * LUT_DEPTH) >> (FRAC_WIDTH + 4);
    
    // 查表（可以添加线性插值以提高精度）
    always @(*) begin
        sigmoid_x = lut_table[lut_addr];
    end
endmodule
                        </div>
                        <p><strong>设计权衡分析：</strong></p>
                        <table>
                            <tr>
                                <th>激活函数</th>
                                <th>硬件成本</th>
                                <th>延迟</th>
                                <th>精度</th>
                            </tr>
                            <tr>
                                <td>ReLU</td>
                                <td>极低（1个比较器）</td>
                                <td>0延迟</td>
                                <td>精确</td>
                            </tr>
                            <tr>
                                <td>Leaky ReLU</td>
                                <td>低（1个乘法器）</td>
                                <td>1个乘法延迟</td>
                                <td>取决于alpha精度</td>
                            </tr>
                            <tr>
                                <td>Swish</td>
                                <td>中等（LUT+乘法器）</td>
                                <td>查表+乘法延迟</td>
                                <td>取决于LUT大小</td>
                            </tr>
                        </table>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目4.5：</strong>分析Tensor Core相比传统脉动阵列在执行批量矩阵乘法(Batched GEMM)时的优势。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p><strong>批量矩阵乘法场景：</strong>计算C[i] = A[i] × B[i]，其中i = 0...batch_size-1</p>
                        
                        <p><strong>1. 传统脉动阵列处理方式：</strong></p>
                        <ul>
                            <li>串行处理：依次计算每个矩阵乘法</li>
                            <li>时间复杂度：O(batch_size × 矩阵乘法时间)</li>
                            <li>无法利用batch维度的并行性</li>
                        </ul>
                        
                        <p><strong>2. Tensor Core优势：</strong></p>
                        <table>
                            <tr>
                                <th>方面</th>
                                <th>传统脉动阵列</th>
                                <th>Tensor Core</th>
                                <th>优势倍数</th>
                            </tr>
                            <tr>
                                <td>基本运算粒度</td>
                                <td>标量MAC</td>
                                <td>4×4×4矩阵乘法</td>
                                <td>64×</td>
                            </tr>
                            <tr>
                                <td>批处理能力</td>
                                <td>串行</td>
                                <td>可并行多个小矩阵</td>
                                <td>与batch size相关</td>
                            </tr>
                            <tr>
                                <td>数据重排开销</td>
                                <td>需要外部重排</td>
                                <td>硬件原生支持</td>
                                <td>-</td>
                            </tr>
                            <tr>
                                <td>寄存器利用率</td>
                                <td>~50%</td>
                                <td>~90%</td>
                                <td>1.8×</td>
                            </tr>
                        </table>
                        
                        <p><strong>3. 具体示例（Transformer注意力计算）：</strong></p>
                        <div class="code-block">
// Transformer中的批量矩阵乘法
// Q, K, V: [batch_size, seq_len, d_model]
// 需要计算：Attention = softmax(Q × K^T) × V

// 传统脉动阵列：
for (batch = 0; batch < batch_size; batch++) {
    // 计算 Q[batch] × K[batch]^T
    systolic_array_compute(Q[batch], K[batch].T);
    // 等待完成...
}
// 总时间：batch_size × (seq_len × seq_len × d_model)

// Tensor Core：
// 可以将多个batch的小块同时映射到不同的Tensor Core
for (batch_group = 0; batch_group < batch_size; batch_group += 4) {
    // 4个batch并行计算
    tensor_core_batch_compute(Q[batch_group:batch_group+4], 
                            K[batch_group:batch_group+4].T);
}
// 总时间：(batch_size/4) × (seq_len × seq_len × d_model) / 64
                        </div>
                        
                        <p><strong>4. 性能提升分析：</strong></p>
                        <ul>
                            <li>理论加速比：最高可达 4× (batch并行) × 64× (Tensor Core加速) = 256×</li>
                            <li>实际加速比：考虑内存带宽限制，通常为10-50×</li>
                            <li>功耗效率提升：3-5×（更少的数据移动）</li>
                        </ul>
                        
                        <p><strong>5. 适用条件：</strong></p>
                        <ul>
                            <li>矩阵尺寸是4的倍数</li>
                            <li>Batch size较大（≥4）</li>
                            <li>支持的数据精度（通常是FP16/INT8混合）</li>
                        </ul>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目4.6：</strong>设计一个支持动态稀疏的MAC阵列。要求能够跳过零权重和零激活值的计算。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module DynamicSparseMACArray #(
    parameter DATA_WIDTH = 8,
    parameter ACC_WIDTH = 32,
    parameter PE_NUM = 16,        // PE数量
    parameter FIFO_DEPTH = 8      // 输入FIFO深度
)(
    input wire clk,
    input wire rst_n,
    input wire enable,
    
    // 稀疏数据输入（压缩格式）
    input wire [DATA_WIDTH-1:0] act_values [0:PE_NUM-1],      // 非零激活值
    input wire [4:0] act_indices [0:PE_NUM-1],                // 激活值索引
    input wire [PE_NUM-1:0] act_valid,                        // 激活值有效标志
    
    input wire [DATA_WIDTH-1:0] weight_values [0:PE_NUM-1],   // 非零权重
    input wire [4:0] weight_indices [0:PE_NUM-1],             // 权重索引
    input wire [PE_NUM-1:0] weight_valid,                     // 权重有效标志
    
    // 输出接口
    output reg [ACC_WIDTH-1:0] results [0:PE_NUM-1],
    output reg [PE_NUM-1:0] result_valid,
    output reg done
);

    // PE阵列
    genvar i;
    generate
        for (i = 0; i < PE_NUM; i = i + 1) begin : sparse_pe
            SparsePE #(
                .DATA_WIDTH(DATA_WIDTH),
                .ACC_WIDTH(ACC_WIDTH),
                .FIFO_DEPTH(FIFO_DEPTH)
            ) pe_inst (
                .clk(clk),
                .rst_n(rst_n),
                .enable(enable),
                .act_value(act_values[i]),
                .act_index(act_indices[i]),
                .act_valid(act_valid[i]),
                .weight_value(weight_values[i]),
                .weight_index(weight_indices[i]),
                .weight_valid(weight_valid[i]),
                .result(results[i]),
                .result_valid(result_valid[i])
            );
        end
    endgenerate
    
    // 完成信号生成
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            done <= 0;
        end else begin
            done <= &result_valid;  // 所有PE完成
        end
    end
endmodule

// 稀疏PE单元
module SparsePE #(
    parameter DATA_WIDTH = 8,
    parameter ACC_WIDTH = 32,
    parameter FIFO_DEPTH = 8
)(
    input wire clk,
    input wire rst_n,
    input wire enable,
    
    // 稀疏输入
    input wire [DATA_WIDTH-1:0] act_value,
    input wire [4:0] act_index,
    input wire act_valid,
    
    input wire [DATA_WIDTH-1:0] weight_value,
    input wire [4:0] weight_index,
    input wire weight_valid,
    
    // 输出
    output reg [ACC_WIDTH-1:0] result,
    output reg result_valid
);

    // 输入FIFO
    reg [DATA_WIDTH-1:0] act_fifo_data [0:FIFO_DEPTH-1];
    reg [4:0] act_fifo_index [0:FIFO_DEPTH-1];
    reg [DATA_WIDTH-1:0] weight_fifo_data [0:FIFO_DEPTH-1];
    reg [4:0] weight_fifo_index [0:FIFO_DEPTH-1];
    
    reg [2:0] act_wr_ptr, act_rd_ptr;
    reg [2:0] weight_wr_ptr, weight_rd_ptr;
    reg [3:0] act_count, weight_count;
    
    // 匹配逻辑
    wire index_match;
    wire compute_valid;
    
    assign index_match = (act_fifo_index[act_rd_ptr] == weight_fifo_index[weight_rd_ptr]);
    assign compute_valid = (act_count > 0) && (weight_count > 0) && index_match;
    
    // MAC计算
    wire signed [2*DATA_WIDTH-1:0] mult_result;
    wire signed [ACC_WIDTH-1:0] acc_result;
    
    assign mult_result = act_fifo_data[act_rd_ptr] * weight_fifo_data[weight_rd_ptr];
    assign acc_result = result + {{(ACC_WIDTH-2*DATA_WIDTH){mult_result[2*DATA_WIDTH-1]}}, mult_result};
    
    // FIFO写入逻辑
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            act_wr_ptr <= 0;
            weight_wr_ptr <= 0;
            act_count <= 0;
            weight_count <= 0;
        end else if (enable) begin
            // 激活值FIFO写入
            if (act_valid && act_count < FIFO_DEPTH) begin
                act_fifo_data[act_wr_ptr] <= act_value;
                act_fifo_index[act_wr_ptr] <= act_index;
                act_wr_ptr <= act_wr_ptr + 1;
                act_count <= act_count + 1;
            end
            
            // 权重FIFO写入
            if (weight_valid && weight_count < FIFO_DEPTH) begin
                weight_fifo_data[weight_wr_ptr] <= weight_value;
                weight_fifo_index[weight_wr_ptr] <= weight_index;
                weight_wr_ptr <= weight_wr_ptr + 1;
                weight_count <= weight_count + 1;
            end
        end
    end
    
    // 计算和FIFO读取逻辑
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            result <= 0;
            result_valid <= 0;
            act_rd_ptr <= 0;
            weight_rd_ptr <= 0;
        end else if (enable) begin
            if (compute_valid) begin
                // 执行MAC运算
                result <= acc_result;
                
                // 更新读指针
                act_rd_ptr <= act_rd_ptr + 1;
                weight_rd_ptr <= weight_rd_ptr + 1;
                act_count <= act_count - 1;
                weight_count <= weight_count - 1;
            end else if (act_count > 0 && weight_count > 0) begin
                // 索引不匹配，跳过较小的索引
                if (act_fifo_index[act_rd_ptr] < weight_fifo_index[weight_rd_ptr]) begin
                    act_rd_ptr <= act_rd_ptr + 1;
                    act_count <= act_count - 1;
                end else begin
                    weight_rd_ptr <= weight_rd_ptr + 1;
                    weight_count <= weight_count - 1;
                end
            end
            
            // 生成完成信号
            result_valid <= (act_count == 0) || (weight_count == 0);
        end
    end
endmodule
                        </div>
                        <p><strong>设计特点：</strong></p>
                        <ul>
                            <li>使用FIFO缓存稀疏数据，解耦输入和计算</li>
                            <li>索引匹配逻辑，只计算索引相同的元素</li>
                            <li>支持不同稀疏度的激活值和权重</li>
                            <li>自动跳过不匹配的索引，提高效率</li>
                        </ul>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目4.7：</strong>优化一个16×16脉动阵列的时钟分配网络，考虑时钟偏斜和功耗。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p><strong>1. 时钟网络挑战：</strong></p>
                        <ul>
                            <li>16×16 = 256个PE，每个PE需要同步时钟</li>
                            <li>时钟偏斜影响最高工作频率</li>
                            <li>时钟网络功耗占总功耗的20-30%</li>
                        </ul>
                        
                        <p><strong>2. H-Tree时钟分配设计：</strong></p>
                        <div class="code-block">
module ClockTreeOptimized_16x16 (
    input wire clk_in,
    input wire [255:0] clock_enable,  // 每个PE的时钟使能
    output wire clk_out [0:15][0:15]  // 分配到每个PE的时钟
);

    // H-Tree层次结构
    // Level 0: 根节点
    wire clk_l0;
    ClockBuffer #(.DRIVE_STRENGTH(16)) buf_l0 (
        .clk_in(clk_in),
        .clk_out(clk_l0)
    );
    
    // Level 1: 4个象限
    wire clk_l1 [0:3];
    genvar q;
    generate
        for (q = 0; q < 4; q = q + 1) begin : quadrant
            ClockBuffer #(.DRIVE_STRENGTH(8)) buf_l1 (
                .clk_in(clk_l0),
                .clk_out(clk_l1[q])
            );
        end
    endgenerate
    
    // Level 2: 16个区域（4×4）
    wire clk_l2 [0:3][0:3];
    genvar i, j;
    generate
        for (i = 0; i < 2; i = i + 1) begin
            for (j = 0; j < 2; j = j + 1) begin
                ClockBuffer #(.DRIVE_STRENGTH(4)) buf_l2_q0 (
                    .clk_in(clk_l1[0]),
                    .clk_out(clk_l2[i][j])
                );
                // 类似处理其他象限...
            end
        end
    endgenerate
    
    // Level 3: 叶节点（带时钟门控）
    generate
        for (i = 0; i < 16; i = i + 1) begin : row
            for (j = 0; j < 16; j = j + 1) begin : col
                ClockGatingCell cgc (
                    .clk_in(clk_l2[i/4][j/4]),
                    .enable(clock_enable[i*16+j]),
                    .clk_out(clk_out[i][j])
                );
            end
        end
    endgenerate
endmodule

// 低偏斜时钟缓冲器
module ClockBuffer #(
    parameter DRIVE_STRENGTH = 1
) (
    input wire clk_in,
    output wire clk_out
);
    // 使用对称的缓冲器链
    wire [DRIVE_STRENGTH-1:0] buf_chain;
    
    assign buf_chain[0] = clk_in;
    genvar k;
    generate
        for (k = 1; k < DRIVE_STRENGTH; k = k + 1) begin
            // 渐进式增大驱动能力
            buf #(.size(2**k)) buffer_inst (
                .in(buf_chain[k-1]),
                .out(buf_chain[k])
            );
        end
    endgenerate
    
    assign clk_out = buf_chain[DRIVE_STRENGTH-1];
endmodule

// 集成时钟门控单元
module ClockGatingCell (
    input wire clk_in,
    input wire enable,
    output wire clk_out
);
    reg enable_latch;
    
    // 锁存使能信号（避免毛刺）
    always @(clk_in or enable) begin
        if (!clk_in)
            enable_latch <= enable;
    end
    
    // AND门输出门控时钟
    assign clk_out = clk_in & enable_latch;
endmodule
                        </div>
                        
                        <p><strong>3. 优化技术：</strong></p>
                        <table>
                            <tr>
                                <th>技术</th>
                                <th>原理</th>
                                <th>效果</th>
                                <th>成本</th>
                            </tr>
                            <tr>
                                <td>H-Tree拓扑</td>
                                <td>对称分支，等长路径</td>
                                <td>偏斜<10ps</td>
                                <td>布线资源多</td>
                            </tr>
                            <tr>
                                <td>细粒度时钟门控</td>
                                <td>PE级别关断</td>
                                <td>功耗降低40%</td>
                                <td>控制复杂</td>
                            </tr>
                            <tr>
                                <td>多级缓冲</td>
                                <td>逐级放大驱动</td>
                                <td>转换时间优化</td>
                                <td>面积增加</td>
                            </tr>
                            <tr>
                                <td>局部时钟域</td>
                                <td>分区异步</td>
                                <td>降低全局偏斜</td>
                                <td>同步开销</td>
                            </tr>
                        </table>
                        
                        <p><strong>4. 实施建议：</strong></p>
                        <ul>
                            <li>使用专用时钟布线层，减少干扰</li>
                            <li>在每个分支点放置去耦电容</li>
                            <li>考虑工艺偏差，预留时序裕量</li>
                            <li>支持动态频率调节（DVFS）</li>
                        </ul>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目4.8：</strong>比较不同MAC阵列规模（8×8、16×16、32×32）的设计权衡，给出选择建议。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <table>
                            <tr>
                                <th>指标</th>
                                <th>8×8阵列</th>
                                <th>16×16阵列</th>
                                <th>32×32阵列</th>
                            </tr>
                            <tr>
                                <td>MAC单元数</td>
                                <td>64</td>
                                <td>256</td>
                                <td>1024</td>
                            </tr>
                            <tr>
                                <td>峰值算力(相对)</td>
                                <td>1×</td>
                                <td>4×</td>
                                <td>16×</td>
                            </tr>
                            <tr>
                                <td>面积(相对)</td>
                                <td>1×</td>
                                <td>~4.5×</td>
                                <td>~20×</td>
                            </tr>
                            <tr>
                                <td>功耗(相对)</td>
                                <td>1×</td>
                                <td>~4.2×</td>
                                <td>~18×</td>
                            </tr>
                            <tr>
                                <td>片上SRAM需求</td>
                                <td>64KB</td>
                                <td>256KB</td>
                                <td>1MB+</td>
                            </tr>
                            <tr>
                                <td>带宽需求</td>
                                <td>64GB/s</td>
                                <td>256GB/s</td>
                                <td>1TB/s</td>
                            </tr>
                            <tr>
                                <td>控制复杂度</td>
                                <td>低</td>
                                <td>中</td>
                                <td>高</td>
                            </tr>
                            <tr>
                                <td>时钟分配难度</td>
                                <td>简单</td>
                                <td>适中</td>
                                <td>困难</td>
                            </tr>
                            <tr>
                                <td>利用率(典型)</td>
                                <td>85%</td>
                                <td>75%</td>
                                <td>60%</td>
                            </tr>
                        </table>
                        
                        <p><strong>设计权衡分析：</strong></p>
                        
                        <p><strong>1. 8×8阵列：</strong></p>
                        <ul>
                            <li><strong>优势：</strong>
                                <ul>
                                    <li>控制简单，易于实现</li>
                                    <li>利用率高，适合小矩阵</li>
                                    <li>功耗密度低，散热容易</li>
                                </ul>
                            </li>
                            <li><strong>劣势：</strong>
                                <ul>
                                    <li>绝对性能有限</li>
                                    <li>大矩阵需要多次分块</li>
                                </ul>
                            </li>
                            <li><strong>适用场景：</strong>边缘设备、低功耗应用</li>
                        </ul>
                        
                        <p><strong>2. 16×16阵列：</strong></p>
                        <ul>
                            <li><strong>优势：</strong>
                                <ul>
                                    <li>性能功耗比最优</li>
                                    <li>适配主流网络的层大小</li>
                                    <li>设计复杂度可控</li>
                                </ul>
                            </li>
                            <li><strong>劣势：</strong>
                                <ul>
                                    <li>需要更复杂的数据调度</li>
                                </ul>
                            </li>
                            <li><strong>适用场景：</strong>主流推理加速器</li>
                        </ul>
                        
                        <p><strong>3. 32×32阵列：</strong></p>
                        <ul>
                            <li><strong>优势：</strong>
                                <ul>
                                    <li>峰值性能高</li>
                                    <li>大矩阵效率好</li>
                                </ul>
                            </li>
                            <li><strong>劣势：</strong>
                                <ul>
                                    <li>面积开销呈超线性增长</li>
                                    <li>带宽墙问题严重</li>
                                    <li>小矩阵利用率低</li>
                                    <li>时序收敛困难</li>
                                </ul>
                            </li>
                            <li><strong>适用场景：</strong>高端服务器、特定大模型</li>
                        </ul>
                        
                        <p><strong>选择建议：</strong></p>
                        <ol>
                            <li><strong>边缘推理：</strong>8×8，功耗优先</li>
                            <li><strong>移动端NPU：</strong>8×8或16×16，平衡性能功耗</li>
                            <li><strong>数据中心推理：</strong>16×16多核，可扩展性好</li>
                            <li><strong>训练加速器：</strong>32×32或更大，性能优先</li>
                        </ol>
                        
                        <p><strong>未来趋势：</strong>多个中等规模阵列（16×16）+ 灵活互联 > 单个超大阵列</p>
                    </div>
                </div>
            </div>
        </div>
        
    </div>

    <script>
        // JavaScript for collapsible answers
        function toggleAnswer(button) {
            const answer = button.nextElementSibling;
            if (answer.classList.contains('show')) {
                answer.classList.remove('show');
                button.textContent = '显示答案';
            } else {
                answer.classList.add('show');
                button.textContent = '隐藏答案';
            }
        }

        // Add event listeners to all toggle buttons
        document.addEventListener('DOMContentLoaded', function() {
            const toggleButtons = document.querySelectorAll('.toggle-answer');
            toggleButtons.forEach(button => {
                button.addEventListener('click', function() {
                    toggleAnswer(this);
                });
            });
        });

        // Smooth scrolling for navigation links
        document.querySelectorAll('nav a').forEach(anchor => {
            anchor.addEventListener('click', function(e) {
                e.preventDefault();
                const target = document.querySelector(this.getAttribute('href'));
                if (target) {
                    target.scrollIntoView({
                        behavior: 'smooth',
                        block: 'start'
                    });
                }
            });
        });
    </script>
</body>
</html>