<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Neural Processing Unit (NPU) 设计教程</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'PingFang SC', 'Microsoft YaHei', sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: #f5f5f5;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }

        header {
            background: linear-gradient(135deg, #2c3e50 0%, #3498db 100%);
            color: white;
            padding: 40px 0;
            text-align: center;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }

        header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
        }

        nav {
            background: #34495e;
            padding: 15px 0;
            position: sticky;
            top: 0;
            z-index: 100;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }

        nav ul {
            list-style: none;
            display: flex;
            flex-wrap: wrap;
            justify-content: center;
            max-width: 1200px;
            margin: 0 auto;
        }

        nav li {
            margin: 5px 15px;
        }

        nav a {
            color: white;
            text-decoration: none;
            padding: 5px 10px;
            border-radius: 4px;
            transition: background 0.3s;
        }

        nav a:hover {
            background: #2c3e50;
        }

        .chapter {
            background: white;
            margin: 20px 0;
            padding: 30px;
            border-radius: 8px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }

        .chapter h2 {
            color: #2c3e50;
            font-size: 2em;
            margin-bottom: 20px;
            padding-bottom: 10px;
            border-bottom: 3px solid #3498db;
        }

        .chapter h3 {
            color: #34495e;
            font-size: 1.5em;
            margin: 25px 0 15px 0;
        }

        .chapter h4 {
            color: #7f8c8d;
            font-size: 1.2em;
            margin: 20px 0 10px 0;
        }

        .code-block {
            background: #2c3e50;
            color: #ecf0f1;
            padding: 20px;
            border-radius: 5px;
            margin: 15px 0;
            overflow-x: auto;
            font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
            font-size: 14px;
            line-height: 1.5;
            white-space: pre-wrap;
            word-wrap: break-word;
        }

        .exercise {
            background: #ecf0f1;
            padding: 20px;
            border-radius: 5px;
            margin: 20px 0;
            border-left: 5px solid #3498db;
        }

        .exercise h4 {
            color: #2c3e50;
            margin-bottom: 10px;
        }

        .question {
            margin: 15px 0;
            padding: 15px;
            background: white;
            border-radius: 5px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
        }

        .answer {
            margin-top: 10px;
            padding: 15px;
            background: #e8f5e9;
            border-radius: 5px;
            display: none;
            border-left: 4px solid #4caf50;
        }

        .answer.show {
            display: block;
        }

        .toggle-answer {
            background: #3498db;
            color: white;
            border: none;
            padding: 8px 15px;
            border-radius: 4px;
            cursor: pointer;
            font-size: 14px;
            margin-top: 10px;
            transition: background 0.3s;
        }

        .toggle-answer:hover {
            background: #2980b9;
        }

        .figure {
            text-align: center;
            margin: 20px 0;
        }

        .figure img {
            max-width: 100%;
            height: auto;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }

        .figure-caption {
            color: #7f8c8d;
            font-size: 0.9em;
            margin-top: 10px;
        }

        .table-wrapper {
            overflow-x: auto;
            margin: 20px 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }

        th, td {
            padding: 12px;
            text-align: left;
            border-bottom: 1px solid #ddd;
        }

        th {
            background: #34495e;
            color: white;
            font-weight: bold;
        }

        tr:hover {
            background: #f5f5f5;
        }

        .highlight {
            background: #fff3cd;
            padding: 2px 5px;
            border-radius: 3px;
        }

        .info-box {
            background: #e3f2fd;
            border-left: 5px solid #2196f3;
            padding: 15px;
            margin: 20px 0;
            border-radius: 5px;
        }

        .warning-box {
            background: #fff3cd;
            border-left: 5px solid #ff9800;
            padding: 15px;
            margin: 20px 0;
            border-radius: 5px;
        }

        @media (max-width: 768px) {
            .container {
                padding: 10px;
            }
            
            header h1 {
                font-size: 1.8em;
            }
            
            .chapter {
                padding: 20px;
            }
            
            nav ul {
                flex-direction: column;
                align-items: center;
            }
        }
    </style>
</head>
<body>
    <header>
        <h1>Neural Processing Unit (NPU) 设计教程</h1>
        <p>从基础到高级的完整NPU芯片设计指南</p>
    </header>

    <nav>
        <ul>
            <li><a href="#intro">课程介绍</a></li>
            <li><a href="#chapter1">1. NPU简介</a></li>
            <li><a href="#chapter2">2. 神经网络基础</a></li>
            <li><a href="#chapter3">3. NPU架构</a></li>
            <li><a href="#chapter4">4. 计算核心</a></li>
            <li><a href="#chapter5">5. 存储系统</a></li>
            <li><a href="#chapter6">6. RTL设计</a></li>
            <li><a href="#chapter7">7. 验证方法</a></li>
            <li><a href="#chapter8">8. 物理设计</a></li>
            <li><a href="#chapter9">9. 先进工艺</a></li>
            <li><a href="#chapter10">10. 软硬件协同</a></li>
            <li><a href="#chapter11">11. 性能优化</a></li>
            <li><a href="#chapter12">12. 实战项目</a></li>
        </ul>
    </nav>

    <div class="container">
        <div id="intro" class="chapter">
            <h2>课程介绍</h2>
            <p>欢迎来到Neural Processing Unit (NPU)设计教程！本教程将带您从零开始，逐步深入了解NPU的设计原理和实现技术。</p>
            
            <h3>课程目标</h3>
            <ul>
                <li>理解NPU的基本原理和架构</li>
                <li>掌握NPU前端设计技术（RTL设计和验证）</li>
                <li>学习NPU后端设计流程（综合、布局布线）</li>
                <li>了解软硬件协同设计方法</li>
                <li>通过实战项目巩固所学知识</li>
            </ul>

            <h3>学习建议</h3>
            <div class="info-box">
                <p><strong>提示：</strong>本教程采用渐进式学习方式，建议按章节顺序学习。每章都包含理论讲解、代码示例和练习题，请确保完成每章的练习题后再进入下一章。</p>
            </div>

            <h3>先修知识</h3>
            <ul>
                <li>数字电路基础</li>
                <li>Verilog/SystemVerilog编程基础</li>
                <li>计算机体系结构基础</li>
                <li>基本的深度学习概念</li>
            </ul>
        </div>

        <div id="chapter1" class="chapter">
            <h2>第1章：NPU简介与发展历程</h2>
            
            <h3>1.1 什么是NPU</h3>
            <p>Neural Processing Unit (NPU) 是一种专门为加速人工智能和机器学习工作负载而设计的处理器。与传统的CPU和GPU不同，NPU针对神经网络计算进行了特殊优化，能够高效执行矩阵运算、卷积运算等AI相关操作。</p>
            
            <p>NPU的诞生源于深度学习计算的特殊需求。随着深度神经网络模型规模的快速增长，从早期的LeNet（约6万参数）到现代的GPT-3（1750亿参数），计算需求呈指数级增长。传统处理器架构在面对这种计算密集型任务时暴露出诸多不足：CPU的串行架构限制了并行计算能力，GPU虽然提供了大规模并行计算，但其通用并行架构并非为神经网络量身定制，存在功耗高、内存带宽利用率低等问题。</p>
            
            <p>NPU通过领域专用架构（Domain-Specific Architecture，DSA）设计理念，从根本上解决了这些问题。DSA的核心思想是：放弃通用性，换取在特定领域的极致性能。NPU正是这一理念在人工智能领域的成功实践。通过深入分析神经网络的计算特征，NPU在硬件层面实现了多项关键优化：</p>
            
            <div class="info-box">
                <p><strong>NPU的核心设计特征：</strong></p>
                <ul>
                    <li><strong>专用硬件加速器：</strong>NPU内部集成了专门为神经网络运算优化的硬件单元。最典型的是脉动阵列（Systolic Array），它通过规律的数据流动模式，实现了计算和数据传输的完美重叠。每个处理单元（PE）只与相邻单元通信，大大简化了互连复杂度。</li>
                    <li><strong>高效的矩阵运算单元（MAC阵列）：</strong>MAC（Multiply-Accumulate）运算占据了神经网络计算的90%以上。NPU通过大规模并行的MAC阵列（如Google TPU的256×256阵列），可以在单个时钟周期内完成数万次乘累加运算。这种设计将芯片面积的大部分用于计算，而非控制逻辑。</li>
                    <li><strong>专门的数据流架构：</strong>NPU采用了多种数据流优化策略，如权重固定（Weight Stationary）、输出固定（Output Stationary）和行固定（Row Stationary）等。这些策略通过最大化数据复用，将外部内存访问降到最低。例如，在权重固定模式下，卷积核参数可以在PE中驻留数千个周期，极大地减少了数据移动开销。</li>
                    <li><strong>支持低精度计算：</strong>研究表明，神经网络具有很强的数值鲁棒性，推理阶段使用INT8甚至INT4精度几乎不影响准确率。NPU原生支持这些低精度格式，相比FP32可以实现4-8倍的吞吐量提升和能效改善。更重要的是，低精度计算大幅减少了存储需求和内存带宽压力。</li>
                    <li><strong>多级存储层次：</strong>NPU通常集成了大容量的片上SRAM（如TPU v3的32MB），配合精心设计的多级缓存结构（L0寄存器文件、L1局部缓存、L2全局缓存），有效缓解了"内存墙"问题。片上存储的访问能耗仅为片外DRAM的1/100。</li>
                </ul>
            </div>

            <h3>1.2 NPU vs CPU vs GPU</h3>
            
            <p>要深入理解NPU的价值，必须将其与CPU和GPU进行比较。这三种处理器代表了不同的设计理念和优化方向，各有其适用场景。通过对比分析，我们可以更好地理解NPU在AI计算领域的独特优势。</p>
            
            <h4>CPU：通用计算的王者</h4>
            <p>CPU（Central Processing Unit）是计算机系统的核心，其设计目标是提供最大的灵活性和通用性。现代CPU采用了复杂的乱序执行、分支预测、多级缓存等技术，能够高效处理各种类型的计算任务。然而，这种通用性是以牺牲专用性能为代价的。在神经网络计算中，CPU的劣势明显：</p>
            <ul>
                <li>有限的并行能力：即使是最先进的服务器CPU，核心数也仅有几十个</li>
                <li>复杂的控制逻辑：大量晶体管用于指令解码、乱序执行等，真正用于计算的比例较低</li>
                <li>缓存层次不匹配：CPU的缓存设计针对随机访问优化，而神经网络计算具有规律的访问模式</li>
            </ul>
            
            <h4>GPU：并行计算的先驱</h4>
            <p>GPU（Graphics Processing Unit）最初为图形渲染设计，后来演化为通用并行计算平台。GPU拥有数千个简单的计算核心，非常适合数据并行任务。在深度学习早期，GPU成为了训练神经网络的主力。但GPU也有其局限性：</p>
            <ul>
                <li>功耗问题：高端GPU功耗动辄300W以上，在边缘设备上难以应用</li>
                <li>内存带宽瓶颈：虽然配备了HBM等高带宽内存，但仍难以满足大规模模型的需求</li>
                <li>编程复杂：需要深入理解CUDA等并行编程模型，开发门槛高</li>
            </ul>
            
            <h4>NPU：AI计算的专家</h4>
            <p>NPU代表了一种全新的设计思路：针对特定应用领域进行极致优化。通过深入分析神经网络的计算特征，NPU在架构层面实现了多项创新，在AI推理任务上展现出显著优势。</p>
            
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>特性</th>
                            <th>CPU</th>
                            <th>GPU</th>
                            <th>NPU</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>设计目标</td>
                            <td>通用计算</td>
                            <td>并行图形/计算</td>
                            <td>AI/ML专用</td>
                        </tr>
                        <tr>
                            <td>架构特点</td>
                            <td>少量复杂核心</td>
                            <td>大量简单核心</td>
                            <td>专用MAC阵列</td>
                        </tr>
                        <tr>
                            <td>内存层次</td>
                            <td>多级缓存</td>
                            <td>高带宽显存</td>
                            <td>片上SRAM为主</td>
                        </tr>
                        <tr>
                            <td>功耗效率</td>
                            <td>中等（~0.1 TOPS/W）</td>
                            <td>较低（~0.5 TOPS/W）</td>
                            <td>高（~10 TOPS/W）</td>
                        </tr>
                        <tr>
                            <td>编程模型</td>
                            <td>串行为主</td>
                            <td>SIMD/SIMT</td>
                            <td>数据流</td>
                        </tr>
                        <tr>
                            <td>典型应用</td>
                            <td>操作系统、控制逻辑</td>
                            <td>图形渲染、科学计算</td>
                            <td>AI推理、边缘智能</td>
                        </tr>
                        <tr>
                            <td>灵活性</td>
                            <td>极高</td>
                            <td>高</td>
                            <td>低（专用）</td>
                        </tr>
                        <tr>
                            <td>成本效益（AI任务）</td>
                            <td>低</td>
                            <td>中</td>
                            <td>高</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            
            <div class="warning-box">
                <p><strong>重要提示：</strong>NPU并不是要取代CPU或GPU，而是作为协处理器与它们协同工作。在典型的AI系统中，CPU负责控制和预处理，GPU负责训练，NPU负责推理，三者各司其职，共同构建高效的计算平台。</p>
            </div>

            <h3>1.3 NPU的应用场景</h3>
            
            <p>NPU的应用场景广泛分布在从边缘到云端的各个领域。根据部署位置和应用特点，可以将NPU的应用场景分为边缘端和数据中心两大类。每类场景对NPU的设计提出了不同的要求，推动了NPU架构的多样化发展。</p>
            
            <h4>边缘端应用</h4>
            <p>边缘计算是NPU最重要的应用领域之一。在边缘设备上部署AI能力，可以实现低延迟、保护隐私、节省带宽等优势。边缘端NPU面临的主要挑战是在极其有限的功耗和成本预算下提供足够的计算能力。</p>
            
            <ul>
                <li><strong>智能手机：</strong>现代智能手机中的NPU已经成为标配，支撑着丰富的AI应用：
                    <ul>
                        <li>人脸识别：3D结构光或ToF深度信息处理，活体检测，表情识别</li>
                        <li>计算摄影：夜景模式、HDR+、人像模式、超分辨率</li>
                        <li>语音助手：唤醒词检测、语音识别、自然语言理解</li>
                        <li>系统优化：应用预测、电池管理、性能调度</li>
                    </ul>
                </li>
                
                <li><strong>智能摄像头：</strong>安防和智能家居领域的核心设备，NPU使其具备本地智能分析能力：
                    <ul>
                        <li>实时物体检测：人、车、动物等目标的检测和跟踪</li>
                        <li>行为分析：异常行为检测、人流统计、热力图生成</li>
                        <li>特征识别：人脸识别、车牌识别、商品识别</li>
                        <li>隐私保护：本地处理避免视频上传，保护用户隐私</li>
                    </ul>
                </li>
                
                <li><strong>自动驾驶：</strong>车载NPU是实现高级辅助驾驶（ADAS）和自动驾驶的关键：
                    <ul>
                        <li>感知融合：摄像头、激光雷达、毫米波雷达数据融合</li>
                        <li>目标检测：车辆、行人、交通标志、车道线识别</li>
                        <li>路径规划：实时轨迹预测和决策</li>
                        <li>功能安全：满足ISO 26262等汽车安全标准</li>
                    </ul>
                </li>
                
                <li><strong>IoT设备：</strong>物联网设备通过集成NPU实现边缘智能：
                    <ul>
                        <li>语音唤醒：超低功耗always-on语音检测</li>
                        <li>异常检测：工业设备预测性维护</li>
                        <li>环境感知：智能传感器数据处理</li>
                        <li>边缘推理：本地决策，减少云端依赖</li>
                    </ul>
                </li>
            </ul>

            <h4>数据中心应用</h4>
            <p>数据中心NPU追求的是极致的性能和吞吐量。与边缘端不同，数据中心可以提供充足的功耗和散热条件，使得NPU可以采用更激进的设计，集成更多的计算资源。</p>
            
            <ul>
                <li><strong>推理服务器：</strong>为大规模在线AI服务提供高性能推理：
                    <ul>
                        <li>搜索排序：实时处理数十亿级别的查询请求</li>
                        <li>推荐系统：个性化推荐，CTR预估</li>
                        <li>内容理解：图像分类、视频分析、文本理解</li>
                        <li>多租户支持：硬件虚拟化，资源隔离</li>
                    </ul>
                </li>
                
                <li><strong>训练加速：</strong>虽然GPU仍是训练的主力，但专用NPU在某些场景下更有优势：
                    <ul>
                        <li>分布式训练：高速互联支持模型并行和数据并行</li>
                        <li>混合精度训练：FP16/BF16/FP32灵活切换</li>
                        <li>稀疏化训练：结构化稀疏支持</li>
                        <li>定制化优化：针对特定模型架构的硬件优化</li>
                    </ul>
                </li>
                
                <li><strong>AI超算：</strong>构建专用的AI超级计算机：
                    <ul>
                        <li>大模型训练：支持万亿参数级别的模型</li>
                        <li>科学计算：蛋白质折叠、气象预测、分子动力学</li>
                        <li>强化学习：大规模并行环境模拟</li>
                        <li>联邦学习：分布式隐私保护学习</li>
                    </ul>
                </li>
            </ul>
            
            <div class="info-box">
                <p><strong>发展趋势：</strong>随着AI应用的普及，NPU正在向更多领域扩展。未来我们将看到NPU在可穿戴设备、AR/VR、机器人、卫星等领域的广泛应用。同时，软硬件协同设计、存内计算、光计算等新技术也在不断推动NPU架构的创新。</p>
            </div>

            <h3>1.4 主流NPU架构概览</h3>
            
            <p>了解主流NPU架构的设计理念和技术特点，对于深入理解NPU设计至关重要。本节将详细介绍几种代表性的NPU架构，分析它们的设计思路、技术创新和应用特点。每种架构都代表了不同的设计哲学和技术路线，通过比较分析，我们可以更好地理解NPU设计的多样性和演进方向。</p>
            
            <h4>1.4.1 Google TPU</h4>
            <p>Google的Tensor Processing Unit (TPU)是业界最早大规模部署的专用AI加速器之一。TPU的设计充分体现了"领域专用架构"的理念，通过针对性优化获得了极高的性能功耗比。Google从2013年开始TPU项目，最初的目标是加速数据中心的推理工作负载，特别是语音识别和图像搜索等应用。</p>
            
            <p><strong>TPU v1的创新设计：</strong></p>
            <p>TPU v1采用了革命性的脉动阵列架构，这是其最核心的创新。脉动阵列的设计灵感来自于生物学中的心脏跳动，数据像血液一样有节奏地在处理单元间流动。在256×256的脉动阵列中，权重从上到下流动并在每个PE中驻留，激活值从左到右流动，部分和在垂直方向累积。这种设计极大地减少了数据移动，提高了能效。</p>
            
            <div class="code-block">
// TPU v1 架构特点
- 脉动阵列（Systolic Array）：256x256 MACs
- 片上缓存：24MB Unified Buffer
- 主频：700MHz
- 峰值性能：92 TOPS (INT8)
- 内存带宽：34 GB/s
- 工艺节点：28nm
- 功耗：40W（典型）
- 面积：331 mm²

// 脉动阵列的优势
1. 数据复用率高：每个数据可被多个PE使用
2. 简单的控制逻辑：规律的数据流动模式
3. 高利用率：几乎100%的计算单元利用率
4. 低功耗：减少了数据搬移的能耗开销
            </div>
            
            <p>TPU v1的另一个重要创新是采用了专用的指令集架构（ISA）。与传统的RISC或CISC不同，TPU的指令集专门为神经网络设计，包括矩阵乘法指令、激活函数指令、归一化指令等。一条矩阵乘法指令可以触发数十万次MAC运算，极大地提高了指令效率。</p>
            
            <p><strong>TPU演进历程：</strong></p>
            <p>从TPU v1到最新的TPU v4，Google持续推动着架构创新。TPU v2引入了浮点运算支持，使其能够进行模型训练；TPU v3大幅提升了内存容量和带宽；TPU v4则引入了稀疏计算加速，进一步提高了效率。这种持续的演进反映了AI工作负载的快速变化和硬件设计的不断创新。</p>

            <h4>1.4.2 华为Ascend</h4>
            <p>华为Ascend系列NPU代表了中国在AI芯片领域的最高成就。Ascend采用了独创的达芬奇架构（Da Vinci Architecture），这是一种全新的AI计算架构，从底层重新设计以适应AI计算的特点。达芬奇架构的核心理念是"全场景覆盖"，从端侧的Ascend 310到云端的Ascend 910，采用统一的架构设计，大大简化了软件栈的复杂度。</p>
            
            <p><strong>达芬奇架构的核心创新：</strong></p>
            <p>达芬奇架构最重要的创新是3D Cube计算引擎。与传统的2D脉动阵列不同，Cube引擎在三个维度上组织计算单元，能够更高效地处理多维张量运算。这种设计特别适合处理卷积神经网络中的多通道特征图，可以在一个时钟周期内完成整个卷积核的计算。</p>
            
            <div class="code-block">
// Ascend 910 架构特点
- 达芬奇架构：3D Cube计算单元
- AI Core数量：32个
- 片上缓存：多级缓存体系（L0/L1/L2）
- 峰值性能：256 TFLOPS (FP16) / 512 TOPS (INT8)
- HBM内存：32GB HBM2
- 内存带宽：1.2 TB/s
- 互联：高速片间互联，支持多芯片扩展
- 工艺：7nm EUV
- 功耗：310W（最大）

// 3D Cube引擎特点
1. 16x16x16的计算矩阵
2. 支持混合精度计算（FP16/INT8/INT4）
3. 硬件级稀疏计算加速
4. 灵活的数据流控制
            </div>
            
            <p>Ascend的另一个重要特性是其完整的软件生态系统。华为提供了CANN（Compute Architecture for Neural Networks）软件栈，包括图编译器、算子库、运行时系统等。CANN支持主流深度学习框架，如TensorFlow、PyTorch等，大大降低了开发者的使用门槛。</p>
            
            <p><strong>端云协同设计：</strong></p>
            <p>Ascend系列的一个独特优势是端云协同能力。Ascend 310针对边缘推理优化，功耗仅8W，而Ascend 910则面向数据中心训练。两者采用相同的达芬奇架构和软件栈，使得模型可以无缝地在端侧和云端之间迁移，这对于实际应用部署具有重要意义。</p>

            <h4>1.4.3 寒武纪MLU</h4>
            <p>寒武纪是中国最早专注于AI芯片的公司之一，其MLU（Machine Learning Unit）系列产品在国内外都有广泛应用。寒武纪的创始团队来自中科院计算所，在神经网络处理器架构研究方面有深厚积累。MLU架构的设计理念是"通用性与专用性的平衡"，既要保证对各类神经网络的良好支持，又要实现高效的计算性能。</p>
            
            <p><strong>MLUv02架构创新：</strong></p>
            <p>MLUv02是寒武纪第二代架构，相比第一代有了重大改进。最核心的创新是引入了更灵活的计算核心设计，每个MLU Core内部包含多个处理集群，可以独立执行不同的任务。这种设计提高了硬件利用率，特别是在处理不规则网络结构时表现优异。</p>
            
            <div class="code-block">
// MLU 290 架构特点
- MLUv02架构：第二代AI处理器架构
- MLU Core数量：16个
- 处理集群：每个Core包含4个集群
- 片上缓存：48MB SRAM（分布式设计）
- 内存：32GB LPDDR4x
- 内存带宽：307.2 GB/s
- 峰值性能：1024 TOPS (INT4) / 256 TOPS (INT8)
- 工艺：7nm
- 功耗：75W（典型负载）

// MLU Core内部结构
1. 向量处理单元（VPU）：处理向量运算
2. 矩阵处理单元（MPU）：专门的矩阵运算
3. 内存处理单元（MLU）：管理数据搬移
4. 控制单元（CU）：指令调度和控制
            </div>
            
            <p>MLU的一个独特优势是其强大的稀疏计算能力。随着模型剪枝和稀疏化技术的发展，如何高效处理稀疏张量成为一个重要课题。MLU 290通过硬件级的稀疏检测和跳过机制，可以在处理稀疏模型时获得2-4倍的性能提升。</p>
            
            <p><strong>软件生态与易用性：</strong></p>
            <p>寒武纪提供了完整的软件开发工具链Cambricon Neuware，包括编程框架、编译器、性能分析工具等。特别值得一提的是其BANG语言（类似于CUDA），允许开发者直接编写MLU上的并行程序，为高级用户提供了更大的优化空间。同时，寒武纪也支持主流框架的模型直接部署，降低了普通用户的使用门槛。</p>

            <h4>1.4.4 Groq TSP</h4>
            <p>Groq的Tensor Streaming Processor (TSP)代表了一种全新的AI计算架构思路——通过消除片上存储瓶颈和实现确定性性能来革新AI推理。Groq由前Google TPU团队成员创立，其TSP架构体现了对传统冯·诺依曼架构的彻底反思。</p>
            
            <p><strong>TSP的革命性设计：</strong></p>
            <p>TSP最大的创新在于其"无缓存"设计理念。传统处理器依赖多级缓存来缓解内存墙问题，但这带来了性能的不确定性。TSP通过软件编译时确定所有数据移动路径，硬件上实现了一个巨大的、完全确定性的数据流网络。每个计算单元都确切知道数据何时到达，无需等待或猜测。</p>
            
            <div class="code-block">
// Groq TSP 架构特点
- 芯片规模：14nm工艺，面积约700mm²
- 计算单元：超过100万个MAC单元
- 片上存储：220MB SRAM（分布式）
- 互连网络：确定性的芯片级数据流网络
- 主频：1GHz
- 峰值性能：1 POPS (INT8) / 250 TFLOPS (FP16)
- 功耗：300W（数据中心版本）

// 确定性执行的优势
1. 零等待时间：数据准时到达，无需缓存miss
2. 100%硬件利用率：每个周期都在执行有效计算
3. 极低延迟：批大小为1时仍保持高性能
4. 可预测性：性能完全由编译器决定
            </div>
            
            <p>TSP的另一个关键创新是其编译器技术。Groq的编译器不仅负责将神经网络映射到硬件，更是整个系统的"大脑"。它在编译时就确定了每个数据的精确移动路径和时间，生成的是一个精确到时钟周期的执行计划。这种"软件定义硬件"的理念使得TSP能够为每个特定模型实现最优的数据流。</p>

            <h4>1.4.5 Wave Computing DPU</h4>
            <p>Wave Computing（现已被MIPS收购）的Dataflow Processing Unit (DPU)是基于数据流计算模型的AI处理器。与传统的控制流架构不同，DPU采用了异步数据流执行模型，这种架构特别适合处理具有大量并行性的深度学习工作负载。</p>
            
            <p><strong>DPU的数据流架构：</strong></p>
            <p>DPU的核心是其粗粒度可重构阵列（CGRA）。与FPGA的细粒度可重构不同，DPU的处理单元是完整的算术逻辑单元，可以高效执行深度学习所需的运算。数据流架构意味着指令的执行完全由数据的可用性驱动，当所有输入操作数准备就绪时，运算自动触发。</p>
            
            <div class="code-block">
// Wave DPU 架构特点
- 处理单元：16,384个处理元素（PE）
- 架构类型：粗粒度可重构阵列（CGRA）
- 执行模型：异步数据流
- 片上内存：分布式SRAM，总计数十MB
- 支持精度：FP16/INT8/INT16
- 互连：可编程的数据流网络

// 数据流执行的特点
1. 无需程序计数器：运算由数据驱动
2. 自然的流水线：不同阶段自动重叠
3. 动态调度：硬件自动处理依赖关系
4. 高并行度：数千个运算可同时进行
            </div>
            
            <p>DPU的一个独特优势是其对稀疏性的原生支持。在数据流模型中，零值可以被自然地"跳过"——如果某个运算的输入是零，该运算可以不被触发，从而节省功耗。这使得DPU在处理剪枝后的稀疏模型时特别高效。</p>

            <h4>1.4.6 SambaNova RDU</h4>
            <p>SambaNova Systems的Reconfigurable Dataflow Unit (RDU)代表了可重构计算在AI领域的最新进展。RDU结合了ASIC的高性能和FPGA的灵活性，通过软件定义的方式实现硬件的动态重构，特别适合大规模模型的训练和推理。</p>
            
            <p><strong>RDU的分层架构：</strong></p>
            <p>RDU采用了分层的可重构架构。最底层是计算和内存单元，中间层是可编程的互连网络，顶层是控制和调度逻辑。这种分层设计使得RDU可以针对不同的工作负载进行优化，从密集的矩阵运算到稀疏的图计算都能高效处理。</p>
            
            <div class="code-block">
// SambaNova RDU 架构特点
- 工艺节点：7nm
- 计算单元：数千个可重构数据流单元
- 内存系统：分层内存，包括HBM和片上SRAM
- 互连：三维环面（3D Torus）拓扑
- 支持精度：BF16/FP32/TF32
- 系统扩展：支持多芯片互连

// RDU的关键创新
1. 数据流图映射：直接将计算图映射到硬件
2. 动态重构：运行时可改变硬件配置
3. 内存计算融合：计算单元紧邻内存
4. 编译器协同：编译器和硬件深度集成
            </div>
            
            <p>SambaNova的独特之处在于其"全栈"方法。公司不仅提供硬件，还提供完整的软件栈和预优化的模型。其SambaFlow软件能够自动将PyTorch或TensorFlow模型映射到RDU硬件上，并进行深度优化。这种端到端的解决方案大大降低了用户的使用门槛。</p>

            <h4>1.4.7 爱芯元智 AiPU</h4>
            <p>爱芯元智（AXera）是中国新兴的AI芯片公司，其AiPU产品线专注于边缘AI计算。AiPU的设计理念是在有限的功耗和成本预算下，提供最优的AI推理性能，特别针对视觉AI应用进行了深度优化。</p>
            
            <p><strong>AiPU的混合精度架构：</strong></p>
            <p>AiPU最大的特色是其灵活的混合精度计算能力。芯片内部集成了多种计算单元，可以同时支持INT4、INT8、INT16和FP16等多种精度。更重要的是，AiPU支持层级精度配置——同一个模型的不同层可以使用不同的精度，从而在保证精度的前提下最大化性能。</p>
            
            <div class="code-block">
// 爱芯元智 AX630A 架构特点
- 工艺：12nm
- NPU算力：14.4 TOPS (INT8)
- CPU：四核Cortex-A53
- ISP：支持4K@30fps
- 视频编解码：H.264/H.265
- 内存接口：LPDDR4/4x
- 功耗：3-5W（典型）

// 混合精度计算特性
1. 动态精度切换：运行时可调整精度
2. 层级精度优化：每层独立配置精度
3. 量化引擎：硬件加速的量化/反量化
4. 精度感知训练：支持QAT模型部署
            </div>
            
            <p>AiPU的另一个亮点是其强大的视觉处理能力。芯片集成了高性能ISP（图像信号处理器）和视频编解码单元，可以直接处理来自摄像头的原始数据。这种"端到端"的设计避免了数据在不同处理单元间的搬移，大大提高了系统效率。对于智能摄像头、无人机等应用场景，AiPU提供了理想的解决方案。</p>

            <div class="exercise">
                <h4>练习题集 1</h4>
                <p>通过以下练习题，你可以检验对NPU基础概念的理解程度。这些题目涵盖了理论知识、计算分析和实践编程等多个方面。建议先独立思考，再查看参考答案。记住，理解原理比记忆答案更重要。</p>
                
                <div class="question">
                    <p><strong>题目1.1：</strong>简述NPU相比GPU在AI推理任务上的三个主要优势。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <ol>
                            <li><strong>功耗效率更高：</strong>NPU采用专用硬件设计，去除了GPU中用于图形渲染的部分，并针对神经网络运算进行优化，在相同性能下功耗可降低50%以上。</li>
                            <li><strong>推理延迟更低：</strong>NPU的数据流架构和片上存储设计减少了内存访问延迟，批处理大小为1时性能优势明显。</li>
                            <li><strong>支持低精度计算：</strong>NPU原生支持INT8、INT4等低精度格式，可在保持精度的同时大幅提升吞吐量。</li>
                        </ol>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目1.2：</strong>解释什么是脉动阵列（Systolic Array），以及它为什么适合神经网络计算？</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p>脉动阵列是一种规则的处理单元阵列，数据像心脏跳动一样有节奏地在阵列中流动。其特点包括：</p>
                        <ul>
                            <li><strong>数据复用：</strong>输入数据在多个PE间传递，减少内存访问</li>
                            <li><strong>规则结构：</strong>易于实现和扩展，面积利用率高</li>
                            <li><strong>高并行度：</strong>可同时执行大量MAC运算</li>
                        </ul>
                        <p>适合神经网络的原因：</p>
                        <ol>
                            <li>神经网络主要是矩阵乘法运算，与脉动阵列的计算模式匹配</li>
                            <li>权重可以预加载并保持静止，提高数据复用率</li>
                            <li>规则的计算模式便于流水线设计</li>
                        </ol>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目1.3：</strong>某NPU的MAC阵列为16x16，主频为1GHz，每个周期每个MAC可完成2次INT8运算。计算该NPU的理论峰值性能（TOPS）。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p>计算步骤：</p>
                        <ol>
                            <li>MAC单元总数 = 16 × 16 = 256</li>
                            <li>每秒周期数 = 1GHz = 10^9 cycles/s</li>
                            <li>每周期运算次数 = 256 × 2 = 512 ops/cycle</li>
                            <li>峰值性能 = 10^9 × 512 = 512 × 10^9 ops/s = 512 GOPS = 0.512 TOPS</li>
                        </ol>
                        <p><strong>答案：0.512 TOPS</strong></p>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目1.4：</strong>设计一个简单的4x4脉动阵列，用Verilog描述其中一个PE（Processing Element）的基本结构。PE需要支持乘累加操作。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module PE #(
    parameter DATA_WIDTH = 8,
    parameter ACC_WIDTH = 32
)(
    input wire clk,
    input wire rst_n,
    input wire en,
    
    // 数据输入
    input wire [DATA_WIDTH-1:0] data_in,    // 从左边PE传入
    input wire [DATA_WIDTH-1:0] weight_in,  // 从上边PE传入
    
    // 数据输出
    output reg [DATA_WIDTH-1:0] data_out,   // 传给右边PE
    output reg [DATA_WIDTH-1:0] weight_out, // 传给下边PE
    
    // 部分和
    input wire [ACC_WIDTH-1:0] psum_in,     // 从上边PE传入
    output reg [ACC_WIDTH-1:0] psum_out     // 传给下边PE
);

    // 内部寄存器
    reg [DATA_WIDTH-1:0] weight_reg;
    wire [2*DATA_WIDTH-1:0] mult_result;
    wire [ACC_WIDTH-1:0] acc_result;
    
    // 乘法器
    assign mult_result = data_in * weight_reg;
    
    // 加法器
    assign acc_result = psum_in + {{(ACC_WIDTH-2*DATA_WIDTH){mult_result[2*DATA_WIDTH-1]}}, mult_result};
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            data_out <= 0;
            weight_out <= 0;
            psum_out <= 0;
            weight_reg <= 0;
        end else if (en) begin
            // 数据向右传递
            data_out <= data_in;
            
            // 权重向下传递并保存
            weight_out <= weight_in;
            weight_reg <= weight_in;
            
            // 累加结果向下传递
            psum_out <= acc_result;
        end
    end
endmodule
                        </div>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目1.5：</strong>分析边缘端NPU和云端NPU在设计上的主要差异，至少列举4个方面。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <table>
                            <tr>
                                <th>设计方面</th>
                                <th>边缘端NPU</th>
                                <th>云端NPU</th>
                            </tr>
                            <tr>
                                <td>功耗预算</td>
                                <td>通常&lt;5W，需要极致的功耗优化</td>
                                <td>可达100W以上，更关注性能</td>
                            </tr>
                            <tr>
                                <td>内存系统</td>
                                <td>小容量片上SRAM，有限的外部带宽</td>
                                <td>大容量HBM/GDDR，高带宽</td>
                            </tr>
                            <tr>
                                <td>计算精度</td>
                                <td>主要INT8/INT4，追求高压缩比</td>
                                <td>FP16/FP32/INT8混合精度</td>
                            </tr>
                            <tr>
                                <td>芯片面积</td>
                                <td>&lt;50mm²，成本敏感</td>
                                <td>可达800mm²，性能优先</td>
                            </tr>
                            <tr>
                                <td>应用场景</td>
                                <td>推理为主，实时性要求高</td>
                                <td>训练和推理，吞吐量优先</td>
                            </tr>
                        </table>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目1.6：</strong>计算题：某手机NPU需要实时处理1080p@30fps的视频流进行物体检测。假设每帧需要100M次MAC运算，计算所需的最小算力（GOPS）。如果NPU效率为70%，实际需要多少GOPS的峰值性能？</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p>计算步骤：</p>
                        <ol>
                            <li>每秒帧数：30 fps</li>
                            <li>每帧运算量：100M = 10^8 ops</li>
                            <li>每秒运算量：30 × 10^8 = 3 × 10^9 ops = 3 GOPS</li>
                            <li>考虑70%效率，实际需要：3 ÷ 0.7 ≈ 4.29 GOPS</li>
                        </ol>
                        <p><strong>答案：最小算力需求为3 GOPS，考虑效率后需要4.29 GOPS的峰值性能。</strong></p>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目1.7：</strong>编程题：用Python实现一个简单的脉动阵列模拟器，计算两个4x4矩阵的乘法。要求展示数据在阵列中的流动过程。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
import numpy as np

class SystolicArray:
    def __init__(self, size=4):
        self.size = size
        self.array = [[{'a': 0, 'b': 0, 'c': 0} for _ in range(size)] for _ in range(size)]
        self.cycle = 0
        
    def reset(self):
        """重置脉动阵列"""
        self.array = [[{'a': 0, 'b': 0, 'c': 0} for _ in range(size)] for _ in range(size)]
        self.cycle = 0
    
    def step(self, a_inputs, b_inputs):
        """执行一个时钟周期"""
        # 创建新的阵列状态
        new_array = [[{'a': 0, 'b': 0, 'c': 0} for _ in range(self.size)] for _ in range(self.size)]
        
        # 更新每个PE
        for i in range(self.size):
            for j in range(self.size):
                # 获取输入
                if j == 0:
                    a_in = a_inputs[i] if i < len(a_inputs) else 0
                else:
                    a_in = self.array[i][j-1]['a']
                    
                if i == 0:
                    b_in = b_inputs[j] if j < len(b_inputs) else 0
                else:
                    b_in = self.array[i-1][j]['b']
                
                # 计算MAC
                new_array[i][j]['c'] = self.array[i][j]['c'] + a_in * b_in
                
                # 传递数据
                new_array[i][j]['a'] = a_in
                new_array[i][j]['b'] = b_in
        
        self.array = new_array
        self.cycle += 1
        
    def get_result(self):
        """获取计算结果"""
        result = np.zeros((self.size, self.size))
        for i in range(self.size):
            for j in range(self.size):
                result[i][j] = self.array[i][j]['c']
        return result
    
    def print_state(self):
        """打印当前状态"""
        print(f"\n周期 {self.cycle}:")
        for i in range(self.size):
            for j in range(self.size):
                pe = self.array[i][j]
                print(f"({pe['a']},{pe['b']},{pe['c']:3})", end=" ")
            print()

# 使用示例
def matrix_multiply_systolic(A, B):
    """使用脉动阵列计算矩阵乘法"""
    size = len(A)
    sa = SystolicArray(size)
    
    # 准备输入数据（需要错开时序）
    a_streams = []
    b_streams = []
    
    for i in range(size):
        # A矩阵的行需要错开输入
        a_stream = [0] * i + list(A[i]) + [0] * (size - 1)
        a_streams.append(a_stream)
        
        # B矩阵的列需要错开输入
        b_stream = [0] * i + [B[j][i] for j in range(size)] + [0] * (size - 1)
        b_streams.append(b_stream)
    
    # 执行计算
    max_cycles = 3 * size - 2  # 完成计算需要的周期数
    
    for cycle in range(max_cycles):
        # 准备这个周期的输入
        a_inputs = []
        b_inputs = []
        
        for i in range(size):
            if cycle < len(a_streams[i]):
                a_inputs.append(a_streams[i][cycle])
            else:
                a_inputs.append(0)
                
            if cycle < len(b_streams[i]):
                b_inputs.append(b_streams[i][cycle])
            else:
                b_inputs.append(0)
        
        sa.step(a_inputs[:size], b_inputs[:size])
        sa.print_state()
    
    return sa.get_result()

# 测试
if __name__ == "__main__":
    A = np.array([[1, 2, 3, 4],
                  [5, 6, 7, 8],
                  [9, 10, 11, 12],
                  [13, 14, 15, 16]])
    
    B = np.array([[1, 0, 0, 0],
                  [0, 1, 0, 0],
                  [0, 0, 1, 0],
                  [0, 0, 0, 1]])
    
    print("矩阵A:")
    print(A)
    print("\n矩阵B:")
    print(B)
    
    result = matrix_multiply_systolic(A, B)
    print("\n脉动阵列计算结果:")
    print(result)
    
    print("\nNumPy验证结果:")
    print(np.matmul(A, B))
                        </div>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目1.8：</strong>分析题：为什么大多数NPU采用INT8而不是FP32进行推理？从硬件实现角度分析其优势。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p>NPU采用INT8进行推理的硬件优势：</p>
                        <ol>
                            <li><strong>硬件面积：</strong>
                                <ul>
                                    <li>INT8乘法器面积约为FP32的1/8</li>
                                    <li>INT8加法器面积约为FP32的1/4</li>
                                    <li>相同面积可集成4-8倍的计算单元</li>
                                </ul>
                            </li>
                            <li><strong>功耗效率：</strong>
                                <ul>
                                    <li>INT8运算功耗约为FP32的1/4</li>
                                    <li>数据位宽减少，总线功耗降低75%</li>
                                </ul>
                            </li>
                            <li><strong>内存带宽：</strong>
                                <ul>
                                    <li>数据量减少4倍，缓解内存瓶颈</li>
                                    <li>片上缓存可存储更多数据</li>
                                </ul>
                            </li>
                            <li><strong>时序优化：</strong>
                                <ul>
                                    <li>INT8运算延迟更低，便于提高主频</li>
                                    <li>流水线级数减少，控制逻辑简化</li>
                                </ul>
                            </li>
                        </ol>
                        <p><strong>实际应用中通过量化感知训练，INT8精度损失通常小于1%，是性能功耗比的最佳选择。</strong></p>
                    </div>
                </div>
            </div>
        </div>

        <div id="chapter2" class="chapter">
            <h2>第2章：神经网络计算基础</h2>
            
            <p>要设计高效的NPU，必须深入理解神经网络的计算本质。本章将从硬件设计者的视角，详细分析神经网络的基本运算、数据流特征和优化机会。通过对计算模式的深入剖析，我们能够识别出硬件加速的关键点，为后续的NPU架构设计奠定基础。</p>
            
            <h3>2.1 神经网络基本运算</h3>
            
            <p>神经网络虽然结构复杂，但其底层运算却相对简单和规律。这种"复杂系统由简单元素构成"的特性，正是硬件加速的机会所在。通过对基本运算的深入分析，我们可以设计出高效的硬件加速单元。</p>
            
            <h4>2.1.1 神经元计算模型</h4>
            <p>神经元是神经网络的基本计算单元，其灵感来源于生物神经元。从数学角度看，一个神经元执行的是加权求和后的非线性变换。虽然概念简单，但当数百万个神经元协同工作时，就能展现出强大的学习和推理能力。</p>
            
            <p>人工神经元的数学模型可以表示为：</p>
            <div class="code-block">
y = f(Σ(wi * xi) + b)

其中：
- xi：输入信号（来自上一层神经元的输出）
- wi：连接权重（通过学习得到的参数）
- wi * xi：加权输入 (Weighted Input)
- Σ(...)：对所有输入的求和 (Summation)  
- b：偏置项 (Bias)，用于调节神经元的激活阈值
- f(...)：激活函数 (Activation Function)，引入非线性
- y：神经元的输出
            </div>
            
            <p>从硬件实现的角度，我们需要关注这个计算过程的几个关键特征：</p>
            
            <div class="info-box">
                <p><strong>硬件视角：计算分解</strong></p>
                <p>神经元的计算可以分解为以下几个阶段，每个阶段对应不同的硬件需求：</p>
                <ol>
                    <li><strong>乘法运算阶段：</strong>wi * xi
                        <ul>
                            <li>需要大量并行乘法器</li>
                            <li>数据类型通常为定点数（INT8/INT16）或浮点数（FP16/FP32）</li>
                            <li>乘法器的位宽直接影响芯片面积和功耗</li>
                        </ul>
                    </li>
                    <li><strong>累加运算阶段：</strong>Σ(wi * xi)
                        <ul>
                            <li>需要加法树或累加器</li>
                            <li>要考虑累加过程中的位宽增长</li>
                            <li>流水线设计可以提高吞吐量</li>
                        </ul>
                    </li>
                    <li><strong>偏置加法：</strong>+ b
                        <ul>
                            <li>简单的加法运算</li>
                            <li>可以与累加阶段合并</li>
                        </ul>
                    </li>
                    <li><strong>激活函数：</strong>f(...)
                        <ul>
                            <li>不同激活函数的硬件复杂度差异很大</li>
                            <li>可以使用查找表（LUT）或分段线性近似</li>
                            <li>某些函数（如ReLU）可以用简单逻辑实现</li>
                        </ul>
                    </li>
                </ol>
            </div>
            
            <p><strong>计算密度分析：</strong></p>
            <p>在典型的全连接层中，假设输入维度为N，输出维度为M，则需要：</p>
            <ul>
                <li>乘法运算：N × M 次</li>
                <li>加法运算：(N-1) × M 次（累加）+ M 次（偏置）</li>
                <li>激活函数：M 次</li>
            </ul>
            
            <p>可以看出，乘累加（MAC）运算占据了绝大部分的计算量。这就是为什么MAC阵列成为NPU设计的核心。一个高效的MAC阵列设计，可以在单个时钟周期内完成大量的乘累加运算，这是NPU相比通用处理器的主要优势来源。</p>

            <p><strong>量化（Quantization）：NPU设计的关键优化</strong></p>
            <p>在传统的深度学习训练中，通常使用32位浮点数（FP32）来保证精度。然而，在推理阶段，这种精度往往是过度的。量化技术通过降低数值精度来换取显著的硬件效率提升：</p>
            
            <p><strong>1. 量化的动机：</strong></p>
            <ul>
                <li><strong>功耗降低：</strong>INT8乘法器的功耗仅为FP32的1/30</li>
                <li><strong>面积缩减：</strong>INT8乘法器面积约为FP32的1/16</li>
                <li><strong>带宽节省：</strong>数据位宽减少4倍，内存带宽需求相应降低</li>
                <li><strong>性能提升：</strong>同样的硬件面积可以部署更多的INT8 MAC单元</li>
            </ul>
            
            <p><strong>2. 量化的挑战与硬件支持：</strong></p>
            <ul>
                <li><strong>精度损失：</strong>需要精心的量化策略（如感知量化训练QAT）</li>
                <li><strong>溢出风险：</strong>累加过程中需要防止整数溢出</li>
                <li><strong>非对称量化支持：</strong>硬件需要支持零点（Zero-Point）和缩放因子（Scale Factor）的计算</li>
            </ul>
            
            <div class="code-block">
// 非对称量化的硬件实现
quantized_value = round((float_value / scale) + zero_point)
dequantized_value = (quantized_value - zero_point) * scale

// 硬件需要高效实现：
// 1. 缩放因子的乘法（通常使用移位近似）
// 2. 零点的加减运算
// 3. 饱和运算防止溢出
            </div>
            
            <p><strong>3. 动态定点数（Dynamic Fixed-Point）：</strong></p>
            <p>现代NPU通常支持动态调整定点数的小数位，在不同层使用不同的量化参数，以在精度和效率间取得最佳平衡。硬件需要支持：</p>
            <ul>
                <li>可配置的移位器（Configurable Shifters）</li>
                <li>饱和逻辑（Saturation Logic）</li>
                <li>溢出检测（Overflow Detection）</li>
            </ul>

            <h4>2.1.2 激活函数的硬件实现</h4>
            <p>激活函数是神经网络的关键组成部分，它为网络引入非线性，使得网络能够学习复杂的函数映射关系。从硬件设计的角度，不同激活函数的实现复杂度差异巨大。选择合适的激活函数，不仅影响模型的准确性，还直接影响NPU的面积、功耗和性能。</p>
            
            <p><strong>激活函数的硬件实现策略：</strong></p>
            <p>在NPU设计中，激活函数的实现通常采用以下几种策略：</p>
            <ol>
                <li><strong>直接计算法：</strong>对于简单的函数如ReLU，使用基本逻辑门即可实现</li>
                <li><strong>查找表法（LUT）：</strong>预先计算函数值存储在ROM中，通过查表获得结果</li>
                <li><strong>分段线性逼近：</strong>将复杂函数分段用直线逼近，平衡精度和硬件成本</li>
                <li><strong>多项式逼近：</strong>使用泰勒级数或其他多项式逼近复杂函数</li>
                <li><strong>CORDIC算法：</strong>用于计算三角函数和指数函数的迭代算法</li>
            </ol>
            
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>激活函数</th>
                            <th>公式</th>
                            <th>硬件实现方式</th>
                            <th>硬件成本</th>
                            <th>设计考虑</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>ReLU</td>
                            <td>max(0, x)</td>
                            <td>比较器 + 选择器</td>
                            <td>极低</td>
                            <td>最简单高效，广泛使用</td>
                        </tr>
                        <tr>
                            <td>Leaky ReLU</td>
                            <td>max(αx, x)</td>
                            <td>乘法器 + 比较器 + 选择器</td>
                            <td>低</td>
                            <td>需要额外的乘法器</td>
                        </tr>
                        <tr>
                            <td>Sigmoid</td>
                            <td>1/(1+e^(-x))</td>
                            <td>查找表(LUT) / 分段线性逼近</td>
                            <td>高</td>
                            <td>需要大容量存储或复杂逻辑</td>
                        </tr>
                        <tr>
                            <td>Tanh</td>
                            <td>(e^x - e^(-x))/(e^x + e^(-x))</td>
                            <td>查找表(LUT) / 分段线性逼近</td>
                            <td>高</td>
                            <td>与Sigmoid类似的复杂度</td>
                        </tr>
                        <tr>
                            <td>GeLU</td>
                            <td>x * Φ(x)</td>
                            <td>多级查找表 + 插值</td>
                            <td>很高</td>
                            <td>需要高精度实现</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h3>2.2 矩阵乘法与卷积运算</h3>
            
            <p>矩阵运算是神经网络的计算核心。据统计，在典型的深度学习模型中，超过90%的计算时间都花费在矩阵乘法和卷积运算上。深入理解这些运算的特点，对于设计高效的NPU至关重要。本节将从算法原理、硬件映射和优化策略等多个角度，全面分析这些核心运算。</p>
            
            <h4>2.2.1 通用矩阵乘法（GEMM）</h4>
            <p>通用矩阵乘法（General Matrix Multiplication, GEMM）是线性代数的基础运算，也是全连接层、循环神经网络等结构的核心。在深度学习中，GEMM通常表示为：<code>Y = αXW + βY</code>，其中α和β是标量系数。</p>
            
            <p><strong>GEMM的计算特征分析：</strong></p>
            <p>考虑矩阵乘法 C = A × B，其中A的维度为M×K，B的维度为K×N，结果C的维度为M×N。这个运算具有以下特征：</p>
            <ul>
                <li><strong>计算密度：</strong>需要M×N×K次乘法和M×N×(K-1)次加法</li>
                <li><strong>数据复用：</strong>A的每个元素被复用N次，B的每个元素被复用M次</li>
                <li><strong>并行性：</strong>输出矩阵的每个元素可以独立计算，具有天然的并行性</li>
                <li><strong>访存比：</strong>计算访存比为O(MNK)/O(MK+KN+MN) = O(K)，K越大越有利</li>
            </ul>
            
            <div class="code-block">
// 矩阵乘法的基本实现
for (int i = 0; i < M; i++) {
    for (int j = 0; j < N; j++) {
        float sum = 0;
        for (int k = 0; k < K; k++) {
            sum += A[i][k] * B[k][j];  // MAC运算
        }
        C[i][j] = sum;
    }
}

// 硬件视角的优化考虑：
// 1. 内层循环是MAC运算，适合并行化
// 2. 数据复用：A的每一行被复用N次，B的每一列被复用M次
// 3. 访存模式：顺序访问A，跳跃访问B（缓存不友好）
// 4. 可以通过分块（tiling）提高缓存利用率
            </div>
            
            <p><strong>GEMM的硬件加速策略：</strong></p>
            <p>NPU通过以下策略加速GEMM运算：</p>
            <ol>
                <li><strong>空间并行化：</strong>使用二维MAC阵列，同时计算多个输出元素</li>
                <li><strong>时间流水线：</strong>将乘法和加法操作流水线化，提高吞吐量</li>
                <li><strong>数据分块：</strong>将大矩阵分解为小块，适配片上缓存大小</li>
                <li><strong>双缓冲技术：</strong>计算和数据传输重叠，隐藏内存延迟</li>
            </ol>

            <h4>2.2.2 卷积运算的实现方式</h4>
            
            <p>卷积是卷积神经网络（CNN）的核心运算，负责提取局部特征。与全连接层不同，卷积利用了参数共享和局部连接的特性，大大减少了参数量。然而，卷积的多维特性和复杂的数据访问模式，给硬件实现带来了独特的挑战。</p>
            
            <div class="warning-box">
                <p><strong>核心挑战：</strong>卷积运算涉及多维数据和复杂的访存模式，如何高效地映射到硬件是NPU设计的关键。主要挑战包括：</p>
                <ul>
                    <li>多重嵌套循环，循环边界复杂</li>
                    <li>数据复用模式不规则</li>
                    <li>需要处理边界填充（padding）</li>
                    <li>步长（stride）可能导致不规则访问</li>
                </ul>
            </div>

            <p><strong>方法1：Im2Col + GEMM</strong></p>
            <p>Im2Col（Image to Column）是将卷积转换为矩阵乘法的经典方法。这种方法通过数据重组，将卷积运算转化为标准的GEMM运算，从而可以复用已有的矩阵乘法硬件。</p>
            
            <div class="code-block">
// Im2Col转换示例
// 输入: [H, W, C_in]
// 卷积核: [K_h, K_w, C_in, C_out]
// 输出: [H_out, W_out, C_out]

// Step 1: Im2Col展开
// 将每个卷积窗口展开成一列
// 展开后矩阵大小: [K_h * K_w * C_in, H_out * W_out]

// Step 2: 矩阵乘法
// 权重矩阵: [C_out, K_h * K_w * C_in]
// 结果 = 权重矩阵 × Im2Col矩阵

// 优点：
// - 可以复用高效的GEMM硬件
// - 实现简单，易于优化
// - 适合大batch size的场景

// 缺点：
// - 内存开销大（K_h * K_w倍的数据冗余）
// - 数据重组本身需要时间
// - 对缓存不友好
            </div>
            
            <p><strong>Im2Col的内存开销分析：</strong></p>
            <p>假设输入特征图大小为224×224×3（典型的ImageNet输入），使用3×3卷积核，则Im2Col后的数据量为：</p>
            <ul>
                <li>原始数据：224 × 224 × 3 = 150,528 个元素</li>
                <li>Im2Col后：3 × 3 × 3 × 224 × 224 = 1,354,752 个元素</li>
                <li>数据膨胀：9倍</li>
            </ul>

            <p><strong>方法2：直接卷积</strong></p>
            <p>直接卷积是专门为卷积运算设计的硬件架构，避免了Im2Col的内存开销。这种方法通过巧妙的数据流设计和缓存策略，直接在输入数据上执行卷积运算。</p>
            
            <p><strong>直接卷积的数据流模式：</strong></p>
            <p>在硬件实现上，直接卷积有不同的数据流派，每种流派针对不同的优化目标：</p>
            <ul>
                <li><strong>输入固定流（Input Stationary）：</strong>最大化输入数据复用，适合大卷积核</li>
                <li><strong>权重固定流（Weight Stationary）：</strong>最小化权重读取，适合深度可分离卷积</li>
                <li><strong>输出固定流（Output Stationary）：</strong>最小化部分和的读写，适合标准卷积</li>
            </ul>
            
            <p><strong>直接卷积的关键组件：</strong></p>
            <ol>
                <li><strong>Line Buffer：</strong>缓存多行输入数据，支持垂直方向的数据复用</li>
                <li><strong>Window Buffer：</strong>提取当前卷积窗口的所有像素</li>
                <li><strong>MAC阵列：</strong>并行执行卷积窗口内的所有乘累加运算</li>
                <li><strong>控制逻辑：</strong>管理数据流动、处理边界条件</li>
            </ol>
            
            <div class="code-block">
// 直接卷积的硬件实现示例
module ConvolutionEngine #(
    parameter IN_WIDTH = 8,        // 输入数据位宽
    parameter WEIGHT_WIDTH = 8,    // 权重位宽
    parameter OUT_WIDTH = 32,      // 输出位宽（考虑累加后的位宽增长）
    parameter KERNEL_SIZE = 3,     // 卷积核大小
    parameter IN_CHANNELS = 64,    // 输入通道数
    parameter OUT_CHANNELS = 128   // 输出通道数
)(
    input clk,
    input rst_n,
    input [IN_WIDTH-1:0] pixel_in,
    input [WEIGHT_WIDTH-1:0] weight,
    input valid_in,
    output [OUT_WIDTH-1:0] conv_out,
    output valid_out
);
    // Line Buffer：缓存KERNEL_SIZE-1行数据
    // 每行包含图像宽度个像素
    reg [IN_WIDTH-1:0] line_buffer[KERNEL_SIZE-1][IMAGE_WIDTH];
    
    // Window Buffer：提取KERNEL_SIZE×KERNEL_SIZE的卷积窗口
    reg [IN_WIDTH-1:0] window[KERNEL_SIZE][KERNEL_SIZE];
    
    // MAC阵列：KERNEL_SIZE×KERNEL_SIZE个MAC单元
    // 可以在一个周期内完成一个卷积窗口的计算
    wire [OUT_WIDTH-1:0] mac_results[KERNEL_SIZE][KERNEL_SIZE];
    
    // 累加树：将所有MAC结果累加
    wire [OUT_WIDTH-1:0] conv_result;
    
    // 数据流控制逻辑
    // - 管理Line Buffer的更新
    // - 控制Window Buffer的滑动
    // - 处理padding和stride
endmodule
            </div>
            
            <p><strong>直接卷积的优化技术：</strong></p>
            <ul>
                <li><strong>循环展开：</strong>将内层循环完全展开，用硬件并行实现</li>
                <li><strong>流水线设计：</strong>将卷积计算分解为多个流水级</li>
                <li><strong>数据预取：</strong>提前加载下一个卷积窗口的数据</li>
                <li><strong>部分和累加：</strong>跨输入通道的部分和可以流水线累加</li>
            </ul>

            <p><strong>方法3：Winograd算法</strong></p>
            <p>Winograd算法是一种通过数学变换减少乘法次数的快速卷积方法，特别适合小卷积核（如3×3）的实现。其核心思想是将卷积域的计算转换到变换域，在变换域中用更少的乘法完成等效计算。</p>
            
            <p><strong>Winograd F(2,3)算法示例：</strong></p>
            <p>对于3×3卷积，输出2×2的块，Winograd可以将原本需要的36次乘法减少到16次：</p>
            
            <div class="code-block">
// Winograd F(2,3)变换矩阵
// 输入变换矩阵 B^T
B^T = [1   0  -1   0]
      [0   1   1   0]
      [0  -1   1   0]
      [0   1   0  -1]

// 权重变换矩阵 G
G = [1    0    0]
    [0.5  0.5  0.5]
    [0.5 -0.5  0.5]
    [0    0    1]

// 输出变换矩阵 A^T
A^T = [1  1  1  0]
      [0  1 -1 -1]

// 计算流程：
// 1. 变换输入：V = B^T × d × B  (d是4×4输入块)
// 2. 变换权重：U = G × g × G^T  (g是3×3卷积核)
// 3. 元素乘法：M = U ⊙ V       (只需16次乘法)
// 4. 逆变换：Y = A^T × M × A   (得到2×2输出)
            </div>
            
            <p><strong>Winograd的硬件实现考虑：</strong></p>
            <ul>
                <li><strong>优点：</strong>
                    <ul>
                        <li>显著减少乘法次数（3×3卷积可减少2.25倍）</li>
                        <li>适合小卷积核，特别是3×3和5×5</li>
                        <li>可以与量化技术结合，进一步提升效率</li>
                    </ul>
                </li>
                <li><strong>缺点：</strong>
                    <ul>
                        <li>需要额外的变换运算（主要是加法）</li>
                        <li>数值稳定性问题，可能需要更高的中间精度</li>
                        <li>对大卷积核或步长>1的情况效果不佳</li>
                        <li>硬件实现复杂度较高</li>
                    </ul>
                </li>
            </ul>
            
            <p><strong>适用场景：</strong></p>
            <p>Winograd算法在以下场景中特别有效：</p>
            <ul>
                <li>卷积核大小固定（通常是3×3）</li>
                <li>步长为1的卷积层</li>
                <li>对功耗敏感的边缘设备</li>
                <li>批量大小较小的推理场景</li>
            </ul>

            <h4>2.2.3 池化层的硬件实现</h4>
            <p>池化（Pooling）是CNN中的下采样操作，虽然计算量远小于卷积，但其特殊的数据访问模式对硬件设计仍有一定要求。池化层通过聚合局部区域的特征来减少特征图的空间维度，既减少了后续层的计算量，又提供了一定的平移不变性。</p>
            
            <p><strong>常见池化类型的硬件实现：</strong></p>
            
            <p><strong>1. 最大池化（Max Pooling）</strong></p>
            <p>最大池化选择窗口内的最大值，硬件实现非常简单，主要使用比较器树：</p>
            
            <div class="code-block">
// 2×2 最大池化的硬件实现
module MaxPool2x2 #(
    parameter DATA_WIDTH = 8
)(
    input wire [DATA_WIDTH-1:0] in0, in1, in2, in3,
    output wire [DATA_WIDTH-1:0] out
);
    wire [DATA_WIDTH-1:0] max_01, max_23;
    
    // 第一级比较
    assign max_01 = (in0 > in1) ? in0 : in1;
    assign max_23 = (in2 > in3) ? in2 : in3;
    
    // 第二级比较
    assign out = (max_01 > max_23) ? max_01 : max_23;
endmodule

// 对于更大的池化窗口，可以构建比较器树
// 例如3×3需要log2(9)≈4级比较
            </div>
            
            <p><strong>2. 平均池化（Average Pooling）</strong></p>
            <p>平均池化计算窗口内所有值的平均，需要加法器和除法器（或移位器）：</p>
            
            <div class="code-block">
// 2×2 平均池化的硬件实现
module AvgPool2x2 #(
    parameter DATA_WIDTH = 8
)(
    input wire [DATA_WIDTH-1:0] in0, in1, in2, in3,
    output wire [DATA_WIDTH-1:0] out
);
    wire [DATA_WIDTH+1:0] sum;
    
    // 求和（位宽增加2位防止溢出）
    assign sum = in0 + in1 + in2 + in3;
    
    // 除以4（右移2位）
    assign out = sum[DATA_WIDTH+1:2];
endmodule

// 对于非2的幂次的池化窗口，需要真正的除法器
// 或使用乘法器配合预计算的倒数
            </div>
            
            <p><strong>池化层的优化策略：</strong></p>
            <ul>
                <li><strong>与激活函数集成：</strong>池化通常紧跟在ReLU之后，可以将两者合并在一个硬件模块中</li>
                <li><strong>行缓冲复用：</strong>池化的行缓冲可以与卷积共享，减少硬件开销</li>
                <li><strong>流水线设计：</strong>虽然池化计算简单，但仍需要流水线化以匹配卷积的吞吐率</li>
                <li><strong>可配置设计：</strong>支持不同的池化窗口大小和步长，提高硬件灵活性</li>
            </ul>

            <h3>2.3 数据流与并行计算</h3>
            
            <p>数据流架构是NPU设计的核心，它决定了数据如何在计算单元间流动、如何被复用，以及如何实现计算与数据传输的重叠。良好的数据流设计可以最大化硬件利用率，最小化内存访问，从而实现高性能和高能效。本节将深入探讨NPU中的数据流模式和并行计算策略。</p>
            
            <h4>2.3.1 数据流架构</h4>
            <p>在NPU设计中，数据流架构定义了数据在处理单元阵列中的移动模式。不同的数据流架构有不同的优缺点，适用于不同的应用场景。理解这些架构的特点，对于选择合适的NPU设计方案至关重要。</p>
            
            <p><strong>数据流架构的设计目标：</strong></p>
            <ul>
                <li><strong>最大化数据复用：</strong>减少对外部内存的访问次数</li>
                <li><strong>最小化数据移动：</strong>降低功耗，提高能效</li>
                <li><strong>平衡计算和访存：</strong>避免计算单元空闲等待数据</li>
                <li><strong>支持灵活的网络结构：</strong>适应不同大小的层和不同类型的运算</li>
            </ul>
            
            <p><strong>主流数据流架构详解：</strong></p>
            
            <p><strong>1. 权重固定流（Weight Stationary, WS）</strong></p>
            <p>权重固定流是最直观的数据流模式之一。在这种架构中，每个处理单元（PE）预先加载并保存一个或多个权重值，输入激活值和部分和在PE阵列中流动。</p>
            
            <div class="code-block">
// 权重固定流示例（2×2 PE阵列）
// PE[i][j]存储权重W[i][j]
PE[0][0]: W[0][0]  PE[0][1]: W[0][1]
PE[1][0]: W[1][0]  PE[1][1]: W[1][1]

// 时刻1：输入X[0]广播到第一行
PE[0][0]: X[0]×W[0][0]  PE[0][1]: X[0]×W[0][1]

// 时刻2：输入X[1]广播到第二行，部分和向下传递
PE[0][0]: X[1]×W[0][0]  PE[0][1]: X[1]×W[0][1]
PE[1][0]: P[0]+X[0]×W[1][0]  PE[1][1]: P[1]+X[0]×W[1][1]
            </div>
            
            <p>优势：权重只需加载一次，大大减少了权重内存带宽需求。特别适合批处理场景，可以对同一批次的多个样本复用权重。</p>
            
            <p><strong>2. 输出固定流（Output Stationary, OS）</strong></p>
            <p>输出固定流中，每个PE负责计算输出特征图的一个或多个固定位置。权重和输入数据流经PE阵列，部分和在PE内部累积直到计算完成。Google TPU的脉动阵列（Systolic Array）是这种架构的经典实现。</p>
            
            <div class="code-block">
// 脉动阵列示例
// 每个PE计算一个输出元素C[i][j] = Σ A[i][k] × B[k][j]

// PE阵列布局
PE[0][0] → PE[0][1] → PE[0][2]
   ↓          ↓          ↓
PE[1][0] → PE[1][1] → PE[1][2]
   ↓          ↓          ↓
PE[2][0] → PE[2][1] → PE[2][2]

// 数据流动：
// - A矩阵的行从左向右流动
// - B矩阵的列从上向下流动
// - 每个PE在本地累积部分和
            </div>
            
            <p>优势：最小化部分和的移动，减少了寄存器文件的读写。规则的数据流动模式使得控制逻辑简单，易于实现高频率设计。</p>
            
            <p><strong>3. 行固定流（Row Stationary, RS）</strong></p>
            <p>行固定流是MIT Eyeriss提出的一种更灵活的数据流模式。它试图在一行PE中最大化所有类型数据（输入、权重、部分和）的复用，是一种折中的设计。</p>
            
            <p>优势：能够同时利用多种数据的局部性，在不同的网络层配置下都能保持较好的性能。支持灵活的映射策略，可以适应不同大小的卷积核和特征图。</p>
            
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>数据流类型</th>
                            <th>固定数据</th>
                            <th>移动数据</th>
                            <th>优势</th>
                            <th>适用场景</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>权重固定(WS)</td>
                            <td>权重</td>
                            <td>输入、部分和</td>
                            <td>权重复用率高</td>
                            <td>权重大、批处理小</td>
                        </tr>
                        <tr>
                            <td>输出固定(OS)</td>
                            <td>部分和</td>
                            <td>权重、输入</td>
                            <td>减少部分和读写</td>
                            <td>输出通道多</td>
                        </tr>
                        <tr>
                            <td>输入固定(IS)</td>
                            <td>输入</td>
                            <td>权重、部分和</td>
                            <td>输入复用率高</td>
                            <td>输入大、权重小</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h4>2.3.2 并行计算维度</h4>
            <div class="code-block">
// 卷积运算的7个循环维度
for (n = 0; n < N; n++)         // Batch
  for (k = 0; k < K; k++)       // 输出通道
    for (c = 0; c < C; c++)     // 输入通道
      for (y = 0; y < Y; y++)   // 输出高度
        for (x = 0; x < X; x++) // 输出宽度
          for (fy = 0; fy < FY; fy++)   // 卷积核高度
            for (fx = 0; fx < FX; fx++) // 卷积核宽度
              out[n][k][y][x] += in[n][c][y+fy][x+fx] * w[k][c][fy][fx]

// NPU可以选择在不同维度上并行化：
// 1. 空间并行：在Y、X维度展开
// 2. 通道并行：在K、C维度展开
// 3. 批处理并行：在N维度展开
            </div>

            <h3>2.4 量化与数据格式</h3>
            
            <h4>2.4.1 量化原理</h4>
            <p>量化是将高精度浮点数转换为低精度定点数的过程，是NPU提升效率的关键技术。</p>
            
            <div class="code-block">
// 对称量化
int8_value = round(fp32_value / scale)
fp32_value = int8_value * scale

// 非对称量化
int8_value = round(fp32_value / scale) + zero_point
fp32_value = (int8_value - zero_point) * scale

// 量化参数计算
scale = (max_val - min_val) / (2^bits - 1)
zero_point = round(-min_val / scale)
            </div>

            <h4>2.4.2 不同精度的硬件开销对比</h4>
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>数据类型</th>
                            <th>位宽</th>
                            <th>乘法器面积</th>
                            <th>加法器面积</th>
                            <th>功耗比例</th>
                            <th>内存带宽</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>FP32</td>
                            <td>32-bit</td>
                            <td>1.0x</td>
                            <td>1.0x</td>
                            <td>1.0x</td>
                            <td>1.0x</td>
                        </tr>
                        <tr>
                            <td>FP16</td>
                            <td>16-bit</td>
                            <td>~0.25x</td>
                            <td>~0.5x</td>
                            <td>~0.4x</td>
                            <td>0.5x</td>
                        </tr>
                        <tr>
                            <td>INT8</td>
                            <td>8-bit</td>
                            <td>~0.125x</td>
                            <td>~0.25x</td>
                            <td>~0.25x</td>
                            <td>0.25x</td>
                        </tr>
                        <tr>
                            <td>INT4</td>
                            <td>4-bit</td>
                            <td>~0.06x</td>
                            <td>~0.125x</td>
                            <td>~0.1x</td>
                            <td>0.125x</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <div class="exercise">
                <h4>练习题集 2</h4>
                <p>本章的练习题旨在加深你对神经网络计算原理和硬件实现的理解。这些题目涵盖了MAC运算、矩阵乘法、卷积实现和数据流分析等关键概念。通过解决这些问题，你将更好地理解NPU设计中的权衡和优化策略。</p>
                
                <div class="question">
                    <p><strong>题目2.1：</strong>某NPU的MAC阵列大小为32×32，计算一个[512, 1024] × [1024, 2048]的矩阵乘法需要多少个计算周期？假设每个周期可以完成阵列大小的MAC运算。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p>矩阵分块计算：</p>
                        <ol>
                            <li>结果矩阵大小：[512, 2048]</li>
                            <li>总MAC运算次数：512 × 1024 × 2048 = 1,073,741,824</li>
                            <li>MAC阵列每周期运算次数：32 × 32 = 1,024</li>
                            <li>分块数量：
                                <ul>
                                    <li>M维度分块：⌈512/32⌉ = 16</li>
                                    <li>N维度分块：⌈2048/32⌉ = 64</li>
                                    <li>K维度分块：⌈1024/32⌉ = 32</li>
                                </ul>
                            </li>
                            <li>总周期数：16 × 64 × 32 = 32,768 周期</li>
                        </ol>
                        <p><strong>验证：</strong>32,768 × 1,024 = 33,554,432 ≈ 1,073,741,824 / 32（考虑边界填充）</p>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目2.2：</strong>设计一个支持ReLU和Sigmoid激活函数的硬件模块。对于Sigmoid，使用4段分段线性逼近。给出RTL设计框架。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module ActivationUnit #(
    parameter DATA_WIDTH = 16,
    parameter FRAC_WIDTH = 8
)(
    input wire clk,
    input wire rst_n,
    input wire [DATA_WIDTH-1:0] data_in,
    input wire [1:0] act_type,  // 00: bypass, 01: ReLU, 10: Sigmoid
    input wire valid_in,
    output reg [DATA_WIDTH-1:0] data_out,
    output reg valid_out
);

    // Sigmoid分段线性逼近参数（4段）
    // 区间: [-8, -2.5], [-2.5, 0], [0, 2.5], [2.5, 8]
    localparam signed [DATA_WIDTH-1:0] SIGMOID_X1 = -16'd2048;  // -8 (Q8.8)
    localparam signed [DATA_WIDTH-1:0] SIGMOID_X2 = -16'd640;   // -2.5
    localparam signed [DATA_WIDTH-1:0] SIGMOID_X3 = 16'd0;      // 0
    localparam signed [DATA_WIDTH-1:0] SIGMOID_X4 = 16'd640;    // 2.5
    localparam signed [DATA_WIDTH-1:0] SIGMOID_X5 = 16'd2048;   // 8
    
    // 斜率和截距（根据Sigmoid曲线拟合得出）
    localparam [DATA_WIDTH-1:0] SLOPE1 = 16'd13;    // 0.05
    localparam [DATA_WIDTH-1:0] SLOPE2 = 16'd51;    // 0.2
    localparam [DATA_WIDTH-1:0] SLOPE3 = 16'd64;    // 0.25
    localparam [DATA_WIDTH-1:0] SLOPE4 = 16'd51;    // 0.2
    
    wire signed [DATA_WIDTH-1:0] data_in_signed;
    reg [DATA_WIDTH-1:0] relu_out;
    reg [DATA_WIDTH-1:0] sigmoid_out;
    reg [2*DATA_WIDTH-1:0] mult_result;
    
    assign data_in_signed = data_in;
    
    // ReLU实现
    always @(*) begin
        if (data_in_signed < 0)
            relu_out = 0;
        else
            relu_out = data_in;
    end
    
    // Sigmoid分段线性逼近
    always @(*) begin
        if (data_in_signed <= SIGMOID_X1) begin
            sigmoid_out = 16'd0;  // 0
        end else if (data_in_signed <= SIGMOID_X2) begin
            mult_result = (data_in_signed - SIGMOID_X1) * SLOPE1;
            sigmoid_out = mult_result[DATA_WIDTH+FRAC_WIDTH-1:FRAC_WIDTH];
        end else if (data_in_signed <= SIGMOID_X3) begin
            mult_result = (data_in_signed - SIGMOID_X2) * SLOPE2;
            sigmoid_out = 16'd26 + mult_result[DATA_WIDTH+FRAC_WIDTH-1:FRAC_WIDTH];  // 0.1 + ...
        end else if (data_in_signed <= SIGMOID_X4) begin
            mult_result = data_in_signed * SLOPE3;
            sigmoid_out = 16'd128 + mult_result[DATA_WIDTH+FRAC_WIDTH-1:FRAC_WIDTH];  // 0.5 + ...
        end else if (data_in_signed <= SIGMOID_X5) begin
            mult_result = (data_in_signed - SIGMOID_X4) * SLOPE4;
            sigmoid_out = 16'd230 + mult_result[DATA_WIDTH+FRAC_WIDTH-1:FRAC_WIDTH];  // 0.9 + ...
        end else begin
            sigmoid_out = 16'd256;  // 1.0
        end
    end
    
    // 输出选择
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            data_out <= 0;
            valid_out <= 0;
        end else if (valid_in) begin
            case (act_type)
                2'b00: data_out <= data_in;      // Bypass
                2'b01: data_out <= relu_out;     // ReLU
                2'b10: data_out <= sigmoid_out;  // Sigmoid
                default: data_out <= data_in;
            endcase
            valid_out <= 1;
        end else begin
            valid_out <= 0;
        end
    end
endmodule
                        </div>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目2.3：</strong>比较Im2Col+GEMM和直接卷积两种实现方式。对于一个输入[224,224,3]、卷积核[3,3,3,64]的卷积层，计算Im2Col的内存开销。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p><strong>1. Im2Col内存开销计算：</strong></p>
                        <ol>
                            <li>输出特征图大小（假设stride=1, padding=1）：[224, 224, 64]</li>
                            <li>Im2Col展开后每个位置：3×3×3 = 27个元素</li>
                            <li>总位置数：224×224 = 50,176</li>
                            <li>Im2Col矩阵大小：[27, 50,176]</li>
                            <li>内存占用（FP32）：27 × 50,176 × 4 bytes = 5.42 MB</li>
                            <li>原始输入大小：224 × 224 × 3 × 4 bytes = 0.60 MB</li>
                            <li><strong>内存扩展比例：9.0倍</strong></li>
                        </ol>
                        
                        <p><strong>2. 两种方式对比：</strong></p>
                        <table>
                            <tr>
                                <th>特性</th>
                                <th>Im2Col + GEMM</th>
                                <th>直接卷积</th>
                            </tr>
                            <tr>
                                <td>内存开销</td>
                                <td>高（9倍扩展）</td>
                                <td>低（仅需Line Buffer）</td>
                            </tr>
                            <tr>
                                <td>计算效率</td>
                                <td>高（复用GEMM优化）</td>
                                <td>中等</td>
                            </tr>
                            <tr>
                                <td>硬件复杂度</td>
                                <td>简单（复用GEMM单元）</td>
                                <td>复杂（需要专用控制）</td>
                            </tr>
                            <tr>
                                <td>适用场景</td>
                                <td>大卷积核、服务器端</td>
                                <td>小卷积核、边缘设备</td>
                            </tr>
                        </table>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目2.4：</strong>设计一个简单的脉动阵列数据流控制器，支持权重固定（Weight Stationary）模式。要求能够处理8×8的MAC阵列。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module WeightStationaryController #(
    parameter ARRAY_SIZE = 8,
    parameter DATA_WIDTH = 8,
    parameter ADDR_WIDTH = 16
)(
    input wire clk,
    input wire rst_n,
    input wire start,
    
    // 配置接口
    input wire [ADDR_WIDTH-1:0] input_base_addr,
    input wire [ADDR_WIDTH-1:0] weight_base_addr,
    input wire [ADDR_WIDTH-1:0] output_base_addr,
    input wire [15:0] M, N, K,  // 矩阵维度
    
    // SRAM接口
    output reg [ADDR_WIDTH-1:0] input_addr,
    output reg input_rd_en,
    input wire [DATA_WIDTH*ARRAY_SIZE-1:0] input_data,
    
    output reg [ADDR_WIDTH-1:0] weight_addr,
    output reg weight_rd_en,
    input wire [DATA_WIDTH*ARRAY_SIZE-1:0] weight_data,
    
    output reg [ADDR_WIDTH-1:0] output_addr,
    output reg output_wr_en,
    output reg [DATA_WIDTH*ARRAY_SIZE-1:0] output_data,
    
    // MAC阵列接口
    output reg [DATA_WIDTH-1:0] input_to_array [0:ARRAY_SIZE-1],
    output reg [DATA_WIDTH-1:0] weight_to_array [0:ARRAY_SIZE-1][0:ARRAY_SIZE-1],
    output reg weight_load,
    output reg compute_en,
    input wire [DATA_WIDTH-1:0] output_from_array [0:ARRAY_SIZE-1],
    
    // 状态输出
    output reg busy,
    output reg done
);

    // 状态机定义
    localparam IDLE = 3'd0;
    localparam LOAD_WEIGHT = 3'd1;
    localparam COMPUTE = 3'd2;
    localparam STORE_OUTPUT = 3'd3;
    localparam NEXT_TILE = 3'd4;
    
    reg [2:0] state, next_state;
    reg [15:0] tile_m, tile_n, tile_k;  // 当前处理的分块索引
    reg [15:0] cycle_cnt;                // 周期计数器
    reg [15:0] k_iter;                   // K维度迭代计数
    
    // 计算分块数量
    wire [15:0] num_tile_m = (M + ARRAY_SIZE - 1) / ARRAY_SIZE;
    wire [15:0] num_tile_n = (N + ARRAY_SIZE - 1) / ARRAY_SIZE;
    wire [15:0] num_tile_k = (K + ARRAY_SIZE - 1) / ARRAY_SIZE;
    
    // 状态机
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n)
            state <= IDLE;
        else
            state <= next_state;
    end
    
    // 状态转换逻辑
    always @(*) begin
        next_state = state;
        case (state)
            IDLE: begin
                if (start)
                    next_state = LOAD_WEIGHT;
            end
            
            LOAD_WEIGHT: begin
                if (cycle_cnt == ARRAY_SIZE - 1)
                    next_state = COMPUTE;
            end
            
            COMPUTE: begin
                if (k_iter == K - 1)
                    next_state = STORE_OUTPUT;
            end
            
            STORE_OUTPUT: begin
                if (cycle_cnt == ARRAY_SIZE - 1)
                    next_state = NEXT_TILE;
            end
            
            NEXT_TILE: begin
                if (tile_n == num_tile_n - 1 && 
                    tile_m == num_tile_m - 1)
                    next_state = IDLE;
                else
                    next_state = LOAD_WEIGHT;
            end
        endcase
    end
    
    // 控制逻辑
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            tile_m <= 0;
            tile_n <= 0;
            tile_k <= 0;
            cycle_cnt <= 0;
            k_iter <= 0;
            weight_load <= 0;
            compute_en <= 0;
            busy <= 0;
            done <= 0;
        end else begin
            case (state)
                IDLE: begin
                    if (start) begin
                        tile_m <= 0;
                        tile_n <= 0;
                        tile_k <= 0;
                        busy <= 1;
                        done <= 0;
                    end
                end
                
                LOAD_WEIGHT: begin
                    // 加载权重到阵列
                    weight_load <= 1;
                    weight_rd_en <= 1;
                    weight_addr <= weight_base_addr + 
                                  (tile_n * ARRAY_SIZE + cycle_cnt) * K + 
                                  tile_k * ARRAY_SIZE;
                    
                    // 将权重数据分配到阵列
                    for (int i = 0; i < ARRAY_SIZE; i++) begin
                        for (int j = 0; j < ARRAY_SIZE; j++) begin
                            weight_to_array[i][j] <= weight_data[j*DATA_WIDTH +: DATA_WIDTH];
                        end
                    end
                    
                    cycle_cnt <= cycle_cnt + 1;
                    if (cycle_cnt == ARRAY_SIZE - 1) begin
                        cycle_cnt <= 0;
                        weight_load <= 0;
                        weight_rd_en <= 0;
                    end
                end
                
                COMPUTE: begin
                    // 启动计算
                    compute_en <= 1;
                    input_rd_en <= 1;
                    
                    // 读取输入数据
                    input_addr <= input_base_addr + 
                                 (tile_m * ARRAY_SIZE) * K + 
                                 k_iter;
                    
                    // 将输入数据送入阵列
                    for (int i = 0; i < ARRAY_SIZE; i++) begin
                        input_to_array[i] <= input_data[i*DATA_WIDTH +: DATA_WIDTH];
                    end
                    
                    k_iter <= k_iter + 1;
                    if (k_iter == K - 1) begin
                        k_iter <= 0;
                        compute_en <= 0;
                        input_rd_en <= 0;
                    end
                end
                
                STORE_OUTPUT: begin
                    // 存储输出结果
                    output_wr_en <= 1;
                    output_addr <= output_base_addr + 
                                  (tile_m * ARRAY_SIZE + cycle_cnt) * N + 
                                  tile_n * ARRAY_SIZE;
                    
                    // 从阵列收集输出
                    for (int i = 0; i < ARRAY_SIZE; i++) begin
                        output_data[i*DATA_WIDTH +: DATA_WIDTH] <= output_from_array[i];
                    end
                    
                    cycle_cnt <= cycle_cnt + 1;
                    if (cycle_cnt == ARRAY_SIZE - 1) begin
                        cycle_cnt <= 0;
                        output_wr_en <= 0;
                    end
                end
                
                NEXT_TILE: begin
                    // 移动到下一个分块
                    if (tile_n < num_tile_n - 1) begin
                        tile_n <= tile_n + 1;
                    end else begin
                        tile_n <= 0;
                        tile_m <= tile_m + 1;
                    end
                    
                    if (tile_n == num_tile_n - 1 && 
                        tile_m == num_tile_m - 1) begin
                        busy <= 0;
                        done <= 1;
                    end
                end
            endcase
        end
    end
endmodule
                        </div>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目2.5：</strong>分析深度可分离卷积（Depthwise Separable Convolution）的计算特点，说明为什么它对NPU的内存带宽要求更高。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p><strong>深度可分离卷积分解为两步：</strong></p>
                        <ol>
                            <li><strong>Depthwise Convolution：</strong>每个输入通道独立卷积
                                <ul>
                                    <li>计算量：H×W×C×K×K</li>
                                    <li>参数量：C×K×K</li>
                                </ul>
                            </li>
                            <li><strong>Pointwise Convolution (1×1卷积)：</strong>跨通道混合
                                <ul>
                                    <li>计算量：H×W×C×M</li>
                                    <li>参数量：C×M</li>
                                </ul>
                            </li>
                        </ol>
                        
                        <p><strong>计算强度分析（Compute-to-Memory Ratio）：</strong></p>
                        <table>
                            <tr>
                                <th>卷积类型</th>
                                <th>计算量</th>
                                <th>内存访问量</th>
                                <th>计算强度</th>
                            </tr>
                            <tr>
                                <td>标准卷积</td>
                                <td>H×W×C×M×K×K</td>
                                <td>H×W×(C+M) + C×M×K×K</td>
                                <td>O(K×K)</td>
                            </tr>
                            <tr>
                                <td>Depthwise</td>
                                <td>H×W×C×K×K</td>
                                <td>H×W×C×2 + C×K×K</td>
                                <td>O(1)</td>
                            </tr>
                            <tr>
                                <td>Pointwise</td>
                                <td>H×W×C×M</td>
                                <td>H×W×(C+M) + C×M</td>
                                <td>O(1)</td>
                            </tr>
                        </table>
                        
                        <p><strong>为什么内存带宽要求更高：</strong></p>
                        <ol>
                            <li><strong>计算强度低：</strong>Depthwise卷积的计算强度为O(1)，而标准卷积为O(K²)。这意味着每次内存访问只能支撑很少的计算。</li>
                            <li><strong>数据复用率低：</strong>
                                <ul>
                                    <li>标准卷积中，每个输入被M个输出通道复用</li>
                                    <li>Depthwise中，每个输入只被1个输出通道使用</li>
                                </ul>
                            </li>
                            <li><strong>Memory Bound：</strong>NPU的计算单元经常处于空闲状态，等待数据从内存加载。</li>
                        </ol>
                        
                        <p><strong>优化策略：</strong></p>
                        <ul>
                            <li>增加片上缓存容量</li>
                            <li>使用更宽的内存接口</li>
                            <li>将Depthwise和Pointwise融合执行，减少中间结果的存储</li>
                            <li>使用专门的DMA引擎进行数据预取</li>
                        </ul>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目2.6：</strong>实现一个简单的INT8量化模块，支持对称量化和非对称量化两种模式。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module Quantizer #(
    parameter IN_WIDTH = 32,    // FP32输入
    parameter OUT_WIDTH = 8,    // INT8输出
    parameter SCALE_WIDTH = 16  // 定点scale表示
)(
    input wire clk,
    input wire rst_n,
    input wire [IN_WIDTH-1:0] fp_in,      // 浮点输入
    input wire [SCALE_WIDTH-1:0] scale,   // 量化尺度
    input wire [OUT_WIDTH-1:0] zero_point,// 零点（非对称量化）
    input wire symmetric_mode,            // 0: 非对称, 1: 对称
    input wire valid_in,
    
    output reg signed [OUT_WIDTH-1:0] int_out,  // 量化输出
    output reg valid_out
);

    // 内部信号
    reg [IN_WIDTH+SCALE_WIDTH-1:0] scaled_value;
    reg signed [IN_WIDTH-1:0] rounded_value;
    reg signed [IN_WIDTH-1:0] shifted_value;
    wire signed [OUT_WIDTH-1:0] saturated_value;
    
    // 饱和边界
    localparam signed [IN_WIDTH-1:0] MAX_INT8 = 127;
    localparam signed [IN_WIDTH-1:0] MIN_INT8 = -128;
    
    // Step 1: 缩放
    always @(*) begin
        // 假设scale是定点表示 (Q8.8格式)
        // 实际硬件中需要浮点转定点单元
        scaled_value = fp_in * scale;
    end
    
    // Step 2: 四舍五入
    always @(*) begin
        // 简化的四舍五入：加0.5后截断
        rounded_value = scaled_value[IN_WIDTH+SCALE_WIDTH-1:SCALE_WIDTH] + 
                       (scaled_value[SCALE_WIDTH-1] ? 1 : 0);
    end
    
    // Step 3: 加零点（非对称量化）
    always @(*) begin
        if (symmetric_mode)
            shifted_value = rounded_value;
        else
            shifted_value = rounded_value + {{(IN_WIDTH-OUT_WIDTH){1'b0}}, zero_point};
    end
    
    // Step 4: 饱和处理
    assign saturated_value = (shifted_value > MAX_INT8) ? MAX_INT8 :
                            (shifted_value < MIN_INT8) ? MIN_INT8 :
                            shifted_value[OUT_WIDTH-1:0];
    
    // 输出寄存
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            int_out <= 0;
            valid_out <= 0;
        end else if (valid_in) begin
            int_out <= saturated_value;
            valid_out <= 1;
        end else begin
            valid_out <= 0;
        end
    end
endmodule

// 反量化模块
module Dequantizer #(
    parameter IN_WIDTH = 8,     // INT8输入
    parameter OUT_WIDTH = 32,   // FP32输出
    parameter SCALE_WIDTH = 16
)(
    input wire clk,
    input wire rst_n,
    input wire signed [IN_WIDTH-1:0] int_in,
    input wire [SCALE_WIDTH-1:0] scale,
    input wire [IN_WIDTH-1:0] zero_point,
    input wire symmetric_mode,
    input wire valid_in,
    
    output reg [OUT_WIDTH-1:0] fp_out,
    output reg valid_out
);

    // 内部信号
    reg signed [OUT_WIDTH-1:0] shifted_value;
    reg [OUT_WIDTH+SCALE_WIDTH-1:0] scaled_value;
    
    // Step 1: 减去零点
    always @(*) begin
        if (symmetric_mode)
            shifted_value = {{(OUT_WIDTH-IN_WIDTH){int_in[IN_WIDTH-1]}}, int_in};
        else
            shifted_value = {{(OUT_WIDTH-IN_WIDTH){int_in[IN_WIDTH-1]}}, int_in} - 
                           {{(OUT_WIDTH-IN_WIDTH){1'b0}}, zero_point};
    end
    
    // Step 2: 乘以scale
    always @(*) begin
        scaled_value = shifted_value * scale;
    end
    
    // 输出寄存
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            fp_out <= 0;
            valid_out <= 0;
        end else if (valid_in) begin
            // 提取定点结果的整数部分
            fp_out <= scaled_value[OUT_WIDTH+SCALE_WIDTH-1:SCALE_WIDTH];
            valid_out <= 1;
        end else begin
            valid_out <= 0;
        end
    end
endmodule
                        </div>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目2.7：</strong>计算并比较不同批处理大小（batch size）对NPU效率的影响。假设处理一个ResNet50的第一个卷积层，输入[N,224,224,3]，卷积核[7,7,3,64]。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p><strong>不同batch size的影响分析：</strong></p>
                        
                        <table>
                            <tr>
                                <th>Batch Size</th>
                                <th>计算量(GFLOPs)</th>
                                <th>内存占用(MB)</th>
                                <th>并行度</th>
                                <th>数据复用率</th>
                            </tr>
                            <tr>
                                <td>1</td>
                                <td>0.118</td>
                                <td>输入: 0.6<br>输出: 3.2</td>
                                <td>低</td>
                                <td>权重复用率: 1x</td>
                            </tr>
                            <tr>
                                <td>8</td>
                                <td>0.944</td>
                                <td>输入: 4.8<br>输出: 25.6</td>
                                <td>中</td>
                                <td>权重复用率: 8x</td>
                            </tr>
                            <tr>
                                <td>32</td>
                                <td>3.776</td>
                                <td>输入: 19.2<br>输出: 102.4</td>
                                <td>高</td>
                                <td>权重复用率: 32x</td>
                            </tr>
                            <tr>
                                <td>128</td>
                                <td>15.104</td>
                                <td>输入: 76.8<br>输出: 409.6</td>
                                <td>很高</td>
                                <td>权重复用率: 128x</td>
                            </tr>
                        </table>
                        
                        <p><strong>计算过程：</strong></p>
                        <ol>
                            <li>输出大小：(224-7+2*3)/2+1 = 112，即[N,112,112,64]</li>
                            <li>每个输出像素的计算量：7×7×3×2 = 294 FLOPs</li>
                            <li>总计算量：N×112×112×64×294</li>
                        </ol>
                        
                        <p><strong>NPU效率影响：</strong></p>
                        <ol>
                            <li><strong>小batch size (1-8)：</strong>
                                <ul>
                                    <li>权重复用率低，需要频繁重新加载权重</li>
                                    <li>MAC阵列利用率低，很多PE空闲</li>
                                    <li>适合边缘设备，响应延迟低</li>
                                </ul>
                            </li>
                            <li><strong>中等batch size (16-32)：</strong>
                                <ul>
                                    <li>权重复用率适中</li>
                                    <li>MAC阵列利用率较好</li>
                                    <li>内存占用在可接受范围</li>
                                </ul>
                            </li>
                            <li><strong>大batch size (64-128)：</strong>
                                <ul>
                                    <li>权重复用率高，摊销权重加载开销</li>
                                    <li>MAC阵列充分利用</li>
                                    <li>可能受限于片上SRAM容量</li>
                                    <li>适合云端训练场景</li>
                                </ul>
                            </li>
                        </ol>
                        
                        <p><strong>优化建议：</strong></p>
                        <ul>
                            <li>边缘NPU：优化batch=1的性能，采用权重固定数据流</li>
                            <li>云端NPU：支持大batch，增加片上SRAM容量</li>
                            <li>动态批处理：根据负载自适应调整batch size</li>
                        </ul>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目2.8：</strong>设计一个简单的稀疏计算单元，能够跳过零值计算。给出零检测和地址生成的RTL框架。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module SparseComputeUnit #(
    parameter DATA_WIDTH = 8,
    parameter ADDR_WIDTH = 16,
    parameter PE_NUM = 16       // 并行PE数量
)(
    input wire clk,
    input wire rst_n,
    
    // 输入数据和索引
    input wire [DATA_WIDTH-1:0] activation_data [0:PE_NUM-1],
    input wire [DATA_WIDTH-1:0] weight_data [0:PE_NUM-1],
    input wire [PE_NUM-1:0] activation_valid,  // 非零标志
    input wire [PE_NUM-1:0] weight_valid,      // 非零标志
    input wire data_valid,
    
    // 稀疏索引
    input wire [ADDR_WIDTH-1:0] activation_indices [0:PE_NUM-1],
    input wire [ADDR_WIDTH-1:0] weight_indices [0:PE_NUM-1],
    
    // 输出接口
    output reg [2*DATA_WIDTH-1:0] result_data [0:PE_NUM-1],
    output reg [ADDR_WIDTH-1:0] result_indices [0:PE_NUM-1],
    output reg [PE_NUM-1:0] result_valid,
    output reg output_valid
);

    // 内部信号
    reg [PE_NUM-1:0] compute_mask;
    wire [2*DATA_WIDTH-1:0] mult_results [0:PE_NUM-1];
    reg [4:0] valid_count;
    reg [4:0] compact_indices [0:PE_NUM-1];
    
    // 生成计算掩码（只有当激活值和权重都非零时才计算）
    always @(*) begin
        compute_mask = activation_valid & weight_valid;
    end
    
    // 并行乘法器
    genvar i;
    generate
        for (i = 0; i < PE_NUM; i = i + 1) begin : mult_gen
            assign mult_results[i] = activation_data[i] * weight_data[i];
        end
    endgenerate
    
    // 计算有效结果数量
    always @(*) begin
        valid_count = 0;
        for (int j = 0; j < PE_NUM; j = j + 1) begin
            if (compute_mask[j])
                valid_count = valid_count + 1;
        end
    end
    
    // 压缩有效结果（去除零值结果）
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            output_valid <= 0;
            result_valid <= 0;
        end else if (data_valid) begin
            int compact_idx = 0;
            
            // 压缩非零结果
            for (int j = 0; j < PE_NUM; j = j + 1) begin
                if (compute_mask[j]) begin
                    result_data[compact_idx] <= mult_results[j];
                    result_indices[compact_idx] <= activation_indices[j];
                    result_valid[compact_idx] <= 1'b1;
                    compact_idx = compact_idx + 1;
                end
            end
            
            // 清空未使用的输出
            for (int j = compact_idx; j < PE_NUM; j = j + 1) begin
                result_data[j] <= 0;
                result_indices[j] <= 0;
                result_valid[j] <= 1'b0;
            end
            
            output_valid <= 1;
        end else begin
            output_valid <= 0;
        end
    end
endmodule

// 稀疏数据加载器
module SparseDataLoader #(
    parameter DATA_WIDTH = 8,
    parameter ADDR_WIDTH = 16,
    parameter SPARSE_FORMAT = "CSR"  // CSR或COO格式
)(
    input wire clk,
    input wire rst_n,
    
    // 内存接口
    output reg [ADDR_WIDTH-1:0] mem_addr,
    output reg mem_rd_en,
    input wire [31:0] mem_data,
    
    // 稀疏数据输出
    output reg [DATA_WIDTH-1:0] value_out,
    output reg [ADDR_WIDTH-1:0] row_idx_out,
    output reg [ADDR_WIDTH-1:0] col_idx_out,
    output reg data_valid_out,
    
    // 控制接口
    input wire start,
    input wire [ADDR_WIDTH-1:0] base_addr,
    input wire [15:0] nnz,  // 非零元素数量
    output reg done
);

    // CSR格式存储结构
    // values[nnz]: 非零值数组
    // col_indices[nnz]: 列索引数组
    // row_ptrs[rows+1]: 行指针数组
    
    reg [15:0] element_cnt;
    reg [2:0] load_state;
    
    localparam IDLE = 3'd0;
    localparam LOAD_VALUE = 3'd1;
    localparam LOAD_COL_IDX = 3'd2;
    localparam OUTPUT = 3'd3;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            load_state <= IDLE;
            element_cnt <= 0;
            done <= 0;
            mem_rd_en <= 0;
            data_valid_out <= 0;
        end else begin
            case (load_state)
                IDLE: begin
                    if (start) begin
                        element_cnt <= 0;
                        load_state <= LOAD_VALUE;
                        done <= 0;
                    end
                end
                
                LOAD_VALUE: begin
                    mem_rd_en <= 1;
                    mem_addr <= base_addr + element_cnt;
                    load_state <= LOAD_COL_IDX;
                end
                
                LOAD_COL_IDX: begin
                    value_out <= mem_data[DATA_WIDTH-1:0];
                    mem_addr <= base_addr + nnz + element_cnt;
                    load_state <= OUTPUT;
                end
                
                OUTPUT: begin
                    col_idx_out <= mem_data[ADDR_WIDTH-1:0];
                    data_valid_out <= 1;
                    mem_rd_en <= 0;
                    
                    element_cnt <= element_cnt + 1;
                    if (element_cnt == nnz - 1) begin
                        load_state <= IDLE;
                        done <= 1;
                    end else begin
                        load_state <= LOAD_VALUE;
                    end
                end
            endcase
        end
    end
endmodule
                        </div>
                    </div>
                </div>
                
                <div class="question">
                    <p><strong>题目2.4：</strong>分析不同数据流架构的特点。给定一个16×16的PE阵列，分别计算在权重固定流(WS)、输出固定流(OS)和行固定流(RS)下，执行一个[64,64]×[64,64]矩阵乘法所需的数据传输量。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p><strong>1. 权重固定流（WS）：</strong></p>
                        <ul>
                            <li>权重加载：每个PE加载一次权重，共16×16×(64/16)×(64/16) = 4,096次权重读取</li>
                            <li>输入广播：每个输入需要广播到16个PE，共64×64×16 = 65,536次输入读取</li>
                            <li>部分和传递：在PE间传递，共64×64×15 = 61,440次部分和传输</li>
                            <li>总数据传输：131,072次</li>
                        </ul>
                        
                        <p><strong>2. 输出固定流（OS）：</strong></p>
                        <ul>
                            <li>每个PE负责计算一个输出元素</li>
                            <li>输入流动：64×64×16×16 = 1,048,576次</li>
                            <li>权重流动：64×64×16×16 = 1,048,576次</li>
                            <li>部分和：在PE内部累积，无需传输</li>
                            <li>总数据传输：2,097,152次（但数据流动规则，易于控制）</li>
                        </ul>
                        
                        <p><strong>3. 行固定流（RS）：</strong></p>
                        <ul>
                            <li>每行PE复用部分输入和权重</li>
                            <li>输入复用率：约4倍</li>
                            <li>权重复用率：约4倍</li>
                            <li>部分和传递：部分在行内，部分跨行</li>
                            <li>总数据传输：约524,288次（取决于具体映射策略）</li>
                        </ul>
                        
                        <p><strong>结论：</strong>WS在权重复用上最优，OS在控制简单性上最优，RS在整体数据复用上较为平衡。</p>
                    </div>
                </div>
                
                <div class="question">
                    <p><strong>题目2.5：</strong>设计一个支持INT8量化的MAC单元。要求：(1)支持对称和非对称量化；(2)防止累加溢出；(3)支持动态缩放。给出关键设计要点。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <div class="code-block">
module QuantizedMAC #(
    parameter IN_WIDTH = 8,      // INT8输入
    parameter ACC_WIDTH = 32,    // 累加器位宽
    parameter SCALE_WIDTH = 16   // 缩放因子位宽
)(
    input wire clk,
    input wire rst_n,
    input wire signed [IN_WIDTH-1:0] activation,
    input wire signed [IN_WIDTH-1:0] weight,
    input wire signed [IN_WIDTH-1:0] zero_point_act,    // 激活值零点
    input wire signed [IN_WIDTH-1:0] zero_point_wgt,    // 权重零点
    input wire [SCALE_WIDTH-1:0] scale_act,             // 激活值缩放
    input wire [SCALE_WIDTH-1:0] scale_wgt,             // 权重缩放
    input wire acc_en,           // 累加使能
    input wire clear_acc,        // 清除累加器
    output reg signed [ACC_WIDTH-1:0] acc_out,
    output reg overflow_flag
);

    // 内部信号
    wire signed [IN_WIDTH:0] act_adjusted;
    wire signed [IN_WIDTH:0] wgt_adjusted;
    wire signed [2*IN_WIDTH+1:0] mult_result;
    wire signed [ACC_WIDTH:0] acc_next;
    
    // 1. 零点调整（支持非对称量化）
    assign act_adjusted = activation - zero_point_act;
    assign wgt_adjusted = weight - zero_point_wgt;
    
    // 2. 乘法运算
    assign mult_result = act_adjusted * wgt_adjusted;
    
    // 3. 累加与溢出检测
    assign acc_next = acc_out + mult_result;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            acc_out <= 0;
            overflow_flag <= 0;
        end else if (clear_acc) begin
            acc_out <= 0;
            overflow_flag <= 0;
        end else if (acc_en) begin
            // 溢出检测
            if ((acc_out[ACC_WIDTH-1] == mult_result[2*IN_WIDTH+1]) && 
                (acc_next[ACC_WIDTH] != acc_out[ACC_WIDTH-1])) begin
                overflow_flag <= 1;
                // 饱和处理
                acc_out <= acc_out[ACC_WIDTH-1] ? {1'b1, {(ACC_WIDTH-1){1'b0}}} : 
                                                  {1'b0, {(ACC_WIDTH-1){1'b1}}};
            end else begin
                acc_out <= acc_next[ACC_WIDTH-1:0];
            end
        end
    end
    
    // 4. 动态缩放模块（可选，用于最终输出）
    // 实际实现中，缩放通常在MAC阵列外部进行
    // scale_final = scale_act * scale_wgt
    
endmodule

// 设计要点：
// 1. 位宽管理：累加器位宽要足够大，防止溢出
// 2. 零点处理：支持非对称量化的零点偏移
// 3. 溢出保护：实时检测并饱和处理
// 4. 流水线：可在乘法和加法间插入寄存器提高频率
// 5. 缩放延迟：将缩放操作延迟到累加完成后
                        </div>
                    </div>
                </div>
            </div>
            
            <div class="section-summary">
                <h4>本章小结</h4>
                <ul>
                    <li><strong>神经网络的核心计算是MAC运算，</strong>这决定了NPU以MAC阵列为计算核心</li>
                    <li><strong>量化技术是NPU效率提升的关键，</strong>INT8相比FP32可带来16倍面积效率和30倍功耗效率的提升</li>
                    <li><strong>卷积实现有三种主要方法：</strong>Im2Col适合复用GEMM硬件但内存开销大，直接卷积内存效率高但控制复杂，Winograd减少乘法但增加加法</li>
                    <li><strong>数据流架构决定了NPU的效率：</strong>权重固定流最小化权重访问，输出固定流简化控制逻辑，行固定流平衡各种数据复用</li>
                    <li><strong>硬件设计需要考虑多种权衡：</strong>计算密度vs灵活性、内存带宽vs计算能力、功耗vs性能</li>
                </ul>
            </div>
        </div>

        <div id="chapter3" class="chapter">
            <h2>第3章：NPU系统架构</h2>
            
            <h3>3.1 整体架构设计</h3>
            
            <h4>3.1.1 NPU系统组成</h4>
            <p>现代NPU系统通常包含以下核心组件：</p>
            
            <div class="code-block">
NPU系统架构层次：
┌─────────────────────────────────────────┐
│          Host Interface (PCIe/AXI)       │
├─────────────────────────────────────────┤
│         Command Processor & Scheduler    │
├─────────────────────────────────────────┤
│  ┌─────────┐  ┌─────────┐  ┌─────────┐ │
│  │ Compute │  │ Memory  │  │  DMA    │ │
│  │ Cluster │  │ System  │  │ Engine  │ │
│  └─────────┘  └─────────┘  └─────────┘ │
├─────────────────────────────────────────┤
│         On-chip Interconnect (NoC)      │
├─────────────────────────────────────────┤
│         External Memory Interface        │
└─────────────────────────────────────────┘
            </div>

            <h4>3.1.2 设计考虑因素</h4>
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>设计维度</th>
                            <th>关键指标</th>
                            <th>架构影响</th>
                            <th>优化方向</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>算力</td>
                            <td>TOPS/TFLOPS</td>
                            <td>MAC阵列规模</td>
                            <td>增加PE数量、提高频率</td>
                        </tr>
                        <tr>
                            <td>能效</td>
                            <td>TOPS/W</td>
                            <td>数据复用、电压调节</td>
                            <td>减少数据移动、低功耗设计</td>
                        </tr>
                        <tr>
                            <td>灵活性</td>
                            <td>支持的算子类型</td>
                            <td>可编程性</td>
                            <td>VLIW/SIMD混合架构</td>
                        </tr>
                        <tr>
                            <td>成本</td>
                            <td>$/TOPS</td>
                            <td>芯片面积</td>
                            <td>架构简化、工艺选择</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h3>3.2 计算单元设计</h3>
            
            <h4>3.2.1 计算集群架构</h4>
            <p>NPU的计算能力主要来自于大规模并行的计算集群：</p>
            
            <div class="code-block">
// 典型的计算集群组织
Compute Cluster
├── MAC Array (脉动阵列或其他拓扑)
│   ├── PE[0][0] ... PE[0][N-1]
│   ├── PE[1][0] ... PE[1][N-1]
│   └── PE[M-1][0] ... PE[M-1][N-1]
├── Vector Unit (向量处理单元)
│   ├── SIMD ALU
│   ├── Special Function Unit
│   └── Reduction Unit
├── Local Memory
│   ├── Weight Buffer
│   ├── Input Buffer
│   └── Output Buffer
└── Control Unit
    ├── Instruction Decoder
    ├── Address Generator
    └── Synchronization Logic
            </div>

            <h4>3.2.2 处理单元(PE)设计</h4>
            <div class="info-box">
                <p><strong>PE设计原则：</strong></p>
                <ul>
                    <li>面积效率：最大化MAC密度</li>
                    <li>功耗优化：时钟门控、操作数隔离</li>
                    <li>数据通路：支持多种精度(INT8/16, FP16/32)</li>
                    <li>流水线：平衡延迟和吞吐量</li>
                </ul>
            </div>

            <h3>3.3 存储层次结构</h3>
            
            <h4>3.3.1 存储层次设计</h4>
            <div class="code-block">
存储层次（从快到慢）：
1. Register File (RF)
   - 容量: ~1KB per PE
   - 延迟: 1 cycle
   - 带宽: 极高
   
2. L1 Buffer (私有)
   - 容量: 16-64KB per cluster
   - 延迟: 2-4 cycles
   - 用途: 权重/激活值缓存

3. L2 Buffer (共享)
   - 容量: 256KB-2MB
   - 延迟: 8-16 cycles
   - 用途: 跨cluster数据共享

4. Global Buffer
   - 容量: 4-32MB
   - 延迟: 20-40 cycles
   - 用途: 大型特征图存储

5. External Memory (DDR/HBM)
   - 容量: GB级别
   - 延迟: 100+ cycles
   - 带宽: 受限（关键瓶颈）
            </div>

            <h4>3.3.2 内存访问优化</h4>
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>优化技术</th>
                            <th>原理</th>
                            <th>硬件支持</th>
                            <th>效果</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>数据预取</td>
                            <td>提前加载数据到片上</td>
                            <td>硬件预取器</td>
                            <td>隐藏内存延迟</td>
                        </tr>
                        <tr>
                            <td>双缓冲</td>
                            <td>计算与数据传输重叠</td>
                            <td>乒乓Buffer</td>
                            <td>提高利用率</td>
                        </tr>
                        <tr>
                            <td>数据压缩</td>
                            <td>减少传输数据量</td>
                            <td>压缩/解压单元</td>
                            <td>节省带宽</td>
                        </tr>
                        <tr>
                            <td>地址映射</td>
                            <td>优化数据布局</td>
                            <td>可编程DMA</td>
                            <td>提高局部性</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h3>3.4 互连网络设计</h3>
            
            <h4>3.4.1 片上网络拓扑</h4>
            <div class="code-block">
常见的NoC拓扑结构：

1. Mesh (网格)
   优点：规则、可扩展
   缺点：跳数多、延迟大
   
   [R]--[R]--[R]--[R]
    |    |    |    |
   [R]--[R]--[R]--[R]
    |    |    |    |
   [R]--[R]--[R]--[R]

2. Torus (环面)
   优点：降低平均跳数
   缺点：布线复杂
   
3. Tree (树形)
   优点：层次化、易于广播
   缺点：根节点瓶颈

4. Crossbar (交叉开关)
   优点：单跳连接
   缺点：面积O(N²)，不可扩展
            </div>

            <h4>3.4.2 数据通信模式</h4>
            <p>NPU中的典型通信模式：</p>
            <ul>
                <li><strong>单播(Unicast)：</strong>点对点数据传输</li>
                <li><strong>多播(Multicast)：</strong>权重广播到多个PE</li>
                <li><strong>归约(Reduction)：</strong>部分和累加</li>
                <li><strong>全局同步：</strong>barrier同步</li>
            </ul>

            <div class="warning-box">
                <p><strong>设计挑战：</strong>如何在保证高带宽的同时控制功耗和面积开销是NoC设计的核心挑战。</p>
            </div>

            <div class="exercise">
                <h4>练习题集 3</h4>
                
                <div class="question">
                    <p><strong>题目3.1：</strong>设计一个NPU的存储层次结构。给定：MAC阵列32×32，主频1GHz，外部内存带宽100GB/s。计算各级存储的容量和带宽需求。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p><strong>1. 计算MAC阵列带宽需求：</strong></p>
                        <ul>
                            <li>MAC阵列规模：32×32 = 1024个MAC</li>
                            <li>每个MAC每周期需要：2个输入(weight, activation) + 1个输出</li>
                            <li>假设INT8精度：每个数据1字节</li>
                            <li>总带宽需求：1024 × 3 × 1B × 1GHz = 3.072 TB/s</li>
                        </ul>
                        
                        <p><strong>2. 存储层次设计：</strong></p>
                        <table>
                            <tr>
                                <th>存储级别</th>
                                <th>容量</th>
                                <th>带宽</th>
                                <th>设计理由</th>
                            </tr>
                            <tr>
                                <td>L0 (Register)</td>
                                <td>1KB/PE</td>
                                <td>3TB/s</td>
                                <td>直接供给MAC运算</td>
                            </tr>
                            <tr>
                                <td>L1 Buffer</td>
                                <td>64KB</td>
                                <td>1TB/s</td>
                                <td>存储当前tile的数据</td>
                            </tr>
                            <tr>
                                <td>L2 Buffer</td>
                                <td>2MB</td>
                                <td>400GB/s</td>
                                <td>预取下一个tile</td>
                            </tr>
                            <tr>
                                <td>Global Buffer</td>
                                <td>16MB</td>
                                <td>200GB/s</td>
                                <td>存储整层的部分数据</td>
                            </tr>
                            <tr>
                                <td>External Mem</td>
                                <td>16GB</td>
                                <td>100GB/s</td>
                                <td>给定约束</td>
                            </tr>
                        </table>
                        
                        <p><strong>3. 带宽逐级递减原理：</strong></p>
                        <ul>
                            <li>数据复用降低上级需求</li>
                            <li>时分复用共享带宽</li>
                            <li>预取隐藏延迟</li>
                        </ul>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目3.2：</strong>比较Weight Stationary、Output Stationary和Row Stationary三种数据流的优缺点，并给出适用场景。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <table>
                            <tr>
                                <th>数据流</th>
                                <th>固定数据</th>
                                <th>优点</th>
                                <th>缺点</th>
                                <th>适用场景</th>
                            </tr>
                            <tr>
                                <td>Weight Stationary (WS)</td>
                                <td>权重</td>
                                <td>• 权重复用最大化<br>• 减少权重读取能耗<br>• 实现简单</td>
                                <td>• 输入/输出需要大量移动<br>• 对大feature map不友好</td>
                                <td>• 全连接层<br>• 小batch推理<br>• 权重>>激活值</td>
                            </tr>
                            <tr>
                                <td>Output Stationary (OS)</td>
                                <td>部分和</td>
                                <td>• 减少部分和读写<br>• 累加在PE本地完成<br>• 适合深度网络</td>
                                <td>• 权重和输入都需移动<br>• 控制复杂度高</td>
                                <td>• 深度卷积<br>• 输出通道数多<br>• ResNet类结构</td>
                            </tr>
                            <tr>
                                <td>Row Stationary (RS)</td>
                                <td>卷积行</td>
                                <td>• 所有数据类型都有复用<br>• 能量效率最优<br>• 适应性强</td>
                                <td>• 实现最复杂<br>• 需要复杂的控制器<br>• 面积开销大</td>
                                <td>• 通用场景<br>• 各种卷积层<br>• 需要灵活性</td>
                            </tr>
                        </table>
                        
                        <p><strong>具体例子：</strong></p>
                        <p>对于1×1卷积（Pointwise）：</p>
                        <ul>
                            <li>WS最优：因为没有空间维度的复用</li>
                            <li>RS退化为WS</li>
                        </ul>
                        <p>对于3×3卷积：</p>
                        <ul>
                            <li>RS最优：可以复用所有维度的数据</li>
                            <li>OS次优：如果输出通道很多</li>
                        </ul>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目3.3：</strong>设计一个4×4 Mesh NoC的路由器。要求支持XY路由算法，包含5个端口（东南西北+本地）。给出RTL框架。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module MeshRouter #(
    parameter DATA_WIDTH = 32,
    parameter ADDR_WIDTH = 8,
    parameter X_COORD = 0,
    parameter Y_COORD = 0,
    parameter FIFO_DEPTH = 4
)(
    input wire clk,
    input wire rst_n,
    
    // 5个输入端口 (North, South, East, West, Local)
    input wire [DATA_WIDTH-1:0] data_in_n, data_in_s, data_in_e, data_in_w, data_in_l,
    input wire valid_in_n, valid_in_s, valid_in_e, valid_in_w, valid_in_l,
    output wire ready_out_n, ready_out_s, ready_out_e, ready_out_w, ready_out_l,
    
    // 5个输出端口
    output wire [DATA_WIDTH-1:0] data_out_n, data_out_s, data_out_e, data_out_w, data_out_l,
    output wire valid_out_n, valid_out_s, valid_out_e, valid_out_w, valid_out_l,
    input wire ready_in_n, ready_in_s, ready_in_e, ready_in_w, ready_in_l
);

    // 数据包格式：[DATA | SRC_Y | SRC_X | DST_Y | DST_X]
    localparam DST_X_START = 0;
    localparam DST_X_END = 3;
    localparam DST_Y_START = 4;
    localparam DST_Y_END = 7;
    
    // 内部信号
    wire [4:0] route_req_n, route_req_s, route_req_e, route_req_w, route_req_l;
    wire [4:0] grant_n, grant_s, grant_e, grant_w, grant_l;
    
    // 输入FIFO
    wire [DATA_WIDTH-1:0] fifo_data_n, fifo_data_s, fifo_data_e, fifo_data_w, fifo_data_l;
    wire fifo_empty_n, fifo_empty_s, fifo_empty_e, fifo_empty_w, fifo_empty_l;
    wire fifo_rd_en_n, fifo_rd_en_s, fifo_rd_en_e, fifo_rd_en_w, fifo_rd_en_l;
    
    // FIFO实例化（每个输入端口一个）
    genvar i;
    generate
        // North port FIFO
        FIFO #(.WIDTH(DATA_WIDTH), .DEPTH(FIFO_DEPTH)) fifo_n (
            .clk(clk), .rst_n(rst_n),
            .wr_en(valid_in_n), .wr_data(data_in_n),
            .rd_en(fifo_rd_en_n), .rd_data(fifo_data_n),
            .empty(fifo_empty_n), .full(~ready_out_n)
        );
        // 类似地实例化其他4个FIFO...
    endgenerate
    
    // XY路由计算模块
    XYRouteCompute route_comp_n (
        .current_x(X_COORD), .current_y(Y_COORD),
        .dest_x(fifo_data_n[DST_X_END:DST_X_START]),
        .dest_y(fifo_data_n[DST_Y_END:DST_Y_START]),
        .valid(!fifo_empty_n),
        .route_request(route_req_n)  // 5-bit one-hot
    );
    // 为其他端口实例化路由计算...
    
    // 5×5交叉开关仲裁器
    SwitchAllocator allocator (
        .clk(clk), .rst_n(rst_n),
        // 来自5个输入端口的请求
        .req_n(route_req_n), .req_s(route_req_s), 
        .req_e(route_req_e), .req_w(route_req_w), .req_l(route_req_l),
        // 授权信号
        .grant_n(grant_n), .grant_s(grant_s),
        .grant_e(grant_e), .grant_w(grant_w), .grant_l(grant_l)
    );
    
    // 交叉开关矩阵
    Crossbar5x5 xbar (
        // 输入数据
        .data_in({fifo_data_l, fifo_data_w, fifo_data_e, fifo_data_s, fifo_data_n}),
        // 控制信号
        .sel_n(grant_n), .sel_s(grant_s), 
        .sel_e(grant_e), .sel_w(grant_w), .sel_l(grant_l),
        // 输出数据
        .data_out_n(data_out_n), .data_out_s(data_out_s),
        .data_out_e(data_out_e), .data_out_w(data_out_w), .data_out_l(data_out_l)
    );
    
    // 输出valid信号生成
    assign valid_out_n = |grant_n & ready_in_n;
    assign valid_out_s = |grant_s & ready_in_s;
    assign valid_out_e = |grant_e & ready_in_e;
    assign valid_out_w = |grant_w & ready_in_w;
    assign valid_out_l = |grant_l & ready_in_l;
    
    // FIFO读使能
    assign fifo_rd_en_n = |(grant_n & {ready_in_l, ready_in_w, ready_in_e, ready_in_s, ready_in_n});
    // 类似处理其他端口...

endmodule

// XY路由计算模块
module XYRouteCompute #(
    parameter COORD_WIDTH = 4
)(
    input [COORD_WIDTH-1:0] current_x, current_y,
    input [COORD_WIDTH-1:0] dest_x, dest_y,
    input valid,
    output reg [4:0] route_request  // [Local, West, East, South, North]
);
    always @(*) begin
        route_request = 5'b00000;
        if (valid) begin
            if (dest_x == current_x && dest_y == current_y) begin
                route_request[4] = 1'b1;  // Local
            end else if (dest_x < current_x) begin
                route_request[3] = 1'b1;  // West
            end else if (dest_x > current_x) begin
                route_request[2] = 1'b1;  // East
            end else if (dest_y < current_y) begin
                route_request[1] = 1'b1;  // South
            end else begin
                route_request[0] = 1'b1;  // North
            end
        end
    end
endmodule
                        </div>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目3.4：</strong>计算一个NPU执行ResNet50一个残差块所需的片上存储容量。假设特征图大小为56×56×256，使用3×3卷积。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p><strong>ResNet50残差块结构：</strong></p>
                        <pre>
Input (56×56×256)
    │
    ├─────────────────────┐
    │                     │
    ▼                     │
Conv1 (1×1, 64)          │
    │                     │
    ▼                     │
Conv2 (3×3, 64)          │
    │                     │
    ▼                     │
Conv3 (1×1, 256)         │
    │                     │
    ▼                     │
    + ←──────────────────┘
    │
Output (56×56×256)
                        </pre>
                        
                        <p><strong>存储需求计算（INT8）：</strong></p>
                        <table>
                            <tr>
                                <th>数据类型</th>
                                <th>尺寸</th>
                                <th>容量(KB)</th>
                                <th>说明</th>
                            </tr>
                            <tr>
                                <td>输入特征图</td>
                                <td>56×56×256</td>
                                <td>784</td>
                                <td>需要保存用于残差连接</td>
                            </tr>
                            <tr>
                                <td>Conv1权重</td>
                                <td>1×1×256×64</td>
                                <td>16</td>
                                <td>Pointwise卷积</td>
                            </tr>
                            <tr>
                                <td>Conv1输出</td>
                                <td>56×56×64</td>
                                <td>196</td>
                                <td>中间特征图</td>
                            </tr>
                            <tr>
                                <td>Conv2权重</td>
                                <td>3×3×64×64</td>
                                <td>36</td>
                                <td>Depthwise卷积</td>
                            </tr>
                            <tr>
                                <td>Conv2输出</td>
                                <td>56×56×64</td>
                                <td>196</td>
                                <td>中间特征图</td>
                            </tr>
                            <tr>
                                <td>Conv3权重</td>
                                <td>1×1×64×256</td>
                                <td>16</td>
                                <td>Pointwise卷积</td>
                            </tr>
                            <tr>
                                <td>Conv3输出</td>
                                <td>56×56×256</td>
                                <td>784</td>
                                <td>用于残差加法</td>
                            </tr>
                            <tr>
                                <td><strong>总计</strong></td>
                                <td>-</td>
                                <td><strong>2028</strong></td>
                                <td>约2MB</td>
                            </tr>
                        </table>
                        
                        <p><strong>优化策略：</strong></p>
                        <ol>
                            <li><strong>层融合：</strong>将Conv1输出直接送入Conv2，节省196KB</li>
                            <li><strong>流水线执行：</strong>分块处理，每块只需存储部分特征图</li>
                            <li><strong>权重压缩：</strong>使用稀疏或量化技术减少权重存储</li>
                            <li><strong>双缓冲：</strong>计算当前块时预取下一块数据</li>
                        </ol>
                        
                        <p><strong>实际需求：</strong>考虑优化后，片上存储约需1MB即可高效执行。</p>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目3.5：</strong>设计一个DMA控制器，支持2D数据传输和简单的数据重排。要求支持stride访问模式。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module DMA2D #(
    parameter ADDR_WIDTH = 32,
    parameter DATA_WIDTH = 128,  // 128-bit宽接口
    parameter BURST_LEN = 16     // 最大突发长度
)(
    input wire clk,
    input wire rst_n,
    
    // 配置接口
    input wire [ADDR_WIDTH-1:0] src_addr,      // 源地址
    input wire [ADDR_WIDTH-1:0] dst_addr,      // 目标地址
    input wire [15:0] width,                   // 2D传输宽度（字节）
    input wire [15:0] height,                  // 2D传输高度
    input wire [15:0] src_stride,              // 源跨步（字节）
    input wire [15:0] dst_stride,              // 目标跨步（字节）
    input wire [2:0] transfer_mode,            // 传输模式
    input wire start,
    output reg done,
    output reg busy,
    
    // 源内存接口（AXI-like）
    output reg [ADDR_WIDTH-1:0] src_araddr,
    output reg src_arvalid,
    input wire src_arready,
    input wire [DATA_WIDTH-1:0] src_rdata,
    input wire src_rvalid,
    output reg src_rready,
    
    // 目标内存接口
    output reg [ADDR_WIDTH-1:0] dst_awaddr,
    output reg dst_awvalid,
    input wire dst_awready,
    output reg [DATA_WIDTH-1:0] dst_wdata,
    output reg dst_wvalid,
    input wire dst_wready,
    input wire dst_bvalid,
    output reg dst_bready
);

    // 传输模式定义
    localparam MODE_LINEAR = 3'd0;      // 线性传输
    localparam MODE_2D_BLOCK = 3'd1;    // 2D块传输
    localparam MODE_TRANSPOSE = 3'd2;   // 转置
    localparam MODE_INTERLEAVE = 3'd3;  // 交织
    
    // 状态机
    localparam IDLE = 3'd0;
    localparam CALC_ADDR = 3'd1;
    localparam READ_REQ = 3'd2;
    localparam READ_DATA = 3'd3;
    localparam WRITE_REQ = 3'd4;
    localparam WRITE_DATA = 3'd5;
    localparam WRITE_RESP = 3'd6;
    localparam NEXT_LINE = 3'd7;
    
    reg [2:0] state, next_state;
    
    // 内部计数器
    reg [15:0] row_cnt, col_cnt;
    reg [15:0] burst_cnt;
    reg [ADDR_WIDTH-1:0] current_src_addr, current_dst_addr;
    
    // 数据缓冲（支持突发传输）
    reg [DATA_WIDTH-1:0] data_buffer [0:BURST_LEN-1];
    reg [4:0] buffer_wr_ptr, buffer_rd_ptr;
    reg [4:0] buffer_count;
    
    // 地址计算单元
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            current_src_addr <= 0;
            current_dst_addr <= 0;
        end else if (state == CALC_ADDR) begin
            case (transfer_mode)
                MODE_LINEAR: begin
                    current_src_addr <= src_addr + (row_cnt * src_stride) + col_cnt;
                    current_dst_addr <= dst_addr + (row_cnt * dst_stride) + col_cnt;
                end
                MODE_2D_BLOCK: begin
                    current_src_addr <= src_addr + (row_cnt * src_stride) + col_cnt;
                    current_dst_addr <= dst_addr + (row_cnt * dst_stride) + col_cnt;
                end
                MODE_TRANSPOSE: begin
                    // 转置：源按行读，目标按列写
                    current_src_addr <= src_addr + (row_cnt * src_stride) + col_cnt;
                    current_dst_addr <= dst_addr + (col_cnt * dst_stride) + row_cnt * (DATA_WIDTH/8);
                end
                MODE_INTERLEAVE: begin
                    // 交织模式：用于通道重排
                    // 实现NCHW -> NHWC转换等
                    current_src_addr <= src_addr + calculate_interleave_src(row_cnt, col_cnt);
                    current_dst_addr <= dst_addr + calculate_interleave_dst(row_cnt, col_cnt);
                end
            endcase
        end
    end
    
    // 状态机控制
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n)
            state <= IDLE;
        else
            state <= next_state;
    end
    
    always @(*) begin
        next_state = state;
        case (state)
            IDLE: begin
                if (start)
                    next_state = CALC_ADDR;
            end
            
            CALC_ADDR: begin
                next_state = READ_REQ;
            end
            
            READ_REQ: begin
                if (src_arready)
                    next_state = READ_DATA;
            end
            
            READ_DATA: begin
                if (src_rvalid && burst_cnt == calculate_burst_len() - 1)
                    next_state = WRITE_REQ;
            end
            
            WRITE_REQ: begin
                if (dst_awready)
                    next_state = WRITE_DATA;
            end
            
            WRITE_DATA: begin
                if (dst_wready && buffer_rd_ptr == buffer_wr_ptr - 1)
                    next_state = WRITE_RESP;
            end
            
            WRITE_RESP: begin
                if (dst_bvalid)
                    next_state = NEXT_LINE;
            end
            
            NEXT_LINE: begin
                if (row_cnt == height - 1 && col_cnt >= width - (DATA_WIDTH/8))
                    next_state = IDLE;
                else
                    next_state = CALC_ADDR;
            end
        endcase
    end
    
    // 数据路径控制
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            row_cnt <= 0;
            col_cnt <= 0;
            burst_cnt <= 0;
            buffer_wr_ptr <= 0;
            buffer_rd_ptr <= 0;
            done <= 0;
            busy <= 0;
        end else begin
            case (state)
                IDLE: begin
                    done <= 0;
                    if (start) begin
                        row_cnt <= 0;
                        col_cnt <= 0;
                        busy <= 1;
                    end
                end
                
                READ_DATA: begin
                    if (src_rvalid) begin
                        data_buffer[buffer_wr_ptr] <= apply_transform(src_rdata);
                        buffer_wr_ptr <= buffer_wr_ptr + 1;
                        burst_cnt <= burst_cnt + 1;
                    end
                end
                
                WRITE_DATA: begin
                    if (dst_wready) begin
                        buffer_rd_ptr <= buffer_rd_ptr + 1;
                    end
                end
                
                NEXT_LINE: begin
                    col_cnt <= col_cnt + (DATA_WIDTH/8) * calculate_burst_len();
                    if (col_cnt >= width - (DATA_WIDTH/8)) begin
                        col_cnt <= 0;
                        row_cnt <= row_cnt + 1;
                        if (row_cnt == height - 1) begin
                            done <= 1;
                            busy <= 0;
                        end
                    end
                    burst_cnt <= 0;
                    buffer_wr_ptr <= 0;
                    buffer_rd_ptr <= 0;
                end
            endcase
        end
    end
    
    // AXI接口信号
    always @(*) begin
        // 默认值
        src_arvalid = 0;
        src_rready = 0;
        dst_awvalid = 0;
        dst_wvalid = 0;
        dst_bready = 0;
        
        case (state)
            READ_REQ: begin
                src_araddr = current_src_addr;
                src_arvalid = 1;
            end
            
            READ_DATA: begin
                src_rready = 1;
            end
            
            WRITE_REQ: begin
                dst_awaddr = current_dst_addr;
                dst_awvalid = 1;
            end
            
            WRITE_DATA: begin
                dst_wdata = data_buffer[buffer_rd_ptr];
                dst_wvalid = 1;
            end
            
            WRITE_RESP: begin
                dst_bready = 1;
            end
        endcase
    end
    
    // 辅助函数
    function [4:0] calculate_burst_len;
        begin
            // 根据剩余数据量计算突发长度
            if (width - col_cnt >= BURST_LEN * (DATA_WIDTH/8))
                calculate_burst_len = BURST_LEN;
            else
                calculate_burst_len = (width - col_cnt) / (DATA_WIDTH/8);
        end
    endfunction
    
    function [DATA_WIDTH-1:0] apply_transform;
        input [DATA_WIDTH-1:0] data;
        begin
            // 根据模式应用数据变换（如字节序转换等）
            case (transfer_mode)
                MODE_LINEAR, MODE_2D_BLOCK: 
                    apply_transform = data;
                MODE_TRANSPOSE:
                    apply_transform = transpose_bytes(data);
                MODE_INTERLEAVE:
                    apply_transform = interleave_channels(data);
                default:
                    apply_transform = data;
            endcase
        end
    endfunction

endmodule
                        </div>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目3.6：</strong>分析Tensor Core架构相比传统MAC阵列的优势，并计算其理论性能提升。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p><strong>1. 架构对比：</strong></p>
                        <table>
                            <tr>
                                <th>特性</th>
                                <th>传统MAC阵列</th>
                                <th>Tensor Core</th>
                            </tr>
                            <tr>
                                <td>基本运算</td>
                                <td>标量MAC: c += a × b</td>
                                <td>矩阵MAC: D = A×B + C</td>
                            </tr>
                            <tr>
                                <td>运算粒度</td>
                                <td>1×1</td>
                                <td>4×4×4 (或更大)</td>
                            </tr>
                            <tr>
                                <td>每周期运算量</td>
                                <td>2 ops (乘+加)</td>
                                <td>128 ops (4×4×4×2)</td>
                            </tr>
                            <tr>
                                <td>数据复用</td>
                                <td>有限</td>
                                <td>矩阵级复用</td>
                            </tr>
                        </table>
                        
                        <p><strong>2. Tensor Core工作原理：</strong></p>
                        <div class="code-block">
// Tensor Core执行的运算
D[4×4] = A[4×4] × B[4×4] + C[4×4]

// 分解为标量运算：
for i in 0..3:
    for j in 0..3:
        sum = 0
        for k in 0..3:
            sum += A[i][k] * B[k][j]
        D[i][j] = sum + C[i][j]

// 总运算数：4×4×4 = 64次乘法，48次加法，16次加法
// 共128 ops
                        </div>
                        
                        <p><strong>3. 性能提升计算：</strong></p>
                        <p>假设：</p>
                        <ul>
                            <li>传统MAC阵列：16×16 = 256个MAC单元</li>
                            <li>Tensor Core阵列：4×4 = 16个Tensor Core</li>
                            <li>相同的总硬件面积</li>
                        </ul>
                        
                        <p>性能对比：</p>
                        <ul>
                            <li>传统MAC：256 × 2 = 512 ops/cycle</li>
                            <li>Tensor Core：16 × 128 = 2048 ops/cycle</li>
                            <li><strong>理论加速比：4×</strong></li>
                        </ul>
                        
                        <p><strong>4. 优势分析：</strong></p>
                        <ol>
                            <li><strong>更高的计算密度：</strong>相同面积下提供更多运算</li>
                            <li><strong>更好的数据复用：</strong>矩阵运算天然具有数据复用</li>
                            <li><strong>减少控制开销：</strong>一条指令完成更多运算</li>
                            <li><strong>更适合深度学习：</strong>直接匹配GEMM运算模式</li>
                        </ol>
                        
                        <p><strong>5. 限制条件：</strong></p>
                        <ul>
                            <li>需要对齐到4×4块大小</li>
                            <li>不适合稀疏或不规则运算</li>
                            <li>精度限制（通常是混合精度）</li>
                            <li>编程模型相对复杂</li>
                        </ul>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目3.7：</strong>设计一个简单的NPU指令集架构(ISA)，包含计算、数据传输和控制指令。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p><strong>NPU ISA设计：</strong></p>
                        
                        <p><strong>1. 指令格式（32-bit）：</strong></p>
                        <div class="code-block">
[31:28] | [27:24] | [23:16] | [15:8] | [7:0]
OPCODE  | FLAGS   | DEST    | SRC1   | SRC2/IMM

OPCODE: 4-bit 操作码
FLAGS:  4-bit 标志位（精度、饱和模式等）
DEST:   8-bit 目标寄存器/地址
SRC1:   8-bit 源操作数1
SRC2:   8-bit 源操作数2或立即数
                        </div>
                        
                        <p><strong>2. 指令集分类：</strong></p>
                        
                        <p><strong>A. 计算指令：</strong></p>
                        <table>
                            <tr>
                                <th>助记符</th>
                                <th>操作码</th>
                                <th>功能</th>
                                <th>示例</th>
                            </tr>
                            <tr>
                                <td>MMUL</td>
                                <td>0x0</td>
                                <td>矩阵乘法</td>
                                <td>MMUL R0, M1, M2</td>
                            </tr>
                            <tr>
                                <td>CONV</td>
                                <td>0x1</td>
                                <td>卷积运算</td>
                                <td>CONV R0, I1, W1</td>
                            </tr>
                            <tr>
                                <td>MADD</td>
                                <td>0x2</td>
                                <td>矩阵加法</td>
                                <td>MADD R0, M1, M2</td>
                            </tr>
                            <tr>
                                <td>ACTV</td>
                                <td>0x3</td>
                                <td>激活函数</td>
                                <td>ACTV.RELU R0, R1</td>
                            </tr>
                            <tr>
                                <td>POOL</td>
                                <td>0x4</td>
                                <td>池化操作</td>
                                <td>POOL.MAX R0, I1</td>
                            </tr>
                        </table>
                        
                        <p><strong>B. 数据传输指令：</strong></p>
                        <table>
                            <tr>
                                <th>助记符</th>
                                <th>操作码</th>
                                <th>功能</th>
                                <th>示例</th>
                            </tr>
                            <tr>
                                <td>LOAD</td>
                                <td>0x8</td>
                                <td>从内存加载</td>
                                <td>LOAD R0, [ADDR]</td>
                            </tr>
                            <tr>
                                <td>STORE</td>
                                <td>0x9</td>
                                <td>存储到内存</td>
                                <td>STORE [ADDR], R0</td>
                            </tr>
                            <tr>
                                <td>DMA</td>
                                <td>0xA</td>
                                <td>DMA传输</td>
                                <td>DMA DST, SRC, LEN</td>
                            </tr>
                            <tr>
                                <td>BCAST</td>
                                <td>0xB</td>
                                <td>广播数据</td>
                                <td>BCAST R0, VAL</td>
                            </tr>
                        </table>
                        
                        <p><strong>C. 控制指令：</strong></p>
                        <table>
                            <tr>
                                <th>助记符</th>
                                <th>操作码</th>
                                <th>功能</th>
                                <th>示例</th>
                            </tr>
                            <tr>
                                <td>SYNC</td>
                                <td>0xC</td>
                                <td>同步屏障</td>
                                <td>SYNC</td>
                            </tr>
                            <tr>
                                <td>LOOP</td>
                                <td>0xD</td>
                                <td>循环控制</td>
                                <td>LOOP CNT, LABEL</td>
                            </tr>
                            <tr>
                                <td>JUMP</td>
                                <td>0xE</td>
                                <td>跳转</td>
                                <td>JUMP LABEL</td>
                            </tr>
                            <tr>
                                <td>HALT</td>
                                <td>0xF</td>
                                <td>停止执行</td>
                                <td>HALT</td>
                            </tr>
                        </table>
                        
                        <p><strong>3. 寄存器组织：</strong></p>
                        <div class="code-block">
// 通用寄存器
R0-R31: 32个通用寄存器（标量）
M0-M15: 16个矩阵寄存器（每个可存储32×32矩阵）
V0-V15: 16个向量寄存器（每个256元素）

// 特殊寄存器
PC:     程序计数器
SP:     栈指针
STATUS: 状态寄存器
CONFIG: 配置寄存器（精度模式等）
                        </div>
                        
                        <p><strong>4. 示例程序（卷积层）：</strong></p>
                        <div class="code-block">
// 执行一个3×3卷积层
// 输入: I0, 权重: W0, 输出: O0

    // 配置卷积参数
    LOAD  R0, #3        // 卷积核大小
    LOAD  R1, #1        // stride
    LOAD  R2, #1        // padding
    
    // 加载数据
    DMA   M0, [input_addr], #input_size
    DMA   M1, [weight_addr], #weight_size
    
    // 执行卷积
    CONV  M2, M0, M1    // 使用配置的参数
    
    // 应用激活函数
    ACTV.RELU M3, M2
    
    // 存储结果
    DMA   [output_addr], M3, #output_size
    
    // 同步确保完成
    SYNC
    HALT
                        </div>
                        
                        <p><strong>5. ISA特点：</strong></p>
                        <ul>
                            <li><strong>CISC风格：</strong>单条指令完成复杂操作</li>
                            <li><strong>数据并行：</strong>原生支持矩阵/向量操作</li>
                            <li><strong>内存层次感知：</strong>显式DMA管理</li>
                            <li><strong>灵活精度：</strong>通过FLAGS支持多精度</li>
                            <li><strong>硬件加速：</strong>直接映射到硬件单元</li>
                        </ul>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目3.8：</strong>评估不同的功耗优化技术对NPU的影响。给定一个100 TOPS的NPU，分析各种技术的节能潜力。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p><strong>基准NPU规格：</strong></p>
                        <ul>
                            <li>峰值性能：100 TOPS (INT8)</li>
                            <li>功耗：50W (2 TOPS/W)</li>
                            <li>工艺：7nm</li>
                            <li>频率：1GHz</li>
                        </ul>
                        
                        <p><strong>功耗优化技术分析：</strong></p>
                        <table>
                            <tr>
                                <th>优化技术</th>
                                <th>原理</th>
                                <th>节能潜力</th>
                                <th>性能影响</th>
                                <th>实现复杂度</th>
                            </tr>
                            <tr>
                                <td>时钟门控</td>
                                <td>关闭空闲单元时钟</td>
                                <td>10-20%</td>
                                <td>无</td>
                                <td>低</td>
                            </tr>
                            <tr>
                                <td>电源门控</td>
                                <td>关闭空闲单元电源</td>
                                <td>20-30%</td>
                                <td>唤醒延迟</td>
                                <td>中</td>
                            </tr>
                            <tr>
                                <td>DVFS</td>
                                <td>动态调节电压频率</td>
                                <td>30-40%</td>
                                <td>性能下降</td>
                                <td>中</td>
                            </tr>
                            <tr>
                                <td>近阈值计算</td>
                                <td>降低工作电压</td>
                                <td>50-70%</td>
                                <td>频率降低</td>
                                <td>高</td>
                            </tr>
                            <tr>
                                <td>数据压缩</td>
                                <td>减少数据传输</td>
                                <td>15-25%</td>
                                <td>轻微</td>
                                <td>中</td>
                            </tr>
                            <tr>
                                <td>稀疏计算</td>
                                <td>跳过零值运算</td>
                                <td>20-60%</td>
                                <td>依赖稀疏度</td>
                                <td>高</td>
                            </tr>
                            <tr>
                                <td>精度缩放</td>
                                <td>动态调整精度</td>
                                <td>25-40%</td>
                                <td>精度损失</td>
                                <td>中</td>
                            </tr>
                        </table>
                        
                        <p><strong>功耗分解（50W总功耗）：</strong></p>
                        <div class="code-block">
计算单元：    20W (40%)
├── MAC阵列： 15W
└── 向量单元： 5W

存储系统：    15W (30%)
├── SRAM：    10W
└── 接口：     5W

互连网络：     8W (16%)

控制逻辑：     4W (8%)

IO接口：       3W (6%)
                        </div>
                        
                        <p><strong>组合优化方案：</strong></p>
                        <ol>
                            <li><strong>方案A（保守型）：</strong>
                                <ul>
                                    <li>时钟门控 + 基础DVFS</li>
                                    <li>预期节能：25%</li>
                                    <li>功耗降至：37.5W</li>
                                    <li>能效提升至：2.67 TOPS/W</li>
                                </ul>
                            </li>
                            <li><strong>方案B（平衡型）：</strong>
                                <ul>
                                    <li>时钟/电源门控 + DVFS + 数据压缩</li>
                                    <li>预期节能：45%</li>
                                    <li>功耗降至：27.5W</li>
                                    <li>能效提升至：3.64 TOPS/W</li>
                                </ul>
                            </li>
                            <li><strong>方案C（激进型）：</strong>
                                <ul>
                                    <li>全部技术组合 + 近阈值计算</li>
                                    <li>预期节能：70%</li>
                                    <li>功耗降至：15W（但性能降至70 TOPS）</li>
                                    <li>能效提升至：4.67 TOPS/W</li>
                                </ul>
                            </li>
                        </ol>
                        
                        <p><strong>实施建议：</strong></p>
                        <ul>
                            <li>优先实施低复杂度高收益技术（时钟门控）</li>
                            <li>根据应用场景选择DVFS策略</li>
                            <li>稀疏计算需要软硬件协同优化</li>
                            <li>考虑功耗-性能-面积(PPA)平衡</li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>

        <div id="chapter4" class="chapter">
            <h2>第4章：计算核心设计</h2>
            
            <h3>4.1 MAC阵列设计</h3>
            
            <h4>4.1.1 基础MAC单元</h4>
            <p>MAC (Multiply-Accumulate) 是NPU的基本计算单元，执行 <code>C = C + A × B</code> 运算。</p>
            
            <div class="code-block">
module MAC_Unit #(
    parameter DATA_WIDTH = 8,      // 输入数据位宽(INT8)
    parameter ACC_WIDTH = 32       // 累加器位宽(防止溢出)
)(
    input wire clk,
    input wire rst_n,
    input wire enable,
    
    // 输入接口
    input wire signed [DATA_WIDTH-1:0] a_in,      // 激活值
    input wire signed [DATA_WIDTH-1:0] b_in,      // 权重
    input wire signed [ACC_WIDTH-1:0] c_in,       // 部分和输入
    
    // 输出接口
    output reg signed [ACC_WIDTH-1:0] c_out,      // 累加结果
    output reg valid_out
);

    // 内部信号
    wire signed [2*DATA_WIDTH-1:0] mult_result;
    wire signed [ACC_WIDTH-1:0] add_result;
    
    // 乘法器
    assign mult_result = a_in * b_in;
    
    // 加法器（扩展乘法结果位宽后相加）
    assign add_result = c_in + {{(ACC_WIDTH-2*DATA_WIDTH){mult_result[2*DATA_WIDTH-1]}}, mult_result};
    
    // 寄存输出
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            c_out <= 0;
            valid_out <= 0;
        end else if (enable) begin
            c_out <= add_result;
            valid_out <= 1;
        end else begin
            valid_out <= 0;
        end
    end
endmodule
            </div>

            <h4>4.1.2 多精度MAC设计</h4>
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>数据类型</th>
                            <th>乘法器面积</th>
                            <th>功耗</th>
                            <th>延迟</th>
                            <th>应用场景</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>INT4</td>
                            <td>16 gates</td>
                            <td>0.1x</td>
                            <td>1 cycle</td>
                            <td>极低功耗推理</td>
                        </tr>
                        <tr>
                            <td>INT8</td>
                            <td>64 gates</td>
                            <td>0.25x</td>
                            <td>1 cycle</td>
                            <td>主流推理</td>
                        </tr>
                        <tr>
                            <td>FP16</td>
                            <td>~400 gates</td>
                            <td>0.4x</td>
                            <td>2 cycles</td>
                            <td>训练/高精度推理</td>
                        </tr>
                        <tr>
                            <td>FP32</td>
                            <td>~1600 gates</td>
                            <td>1.0x</td>
                            <td>3 cycles</td>
                            <td>科学计算/训练</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h4>4.1.3 MAC阵列组织</h4>
            <div class="code-block">
// 二维MAC阵列组织示例 (8x8)
module MAC_Array_8x8 #(
    parameter DATA_WIDTH = 8,
    parameter ACC_WIDTH = 32,
    parameter ARRAY_SIZE = 8
)(
    input wire clk,
    input wire rst_n,
    input wire enable,
    
    // 输入数据广播
    input wire [DATA_WIDTH-1:0] act_broadcast [0:ARRAY_SIZE-1],  // 激活值广播
    input wire [DATA_WIDTH-1:0] weight_array [0:ARRAY_SIZE-1][0:ARRAY_SIZE-1],  // 权重
    
    // 部分和累加
    output wire [ACC_WIDTH-1:0] psum_out [0:ARRAY_SIZE-1][0:ARRAY_SIZE-1]
);

    // MAC单元阵列
    genvar i, j;
    generate
        for (i = 0; i < ARRAY_SIZE; i = i + 1) begin : row
            for (j = 0; j < ARRAY_SIZE; j = j + 1) begin : col
                MAC_Unit #(
                    .DATA_WIDTH(DATA_WIDTH),
                    .ACC_WIDTH(ACC_WIDTH)
                ) mac_inst (
                    .clk(clk),
                    .rst_n(rst_n),
                    .enable(enable),
                    .a_in(act_broadcast[i]),              // 行广播
                    .b_in(weight_array[i][j]),            // 本地权重
                    .c_in(/* 根据数据流选择 */),
                    .c_out(psum_out[i][j])
                );
            end
        end
    endgenerate
endmodule
            </div>

            <h3>4.2 脉动阵列架构</h3>
            
            <h4>4.2.1 脉动阵列原理</h4>
            <p>脉动阵列通过数据在PE间的有节奏流动，实现高效的数据复用和规则的计算模式。</p>
            
            <div class="info-box">
                <p><strong>核心优势：</strong></p>
                <ul>
                    <li>数据复用率高：每个数据被多个PE使用</li>
                    <li>通信局部化：只需要邻近PE间通信</li>
                    <li>控制简单：规则的数据流动模式</li>
                    <li>易于扩展：模块化设计便于增加阵列规模</li>
                </ul>
            </div>

            <h4>4.2.2 Weight Stationary脉动阵列实现</h4>
            <div class="code-block">
// 权重固定型脉动阵列PE
module SystolicPE_WS #(
    parameter DATA_WIDTH = 8,
    parameter ACC_WIDTH = 32
)(
    input wire clk,
    input wire rst_n,
    
    // 控制信号
    input wire weight_load,      // 权重加载使能
    input wire compute_en,       // 计算使能
    
    // 数据输入
    input wire [DATA_WIDTH-1:0] act_in,      // 激活值输入（从上方）
    input wire [DATA_WIDTH-1:0] weight_in,   // 权重输入（加载时）
    input wire [ACC_WIDTH-1:0] psum_in,      // 部分和输入（从左侧）
    
    // 数据输出
    output reg [DATA_WIDTH-1:0] act_out,     // 激活值输出（向下方）
    output reg [ACC_WIDTH-1:0] psum_out      // 部分和输出（向右侧）
);

    // 内部寄存器
    reg [DATA_WIDTH-1:0] weight_reg;         // 存储的权重
    reg [DATA_WIDTH-1:0] act_reg;            // 激活值寄存器
    
    // MAC运算
    wire [2*DATA_WIDTH-1:0] mult_result;
    wire [ACC_WIDTH-1:0] mac_result;
    
    assign mult_result = act_reg * weight_reg;
    assign mac_result = psum_in + {{(ACC_WIDTH-2*DATA_WIDTH){mult_result[2*DATA_WIDTH-1]}}, mult_result};
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            weight_reg <= 0;
            act_reg <= 0;
            act_out <= 0;
            psum_out <= 0;
        end else begin
            // 权重加载
            if (weight_load) begin
                weight_reg <= weight_in;
            end
            
            // 计算模式
            if (compute_en) begin
                // 激活值向下传递
                act_reg <= act_in;
                act_out <= act_reg;
                
                // MAC结果向右传递
                psum_out <= mac_result;
            end
        end
    end
endmodule

// 4x4 Weight Stationary脉动阵列
module SystolicArray_4x4_WS #(
    parameter DATA_WIDTH = 8,
    parameter ACC_WIDTH = 32,
    parameter ARRAY_DIM = 4
)(
    input wire clk,
    input wire rst_n,
    input wire weight_load,
    input wire compute_en,
    
    // 激活值输入（从顶部进入）
    input wire [DATA_WIDTH-1:0] act_in [0:ARRAY_DIM-1],
    
    // 权重加载接口
    input wire [DATA_WIDTH-1:0] weight_in [0:ARRAY_DIM-1][0:ARRAY_DIM-1],
    
    // 结果输出（从右侧输出）
    output wire [ACC_WIDTH-1:0] result_out [0:ARRAY_DIM-1]
);

    // PE间的连接线
    wire [DATA_WIDTH-1:0] act_h [0:ARRAY_DIM][0:ARRAY_DIM-1];  // 垂直连接
    wire [ACC_WIDTH-1:0] psum_h [0:ARRAY_DIM-1][0:ARRAY_DIM];  // 水平连接
    
    // 初始化边界
    genvar i, j;
    generate
        // 左边界部分和为0
        for (i = 0; i < ARRAY_DIM; i = i + 1) begin
            assign psum_h[i][0] = 0;
        end
        
        // 顶部输入激活值
        for (j = 0; j < ARRAY_DIM; j = j + 1) begin
            assign act_h[0][j] = act_in[j];
        end
    endgenerate
    
    // PE阵列实例化
    generate
        for (i = 0; i < ARRAY_DIM; i = i + 1) begin : pe_row
            for (j = 0; j < ARRAY_DIM; j = j + 1) begin : pe_col
                SystolicPE_WS #(
                    .DATA_WIDTH(DATA_WIDTH),
                    .ACC_WIDTH(ACC_WIDTH)
                ) pe_inst (
                    .clk(clk),
                    .rst_n(rst_n),
                    .weight_load(weight_load),
                    .compute_en(compute_en),
                    .act_in(act_h[i][j]),
                    .weight_in(weight_in[i][j]),
                    .psum_in(psum_h[i][j]),
                    .act_out(act_h[i+1][j]),
                    .psum_out(psum_h[i][j+1])
                );
            end
        end
    endgenerate
    
    // 输出连接
    generate
        for (i = 0; i < ARRAY_DIM; i = i + 1) begin
            assign result_out[i] = psum_h[i][ARRAY_DIM];
        end
    endgenerate
endmodule
            </div>

            <h4>4.2.3 脉动阵列数据流动示例</h4>
            <p>以2×2矩阵乘法为例，展示数据在脉动阵列中的流动过程：</p>
            <div class="code-block">
矩阵A = [a00 a01]    矩阵B = [b00 b01]    结果C = A×B
        [a10 a11]            [b10 b11]

时刻0: 权重加载
PE[0][0] <- b00    PE[0][1] <- b01
PE[1][0] <- b10    PE[1][1] <- b11

时刻1: 
输入: a00, a10 (错开一个周期)
      ↓
    [b00]--[b01]    a00×b00 → PE[0][0]
      ↓
    [b10]--[b11]    

时刻2:
输入: a01, a11
    a00  ↓
    [b00]--[b01]    a00×b01 → PE[0][1], a10×b00 → PE[1][0]
    a10  ↓
    [b10]--[b11]

时刻3:
    a01  a00
    [b00]--[b01]→c00   a01×b10 → PE[0][0], a10×b01 → PE[1][1]
    a11  a10
    [b10]--[b11]

时刻4:
         a01
    [b00]--[b01]→c01   a01×b11 → PE[0][1], a11×b10 → PE[1][0]
         a11
    [b10]--[b11]→c10

时刻5:
    [b00]--[b01]       a11×b11 → PE[1][1]
    [b10]--[b11]→c11
            </div>

            <h3>4.3 向量处理单元</h3>
            
            <h4>4.3.1 SIMD架构设计</h4>
            <p>向量处理单元采用SIMD架构，支持非线性激活、池化等操作。</p>
            
            <div class="code-block">
module VectorProcessingUnit #(
    parameter VECTOR_WIDTH = 16,    // 向量宽度（并行度）
    parameter DATA_WIDTH = 8,       // 数据位宽
    parameter OPCODE_WIDTH = 5      // 操作码宽度
)(
    input wire clk,
    input wire rst_n,
    
    // 指令接口
    input wire [OPCODE_WIDTH-1:0] opcode,
    input wire execute,
    
    // 向量输入
    input wire [DATA_WIDTH-1:0] vec_a [0:VECTOR_WIDTH-1],
    input wire [DATA_WIDTH-1:0] vec_b [0:VECTOR_WIDTH-1],
    
    // 向量输出
    output reg [DATA_WIDTH-1:0] vec_result [0:VECTOR_WIDTH-1],
    output reg done
);

    // 操作码定义
    localparam OP_ADD  = 5'b00001;
    localparam OP_SUB  = 5'b00010;
    localparam OP_MUL  = 5'b00011;
    localparam OP_MAX  = 5'b00100;
    localparam OP_MIN  = 5'b00101;
    localparam OP_RELU = 5'b00110;
    localparam OP_SIGM = 5'b00111;
    localparam OP_TANH = 5'b01000;
    
    // 功能单元输出
    wire [DATA_WIDTH-1:0] alu_out [0:VECTOR_WIDTH-1];
    wire [DATA_WIDTH-1:0] act_out [0:VECTOR_WIDTH-1];
    
    // SIMD ALU阵列
    genvar i;
    generate
        for (i = 0; i < VECTOR_WIDTH; i = i + 1) begin : simd_lane
            // 算术逻辑单元
            VectorALU #(.DATA_WIDTH(DATA_WIDTH)) alu_inst (
                .a(vec_a[i]),
                .b(vec_b[i]),
                .op(opcode[2:0]),
                .result(alu_out[i])
            );
            
            // 激活函数单元
            ActivationUnit #(.DATA_WIDTH(DATA_WIDTH)) act_inst (
                .data_in(vec_a[i]),
                .func_sel(opcode[4:3]),
                .data_out(act_out[i])
            );
        end
    endgenerate
    
    // 结果选择和流水线控制
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            done <= 0;
        end else if (execute) begin
            case (opcode)
                OP_ADD, OP_SUB, OP_MUL, OP_MAX, OP_MIN: begin
                    for (int j = 0; j < VECTOR_WIDTH; j = j + 1) begin
                        vec_result[j] <= alu_out[j];
                    end
                end
                OP_RELU, OP_SIGM, OP_TANH: begin
                    for (int j = 0; j < VECTOR_WIDTH; j = j + 1) begin
                        vec_result[j] <= act_out[j];
                    end
                end
            endcase
            done <= 1;
        end else begin
            done <= 0;
        end
    end
endmodule
            </div>

            <h4>4.3.2 特殊功能单元</h4>
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>功能单元</th>
                            <th>操作</th>
                            <th>实现方式</th>
                            <th>硬件成本</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>ReLU单元</td>
                            <td>max(0, x)</td>
                            <td>比较器+选择器</td>
                            <td>极低</td>
                        </tr>
                        <tr>
                            <td>池化单元</td>
                            <td>max/avg pooling</td>
                            <td>比较树/加法树</td>
                            <td>低</td>
                        </tr>
                        <tr>
                            <td>LUT单元</td>
                            <td>sigmoid/tanh</td>
                            <td>查找表+插值</td>
                            <td>中等</td>
                        </tr>
                        <tr>
                            <td>归一化单元</td>
                            <td>batch/layer norm</td>
                            <td>乘法器+移位器</td>
                            <td>高</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h3>4.4 特殊计算单元</h3>
            
            <h4>4.4.1 Tensor Core设计</h4>
            <p>Tensor Core是一种执行小矩阵乘法的专用单元，提供更高的计算密度。</p>
            
            <div class="code-block">
// 4x4x4 Tensor Core实现
// 计算 D = A×B + C，其中A、B、C、D都是4×4矩阵
module TensorCore_4x4x4 #(
    parameter DATA_WIDTH = 8,
    parameter ACC_WIDTH = 32
)(
    input wire clk,
    input wire rst_n,
    input wire enable,
    
    // 输入矩阵（扁平化表示）
    input wire [DATA_WIDTH-1:0] mat_a [0:15],  // 4x4矩阵A
    input wire [DATA_WIDTH-1:0] mat_b [0:15],  // 4x4矩阵B
    input wire [ACC_WIDTH-1:0] mat_c [0:15],   // 4x4矩阵C（累加）
    
    // 输出矩阵
    output reg [ACC_WIDTH-1:0] mat_d [0:15],   // 4x4结果矩阵D
    output reg valid
);

    // 内部信号
    wire [ACC_WIDTH-1:0] dot_products [0:15];
    
    // 生成16个点积计算单元
    genvar i, j, k;
    generate
        for (i = 0; i < 4; i = i + 1) begin : row
            for (j = 0; j < 4; j = j + 1) begin : col
                // 计算D[i][j] = sum(A[i][k] * B[k][j]) + C[i][j]
                wire [2*DATA_WIDTH-1:0] products [0:3];
                wire [ACC_WIDTH-1:0] sum;
                
                // 4个并行乘法器
                for (k = 0; k < 4; k = k + 1) begin : mult
                    assign products[k] = mat_a[i*4+k] * mat_b[k*4+j];
                end
                
                // 加法树
                assign sum = mat_c[i*4+j] + 
                           {{(ACC_WIDTH-2*DATA_WIDTH){products[0][2*DATA_WIDTH-1]}}, products[0]} +
                           {{(ACC_WIDTH-2*DATA_WIDTH){products[1][2*DATA_WIDTH-1]}}, products[1]} +
                           {{(ACC_WIDTH-2*DATA_WIDTH){products[2][2*DATA_WIDTH-1]}}, products[2]} +
                           {{(ACC_WIDTH-2*DATA_WIDTH){products[3][2*DATA_WIDTH-1]}}, products[3]};
                
                assign dot_products[i*4+j] = sum;
            end
        end
    endgenerate
    
    // 寄存输出
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            valid <= 0;
        end else if (enable) begin
            for (int idx = 0; idx < 16; idx = idx + 1) begin
                mat_d[idx] <= dot_products[idx];
            end
            valid <= 1;
        end else begin
            valid <= 0;
        end
    end
endmodule
            </div>

            <h4>4.4.2 稀疏计算支持</h4>
            <p>支持结构化稀疏（如2:4稀疏）可以显著提升有效计算吞吐量。</p>
            
            <div class="code-block">
// 2:4结构化稀疏MAC单元
// 每4个权重中有2个非零值
module SparseMACUnit_2in4 #(
    parameter DATA_WIDTH = 8,
    parameter ACC_WIDTH = 32
)(
    input wire clk,
    input wire rst_n,
    input wire enable,
    
    // 稀疏权重输入（2个非零值）
    input wire [DATA_WIDTH-1:0] weight_values [0:1],  // 非零权重值
    input wire [1:0] weight_indices [0:1],            // 权重位置索引(0-3)
    
    // 4个激活值输入
    input wire [DATA_WIDTH-1:0] activations [0:3],
    
    // 累加输入输出
    input wire [ACC_WIDTH-1:0] psum_in,
    output reg [ACC_WIDTH-1:0] psum_out,
    output reg valid
);

    // 选择对应的激活值并计算
    wire [DATA_WIDTH-1:0] selected_acts [0:1];
    wire [2*DATA_WIDTH-1:0] products [0:1];
    wire [ACC_WIDTH-1:0] sum;
    
    // 根据索引选择激活值
    assign selected_acts[0] = activations[weight_indices[0]];
    assign selected_acts[1] = activations[weight_indices[1]];
    
    // 计算两个乘积
    assign products[0] = selected_acts[0] * weight_values[0];
    assign products[1] = selected_acts[1] * weight_values[1];
    
    // 累加
    assign sum = psum_in + 
                {{(ACC_WIDTH-2*DATA_WIDTH){products[0][2*DATA_WIDTH-1]}}, products[0]} +
                {{(ACC_WIDTH-2*DATA_WIDTH){products[1][2*DATA_WIDTH-1]}}, products[1]};
    
    // 寄存输出
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            psum_out <= 0;
            valid <= 0;
        end else if (enable) begin
            psum_out <= sum;
            valid <= 1;
        end else begin
            valid <= 0;
        end
    end
endmodule
            </div>

            <div class="exercise">
                <h4>练习题集 4</h4>
                
                <div class="question">
                    <p><strong>题目4.1：</strong>设计一个支持INT8/INT16混合精度的MAC单元。要求能够处理不同精度的输入组合。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module MixedPrecisionMAC #(
    parameter MAX_WIDTH = 16,      // 最大数据宽度
    parameter ACC_WIDTH = 48       // 累加器宽度（支持INT16×INT16）
)(
    input wire clk,
    input wire rst_n,
    input wire enable,
    
    // 输入数据和精度控制
    input wire [MAX_WIDTH-1:0] a_in,
    input wire [MAX_WIDTH-1:0] b_in,
    input wire [1:0] precision_mode,  // 00: INT8×INT8, 01: INT8×INT16, 10: INT16×INT8, 11: INT16×INT16
    input wire [ACC_WIDTH-1:0] c_in,
    
    // 输出
    output reg [ACC_WIDTH-1:0] c_out,
    output reg valid_out
);

    // 内部信号
    reg signed [MAX_WIDTH-1:0] a_ext, b_ext;
    wire signed [2*MAX_WIDTH-1:0] mult_result;
    wire signed [ACC_WIDTH-1:0] add_result;
    
    // 根据精度模式进行符号扩展
    always @(*) begin
        case (precision_mode)
            2'b00: begin  // INT8 × INT8
                a_ext = {{8{a_in[7]}}, a_in[7:0]};
                b_ext = {{8{b_in[7]}}, b_in[7:0]};
            end
            2'b01: begin  // INT8 × INT16
                a_ext = {{8{a_in[7]}}, a_in[7:0]};
                b_ext = b_in;
            end
            2'b10: begin  // INT16 × INT8
                a_ext = a_in;
                b_ext = {{8{b_in[7]}}, b_in[7:0]};
            end
            2'b11: begin  // INT16 × INT16
                a_ext = a_in;
                b_ext = b_in;
            end
        endcase
    end
    
    // 乘法器（支持最大精度）
    assign mult_result = a_ext * b_ext;
    
    // 累加器
    assign add_result = c_in + {{(ACC_WIDTH-2*MAX_WIDTH){mult_result[2*MAX_WIDTH-1]}}, mult_result};
    
    // 输出寄存
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            c_out <= 0;
            valid_out <= 0;
        end else if (enable) begin
            c_out <= add_result;
            valid_out <= 1;
        end else begin
            valid_out <= 0;
        end
    end
    
    // 功耗优化：根据精度模式门控高位逻辑
    // 实际实现中可以添加时钟门控逻辑
endmodule
                        </div>
                        <p><strong>设计要点：</strong></p>
                        <ul>
                            <li>使用参数化的最大位宽支持多种精度</li>
                            <li>根据精度模式进行正确的符号扩展</li>
                            <li>累加器位宽需要足够大以防止溢出</li>
                            <li>可以通过时钟门控优化低精度模式的功耗</li>
                        </ul>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目4.2：</strong>分析脉动阵列的三种数据流（WS/OS/RS）在执行1×1卷积时的效率差异。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p><strong>1×1卷积特点：</strong></p>
                        <ul>
                            <li>没有空间维度的滑动窗口</li>
                            <li>本质上是通道间的线性组合</li>
                            <li>可以完全转化为矩阵乘法</li>
                        </ul>
                        
                        <table>
                            <tr>
                                <th>数据流</th>
                                <th>数据复用</th>
                                <th>带宽需求</th>
                                <th>控制复杂度</th>
                                <th>1×1卷积效率</th>
                            </tr>
                            <tr>
                                <td>Weight Stationary (WS)</td>
                                <td>权重100%复用<br>激活值无复用</td>
                                <td>低（权重预加载）</td>
                                <td>简单</td>
                                <td><strong>最优</strong></td>
                            </tr>
                            <tr>
                                <td>Output Stationary (OS)</td>
                                <td>部分和本地累加<br>权重和激活都需流动</td>
                                <td>高</td>
                                <td>中等</td>
                                <td>较差</td>
                            </tr>
                            <tr>
                                <td>Row Stationary (RS)</td>
                                <td>退化为WS模式</td>
                                <td>低</td>
                                <td>复杂（但退化后简化）</td>
                                <td>等同于WS</td>
                            </tr>
                        </table>
                        
                        <p><strong>定量分析（假设计算1×1×256×256卷积）：</strong></p>
                        <ul>
                            <li><strong>WS模式：</strong>
                                <ul>
                                    <li>权重读取：256×256 = 65,536次（仅一次）</li>
                                    <li>激活值读取：取决于输入特征图大小</li>
                                    <li>部分和写回：每个输出位置一次</li>
                                </ul>
                            </li>
                            <li><strong>OS模式：</strong>
                                <ul>
                                    <li>权重读取：每个空间位置都需要读取所有权重</li>
                                    <li>带宽需求增加H×W倍</li>
                                </ul>
                            </li>
                        </ul>
                        
                        <p><strong>结论：</strong>对于1×1卷积，WS数据流最优，因为可以充分利用权重复用，而没有空间维度的复用需求。</p>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目4.3：</strong>设计一个8×8脉动阵列的控制器，支持矩阵分块计算。输入矩阵可能大于8×8。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module SystolicArrayController #(
    parameter ARRAY_DIM = 8,
    parameter DATA_WIDTH = 8,
    parameter ADDR_WIDTH = 32,
    parameter ACC_WIDTH = 32
)(
    input wire clk,
    input wire rst_n,
    
    // 配置接口
    input wire [31:0] M, N, K,              // 矩阵维度
    input wire [ADDR_WIDTH-1:0] addr_a,    // 矩阵A基地址
    input wire [ADDR_WIDTH-1:0] addr_b,    // 矩阵B基地址
    input wire [ADDR_WIDTH-1:0] addr_c,    // 矩阵C基地址
    input wire start,
    output reg done,
    
    // 内存接口
    output reg [ADDR_WIDTH-1:0] mem_addr_a,
    output reg [ADDR_WIDTH-1:0] mem_addr_b,
    output reg [ADDR_WIDTH-1:0] mem_addr_c,
    output reg mem_rd_a, mem_rd_b,
    output reg mem_wr_c,
    input wire [DATA_WIDTH*ARRAY_DIM-1:0] mem_data_a,
    input wire [DATA_WIDTH*ARRAY_DIM-1:0] mem_data_b,
    output reg [ACC_WIDTH*ARRAY_DIM-1:0] mem_data_c,
    
    // 脉动阵列接口
    output reg sa_weight_load,
    output reg sa_compute_en,
    output reg [DATA_WIDTH-1:0] sa_act_in [0:ARRAY_DIM-1],
    output reg [DATA_WIDTH-1:0] sa_weight_in [0:ARRAY_DIM-1][0:ARRAY_DIM-1],
    input wire [ACC_WIDTH-1:0] sa_result_out [0:ARRAY_DIM-1]
);

    // 状态机定义
    typedef enum logic [3:0] {
        IDLE,
        CALC_TILES,
        LOAD_WEIGHT,
        INIT_COMPUTE,
        COMPUTE,
        DRAIN,
        STORE_RESULT,
        NEXT_TILE
    } state_t;
    
    state_t state, next_state;
    
    // 分块计算控制
    reg [31:0] tile_m, tile_n, tile_k;     // 当前分块索引
    reg [31:0] num_tiles_m, num_tiles_n, num_tiles_k;
    reg [31:0] compute_cycles;              // 计算周期计数
    reg [31:0] row_offset, col_offset;     // 数据输入偏移
    
    // 计算分块数量
    always @(posedge clk) begin
        if (start) begin
            num_tiles_m <= (M + ARRAY_DIM - 1) / ARRAY_DIM;
            num_tiles_n <= (N + ARRAY_DIM - 1) / ARRAY_DIM;
            num_tiles_k <= (K + ARRAY_DIM - 1) / ARRAY_DIM;
        end
    end
    
    // 状态转换
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n)
            state <= IDLE;
        else
            state <= next_state;
    end
    
    always @(*) begin
        next_state = state;
        case (state)
            IDLE: begin
                if (start)
                    next_state = CALC_TILES;
            end
            
            CALC_TILES: begin
                next_state = LOAD_WEIGHT;
            end
            
            LOAD_WEIGHT: begin
                if (compute_cycles == ARRAY_DIM - 1)
                    next_state = INIT_COMPUTE;
            end
            
            INIT_COMPUTE: begin
                next_state = COMPUTE;
            end
            
            COMPUTE: begin
                // 需要K个周期完成一个K维的点积
                if (compute_cycles == K - 1)
                    next_state = DRAIN;
            end
            
            DRAIN: begin
                // 等待最后的结果流出
                if (compute_cycles == ARRAY_DIM - 1)
                    next_state = STORE_RESULT;
            end
            
            STORE_RESULT: begin
                if (compute_cycles == ARRAY_DIM - 1)
                    next_state = NEXT_TILE;
            end
            
            NEXT_TILE: begin
                if (tile_k < num_tiles_k - 1) begin
                    // 同一输出块的下一个K分块
                    next_state = LOAD_WEIGHT;
                end else if (tile_n < num_tiles_n - 1 || tile_m < num_tiles_m - 1) begin
                    // 下一个输出块
                    next_state = LOAD_WEIGHT;
                end else begin
                    // 完成所有计算
                    next_state = IDLE;
                end
            end
        endcase
    end
    
    // 数据路径控制
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            tile_m <= 0;
            tile_n <= 0;
            tile_k <= 0;
            compute_cycles <= 0;
            done <= 0;
            sa_weight_load <= 0;
            sa_compute_en <= 0;
            mem_rd_a <= 0;
            mem_rd_b <= 0;
            mem_wr_c <= 0;
        end else begin
            case (state)
                IDLE: begin
                    done <= 0;
                    if (start) begin
                        tile_m <= 0;
                        tile_n <= 0;
                        tile_k <= 0;
                    end
                end
                
                LOAD_WEIGHT: begin
                    // 加载权重矩阵B的一个tile
                    sa_weight_load <= 1;
                    mem_rd_b <= 1;
                    mem_addr_b <= addr_b + 
                                 (tile_n * ARRAY_DIM * K + tile_k * ARRAY_DIM) * DATA_WIDTH/8;
                    
                    // 将权重数据分配到阵列
                    // 简化处理：假设数据已正确排列
                    for (int i = 0; i < ARRAY_DIM; i++) begin
                        for (int j = 0; j < ARRAY_DIM; j++) begin
                            sa_weight_in[i][j] <= mem_data_b[(i*ARRAY_DIM+j)*DATA_WIDTH +: DATA_WIDTH];
                        end
                    end
                    
                    compute_cycles <= compute_cycles + 1;
                    if (compute_cycles == ARRAY_DIM - 1) begin
                        compute_cycles <= 0;
                        sa_weight_load <= 0;
                        mem_rd_b <= 0;
                    end
                end
                
                COMPUTE: begin
                    // 流式输入激活值
                    sa_compute_en <= 1;
                    mem_rd_a <= 1;
                    
                    // 计算当前输入地址
                    mem_addr_a <= addr_a + 
                                 ((tile_m * ARRAY_DIM + row_offset) * K + 
                                  tile_k * ARRAY_DIM + col_offset) * DATA_WIDTH/8;
                    
                    // 错开输入时序（脉动阵列需要）
                    for (int i = 0; i < ARRAY_DIM; i++) begin
                        if (compute_cycles >= i && compute_cycles - i < K) begin
                            sa_act_in[i] <= mem_data_a[i*DATA_WIDTH +: DATA_WIDTH];
                        end else begin
                            sa_act_in[i] <= 0;
                        end
                    end
                    
                    compute_cycles <= compute_cycles + 1;
                    col_offset <= col_offset + 1;
                    
                    if (col_offset == ARRAY_DIM - 1) begin
                        col_offset <= 0;
                        row_offset <= row_offset + 1;
                    end
                    
                    if (compute_cycles == K - 1) begin
                        compute_cycles <= 0;
                        row_offset <= 0;
                        col_offset <= 0;
                        sa_compute_en <= 0;
                        mem_rd_a <= 0;
                    end
                end
                
                STORE_RESULT: begin
                    // 存储计算结果
                    mem_wr_c <= 1;
                    mem_addr_c <= addr_c + 
                                 ((tile_m * ARRAY_DIM + compute_cycles) * N + 
                                  tile_n * ARRAY_DIM) * ACC_WIDTH/8;
                    
                    // 收集结果
                    for (int i = 0; i < ARRAY_DIM; i++) begin
                        mem_data_c[i*ACC_WIDTH +: ACC_WIDTH] <= sa_result_out[i];
                    end
                    
                    compute_cycles <= compute_cycles + 1;
                    if (compute_cycles == ARRAY_DIM - 1) begin
                        compute_cycles <= 0;
                        mem_wr_c <= 0;
                    end
                end
                
                NEXT_TILE: begin
                    if (tile_k < num_tiles_k - 1) begin
                        tile_k <= tile_k + 1;
                    end else begin
                        tile_k <= 0;
                        if (tile_n < num_tiles_n - 1) begin
                            tile_n <= tile_n + 1;
                        end else begin
                            tile_n <= 0;
                            tile_m <= tile_m + 1;
                        end
                    end
                    
                    if (tile_m == num_tiles_m - 1 && 
                        tile_n == num_tiles_n - 1 && 
                        tile_k == num_tiles_k - 1) begin
                        done <= 1;
                    end
                end
            endcase
        end
    end
endmodule
                        </div>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目4.4：</strong>设计一个高效的激活函数单元，支持ReLU、Leaky ReLU和Swish。考虑面积和延迟的权衡。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module EfficientActivationUnit #(
    parameter DATA_WIDTH = 16,
    parameter FRAC_WIDTH = 8    // 小数位宽（定点数）
)(
    input wire clk,
    input wire rst_n,
    input wire enable,
    
    // 输入数据
    input wire signed [DATA_WIDTH-1:0] data_in,
    
    // 功能选择和参数
    input wire [1:0] func_sel,  // 00: ReLU, 01: LeakyReLU, 10: Swish
    input wire [DATA_WIDTH-1:0] alpha,  // LeakyReLU的斜率（定点表示）
    
    // 输出
    output reg signed [DATA_WIDTH-1:0] data_out,
    output reg valid
);

    // 内部信号
    wire is_negative;
    wire signed [DATA_WIDTH-1:0] relu_out;
    wire signed [DATA_WIDTH-1:0] leaky_relu_out;
    wire signed [DATA_WIDTH-1:0] swish_out;
    
    // 负数检测
    assign is_negative = data_in[DATA_WIDTH-1];
    
    // ReLU: max(0, x)
    assign relu_out = is_negative ? {DATA_WIDTH{1'b0}} : data_in;
    
    // Leaky ReLU: x if x > 0, else alpha * x
    wire signed [2*DATA_WIDTH-1:0] alpha_mult;
    assign alpha_mult = data_in * alpha;
    assign leaky_relu_out = is_negative ? 
                           alpha_mult[DATA_WIDTH+FRAC_WIDTH-1:FRAC_WIDTH] : 
                           data_in;
    
    // Swish: x * sigmoid(x)
    // 使用分段线性逼近sigmoid
    wire signed [DATA_WIDTH-1:0] sigmoid_approx;
    SwishLUT #(
        .DATA_WIDTH(DATA_WIDTH),
        .FRAC_WIDTH(FRAC_WIDTH)
    ) swish_lut (
        .x(data_in),
        .sigmoid_x(sigmoid_approx)
    );
    
    wire signed [2*DATA_WIDTH-1:0] swish_mult;
    assign swish_mult = data_in * sigmoid_approx;
    assign swish_out = swish_mult[DATA_WIDTH+FRAC_WIDTH-1:FRAC_WIDTH];
    
    // 输出选择（组合逻辑，最小化延迟）
    always @(*) begin
        case (func_sel)
            2'b00: data_out = relu_out;
            2'b01: data_out = leaky_relu_out;
            2'b10: data_out = swish_out;
            default: data_out = data_in;  // 直通
        endcase
    end
    
    // 有效信号生成
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            valid <= 0;
        end else begin
            valid <= enable;
        end
    end
endmodule

// Swish激活函数的LUT实现
module SwishLUT #(
    parameter DATA_WIDTH = 16,
    parameter FRAC_WIDTH = 8,
    parameter LUT_DEPTH = 256  // LUT条目数
)(
    input wire signed [DATA_WIDTH-1:0] x,
    output reg signed [DATA_WIDTH-1:0] sigmoid_x
);

    // 定义查找表（实际中由工具生成）
    reg signed [DATA_WIDTH-1:0] lut_table [0:LUT_DEPTH-1];
    
    // LUT初始化（sigmoid函数的采样点）
    initial begin
        // 覆盖范围 [-8, 8]，均匀采样
        for (int i = 0; i < LUT_DEPTH; i++) begin
            real x_real = -8.0 + 16.0 * i / (LUT_DEPTH - 1);
            real sigmoid_real = 1.0 / (1.0 + $exp(-x_real));
            lut_table[i] = sigmoid_real * (1 << FRAC_WIDTH);
        end
    end
    
    // 地址计算和查表
    wire [7:0] lut_addr;
    wire signed [DATA_WIDTH-1:0] x_saturated;
    
    // 饱和到[-8, 8]范围
    assign x_saturated = (x > (8 << FRAC_WIDTH)) ? (8 << FRAC_WIDTH) :
                        (x < (-8 << FRAC_WIDTH)) ? (-8 << FRAC_WIDTH) : x;
    
    // 映射到LUT地址
    assign lut_addr = ((x_saturated + (8 << FRAC_WIDTH)) * LUT_DEPTH) >> (FRAC_WIDTH + 4);
    
    // 查表（可以添加线性插值以提高精度）
    always @(*) begin
        sigmoid_x = lut_table[lut_addr];
    end
endmodule
                        </div>
                        <p><strong>设计权衡分析：</strong></p>
                        <table>
                            <tr>
                                <th>激活函数</th>
                                <th>硬件成本</th>
                                <th>延迟</th>
                                <th>精度</th>
                            </tr>
                            <tr>
                                <td>ReLU</td>
                                <td>极低（1个比较器）</td>
                                <td>0延迟</td>
                                <td>精确</td>
                            </tr>
                            <tr>
                                <td>Leaky ReLU</td>
                                <td>低（1个乘法器）</td>
                                <td>1个乘法延迟</td>
                                <td>取决于alpha精度</td>
                            </tr>
                            <tr>
                                <td>Swish</td>
                                <td>中等（LUT+乘法器）</td>
                                <td>查表+乘法延迟</td>
                                <td>取决于LUT大小</td>
                            </tr>
                        </table>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目4.5：</strong>分析Tensor Core相比传统脉动阵列在执行批量矩阵乘法(Batched GEMM)时的优势。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p><strong>批量矩阵乘法场景：</strong>计算C[i] = A[i] × B[i]，其中i = 0...batch_size-1</p>
                        
                        <p><strong>1. 传统脉动阵列处理方式：</strong></p>
                        <ul>
                            <li>串行处理：依次计算每个矩阵乘法</li>
                            <li>时间复杂度：O(batch_size × 矩阵乘法时间)</li>
                            <li>无法利用batch维度的并行性</li>
                        </ul>
                        
                        <p><strong>2. Tensor Core优势：</strong></p>
                        <table>
                            <tr>
                                <th>方面</th>
                                <th>传统脉动阵列</th>
                                <th>Tensor Core</th>
                                <th>优势倍数</th>
                            </tr>
                            <tr>
                                <td>基本运算粒度</td>
                                <td>标量MAC</td>
                                <td>4×4×4矩阵乘法</td>
                                <td>64×</td>
                            </tr>
                            <tr>
                                <td>批处理能力</td>
                                <td>串行</td>
                                <td>可并行多个小矩阵</td>
                                <td>与batch size相关</td>
                            </tr>
                            <tr>
                                <td>数据重排开销</td>
                                <td>需要外部重排</td>
                                <td>硬件原生支持</td>
                                <td>-</td>
                            </tr>
                            <tr>
                                <td>寄存器利用率</td>
                                <td>~50%</td>
                                <td>~90%</td>
                                <td>1.8×</td>
                            </tr>
                        </table>
                        
                        <p><strong>3. 具体示例（Transformer注意力计算）：</strong></p>
                        <div class="code-block">
// Transformer中的批量矩阵乘法
// Q, K, V: [batch_size, seq_len, d_model]
// 需要计算：Attention = softmax(Q × K^T) × V

// 传统脉动阵列：
for (batch = 0; batch < batch_size; batch++) {
    // 计算 Q[batch] × K[batch]^T
    systolic_array_compute(Q[batch], K[batch].T);
    // 等待完成...
}
// 总时间：batch_size × (seq_len × seq_len × d_model)

// Tensor Core：
// 可以将多个batch的小块同时映射到不同的Tensor Core
for (batch_group = 0; batch_group < batch_size; batch_group += 4) {
    // 4个batch并行计算
    tensor_core_batch_compute(Q[batch_group:batch_group+4], 
                            K[batch_group:batch_group+4].T);
}
// 总时间：(batch_size/4) × (seq_len × seq_len × d_model) / 64
                        </div>
                        
                        <p><strong>4. 性能提升分析：</strong></p>
                        <ul>
                            <li>理论加速比：最高可达 4× (batch并行) × 64× (Tensor Core加速) = 256×</li>
                            <li>实际加速比：考虑内存带宽限制，通常为10-50×</li>
                            <li>功耗效率提升：3-5×（更少的数据移动）</li>
                        </ul>
                        
                        <p><strong>5. 适用条件：</strong></p>
                        <ul>
                            <li>矩阵尺寸是4的倍数</li>
                            <li>Batch size较大（≥4）</li>
                            <li>支持的数据精度（通常是FP16/INT8混合）</li>
                        </ul>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目4.6：</strong>设计一个支持动态稀疏的MAC阵列。要求能够跳过零权重和零激活值的计算。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module DynamicSparseMACArray #(
    parameter DATA_WIDTH = 8,
    parameter ACC_WIDTH = 32,
    parameter PE_NUM = 16,        // PE数量
    parameter FIFO_DEPTH = 8      // 输入FIFO深度
)(
    input wire clk,
    input wire rst_n,
    input wire enable,
    
    // 稀疏数据输入（压缩格式）
    input wire [DATA_WIDTH-1:0] act_values [0:PE_NUM-1],      // 非零激活值
    input wire [4:0] act_indices [0:PE_NUM-1],                // 激活值索引
    input wire [PE_NUM-1:0] act_valid,                        // 激活值有效标志
    
    input wire [DATA_WIDTH-1:0] weight_values [0:PE_NUM-1],   // 非零权重
    input wire [4:0] weight_indices [0:PE_NUM-1],             // 权重索引
    input wire [PE_NUM-1:0] weight_valid,                     // 权重有效标志
    
    // 输出接口
    output reg [ACC_WIDTH-1:0] results [0:PE_NUM-1],
    output reg [PE_NUM-1:0] result_valid,
    output reg done
);

    // PE阵列
    genvar i;
    generate
        for (i = 0; i < PE_NUM; i = i + 1) begin : sparse_pe
            SparsePE #(
                .DATA_WIDTH(DATA_WIDTH),
                .ACC_WIDTH(ACC_WIDTH),
                .FIFO_DEPTH(FIFO_DEPTH)
            ) pe_inst (
                .clk(clk),
                .rst_n(rst_n),
                .enable(enable),
                .act_value(act_values[i]),
                .act_index(act_indices[i]),
                .act_valid(act_valid[i]),
                .weight_value(weight_values[i]),
                .weight_index(weight_indices[i]),
                .weight_valid(weight_valid[i]),
                .result(results[i]),
                .result_valid(result_valid[i])
            );
        end
    endgenerate
    
    // 完成信号生成
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            done <= 0;
        end else begin
            done <= &result_valid;  // 所有PE完成
        end
    end
endmodule

// 稀疏PE单元
module SparsePE #(
    parameter DATA_WIDTH = 8,
    parameter ACC_WIDTH = 32,
    parameter FIFO_DEPTH = 8
)(
    input wire clk,
    input wire rst_n,
    input wire enable,
    
    // 稀疏输入
    input wire [DATA_WIDTH-1:0] act_value,
    input wire [4:0] act_index,
    input wire act_valid,
    
    input wire [DATA_WIDTH-1:0] weight_value,
    input wire [4:0] weight_index,
    input wire weight_valid,
    
    // 输出
    output reg [ACC_WIDTH-1:0] result,
    output reg result_valid
);

    // 输入FIFO
    reg [DATA_WIDTH-1:0] act_fifo_data [0:FIFO_DEPTH-1];
    reg [4:0] act_fifo_index [0:FIFO_DEPTH-1];
    reg [DATA_WIDTH-1:0] weight_fifo_data [0:FIFO_DEPTH-1];
    reg [4:0] weight_fifo_index [0:FIFO_DEPTH-1];
    
    reg [2:0] act_wr_ptr, act_rd_ptr;
    reg [2:0] weight_wr_ptr, weight_rd_ptr;
    reg [3:0] act_count, weight_count;
    
    // 匹配逻辑
    wire index_match;
    wire compute_valid;
    
    assign index_match = (act_fifo_index[act_rd_ptr] == weight_fifo_index[weight_rd_ptr]);
    assign compute_valid = (act_count > 0) && (weight_count > 0) && index_match;
    
    // MAC计算
    wire signed [2*DATA_WIDTH-1:0] mult_result;
    wire signed [ACC_WIDTH-1:0] acc_result;
    
    assign mult_result = act_fifo_data[act_rd_ptr] * weight_fifo_data[weight_rd_ptr];
    assign acc_result = result + {{(ACC_WIDTH-2*DATA_WIDTH){mult_result[2*DATA_WIDTH-1]}}, mult_result};
    
    // FIFO写入逻辑
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            act_wr_ptr <= 0;
            weight_wr_ptr <= 0;
            act_count <= 0;
            weight_count <= 0;
        end else if (enable) begin
            // 激活值FIFO写入
            if (act_valid && act_count < FIFO_DEPTH) begin
                act_fifo_data[act_wr_ptr] <= act_value;
                act_fifo_index[act_wr_ptr] <= act_index;
                act_wr_ptr <= act_wr_ptr + 1;
                act_count <= act_count + 1;
            end
            
            // 权重FIFO写入
            if (weight_valid && weight_count < FIFO_DEPTH) begin
                weight_fifo_data[weight_wr_ptr] <= weight_value;
                weight_fifo_index[weight_wr_ptr] <= weight_index;
                weight_wr_ptr <= weight_wr_ptr + 1;
                weight_count <= weight_count + 1;
            end
        end
    end
    
    // 计算和FIFO读取逻辑
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            result <= 0;
            result_valid <= 0;
            act_rd_ptr <= 0;
            weight_rd_ptr <= 0;
        end else if (enable) begin
            if (compute_valid) begin
                // 执行MAC运算
                result <= acc_result;
                
                // 更新读指针
                act_rd_ptr <= act_rd_ptr + 1;
                weight_rd_ptr <= weight_rd_ptr + 1;
                act_count <= act_count - 1;
                weight_count <= weight_count - 1;
            end else if (act_count > 0 && weight_count > 0) begin
                // 索引不匹配，跳过较小的索引
                if (act_fifo_index[act_rd_ptr] < weight_fifo_index[weight_rd_ptr]) begin
                    act_rd_ptr <= act_rd_ptr + 1;
                    act_count <= act_count - 1;
                end else begin
                    weight_rd_ptr <= weight_rd_ptr + 1;
                    weight_count <= weight_count - 1;
                end
            end
            
            // 生成完成信号
            result_valid <= (act_count == 0) || (weight_count == 0);
        end
    end
endmodule
                        </div>
                        <p><strong>设计特点：</strong></p>
                        <ul>
                            <li>使用FIFO缓存稀疏数据，解耦输入和计算</li>
                            <li>索引匹配逻辑，只计算索引相同的元素</li>
                            <li>支持不同稀疏度的激活值和权重</li>
                            <li>自动跳过不匹配的索引，提高效率</li>
                        </ul>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目4.7：</strong>优化一个16×16脉动阵列的时钟分配网络，考虑时钟偏斜和功耗。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p><strong>1. 时钟网络挑战：</strong></p>
                        <ul>
                            <li>16×16 = 256个PE，每个PE需要同步时钟</li>
                            <li>时钟偏斜影响最高工作频率</li>
                            <li>时钟网络功耗占总功耗的20-30%</li>
                        </ul>
                        
                        <p><strong>2. H-Tree时钟分配设计：</strong></p>
                        <div class="code-block">
module ClockTreeOptimized_16x16 (
    input wire clk_in,
    input wire [255:0] clock_enable,  // 每个PE的时钟使能
    output wire clk_out [0:15][0:15]  // 分配到每个PE的时钟
);

    // H-Tree层次结构
    // Level 0: 根节点
    wire clk_l0;
    ClockBuffer #(.DRIVE_STRENGTH(16)) buf_l0 (
        .clk_in(clk_in),
        .clk_out(clk_l0)
    );
    
    // Level 1: 4个象限
    wire clk_l1 [0:3];
    genvar q;
    generate
        for (q = 0; q < 4; q = q + 1) begin : quadrant
            ClockBuffer #(.DRIVE_STRENGTH(8)) buf_l1 (
                .clk_in(clk_l0),
                .clk_out(clk_l1[q])
            );
        end
    endgenerate
    
    // Level 2: 16个区域（4×4）
    wire clk_l2 [0:3][0:3];
    genvar i, j;
    generate
        for (i = 0; i < 2; i = i + 1) begin
            for (j = 0; j < 2; j = j + 1) begin
                ClockBuffer #(.DRIVE_STRENGTH(4)) buf_l2_q0 (
                    .clk_in(clk_l1[0]),
                    .clk_out(clk_l2[i][j])
                );
                // 类似处理其他象限...
            end
        end
    endgenerate
    
    // Level 3: 叶节点（带时钟门控）
    generate
        for (i = 0; i < 16; i = i + 1) begin : row
            for (j = 0; j < 16; j = j + 1) begin : col
                ClockGatingCell cgc (
                    .clk_in(clk_l2[i/4][j/4]),
                    .enable(clock_enable[i*16+j]),
                    .clk_out(clk_out[i][j])
                );
            end
        end
    endgenerate
endmodule

// 低偏斜时钟缓冲器
module ClockBuffer #(
    parameter DRIVE_STRENGTH = 1
) (
    input wire clk_in,
    output wire clk_out
);
    // 使用对称的缓冲器链
    wire [DRIVE_STRENGTH-1:0] buf_chain;
    
    assign buf_chain[0] = clk_in;
    genvar k;
    generate
        for (k = 1; k < DRIVE_STRENGTH; k = k + 1) begin
            // 渐进式增大驱动能力
            buf #(.size(2**k)) buffer_inst (
                .in(buf_chain[k-1]),
                .out(buf_chain[k])
            );
        end
    endgenerate
    
    assign clk_out = buf_chain[DRIVE_STRENGTH-1];
endmodule

// 集成时钟门控单元
module ClockGatingCell (
    input wire clk_in,
    input wire enable,
    output wire clk_out
);
    reg enable_latch;
    
    // 锁存使能信号（避免毛刺）
    always @(clk_in or enable) begin
        if (!clk_in)
            enable_latch <= enable;
    end
    
    // AND门输出门控时钟
    assign clk_out = clk_in & enable_latch;
endmodule
                        </div>
                        
                        <p><strong>3. 优化技术：</strong></p>
                        <table>
                            <tr>
                                <th>技术</th>
                                <th>原理</th>
                                <th>效果</th>
                                <th>成本</th>
                            </tr>
                            <tr>
                                <td>H-Tree拓扑</td>
                                <td>对称分支，等长路径</td>
                                <td>偏斜<10ps</td>
                                <td>布线资源多</td>
                            </tr>
                            <tr>
                                <td>细粒度时钟门控</td>
                                <td>PE级别关断</td>
                                <td>功耗降低40%</td>
                                <td>控制复杂</td>
                            </tr>
                            <tr>
                                <td>多级缓冲</td>
                                <td>逐级放大驱动</td>
                                <td>转换时间优化</td>
                                <td>面积增加</td>
                            </tr>
                            <tr>
                                <td>局部时钟域</td>
                                <td>分区异步</td>
                                <td>降低全局偏斜</td>
                                <td>同步开销</td>
                            </tr>
                        </table>
                        
                        <p><strong>4. 实施建议：</strong></p>
                        <ul>
                            <li>使用专用时钟布线层，减少干扰</li>
                            <li>在每个分支点放置去耦电容</li>
                            <li>考虑工艺偏差，预留时序裕量</li>
                            <li>支持动态频率调节（DVFS）</li>
                        </ul>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目4.8：</strong>比较不同MAC阵列规模（8×8、16×16、32×32）的设计权衡，给出选择建议。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <table>
                            <tr>
                                <th>指标</th>
                                <th>8×8阵列</th>
                                <th>16×16阵列</th>
                                <th>32×32阵列</th>
                            </tr>
                            <tr>
                                <td>MAC单元数</td>
                                <td>64</td>
                                <td>256</td>
                                <td>1024</td>
                            </tr>
                            <tr>
                                <td>峰值算力(相对)</td>
                                <td>1×</td>
                                <td>4×</td>
                                <td>16×</td>
                            </tr>
                            <tr>
                                <td>面积(相对)</td>
                                <td>1×</td>
                                <td>~4.5×</td>
                                <td>~20×</td>
                            </tr>
                            <tr>
                                <td>功耗(相对)</td>
                                <td>1×</td>
                                <td>~4.2×</td>
                                <td>~18×</td>
                            </tr>
                            <tr>
                                <td>片上SRAM需求</td>
                                <td>64KB</td>
                                <td>256KB</td>
                                <td>1MB+</td>
                            </tr>
                            <tr>
                                <td>带宽需求</td>
                                <td>64GB/s</td>
                                <td>256GB/s</td>
                                <td>1TB/s</td>
                            </tr>
                            <tr>
                                <td>控制复杂度</td>
                                <td>低</td>
                                <td>中</td>
                                <td>高</td>
                            </tr>
                            <tr>
                                <td>时钟分配难度</td>
                                <td>简单</td>
                                <td>适中</td>
                                <td>困难</td>
                            </tr>
                            <tr>
                                <td>利用率(典型)</td>
                                <td>85%</td>
                                <td>75%</td>
                                <td>60%</td>
                            </tr>
                        </table>
                        
                        <p><strong>设计权衡分析：</strong></p>
                        
                        <p><strong>1. 8×8阵列：</strong></p>
                        <ul>
                            <li><strong>优势：</strong>
                                <ul>
                                    <li>控制简单，易于实现</li>
                                    <li>利用率高，适合小矩阵</li>
                                    <li>功耗密度低，散热容易</li>
                                </ul>
                            </li>
                            <li><strong>劣势：</strong>
                                <ul>
                                    <li>绝对性能有限</li>
                                    <li>大矩阵需要多次分块</li>
                                </ul>
                            </li>
                            <li><strong>适用场景：</strong>边缘设备、低功耗应用</li>
                        </ul>
                        
                        <p><strong>2. 16×16阵列：</strong></p>
                        <ul>
                            <li><strong>优势：</strong>
                                <ul>
                                    <li>性能功耗比最优</li>
                                    <li>适配主流网络的层大小</li>
                                    <li>设计复杂度可控</li>
                                </ul>
                            </li>
                            <li><strong>劣势：</strong>
                                <ul>
                                    <li>需要更复杂的数据调度</li>
                                </ul>
                            </li>
                            <li><strong>适用场景：</strong>主流推理加速器</li>
                        </ul>
                        
                        <p><strong>3. 32×32阵列：</strong></p>
                        <ul>
                            <li><strong>优势：</strong>
                                <ul>
                                    <li>峰值性能高</li>
                                    <li>大矩阵效率好</li>
                                </ul>
                            </li>
                            <li><strong>劣势：</strong>
                                <ul>
                                    <li>面积开销呈超线性增长</li>
                                    <li>带宽墙问题严重</li>
                                    <li>小矩阵利用率低</li>
                                    <li>时序收敛困难</li>
                                </ul>
                            </li>
                            <li><strong>适用场景：</strong>高端服务器、特定大模型</li>
                        </ul>
                        
                        <p><strong>选择建议：</strong></p>
                        <ol>
                            <li><strong>边缘推理：</strong>8×8，功耗优先</li>
                            <li><strong>移动端NPU：</strong>8×8或16×16，平衡性能功耗</li>
                            <li><strong>数据中心推理：</strong>16×16多核，可扩展性好</li>
                            <li><strong>训练加速器：</strong>32×32或更大，性能优先</li>
                        </ol>
                        
                        <p><strong>未来趋势：</strong>多个中等规模阵列（16×16）+ 灵活互联 > 单个超大阵列</p>
                    </div>
                </div>
            </div>
        </div>

        <!-- Chapter 5: 存储系统设计 -->
        <section id="chapter5" class="chapter">
            <h2>第5章：存储系统设计</h2>
            
            <p>存储系统是NPU性能的关键瓶颈之一。本章深入探讨NPU片上存储系统的架构与设计要点，包括SRAM设计、Memory Banking策略、数据预取机制、缓存一致性、DMA设计以及内存压缩技术。</p>

            <h3>5.1 片上SRAM设计</h3>
            
            <p>片上SRAM是NPU存储层次结构的核心，为计算单元提供超低延迟、超高带宽的数据访问。</p>

            <h4>5.1.1 SRAM设计权衡</h4>
            <div class="code-block">
SRAM设计的关键权衡：

1. 容量 vs. 面积/功耗
   - SRAM面积密度：~0.2 MB/mm² (7nm工艺)
   - 静态功耗：~1mW/MB
   - 动态功耗：与访问频率成正比

2. 端口设计
   - 单端口(1R1W)：面积最小，但限制并行访问
   - 双端口(2R2W)：面积增加~70%，支持同时读写
   - 多端口(nRmW)：面积随端口数超线性增长

3. 访问延迟
   - 容量增大 → 延迟增加（解码器、字线、位线延迟）
   - 典型延迟：32KB ~1 cycle, 256KB ~2-3 cycles
            </div>

            <h4>5.1.2 多级存储层次</h4>
            <div class="code-block">
// 典型的三级存储层次设计
module MemoryHierarchy (
    input wire clk,
    input wire rst_n,
    // L0: PE本地寄存器文件
    // L1: PE集群共享缓存
    // L2: 全局共享缓存
);

// L0 Register File (每个PE私有)
module L0_RegisterFile #(
    parameter DEPTH = 16,       // 16个寄存器
    parameter WIDTH = 256       // 256-bit宽度
)(
    input wire clk,
    input wire [3:0] rd_addr,
    input wire [3:0] wr_addr,
    input wire wr_en,
    input wire [WIDTH-1:0] wr_data,
    output wire [WIDTH-1:0] rd_data
);
    reg [WIDTH-1:0] regs [0:DEPTH-1];
    
    assign rd_data = regs[rd_addr];
    
    always @(posedge clk) begin
        if (wr_en)
            regs[wr_addr] <= wr_data;
    end
endmodule

// L1 Cluster Buffer (PE集群共享)
module L1_ClusterBuffer #(
    parameter SIZE = 64 * 1024,     // 64KB
    parameter PORTS = 4,            // 4个访问端口
    parameter WIDTH = 256
)(
    input wire clk,
    input wire [PORTS-1:0] rd_en,
    input wire [PORTS-1:0] wr_en,
    input wire [15:0] rd_addr [PORTS-1:0],
    input wire [15:0] wr_addr [PORTS-1:0],
    input wire [WIDTH-1:0] wr_data [PORTS-1:0],
    output wire [WIDTH-1:0] rd_data [PORTS-1:0]
);
    // 多端口SRAM实现
endmodule
            </div>

            <h4>5.1.3 特殊SRAM结构</h4>
            <div class="code-block">
// 转置SRAM：支持行列双向访问
module TransposeSRAM #(
    parameter ROWS = 64,
    parameter COLS = 64,
    parameter DATA_WIDTH = 8
)(
    input wire clk,
    input wire row_mode,    // 1: 行访问, 0: 列访问
    input wire [5:0] addr_major,
    input wire [5:0] addr_minor,
    input wire wr_en,
    input wire [DATA_WIDTH*COLS-1:0] wr_data,
    output wire [DATA_WIDTH*COLS-1:0] rd_data
);
    // 实现支持行列转置访问的SRAM
    reg [DATA_WIDTH-1:0] mem [0:ROWS-1][0:COLS-1];
    
    genvar i;
    generate
        for (i = 0; i < COLS; i = i + 1) begin
            always @(posedge clk) begin
                if (wr_en) begin
                    if (row_mode)
                        mem[addr_major][i] <= wr_data[i*DATA_WIDTH +: DATA_WIDTH];
                    else
                        mem[i][addr_major] <= wr_data[i*DATA_WIDTH +: DATA_WIDTH];
                end
            end
            
            assign rd_data[i*DATA_WIDTH +: DATA_WIDTH] = 
                row_mode ? mem[addr_major][i] : mem[i][addr_major];
        end
    endgenerate
endmodule
            </div>

            <h3>5.2 Memory Banking策略</h3>
            
            <p>Memory Banking通过将SRAM划分为多个独立的Bank，实现并行访问，成倍提升有效带宽。</p>

            <h4>5.2.1 Bank冲突分析</h4>
            <div class="code-block">
Bank冲突的主要场景：

1. 卷积中的步长访问
   - 3×3卷积，stride=2时的访问模式
   - Bank数量需要考虑GCD(stride, bank_num)

2. 矩阵转置访问
   - 行访问：连续地址
   - 列访问：地址间隔为矩阵宽度

3. 稀疏访问模式
   - 不规则的访问地址
   - 需要动态仲裁机制
            </div>

            <h4>5.2.2 地址映射策略</h4>
            <div class="code-block">
// 多Bank SRAM控制器
module MultiBank_SRAM #(
    parameter NUM_BANKS = 8,
    parameter BANK_SIZE = 8192,     // 每个Bank 8KB
    parameter DATA_WIDTH = 256,
    parameter ADDR_WIDTH = 16
)(
    input wire clk,
    input wire rst_n,
    
    // 请求接口（支持多个并行请求）
    input wire [3:0] req_valid,
    input wire [ADDR_WIDTH-1:0] req_addr [3:0],
    input wire [3:0] req_wr,
    input wire [DATA_WIDTH-1:0] req_wdata [3:0],
    output reg [3:0] req_ready,
    output reg [DATA_WIDTH-1:0] resp_data [3:0],
    output reg [3:0] resp_valid
);

    // Bank地址解码
    wire [2:0] bank_id [3:0];
    wire [12:0] bank_addr [3:0];
    
    genvar i;
    generate
        for (i = 0; i < 4; i = i + 1) begin
            // 交织映射：低位作为bank索引
            assign bank_id[i] = req_addr[i][2:0];
            assign bank_addr[i] = req_addr[i][ADDR_WIDTH-1:3];
        end
    endgenerate
    
    // Bank仲裁逻辑
    reg [3:0] bank_grant [NUM_BANKS-1:0];
    
    always @(*) begin
        integer j, k;
        // 初始化
        for (j = 0; j < NUM_BANKS; j = j + 1)
            bank_grant[j] = 4'b0000;
            
        // 仲裁：每个Bank只能授权一个请求
        for (k = 0; k < 4; k = k + 1) begin
            if (req_valid[k] && bank_grant[bank_id[k]] == 4'b0000) begin
                bank_grant[bank_id[k]][k] = 1'b1;
            end
        end
    end
    
    // Bank实例化
    generate
        for (i = 0; i < NUM_BANKS; i = i + 1) begin
            BankSRAM #(
                .SIZE(BANK_SIZE),
                .WIDTH(DATA_WIDTH)
            ) bank_inst (
                .clk(clk),
                .en(|bank_grant[i]),
                .wr(/* 根据grant选择写请求 */),
                .addr(/* 根据grant选择地址 */),
                .wdata(/* 根据grant选择写数据 */),
                .rdata(/* 连接到响应数据 */)
            );
        end
    endgenerate
endmodule

// 专用于卷积的Bank映射
module ConvBankMapping #(
    parameter BANK_BITS = 3,        // 8个Bank
    parameter CHANNEL_BITS = 6      // 64个通道
)(
    input wire [15:0] h_idx,        // Height坐标
    input wire [15:0] w_idx,        // Width坐标
    input wire [CHANNEL_BITS-1:0] c_idx,  // Channel坐标
    output wire [BANK_BITS-1:0] bank_id,
    output wire [15:0] bank_offset
);
    // 斜对角映射，避免3×3卷积的Bank冲突
    wire [BANK_BITS-1:0] skew;
    assign skew = (h_idx + w_idx) & ((1 << BANK_BITS) - 1);
    assign bank_id = (c_idx[BANK_BITS-1:0] + skew) & ((1 << BANK_BITS) - 1);
    
    // Bank内偏移地址
    assign bank_offset = {c_idx[CHANNEL_BITS-1:BANK_BITS], h_idx[7:0], w_idx[7:0]};
endmodule
            </div>

            <h4>5.2.3 Bank冲突解决</h4>
            <div class="code-block">
// 带冲突缓冲的Bank访问调度器
module BankScheduler #(
    parameter NUM_BANKS = 8,
    parameter NUM_REQUESTORS = 16,
    parameter QUEUE_DEPTH = 4
)(
    input wire clk,
    input wire rst_n,
    
    // 请求端口
    input wire [NUM_REQUESTORS-1:0] req_valid,
    input wire [2:0] req_bank [NUM_REQUESTORS-1:0],
    input wire [15:0] req_addr [NUM_REQUESTORS-1:0],
    output reg [NUM_REQUESTORS-1:0] req_ready,
    
    // Bank接口
    output reg [NUM_BANKS-1:0] bank_valid,
    output reg [15:0] bank_addr [NUM_BANKS-1:0],
    input wire [NUM_BANKS-1:0] bank_ready
);

    // 每个请求者的请求队列
    reg [2:0] req_queue_bank [NUM_REQUESTORS-1:0][QUEUE_DEPTH-1:0];
    reg [15:0] req_queue_addr [NUM_REQUESTORS-1:0][QUEUE_DEPTH-1:0];
    reg [1:0] req_queue_head [NUM_REQUESTORS-1:0];
    reg [1:0] req_queue_tail [NUM_REQUESTORS-1:0];
    
    // 冲突检测与调度
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            // 复位逻辑
        end else begin
            // 1. 将新请求加入队列
            // 2. 从每个队列头部选择无冲突的请求
            // 3. 发送到对应的Bank
        end
    end
endmodule
            </div>

            <h3>5.3 数据预取机制</h3>
            
            <p>数据预取通过提前将数据从DRAM加载到片上SRAM，隐藏内存访问延迟，是提升NPU性能的关键技术。</p>

            <h4>5.3.1 预取策略</h4>
            <div class="code-block">
预取机制的核心要素：

1. 预取时机
   - 基于计算进度的预取
   - 基于地址模式的预取
   - 软件控制的显式预取

2. 预取粒度
   - 细粒度：单个Tile (如16×16)
   - 粗粒度：整个Feature Map
   - 自适应粒度：根据可用空间动态调整

3. 预取深度
   - Double Buffering: 计算当前数据时预取下一批
   - Triple Buffering: 更深的流水线，容忍更大延迟
            </div>

            <h4>5.3.2 硬件预取引擎</h4>
            <div class="code-block">
// 智能预取引擎
module PrefetchEngine #(
    parameter ADDR_WIDTH = 32,
    parameter DATA_WIDTH = 256,
    parameter PREFETCH_DEPTH = 4
)(
    input wire clk,
    input wire rst_n,
    
    // 控制接口
    input wire prefetch_enable,
    input wire [ADDR_WIDTH-1:0] base_addr,
    input wire [15:0] stride,
    input wire [15:0] count,
    
    // 计算进度监控
    input wire [15:0] compute_progress,
    
    // DRAM接口
    output reg dram_req_valid,
    output reg [ADDR_WIDTH-1:0] dram_req_addr,
    output reg [7:0] dram_req_len,
    input wire dram_req_ready,
    
    // SRAM写接口
    output reg sram_wr_valid,
    output reg [15:0] sram_wr_addr,
    output reg [DATA_WIDTH-1:0] sram_wr_data,
    input wire sram_wr_ready
);

    // 预取状态机
    localparam IDLE = 0, MONITOR = 1, ISSUE_REQ = 2, WAIT_RESP = 3;
    reg [1:0] state, next_state;
    
    // 预取队列
    reg [ADDR_WIDTH-1:0] prefetch_queue [PREFETCH_DEPTH-1:0];
    reg [2:0] queue_head, queue_tail;
    reg [3:0] queue_count;
    
    // 地址生成器
    reg [ADDR_WIDTH-1:0] next_addr;
    reg [15:0] fetch_count;
    
    // 预取距离计算
    wire [15:0] prefetch_distance;
    assign prefetch_distance = queue_count * 16; // 假设每次预取16个元素
    
    // 状态机逻辑
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            state <= IDLE;
            queue_head <= 0;
            queue_tail <= 0;
            queue_count <= 0;
        end else begin
            state <= next_state;
            
            case (state)
                IDLE: begin
                    if (prefetch_enable) begin
                        next_addr <= base_addr;
                        fetch_count <= 0;
                    end
                end
                
                MONITOR: begin
                    // 监控计算进度，决定是否发起预取
                    if (compute_progress + prefetch_distance < count && 
                        queue_count < PREFETCH_DEPTH - 1) begin
                        // 需要预取更多数据
                        prefetch_queue[queue_tail] <= next_addr;
                        queue_tail <= queue_tail + 1;
                        queue_count <= queue_count + 1;
                        next_addr <= next_addr + stride;
                        fetch_count <= fetch_count + 1;
                    end
                end
                
                ISSUE_REQ: begin
                    if (dram_req_ready && queue_count > 0) begin
                        dram_req_valid <= 1'b1;
                        dram_req_addr <= prefetch_queue[queue_head];
                        dram_req_len <= 8'd16; // 预取16个元素
                        queue_head <= queue_head + 1;
                        queue_count <= queue_count - 1;
                    end
                end
            endcase
        end
    end
    
    // 下一状态逻辑
    always @(*) begin
        next_state = state;
        case (state)
            IDLE: 
                if (prefetch_enable) next_state = MONITOR;
            MONITOR:
                if (queue_count > 0) next_state = ISSUE_REQ;
            ISSUE_REQ:
                if (dram_req_ready) next_state = WAIT_RESP;
            WAIT_RESP:
                if (/* DRAM响应完成 */) next_state = MONITOR;
        endcase
    end
endmodule

// 双缓冲预取控制器
module DoubleBufferPrefetch #(
    parameter BUFFER_SIZE = 16384,  // 16KB per buffer
    parameter DATA_WIDTH = 256
)(
    input wire clk,
    input wire rst_n,
    
    // 计算单元接口
    input wire compute_req,
    input wire [13:0] compute_addr,
    output wire [DATA_WIDTH-1:0] compute_data,
    output wire compute_ready,
    
    // 预取控制
    input wire [31:0] prefetch_base_addr,
    input wire [15:0] prefetch_length,
    input wire prefetch_start,
    
    // DRAM接口
    output wire dram_req_valid,
    output wire [31:0] dram_req_addr,
    input wire dram_resp_valid,
    input wire [DATA_WIDTH-1:0] dram_resp_data
);
    
    // 双缓冲控制
    reg buffer_sel;  // 0: Buffer A用于计算, 1: Buffer B用于计算
    reg [13:0] buffer_write_addr [1:0];
    reg buffer_ready [1:0];
    
    // 缓冲区实例
    wire [DATA_WIDTH-1:0] buffer_rdata [1:0];
    
    genvar i;
    generate
        for (i = 0; i < 2; i = i + 1) begin
            SimpleDualPortRAM #(
                .DEPTH(BUFFER_SIZE/32),
                .WIDTH(DATA_WIDTH)
            ) buffer (
                .clk(clk),
                .wr_en(dram_resp_valid && (buffer_sel != i)),
                .wr_addr(buffer_write_addr[i]),
                .wr_data(dram_resp_data),
                .rd_addr(compute_addr),
                .rd_data(buffer_rdata[i])
            );
        end
    endgenerate
    
    // 计算接口
    assign compute_data = buffer_rdata[buffer_sel];
    assign compute_ready = buffer_ready[buffer_sel];
    
    // 缓冲切换逻辑
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            buffer_sel <= 0;
        end else if (/* 当前buffer计算完成 && 另一个buffer预取完成 */) begin
            buffer_sel <= ~buffer_sel;
        end
    end
endmodule
            </div>

            <h4>5.3.3 软件控制预取</h4>
            <div class="code-block">
// 预取指令格式
typedef struct {
    uint32_t opcode : 8;      // PREFETCH指令码
    uint32_t buffer_id : 4;   // 目标缓冲区ID
    uint32_t pattern : 4;     // 访问模式（线性/2D/3D）
    uint32_t priority : 2;    // 预取优先级
    uint32_t reserved : 14;
} prefetch_inst_t;

// 预取描述符
typedef struct {
    uint32_t src_addr;        // 源地址（DRAM）
    uint32_t dst_addr;        // 目标地址（SRAM）
    uint16_t dim0_size;       // 第一维大小
    uint16_t dim0_stride;     // 第一维步长
    uint16_t dim1_size;       // 第二维大小
    uint16_t dim1_stride;     // 第二维步长
    uint16_t dim2_size;       // 第三维大小
    uint16_t dim2_stride;     // 第三维步长
} prefetch_desc_t;

// 软件预取示例（卷积层）
void conv_layer_with_prefetch(
    float* input,     // [N, H, W, C_in]
    float* weights,   // [K, K, C_in, C_out]
    float* output,    // [N, H_out, W_out, C_out]
    conv_params_t params
) {
    // 设置权重预取（权重复用率高，优先预取）
    prefetch_desc_t weight_pf = {
        .src_addr = (uint32_t)weights,
        .dst_addr = WEIGHT_BUFFER_BASE,
        .dim0_size = params.kernel_size,
        .dim0_stride = params.kernel_size * params.c_in * sizeof(float),
        .dim1_size = params.kernel_size,
        .dim1_stride = params.c_in * sizeof(float),
        .dim2_size = params.c_in,
        .dim2_stride = sizeof(float)
    };
    
    // 发起权重预取
    issue_prefetch(WEIGHT_PREFETCH_ENGINE, &weight_pf);
    
    // 双缓冲处理输入特征图
    for (int tile_y = 0; tile_y < params.h_out; tile_y += TILE_SIZE) {
        // 预取下一个tile的输入数据
        if (tile_y + TILE_SIZE < params.h_out) {
            prefetch_desc_t input_pf = {
                .src_addr = (uint32_t)&input[tile_y + TILE_SIZE][0][0],
                .dst_addr = INPUT_BUFFER_B,
                .dim0_size = TILE_SIZE + params.kernel_size - 1,
                .dim0_stride = params.w * params.c_in * sizeof(float),
                .dim1_size = params.w,
                .dim1_stride = params.c_in * sizeof(float),
                .dim2_size = params.c_in,
                .dim2_stride = sizeof(float)
            };
            issue_prefetch(INPUT_PREFETCH_ENGINE, &input_pf);
        }
        
        // 等待当前tile数据就绪
        wait_prefetch_complete(current_buffer);
        
        // 执行计算
        compute_conv_tile(current_buffer, WEIGHT_BUFFER_BASE, 
                         OUTPUT_BUFFER + tile_y * params.w_out * params.c_out);
        
        // 切换缓冲区
        current_buffer = (current_buffer == INPUT_BUFFER_A) ? 
                        INPUT_BUFFER_B : INPUT_BUFFER_A;
    }
}
            </div>

            <h3>5.4 缓存一致性</h3>
            
            <p>在多核NPU系统中，缓存一致性确保不同核心看到的数据是一致的，这对正确性至关重要。</p>

            <h4>5.4.1 NPU缓存一致性挑战</h4>
            <div class="code-block">
NPU缓存一致性的特点：

1. 软件管理为主
   - 神经网络计算流程确定
   - 编译器可以精确分析数据依赖
   - 显式同步点插入

2. 简化的硬件支持
   - 基本的Cache刷新/失效指令
   - DMA与Cache的协同
   - 全局同步屏障

3. 常见场景
   - 多核协同计算大矩阵乘法
   - Pipeline并行中的数据传递
   - 模型参数的广播更新
            </div>

            <h4>5.4.2 软件管理的缓存一致性</h4>
            <div class="code-block">
// 缓存控制单元
module CacheController #(
    parameter CACHE_SIZE = 32768,   // 32KB
    parameter LINE_SIZE = 64,       // 64B cache line
    parameter NUM_WAYS = 4
)(
    input wire clk,
    input wire rst_n,
    
    // 处理器接口
    input wire [31:0] cpu_addr,
    input wire cpu_req,
    input wire cpu_wr,
    input wire [255:0] cpu_wdata,
    output wire [255:0] cpu_rdata,
    output wire cpu_ready,
    
    // 缓存控制指令
    input wire cache_flush,         // 写回所有脏数据
    input wire cache_invalidate,    // 失效所有缓存行
    input wire [31:0] inv_addr,     // 特定地址失效
    input wire inv_addr_valid,
    
    // 内存接口
    output reg mem_req,
    output reg [31:0] mem_addr,
    output reg mem_wr,
    output reg [255:0] mem_wdata,
    input wire [255:0] mem_rdata,
    input wire mem_ready
);

    // Cache标签和数据存储
    reg [19:0] tag_array [NUM_WAYS-1:0][CACHE_SIZE/LINE_SIZE/NUM_WAYS-1:0];
    reg valid_array [NUM_WAYS-1:0][CACHE_SIZE/LINE_SIZE/NUM_WAYS-1:0];
    reg dirty_array [NUM_WAYS-1:0][CACHE_SIZE/LINE_SIZE/NUM_WAYS-1:0];
    reg [255:0] data_array [NUM_WAYS-1:0][CACHE_SIZE/LINE_SIZE/NUM_WAYS-1:0];
    
    // 地址解析
    wire [19:0] tag = cpu_addr[31:12];
    wire [7:0] index = cpu_addr[11:6];
    wire [5:0] offset = cpu_addr[5:0];
    
    // 缓存刷新状态机
    reg [2:0] flush_state;
    reg [7:0] flush_index;
    reg [1:0] flush_way;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            flush_state <= 0;
            flush_index <= 0;
            flush_way <= 0;
        end else if (cache_flush && flush_state == 0) begin
            flush_state <= 1;
            flush_index <= 0;
            flush_way <= 0;
        end else if (flush_state != 0) begin
            case (flush_state)
                1: begin // 检查脏位
                    if (dirty_array[flush_way][flush_index]) begin
                        // 发起写回请求
                        mem_req <= 1'b1;
                        mem_wr <= 1'b1;
                        mem_addr <= {tag_array[flush_way][flush_index], 
                                   flush_index, 6'b0};
                        mem_wdata <= data_array[flush_way][flush_index];
                        flush_state <= 2;
                    end else begin
                        // 继续下一个
                        if (flush_way == NUM_WAYS-1) begin
                            flush_way <= 0;
                            if (flush_index == (CACHE_SIZE/LINE_SIZE/NUM_WAYS-1))
                                flush_state <= 0; // 完成
                            else
                                flush_index <= flush_index + 1;
                        end else begin
                            flush_way <= flush_way + 1;
                        end
                    end
                end
                
                2: begin // 等待写回完成
                    if (mem_ready) begin
                        mem_req <= 1'b0;
                        dirty_array[flush_way][flush_index] <= 1'b0;
                        flush_state <= 1;
                        // 继续下一个
                        if (flush_way == NUM_WAYS-1) begin
                            flush_way <= 0;
                            if (flush_index == (CACHE_SIZE/LINE_SIZE/NUM_WAYS-1))
                                flush_state <= 0;
                            else
                                flush_index <= flush_index + 1;
                        end else begin
                            flush_way <= flush_way + 1;
                        end
                    end
                end
            endcase
        end
    end
    
    // 缓存失效逻辑
    always @(posedge clk) begin
        if (cache_invalidate) begin
            // 全部失效
            integer i, j;
            for (i = 0; i < NUM_WAYS; i = i + 1) begin
                for (j = 0; j < CACHE_SIZE/LINE_SIZE/NUM_WAYS; j = j + 1) begin
                    valid_array[i][j] <= 1'b0;
                end
            end
        end else if (inv_addr_valid) begin
            // 特定地址失效
            wire [7:0] inv_index = inv_addr[11:6];
            wire [19:0] inv_tag = inv_addr[31:12];
            
            integer k;
            for (k = 0; k < NUM_WAYS; k = k + 1) begin
                if (valid_array[k][inv_index] && 
                    tag_array[k][inv_index] == inv_tag) begin
                    valid_array[k][inv_index] <= 1'b0;
                end
            end
        end
    end
endmodule

// 多核同步屏障
module GlobalSyncBarrier #(
    parameter NUM_CORES = 16
)(
    input wire clk,
    input wire rst_n,
    
    // 每个核心的同步请求
    input wire [NUM_CORES-1:0] sync_req,
    output reg [NUM_CORES-1:0] sync_ack,
    
    // 同步ID（支持多个屏障）
    input wire [3:0] sync_id [NUM_CORES-1:0],
    
    // 缓存控制输出
    output reg cache_flush_all,
    output reg cache_inv_all
);

    // 同步状态跟踪
    reg [NUM_CORES-1:0] sync_pending [15:0]; // 16个同步ID
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            sync_ack <= 0;
            cache_flush_all <= 0;
            cache_inv_all <= 0;
        end else begin
            // 收集同步请求
            integer i, j;
            for (i = 0; i < NUM_CORES; i = i + 1) begin
                if (sync_req[i] && !sync_ack[i]) begin
                    sync_pending[sync_id[i]][i] <= 1'b1;
                end
            end
            
            // 检查是否所有核心都到达屏障
            for (j = 0; j < 16; j = j + 1) begin
                if (sync_pending[j] == {NUM_CORES{1'b1}}) begin
                    // 触发全局缓存刷新
                    cache_flush_all <= 1'b1;
                    cache_inv_all <= 1'b1;
                    
                    // 释放所有等待的核心
                    for (i = 0; i < NUM_CORES; i = i + 1) begin
                        if (sync_pending[j][i]) begin
                            sync_ack[i] <= 1'b1;
                            sync_pending[j][i] <= 1'b0;
                        end
                    end
                end
            end
            
            // 清除控制信号
            if (cache_flush_all) cache_flush_all <= 1'b0;
            if (cache_inv_all) cache_inv_all <= 1'b0;
            
            // 清除应答信号
            sync_ack <= sync_ack & ~sync_req;
        end
    end
endmodule
            </div>

            <h4>5.4.3 DMA与缓存协同</h4>
            <div class="code-block">
// DMA与缓存协同示例
// 确保DMA传输的数据一致性

// 场景1：DMA写入内存前，刷新相关缓存
void dma_write_with_cache_sync(
    void* src_sram_addr,
    void* dst_dram_addr,
    size_t size
) {
    // 1. 刷新可能缓存了目标地址的所有缓存行
    cache_flush_range(dst_dram_addr, size);
    
    // 2. 等待刷新完成
    wait_cache_flush_complete();
    
    // 3. 启动DMA传输
    dma_desc_t desc = {
        .src = src_sram_addr,
        .dst = dst_dram_addr,
        .len = size,
        .flags = DMA_FLAG_WRITE_BACK
    };
    dma_start_transfer(&desc);
    
    // 4. 等待DMA完成
    dma_wait_complete();
    
    // 5. 失效相关缓存，确保后续读取获得最新数据
    cache_invalidate_range(dst_dram_addr, size);
}

// 场景2：DMA读取内存前，确保数据已写回
void dma_read_with_cache_sync(
    void* src_dram_addr,
    void* dst_sram_addr,
    size_t size
) {
    // 1. 刷新源地址范围的所有脏数据
    cache_flush_range(src_dram_addr, size);
    
    // 2. 等待刷新完成
    wait_cache_flush_complete();
    
    // 3. 启动DMA传输
    dma_desc_t desc = {
        .src = src_dram_addr,
        .dst = dst_sram_addr,
        .len = size,
        .flags = DMA_FLAG_READ
    };
    dma_start_transfer(&desc);
}

// 硬件实现：DMA控制器与缓存的接口
module DMA_CacheInterface (
    input wire clk,
    input wire rst_n,
    
    // DMA请求
    input wire dma_start,
    input wire [31:0] dma_src_addr,
    input wire [31:0] dma_dst_addr,
    input wire [15:0] dma_length,
    input wire dma_direction, // 0: read, 1: write
    
    // 缓存控制接口
    output reg cache_flush_req,
    output reg [31:0] cache_flush_addr,
    output reg [15:0] cache_flush_len,
    input wire cache_flush_done,
    
    output reg cache_inv_req,
    output reg [31:0] cache_inv_addr,
    output reg [15:0] cache_inv_len,
    input wire cache_inv_done,
    
    // DMA引擎接口
    output reg dma_go,
    input wire dma_done
);

    reg [2:0] state;
    localparam IDLE = 0, FLUSH = 1, WAIT_FLUSH = 2, 
               DMA_TRANS = 3, INVALIDATE = 4;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            state <= IDLE;
        end else begin
            case (state)
                IDLE: begin
                    if (dma_start) begin
                        if (dma_direction) begin
                            // DMA写：先刷新目标地址
                            cache_flush_req <= 1'b1;
                            cache_flush_addr <= dma_dst_addr;
                            cache_flush_len <= dma_length;
                            state <= WAIT_FLUSH;
                        end else begin
                            // DMA读：先刷新源地址
                            cache_flush_req <= 1'b1;
                            cache_flush_addr <= dma_src_addr;
                            cache_flush_len <= dma_length;
                            state <= WAIT_FLUSH;
                        end
                    end
                end
                
                WAIT_FLUSH: begin
                    cache_flush_req <= 1'b0;
                    if (cache_flush_done) begin
                        dma_go <= 1'b1;
                        state <= DMA_TRANS;
                    end
                end
                
                DMA_TRANS: begin
                    dma_go <= 1'b0;
                    if (dma_done) begin
                        if (dma_direction) begin
                            // DMA写完成后，失效目标缓存
                            cache_inv_req <= 1'b1;
                            cache_inv_addr <= dma_dst_addr;
                            cache_inv_len <= dma_length;
                            state <= INVALIDATE;
                        end else begin
                            state <= IDLE;
                        end
                    end
                end
                
                INVALIDATE: begin
                    cache_inv_req <= 1'b0;
                    if (cache_inv_done) begin
                        state <= IDLE;
                    end
                end
            endcase
        end
    end
endmodule
            </div>

            <h3>5.5 DMA设计</h3>
            
            <p>DMA（直接内存访问）控制器是NPU中的数据搬运引擎，负责在片外DRAM和片上SRAM之间高效传输数据。</p>

            <h4>5.5.1 NPU DMA特性</h4>
            <div class="code-block">
NPU DMA的特殊需求：

1. 多维寻址能力
   - 支持2D/3D/4D张量传输
   - 灵活的步长（stride）和填充（padding）
   - 数据重排（如NHWC→NCHW）

2. 高带宽利用率
   - 多通道并行传输
   - 突发传输优化
   - 带宽聚合

3. 与计算的协同
   - 描述符链接
   - 事件触发机制
   - 双缓冲/多缓冲支持
            </div>

            <h4>5.5.2 多维DMA引擎</h4>
            <div class="code-block">
// 支持多维张量传输的DMA引擎
module TensorDMA #(
    parameter ADDR_WIDTH = 32,
    parameter DATA_WIDTH = 256,
    parameter MAX_DIM = 4,
    parameter DESC_DEPTH = 16
)(
    input wire clk,
    input wire rst_n,
    
    // 描述符编程接口
    input wire desc_valid,
    input wire [ADDR_WIDTH-1:0] src_base_addr,
    input wire [ADDR_WIDTH-1:0] dst_base_addr,
    input wire [15:0] dim_size [MAX_DIM-1:0],    // 各维度大小
    input wire [15:0] src_stride [MAX_DIM-1:0],  // 源步长
    input wire [15:0] dst_stride [MAX_DIM-1:0],  // 目标步长
    input wire [2:0] active_dims,                 // 活跃维度数
    output wire desc_ready,
    
    // 内存接口
    output reg mem_rd_req,
    output reg [ADDR_WIDTH-1:0] mem_rd_addr,
    output reg [7:0] mem_rd_len,
    input wire mem_rd_valid,
    input wire [DATA_WIDTH-1:0] mem_rd_data,
    
    output reg mem_wr_req,
    output reg [ADDR_WIDTH-1:0] mem_wr_addr,
    output reg [DATA_WIDTH-1:0] mem_wr_data,
    output reg [7:0] mem_wr_len,
    input wire mem_wr_ready,
    
    // 状态输出
    output reg dma_busy,
    output reg dma_done
);

    // 描述符FIFO
    reg [ADDR_WIDTH-1:0] desc_src_base [DESC_DEPTH-1:0];
    reg [ADDR_WIDTH-1:0] desc_dst_base [DESC_DEPTH-1:0];
    reg [15:0] desc_dim_size [DESC_DEPTH-1:0][MAX_DIM-1:0];
    reg [15:0] desc_src_stride [DESC_DEPTH-1:0][MAX_DIM-1:0];
    reg [15:0] desc_dst_stride [DESC_DEPTH-1:0][MAX_DIM-1:0];
    reg [2:0] desc_active_dims [DESC_DEPTH-1:0];
    reg [3:0] desc_head, desc_tail;
    reg [4:0] desc_count;
    
    // 地址生成器状态
    reg [15:0] dim_counter [MAX_DIM-1:0];
    reg [ADDR_WIDTH-1:0] current_src_addr;
    reg [ADDR_WIDTH-1:0] current_dst_addr;
    reg [2:0] state;
    
    // 描述符入队
    assign desc_ready = (desc_count < DESC_DEPTH);
    
    always @(posedge clk) begin
        if (desc_valid && desc_ready) begin
            desc_src_base[desc_tail] <= src_base_addr;
            desc_dst_base[desc_tail] <= dst_base_addr;
            desc_active_dims[desc_tail] <= active_dims;
            
            integer i;
            for (i = 0; i < MAX_DIM; i = i + 1) begin
                desc_dim_size[desc_tail][i] <= dim_size[i];
                desc_src_stride[desc_tail][i] <= src_stride[i];
                desc_dst_stride[desc_tail][i] <= dst_stride[i];
            end
            
            desc_tail <= desc_tail + 1;
            desc_count <= desc_count + 1;
        end
    end
    
    // 多维地址生成状态机
    localparam IDLE = 0, CALC_ADDR = 1, ISSUE_READ = 2, 
               WAIT_DATA = 3, ISSUE_WRITE = 4, UPDATE_DIM = 5;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            state <= IDLE;
            dma_busy <= 0;
            desc_head <= 0;
            desc_count <= 0;
        end else begin
            case (state)
                IDLE: begin
                    if (desc_count > 0) begin
                        dma_busy <= 1;
                        // 初始化维度计数器
                        integer j;
                        for (j = 0; j < MAX_DIM; j = j + 1) begin
                            dim_counter[j] <= 0;
                        end
                        current_src_addr <= desc_src_base[desc_head];
                        current_dst_addr <= desc_dst_base[desc_head];
                        state <= CALC_ADDR;
                    end
                end
                
                CALC_ADDR: begin
                    // 计算当前传输的地址
                    mem_rd_addr <= current_src_addr;
                    mem_rd_len <= 1; // 简化：每次传输一个元素
                    state <= ISSUE_READ;
                end
                
                ISSUE_READ: begin
                    mem_rd_req <= 1'b1;
                    state <= WAIT_DATA;
                end
                
                WAIT_DATA: begin
                    mem_rd_req <= 1'b0;
                    if (mem_rd_valid) begin
                        mem_wr_data <= mem_rd_data;
                        mem_wr_addr <= current_dst_addr;
                        mem_wr_len <= 1;
                        state <= ISSUE_WRITE;
                    end
                end
                
                ISSUE_WRITE: begin
                    if (mem_wr_ready) begin
                        mem_wr_req <= 1'b1;
                        state <= UPDATE_DIM;
                    end
                end
                
                UPDATE_DIM: begin
                    mem_wr_req <= 1'b0;
                    // 更新多维计数器和地址
                    reg done;
                    done = 1'b1;
                    
                    integer k;
                    for (k = 0; k < MAX_DIM; k = k + 1) begin
                        if (k < desc_active_dims[desc_head]) begin
                            if (dim_counter[k] < desc_dim_size[desc_head][k] - 1) begin
                                dim_counter[k] <= dim_counter[k] + 1;
                                current_src_addr <= current_src_addr + 
                                    desc_src_stride[desc_head][k];
                                current_dst_addr <= current_dst_addr + 
                                    desc_dst_stride[desc_head][k];
                                done = 1'b0;
                                break;
                            end else begin
                                dim_counter[k] <= 0;
                                // 回退到该维度的起始位置
                                current_src_addr <= current_src_addr - 
                                    (desc_dim_size[desc_head][k] - 1) * 
                                    desc_src_stride[desc_head][k];
                                current_dst_addr <= current_dst_addr - 
                                    (desc_dim_size[desc_head][k] - 1) * 
                                    desc_dst_stride[desc_head][k];
                            end
                        end
                    end
                    
                    if (done) begin
                        // 当前描述符完成
                        desc_head <= desc_head + 1;
                        desc_count <= desc_count - 1;
                        dma_done <= 1'b1;
                        state <= IDLE;
                    end else begin
                        state <= CALC_ADDR;
                    end
                end
            endcase
        end
    end
endmodule

// 数据布局转换DMA
module LayoutTransformDMA #(
    parameter DATA_WIDTH = 8,
    parameter MAX_CHANNEL = 1024,
    parameter MAX_HEIGHT = 1024,
    parameter MAX_WIDTH = 1024
)(
    input wire clk,
    input wire rst_n,
    
    // 配置接口
    input wire start,
    input wire [1:0] transform_type, // 0: NHWC->NCHW, 1: NCHW->NHWC
    input wire [9:0] height,
    input wire [9:0] width,
    input wire [9:0] channels,
    input wire [31:0] src_addr,
    input wire [31:0] dst_addr,
    
    // 内存接口
    output reg [31:0] rd_addr,
    output reg rd_req,
    input wire [DATA_WIDTH-1:0] rd_data,
    input wire rd_valid,
    
    output reg [31:0] wr_addr,
    output reg [DATA_WIDTH-1:0] wr_data,
    output reg wr_req,
    input wire wr_ready,
    
    // 状态
    output reg busy,
    output reg done
);

    // 坐标计数器
    reg [9:0] h_cnt, w_cnt, c_cnt;
    
    // 地址计算
    always @(*) begin
        case (transform_type)
            2'b00: begin // NHWC -> NCHW
                // 源地址: base + h*W*C + w*C + c
                rd_addr = src_addr + (h_cnt * width * channels) + 
                         (w_cnt * channels) + c_cnt;
                // 目标地址: base + c*H*W + h*W + w
                wr_addr = dst_addr + (c_cnt * height * width) + 
                         (h_cnt * width) + w_cnt;
            end
            2'b01: begin // NCHW -> NHWC
                // 源地址: base + c*H*W + h*W + w
                rd_addr = src_addr + (c_cnt * height * width) + 
                         (h_cnt * width) + w_cnt;
                // 目标地址: base + h*W*C + w*C + c
                wr_addr = dst_addr + (h_cnt * width * channels) + 
                         (w_cnt * channels) + c_cnt;
            end
            default: begin
                rd_addr = 0;
                wr_addr = 0;
            end
        endcase
    end
    
    // 控制状态机
    reg [2:0] state;
    localparam IDLE = 0, READ = 1, WRITE = 2, NEXT = 3;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            state <= IDLE;
            busy <= 0;
            done <= 0;
        end else begin
            case (state)
                IDLE: begin
                    if (start) begin
                        h_cnt <= 0;
                        w_cnt <= 0;
                        c_cnt <= 0;
                        busy <= 1;
                        done <= 0;
                        state <= READ;
                    end
                end
                
                READ: begin
                    rd_req <= 1;
                    if (rd_valid) begin
                        wr_data <= rd_data;
                        rd_req <= 0;
                        state <= WRITE;
                    end
                end
                
                WRITE: begin
                    if (wr_ready) begin
                        wr_req <= 1;
                        state <= NEXT;
                    end
                end
                
                NEXT: begin
                    wr_req <= 0;
                    // 更新坐标
                    if (c_cnt < channels - 1) begin
                        c_cnt <= c_cnt + 1;
                    end else begin
                        c_cnt <= 0;
                        if (w_cnt < width - 1) begin
                            w_cnt <= w_cnt + 1;
                        end else begin
                            w_cnt <= 0;
                            if (h_cnt < height - 1) begin
                                h_cnt <= h_cnt + 1;
                            end else begin
                                // 完成
                                busy <= 0;
                                done <= 1;
                                state <= IDLE;
                            end
                        end
                    end
                    
                    if (state != IDLE) begin
                        state <= READ;
                    end
                end
            endcase
        end
    end
endmodule
            </div>

            <h4>5.5.3 分散-聚集DMA</h4>
            <div class="code-block">
// 支持分散-聚集操作的DMA控制器
module ScatterGatherDMA #(
    parameter ADDR_WIDTH = 32,
    parameter DATA_WIDTH = 256,
    parameter MAX_SEGMENTS = 64
)(
    input wire clk,
    input wire rst_n,
    
    // 控制接口
    input wire sg_start,
    input wire sg_mode,  // 0: Gather, 1: Scatter
    input wire [5:0] num_segments,
    
    // 段描述符接口
    input wire seg_desc_wr,
    input wire [5:0] seg_desc_addr,
    input wire [ADDR_WIDTH-1:0] seg_src_addr,
    input wire [ADDR_WIDTH-1:0] seg_dst_addr,
    input wire [15:0] seg_length,
    
    // 内存接口
    output reg mem_req,
    output reg mem_wr,
    output reg [ADDR_WIDTH-1:0] mem_addr,
    output reg [DATA_WIDTH-1:0] mem_wdata,
    input wire [DATA_WIDTH-1:0] mem_rdata,
    input wire mem_ready,
    
    // 状态
    output reg sg_busy,
    output reg sg_done
);

    // 段描述符存储
    reg [ADDR_WIDTH-1:0] segment_src [MAX_SEGMENTS-1:0];
    reg [ADDR_WIDTH-1:0] segment_dst [MAX_SEGMENTS-1:0];
    reg [15:0] segment_len [MAX_SEGMENTS-1:0];
    
    // 描述符写入
    always @(posedge clk) begin
        if (seg_desc_wr) begin
            segment_src[seg_desc_addr] <= seg_src_addr;
            segment_dst[seg_desc_addr] <= seg_dst_addr;
            segment_len[seg_desc_addr] <= seg_length;
        end
    end
    
    // 状态机变量
    reg [5:0] current_segment;
    reg [15:0] segment_offset;
    reg [ADDR_WIDTH-1:0] gather_buffer_addr;
    reg [DATA_WIDTH-1:0] data_buffer;
    reg [2:0] state;
    
    localparam IDLE = 0, FETCH_DESC = 1, READ_DATA = 2, 
               WRITE_DATA = 3, NEXT_WORD = 4, NEXT_SEG = 5;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            state <= IDLE;
            sg_busy <= 0;
            sg_done <= 0;
        end else begin
            case (state)
                IDLE: begin
                    if (sg_start) begin
                        sg_busy <= 1;
                        sg_done <= 0;
                        current_segment <= 0;
                        segment_offset <= 0;
                        if (sg_mode == 0) begin
                            // Gather模式：初始化目标地址
                            gather_buffer_addr <= segment_dst[0];
                        end
                        state <= FETCH_DESC;
                    end
                end
                
                FETCH_DESC: begin
                    if (current_segment < num_segments) begin
                        state <= READ_DATA;
                    end else begin
                        // 所有段完成
                        sg_done <= 1;
                        sg_busy <= 0;
                        state <= IDLE;
                    end
                end
                
                READ_DATA: begin
                    mem_req <= 1;
                    mem_wr <= 0;
                    if (sg_mode == 0) begin
                        // Gather: 从分散的源地址读取
                        mem_addr <= segment_src[current_segment] + segment_offset;
                    end else begin
                        // Scatter: 从连续的源地址读取
                        mem_addr <= segment_src[0] + 
                                   (current_segment * segment_len[0]) + segment_offset;
                    end
                    
                    if (mem_ready) begin
                        data_buffer <= mem_rdata;
                        mem_req <= 0;
                        state <= WRITE_DATA;
                    end
                end
                
                WRITE_DATA: begin
                    mem_req <= 1;
                    mem_wr <= 1;
                    mem_wdata <= data_buffer;
                    
                    if (sg_mode == 0) begin
                        // Gather: 写入连续的目标地址
                        mem_addr <= gather_buffer_addr;
                    end else begin
                        // Scatter: 写入分散的目标地址
                        mem_addr <= segment_dst[current_segment] + segment_offset;
                    end
                    
                    if (mem_ready) begin
                        mem_req <= 0;
                        state <= NEXT_WORD;
                    end
                end
                
                NEXT_WORD: begin
                    segment_offset <= segment_offset + (DATA_WIDTH / 8);
                    if (sg_mode == 0) begin
                        gather_buffer_addr <= gather_buffer_addr + (DATA_WIDTH / 8);
                    end
                    
                    if (segment_offset >= segment_len[current_segment]) begin
                        state <= NEXT_SEG;
                    end else begin
                        state <= READ_DATA;
                    end
                end
                
                NEXT_SEG: begin
                    current_segment <= current_segment + 1;
                    segment_offset <= 0;
                    state <= FETCH_DESC;
                end
            endcase
        end
    end
endmodule
            </div>

            <h3>5.6 内存压缩技术</h3>
            
            <p>内存压缩通过减少数据存储和传输的大小，有效提升存储容量和带宽利用率，是优化NPU性能的重要技术。</p>

            <h4>5.6.1 压缩策略概述</h4>
            <div class="code-block">
NPU内存压缩的层次：

1. 权重压缩
   - 量化：FP32→INT8/INT4
   - 剪枝：移除小权重
   - 哈夫曼编码：频率编码
   - 共享权重：权重聚类

2. 激活值压缩
   - 稀疏性压缩：ReLU后大量零值
   - 动态范围压缩：激活值量化
   - 差分编码：相邻值相似

3. 压缩时机
   - 离线压缩：部署前压缩权重
   - 在线压缩：运行时压缩激活值
   - 传输压缩：DRAM↔SRAM传输时压缩
            </div>

            <h4>5.6.2 稀疏性压缩实现</h4>
            <div class="code-block">
// 游程编码（RLE）压缩器
module RLECompressor #(
    parameter DATA_WIDTH = 8,
    parameter MAX_RUN_LENGTH = 255
)(
    input wire clk,
    input wire rst_n,
    
    // 输入接口
    input wire in_valid,
    input wire [DATA_WIDTH-1:0] in_data,
    input wire in_last,
    output wire in_ready,
    
    // 输出接口
    output reg out_valid,
    output reg [DATA_WIDTH-1:0] out_data,
    output reg [7:0] out_count,     // 游程长度
    output reg out_is_zero,         // 标识是否为零游程
    input wire out_ready
);

    // 状态机
    reg [1:0] state;
    localparam IDLE = 0, COLLECT = 1, OUTPUT = 2;
    
    // 游程计数器
    reg [7:0] run_count;
    reg current_is_zero;
    reg [DATA_WIDTH-1:0] current_value;
    
    assign in_ready = (state != OUTPUT);
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            state <= IDLE;
            run_count <= 0;
            out_valid <= 0;
        end else begin
            case (state)
                IDLE: begin
                    if (in_valid) begin
                        current_value <= in_data;
                        current_is_zero <= (in_data == 0);
                        run_count <= 1;
                        state <= COLLECT;
                    end
                end
                
                COLLECT: begin
                    if (in_valid) begin
                        if ((in_data == 0) == current_is_zero && 
                            (!current_is_zero || in_data == current_value) &&
                            run_count < MAX_RUN_LENGTH) begin
                            // 继续当前游程
                            run_count <= run_count + 1;
                            if (!current_is_zero) 
                                current_value <= in_data;
                        end else begin
                            // 游程结束，输出当前游程
                            state <= OUTPUT;
                        end
                        
                        if (in_last && state != OUTPUT) begin
                            state <= OUTPUT;
                        end
                    end
                end
                
                OUTPUT: begin
                    out_valid <= 1;
                    out_data <= current_value;
                    out_count <= run_count;
                    out_is_zero <= current_is_zero;
                    
                    if (out_ready) begin
                        out_valid <= 0;
                        if (in_valid) begin
                            // 开始新的游程
                            current_value <= in_data;
                            current_is_zero <= (in_data == 0);
                            run_count <= 1;
                            state <= COLLECT;
                        end else begin
                            state <= IDLE;
                        end
                    end
                end
            endcase
        end
    end
endmodule

// RLE解压器
module RLEDecompressor #(
    parameter DATA_WIDTH = 8
)(
    input wire clk,
    input wire rst_n,
    
    // 输入接口
    input wire in_valid,
    input wire [DATA_WIDTH-1:0] in_data,
    input wire [7:0] in_count,
    input wire in_is_zero,
    output wire in_ready,
    
    // 输出接口
    output reg out_valid,
    output reg [DATA_WIDTH-1:0] out_data,
    input wire out_ready
);

    reg [7:0] counter;
    reg [DATA_WIDTH-1:0] stored_value;
    reg active;
    
    assign in_ready = !active || (counter == 1 && out_ready);
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            counter <= 0;
            active <= 0;
            out_valid <= 0;
        end else begin
            if (!active && in_valid) begin
                // 接收新的压缩数据
                stored_value <= in_is_zero ? 0 : in_data;
                counter <= in_count;
                active <= 1;
            end
            
            if (active) begin
                out_valid <= 1;
                out_data <= stored_value;
                
                if (out_ready) begin
                    counter <= counter - 1;
                    if (counter == 1) begin
                        active <= 0;
                        out_valid <= 0;
                    end
                end
            end
        end
    end
endmodule

// 位图压缩器（用于2:4稀疏）
module BitmapCompressor #(
    parameter DATA_WIDTH = 8,
    parameter BLOCK_SIZE = 4
)(
    input wire clk,
    input wire rst_n,
    
    // 输入接口
    input wire in_valid,
    input wire [DATA_WIDTH*BLOCK_SIZE-1:0] in_data,
    output wire in_ready,
    
    // 输出接口
    output reg out_valid,
    output reg [BLOCK_SIZE-1:0] out_bitmap,      // 非零位置的位图
    output reg [DATA_WIDTH-1:0] out_values [1:0], // 2个非零值
    input wire out_ready
);

    wire [DATA_WIDTH-1:0] values [BLOCK_SIZE-1:0];
    wire [BLOCK_SIZE-1:0] is_nonzero;
    
    // 解包输入数据
    genvar i;
    generate
        for (i = 0; i < BLOCK_SIZE; i = i + 1) begin
            assign values[i] = in_data[i*DATA_WIDTH +: DATA_WIDTH];
            assign is_nonzero[i] = (values[i] != 0);
        end
    endgenerate
    
    // 计算非零值数量
    wire [2:0] nonzero_count;
    assign nonzero_count = is_nonzero[0] + is_nonzero[1] + 
                          is_nonzero[2] + is_nonzero[3];
    
    assign in_ready = !out_valid || out_ready;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            out_valid <= 0;
        end else begin
            if (in_valid && in_ready) begin
                out_valid <= 1;
                out_bitmap <= is_nonzero;
                
                // 提取非零值（假设正好2个）
                integer j, k;
                k = 0;
                for (j = 0; j < BLOCK_SIZE && k < 2; j = j + 1) begin
                    if (is_nonzero[j]) begin
                        out_values[k] <= values[j];
                        k = k + 1;
                    end
                end
            end else if (out_valid && out_ready) begin
                out_valid <= 0;
            end
        end
    end
endmodule
            </div>

            <h4>5.6.3 压缩系统集成</h4>
            <div class="code-block">
// 带压缩功能的内存控制器
module CompressedMemoryController #(
    parameter ADDR_WIDTH = 32,
    parameter DATA_WIDTH = 256,
    parameter COMPRESSION_RATIO = 4  // 最大压缩比
)(
    input wire clk,
    input wire rst_n,
    
    // CPU/DMA接口
    input wire req_valid,
    input wire req_write,
    input wire [ADDR_WIDTH-1:0] req_addr,
    input wire [DATA_WIDTH-1:0] req_wdata,
    output reg [DATA_WIDTH-1:0] req_rdata,
    output reg req_ready,
    
    // 压缩控制
    input wire compression_enable,
    input wire [1:0] compression_mode, // 0: None, 1: RLE, 2: Bitmap
    
    // DRAM接口
    output reg dram_req,
    output reg dram_write,
    output reg [ADDR_WIDTH-1:0] dram_addr,
    output reg [DATA_WIDTH-1:0] dram_wdata,
    input wire [DATA_WIDTH-1:0] dram_rdata,
    input wire dram_ready,
    
    // 统计信息
    output reg [31:0] compressed_bytes,
    output reg [31:0] uncompressed_bytes
);

    // 元数据表（记录压缩信息）
    reg [15:0] metadata_table [4095:0]; // 4K entries
    // [15:14] - 压缩类型
    // [13:8]  - 压缩块数
    // [7:0]   - 原始块数
    
    // 地址映射
    wire [11:0] block_index = req_addr[23:12];
    wire [15:0] metadata = metadata_table[block_index];
    
    // 压缩/解压缓冲区
    reg [DATA_WIDTH-1:0] compress_buffer;
    reg [DATA_WIDTH/2-1:0] compressed_data;
    reg [7:0] compressed_size;
    
    // 状态机
    reg [2:0] state;
    localparam IDLE = 0, COMPRESS = 1, DECOMPRESS = 2, 
               DRAM_ACCESS = 3, UPDATE_META = 4;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            state <= IDLE;
            req_ready <= 0;
            compressed_bytes <= 0;
            uncompressed_bytes <= 0;
        end else begin
            case (state)
                IDLE: begin
                    if (req_valid) begin
                        if (req_write && compression_enable) begin
                            // 写入时压缩
                            compress_buffer <= req_wdata;
                            state <= COMPRESS;
                        end else if (!req_write && metadata[15:14] != 2'b00) begin
                            // 读取压缩数据需要解压
                            state <= DRAM_ACCESS;
                        end else begin
                            // 直接访问DRAM
                            dram_req <= 1;
                            dram_write <= req_write;
                            dram_addr <= req_addr;
                            dram_wdata <= req_wdata;
                            state <= DRAM_ACCESS;
                        end
                    end
                end
                
                COMPRESS: begin
                    // 简化的压缩逻辑
                    case (compression_mode)
                        2'b01: begin // RLE
                            // 检测零值比例
                            integer zero_count;
                            zero_count = 0;
                            integer i;
                            for (i = 0; i < DATA_WIDTH/8; i = i + 1) begin
                                if (compress_buffer[i*8 +: 8] == 0)
                                    zero_count = zero_count + 1;
                            end
                            
                            if (zero_count > DATA_WIDTH/16) begin
                                // 值得压缩
                                compressed_size <= DATA_WIDTH/8 - zero_count;
                                compressed_bytes <= compressed_bytes + compressed_size;
                                uncompressed_bytes <= uncompressed_bytes + DATA_WIDTH/8;
                            end
                        end
                        
                        2'b10: begin // Bitmap
                            // 2:4稀疏压缩
                            compressed_size <= DATA_WIDTH/16; // 50%压缩
                        end
                        
                        default: begin
                            compressed_size <= DATA_WIDTH/8;
                        end
                    endcase
                    
                    state <= DRAM_ACCESS;
                end
                
                DRAM_ACCESS: begin
                    if (dram_ready) begin
                        dram_req <= 0;
                        if (!req_write) begin
                            req_rdata <= dram_rdata;
                            if (metadata[15:14] != 2'b00) begin
                                state <= DECOMPRESS;
                            end else begin
                                req_ready <= 1;
                                state <= IDLE;
                            end
                        end else begin
                            state <= UPDATE_META;
                        end
                    end
                end
                
                DECOMPRESS: begin
                    // 解压逻辑
                    case (metadata[15:14])
                        2'b01: begin // RLE解压
                            // 恢复零值
                        end
                        2'b10: begin // Bitmap解压
                            // 恢复稀疏数据
                        end
                    endcase
                    
                    req_ready <= 1;
                    state <= IDLE;
                end
                
                UPDATE_META: begin
                    // 更新元数据表
                    metadata_table[block_index] <= {
                        compression_mode,
                        compressed_size[7:2],
                        8'd32  // 原始大小
                    };
                    
                    req_ready <= 1;
                    state <= IDLE;
                end
            endcase
        end
    end
endmodule

// 压缩性能监控
module CompressionMonitor #(
    parameter NUM_ENGINES = 4
)(
    input wire clk,
    input wire rst_n,
    
    // 各压缩引擎的统计输入
    input wire [31:0] compressed_bytes [NUM_ENGINES-1:0],
    input wire [31:0] uncompressed_bytes [NUM_ENGINES-1:0],
    input wire [15:0] compression_cycles [NUM_ENGINES-1:0],
    
    // 性能指标输出
    output reg [15:0] avg_compression_ratio,  // 定点数 8.8
    output reg [31:0] total_saved_bytes,
    output reg [15:0] avg_latency_cycles
);

    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            avg_compression_ratio <= 16'h0100; // 1.0
            total_saved_bytes <= 0;
            avg_latency_cycles <= 0;
        end else begin
            // 计算总压缩比
            reg [63:0] total_compressed, total_uncompressed;
            reg [31:0] total_cycles;
            integer i;
            
            total_compressed = 0;
            total_uncompressed = 0;
            total_cycles = 0;
            
            for (i = 0; i < NUM_ENGINES; i = i + 1) begin
                total_compressed = total_compressed + compressed_bytes[i];
                total_uncompressed = total_uncompressed + uncompressed_bytes[i];
                total_cycles = total_cycles + compression_cycles[i];
            end
            
            // 计算平均压缩比
            if (total_compressed > 0) begin
                avg_compression_ratio <= (total_uncompressed << 8) / total_compressed;
            end
            
            // 计算节省的字节数
            total_saved_bytes <= total_uncompressed - total_compressed;
            
            // 计算平均延迟
            if (total_uncompressed > 0) begin
                avg_latency_cycles <= total_cycles / (total_uncompressed >> 10); // per KB
            end
        end
    end
endmodule
            </div>

            <h3>5.7 习题</h3>
            
            <div class="exercise">
                <h4>习题1：多Bank SRAM地址映射</h4>
                <p>设计一个8-Bank SRAM的地址映射方案，支持3×3卷积的无冲突访问。假设特征图大小为64×64×32（H×W×C），数据类型为INT8。</p>
                <button class="toggle-answer">显示答案</button>
                <div class="answer">
                    <p><strong>解答：</strong></p>
                    <p>为了支持3×3卷积的无冲突访问，需要设计特殊的地址映射函数：</p>
                    
                    <div class="code-block">
// 斜对角Bank映射方案
module Conv3x3BankMapping #(
    parameter BANK_BITS = 3,     // 8 Banks
    parameter HEIGHT = 64,
    parameter WIDTH = 64,
    parameter CHANNELS = 32
)(
    input wire [5:0] h,          // 高度坐标
    input wire [5:0] w,          // 宽度坐标
    input wire [4:0] c,          // 通道坐标
    output wire [2:0] bank_id,
    output wire [13:0] bank_offset
);
    // 斜对角映射函数
    // bank_id = (h + w + c/4) mod 8
    wire [8:0] sum = h + w + (c >> 2);
    assign bank_id = sum[2:0];
    
    // Bank内地址计算
    // offset = (h * WIDTH + w) * (CHANNELS/8) + (c/8)
    wire [11:0] spatial_offset = (h << 6) + w;  // h*64 + w
    wire [13:0] channel_offset = c >> 3;        // c/8
    assign bank_offset = (spatial_offset << 2) + channel_offset;
endmodule

// 验证无冲突访问
module VerifyNoConflict;
    reg conflict_found;
    initial begin
        conflict_found = 0;
        // 测试3×3窗口内的9个位置
        for (int h_base = 0; h_base < 62; h_base++) begin
            for (int w_base = 0; w_base < 62; w_base++) begin
                reg [2:0] banks_used [8:0];
                
                // 计算3×3窗口内每个位置的bank
                for (int dh = 0; dh < 3; dh++) begin
                    for (int dw = 0; dw < 3; dw++) begin
                        int h = h_base + dh;
                        int w = w_base + dw;
                        int idx = dh * 3 + dw;
                        banks_used[idx] = ((h + w) & 7);
                    end
                end
                
                // 检查是否有bank冲突
                for (int i = 0; i < 9; i++) begin
                    for (int j = i+1; j < 9; j++) begin
                        if (banks_used[i] == banks_used[j]) begin
                            conflict_found = 1;
                            $display("Conflict at window (%d,%d)", h_base, w_base);
                        end
                    end
                end
            end
        end
        
        if (!conflict_found) begin
            $display("No conflicts found!");
        end
    end
endmodule
                    </div>
                    
                    <p><strong>关键设计要点：</strong></p>
                    <ol>
                        <li>使用斜对角映射：(h+w+c/4) mod 8，确保3×3窗口内的像素分布到不同Bank</li>
                        <li>通道维度也参与映射，避免不同通道的相同位置冲突</li>
                        <li>每个Bank存储4个通道的数据，提高空间局部性</li>
                        <li>Bank内地址连续存储，便于突发传输</li>
                    </ol>
                </div>
            </div>

            <div class="exercise">
                <h4>习题2：双缓冲预取控制器</h4>
                <p>实现一个支持计算和预取完全重叠的双缓冲控制器，要求计算延迟和预取延迟可以不同。</p>
                <button class="toggle-answer">显示答案</button>
                <div class="answer">
                    <div class="code-block">
module AdaptiveDoubleBuffer #(
    parameter BUFFER_SIZE = 16384,
    parameter DATA_WIDTH = 256
)(
    input wire clk,
    input wire rst_n,
    
    // 计算接口
    input wire compute_start,
    input wire [31:0] compute_cycles,  // 预期计算周期数
    output reg compute_buffer_ready,
    output reg compute_buffer_id,      // 当前计算使用的buffer
    
    // 预取接口
    input wire [31:0] prefetch_addr,
    input wire [15:0] prefetch_size,
    input wire [31:0] prefetch_cycles, // 预期预取周期数
    output reg prefetch_buffer_ready,
    output reg prefetch_buffer_id,     // 当前预取使用的buffer
    
    // 性能监控
    output reg [31:0] idle_cycles,
    output reg [31:0] overlap_cycles
);

    // 状态跟踪
    reg buffer_status [1:0]; // 0: 空闲, 1: 计算中, 2: 预取中, 3: 就绪
    reg [31:0] compute_timer, prefetch_timer;
    reg [31:0] cycle_counter;
    
    // 状态机
    reg [2:0] state;
    localparam INIT = 0, PREFETCH_0 = 1, COMPUTE_0_PREFETCH_1 = 2,
               SWITCH = 3, COMPUTE_1_PREFETCH_0 = 4;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            state <= INIT;
            compute_buffer_id <= 0;
            prefetch_buffer_id <= 0;
            buffer_status[0] <= 0;
            buffer_status[1] <= 0;
            idle_cycles <= 0;
            overlap_cycles <= 0;
            cycle_counter <= 0;
        end else begin
            cycle_counter <= cycle_counter + 1;
            
            // 更新定时器
            if (compute_timer > 0) compute_timer <= compute_timer - 1;
            if (prefetch_timer > 0) prefetch_timer <= prefetch_timer - 1;
            
            case (state)
                INIT: begin
                    // 初始预取到Buffer 0
                    if (prefetch_size > 0) begin
                        prefetch_buffer_id <= 0;
                        prefetch_buffer_ready <= 1;
                        prefetch_timer <= prefetch_cycles;
                        buffer_status[0] <= 2; // 预取中
                        state <= PREFETCH_0;
                    end
                end
                
                PREFETCH_0: begin
                    idle_cycles <= idle_cycles + 1;
                    if (prefetch_timer == 0) begin
                        buffer_status[0] <= 3; // 就绪
                        compute_buffer_ready <= 1;
                        compute_buffer_id <= 0;
                        state <= COMPUTE_0_PREFETCH_1;
                    end
                end
                
                COMPUTE_0_PREFETCH_1: begin
                    overlap_cycles <= overlap_cycles + 1;
                    
                    // 开始在Buffer 0上计算
                    if (compute_start && compute_timer == 0) begin
                        compute_timer <= compute_cycles;
                        buffer_status[0] <= 1; // 计算中
                        compute_buffer_ready <= 0;
                    end
                    
                    // 同时预取到Buffer 1
                    if (prefetch_timer == 0 && buffer_status[1] != 2) begin
                        prefetch_buffer_id <= 1;
                        prefetch_buffer_ready <= 1;
                        prefetch_timer <= prefetch_cycles;
                        buffer_status[1] <= 2; // 预取中
                    end
                    
                    // 检查是否可以切换
                    if (compute_timer == 0 && buffer_status[0] == 1) begin
                        buffer_status[0] <= 0; // 空闲
                    end
                    
                    if (prefetch_timer == 0 && buffer_status[1] == 2) begin
                        buffer_status[1] <= 3; // 就绪
                    end
                    
                    // 两个都完成，切换buffer
                    if (buffer_status[0] == 0 && buffer_status[1] == 3) begin
                        state <= SWITCH;
                    end
                end
                
                SWITCH: begin
                    // 切换计算和预取buffer
                    compute_buffer_id <= 1;
                    prefetch_buffer_id <= 0;
                    compute_buffer_ready <= 1;
                    prefetch_buffer_ready <= 1;
                    state <= COMPUTE_1_PREFETCH_0;
                end
                
                COMPUTE_1_PREFETCH_0: begin
                    overlap_cycles <= overlap_cycles + 1;
                    
                    // 在Buffer 1上计算
                    if (compute_start && compute_timer == 0) begin
                        compute_timer <= compute_cycles;
                        buffer_status[1] <= 1;
                        compute_buffer_ready <= 0;
                    end
                    
                    // 预取到Buffer 0
                    if (prefetch_timer == 0 && buffer_status[0] != 2) begin
                        prefetch_timer <= prefetch_cycles;
                        buffer_status[0] <= 2;
                    end
                    
                    // 完成检查和状态更新
                    if (compute_timer == 0 && buffer_status[1] == 1) begin
                        buffer_status[1] <= 0;
                    end
                    
                    if (prefetch_timer == 0 && buffer_status[0] == 2) begin
                        buffer_status[0] <= 3;
                    end
                    
                    if (buffer_status[1] == 0 && buffer_status[0] == 3) begin
                        state <= SWITCH;
                    end
                end
            endcase
        end
    end
    
    // 性能分析
    wire is_idle = (buffer_status[0] == 0 || buffer_status[0] == 3) && 
                   (buffer_status[1] == 0 || buffer_status[1] == 3) &&
                   (compute_timer == 0) && (prefetch_timer == 0);
    
    always @(posedge clk) begin
        if (is_idle) idle_cycles <= idle_cycles + 1;
    end
endmodule
                    </div>
                    
                    <p><strong>设计特点：</strong></p>
                    <ol>
                        <li>自适应时序：根据实际计算和预取时间动态调整</li>
                        <li>完全重叠：计算和预取可以同时进行</li>
                        <li>性能监控：统计空闲周期和重叠周期</li>
                        <li>灵活切换：自动在两个buffer间切换</li>
                    </ol>
                </div>
            </div>

            <div class="exercise">
                <h4>习题3：缓存一致性协议</h4>
                <p>设计一个简化的缓存一致性协议，支持4个NPU核心共享数据。要求支持独占读、共享读和写操作。</p>
                <button class="toggle-answer">显示答案</button>
                <div class="answer">
                    <div class="code-block">
// 简化的MSI协议实现
module SimpleMSIProtocol #(
    parameter NUM_CORES = 4,
    parameter ADDR_WIDTH = 32,
    parameter CACHE_LINE_SIZE = 64
)(
    input wire clk,
    input wire rst_n,
    
    // 各核心的请求
    input wire [NUM_CORES-1:0] core_req_valid,
    input wire [1:0] core_req_type [NUM_CORES-1:0], // 0:Read, 1:Write, 2:Upgrade
    input wire [ADDR_WIDTH-1:0] core_req_addr [NUM_CORES-1:0],
    output reg [NUM_CORES-1:0] core_req_grant,
    output reg [1:0] core_resp_type [NUM_CORES-1:0], // 0:Data, 1:Ack, 2:Inv
    
    // 目录接口
    output reg dir_req_valid,
    output reg [ADDR_WIDTH-1:0] dir_req_addr,
    input wire [NUM_CORES-1:0] dir_sharers,  // 共享者位图
    input wire dir_modified,                  // 是否被修改
    input wire [1:0] dir_owner                // 独占所有者
);

    // 状态定义
    localparam INVALID = 0, SHARED = 1, MODIFIED = 2;
    
    // 缓存行状态表
    reg [1:0] cache_state [NUM_CORES-1:0][1023:0]; // 1K条目
    
    // 仲裁逻辑
    reg [1:0] current_requester;
    reg [2:0] protocol_state;
    localparam IDLE = 0, CHECK_DIR = 1, SEND_INV = 2, 
               WAIT_ACK = 3, GRANT_ACCESS = 4;
    
    // 失效确认计数
    reg [NUM_CORES-1:0] inv_ack_pending;
    
    // 获取缓存行索引
    function [9:0] get_index(input [ADDR_WIDTH-1:0] addr);
        get_index = addr[15:6]; // 64B行，1K条目
    endfunction
    
    // 仲裁器：轮询选择请求者
    reg [1:0] rr_pointer;
    always @(posedge clk) begin
        if (protocol_state == IDLE) begin
            reg found;
            found = 0;
            for (int i = 0; i < NUM_CORES && !found; i++) begin
                int idx = (rr_pointer + i) % NUM_CORES;
                if (core_req_valid[idx]) begin
                    current_requester <= idx;
                    rr_pointer <= (idx + 1) % NUM_CORES;
                    found = 1;
                end
            end
        end
    end
    
    // 协议状态机
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            protocol_state <= IDLE;
            core_req_grant <= 0;
            inv_ack_pending <= 0;
        end else begin
            case (protocol_state)
                IDLE: begin
                    if (|core_req_valid) begin
                        // 查询目录
                        dir_req_valid <= 1;
                        dir_req_addr <= core_req_addr[current_requester];
                        protocol_state <= CHECK_DIR;
                    end
                end
                
                CHECK_DIR: begin
                    dir_req_valid <= 0;
                    
                    case (core_req_type[current_requester])
                        2'b00: begin // 读请求
                            if (dir_modified && dir_owner != current_requester) begin
                                // 需要从修改者获取数据
                                core_resp_type[dir_owner] <= 2'b10; // 发送失效
                                inv_ack_pending[dir_owner] <= 1;
                                protocol_state <= WAIT_ACK;
                            end else begin
                                // 可以直接授权
                                protocol_state <= GRANT_ACCESS;
                            end
                        end
                        
                        2'b01: begin // 写请求
                            // 失效所有共享者
                            for (int i = 0; i < NUM_CORES; i++) begin
                                if (i != current_requester && 
                                    (dir_sharers[i] || (dir_modified && dir_owner == i))) begin
                                    core_resp_type[i] <= 2'b10; // 失效
                                    inv_ack_pending[i] <= 1;
                                end
                            end
                            
                            if (|inv_ack_pending) begin
                                protocol_state <= WAIT_ACK;
                            end else begin
                                protocol_state <= GRANT_ACCESS;
                            end
                        end
                        
                        2'b10: begin // 升级请求（S->M）
                            // 失效其他共享者
                            for (int i = 0; i < NUM_CORES; i++) begin
                                if (i != current_requester && dir_sharers[i]) begin
                                    core_resp_type[i] <= 2'b10;
                                    inv_ack_pending[i] <= 1;
                                end
                            end
                            
                            if (|inv_ack_pending) begin
                                protocol_state <= WAIT_ACK;
                            end else begin
                                protocol_state <= GRANT_ACCESS;
                            end
                        end
                    endcase
                end
                
                WAIT_ACK: begin
                    // 等待所有失效确认
                    // 简化：假设立即收到确认
                    inv_ack_pending <= 0;
                    protocol_state <= GRANT_ACCESS;
                end
                
                GRANT_ACCESS: begin
                    // 授权访问
                    core_req_grant[current_requester] <= 1;
                    
                    // 更新本地状态
                    wire [9:0] idx = get_index(core_req_addr[current_requester]);
                    
                    case (core_req_type[current_requester])
                        2'b00: // 读
                            cache_state[current_requester][idx] <= SHARED;
                        2'b01, 2'b10: // 写或升级
                            cache_state[current_requester][idx] <= MODIFIED;
                    endcase
                    
                    protocol_state <= IDLE;
                end
            endcase
            
            // 清除授权信号
            if (protocol_state != GRANT_ACCESS) begin
                core_req_grant <= 0;
            end
        end
    end
endmodule
                    </div>
                    
                    <p><strong>协议特点：</strong></p>
                    <ol>
                        <li><strong>三状态MSI：</strong>Invalid、Shared、Modified</li>
                        <li><strong>目录式管理：</strong>跟踪每个缓存行的共享者</li>
                        <li><strong>失效广播：</strong>写操作前失效所有副本</li>
                        <li><strong>轮询仲裁：</strong>公平处理多个请求</li>
                    </ol>
                </div>
            </div>

            <div class="exercise">
                <h4>习题4：张量DMA传输优化</h4>
                <p>优化一个4D张量（N×C×H×W）的DMA传输，支持padding和stride操作。目标是最小化传输次数。</p>
                <button class="toggle-answer">显示答案</button>
                <div class="answer">
                    <div class="code-block">
module OptimizedTensorDMA #(
    parameter ADDR_WIDTH = 32,
    parameter DATA_WIDTH = 256,
    parameter BURST_LEN = 16
)(
    input wire clk,
    input wire rst_n,
    
    // 张量描述
    input wire [15:0] dim_n, dim_c, dim_h, dim_w,
    input wire [3:0] pad_top, pad_bottom, pad_left, pad_right,
    input wire [3:0] stride_h, stride_w,
    input wire [ADDR_WIDTH-1:0] src_addr, dst_addr,
    
    // DMA接口
    output reg dma_req,
    output reg [ADDR_WIDTH-1:0] dma_src,
    output reg [ADDR_WIDTH-1:0] dma_dst,
    output reg [15:0] dma_len,
    output reg dma_2d_mode,
    output reg [15:0] dma_2d_stride,
    input wire dma_done
);

    // 传输优化分析
    reg [2:0] transfer_mode;
    localparam LINEAR = 0, STRIPE_2D = 1, TILE_3D = 2, BLOCK_4D = 3;
    
    // 计算最优传输模式
    always @(*) begin
        // 分析数据布局
        reg is_contiguous_w = (stride_w == 1 && pad_left == 0 && pad_right == 0);
        reg is_contiguous_h = (stride_h == 1 && pad_top == 0 && pad_bottom == 0);
        
        if (is_contiguous_w && is_contiguous_h) begin
            // 可以使用大块传输
            if (dim_w * dim_h <= BURST_LEN * 8) begin
                transfer_mode = STRIPE_2D; // 2D条带传输
            end else begin
                transfer_mode = TILE_3D;   // 3D块传输
            end
        end else if (is_contiguous_w) begin
            transfer_mode = STRIPE_2D;     // 逐行传输
        end else begin
            transfer_mode = LINEAR;        // 逐元素传输
        end
    end
    
    // 传输状态机
    reg [3:0] state;
    reg [15:0] n_idx, c_idx, h_idx, w_idx;
    reg [15:0] h_out, w_out;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            state <= 0;
            dma_req <= 0;
        end else begin
            case (state)
                0: begin // 初始化
                    n_idx <= 0;
                    c_idx <= 0;
                    h_idx <= 0;
                    w_idx <= 0;
                    h_out <= 0;
                    w_out <= 0;
                    state <= 1;
                end
                
                1: begin // 计算传输参数
                    case (transfer_mode)
                        STRIPE_2D: begin
                            // 计算2D传输的源地址
                            reg [31:0] src_offset;
                            src_offset = n_idx * dim_c * dim_h * dim_w +
                                       c_idx * dim_h * dim_w +
                                       h_idx * dim_w;
                            
                            // 处理padding
                            if (h_out < pad_top || h_out >= dim_h + pad_top) begin
                                // Padding区域，跳过
                                state <= 4;
                            end else begin
                                dma_req <= 1;
                                dma_src <= src_addr + src_offset * (DATA_WIDTH/8);
                                dma_dst <= dst_addr + 
                                         (n_idx * dim_c * (dim_h + pad_top + pad_bottom) * 
                                          (dim_w + pad_left + pad_right) +
                                          c_idx * (dim_h + pad_top + pad_bottom) * 
                                          (dim_w + pad_left + pad_right) +
                                          h_out * (dim_w + pad_left + pad_right) + 
                                          pad_left) * (DATA_WIDTH/8);
                                
                                dma_len <= dim_w;
                                dma_2d_mode <= 0;
                                state <= 2;
                            end
                        end
                        
                        TILE_3D: begin
                            // 3D块传输，一次传输多行
                            reg [15:0] rows_to_transfer;
                            rows_to_transfer = (dim_h - h_idx > 16) ? 16 : (dim_h - h_idx);
                            
                            dma_req <= 1;
                            dma_src <= src_addr + 
                                     (n_idx * dim_c * dim_h * dim_w +
                                      c_idx * dim_h * dim_w +
                                      h_idx * dim_w) * (DATA_WIDTH/8);
                            dma_dst <= dst_addr + 
                                     (n_idx * dim_c * (dim_h + pad_top + pad_bottom) * 
                                      (dim_w + pad_left + pad_right) +
                                      c_idx * (dim_h + pad_top + pad_bottom) * 
                                      (dim_w + pad_left + pad_right) +
                                      (h_idx + pad_top) * (dim_w + pad_left + pad_right) + 
                                      pad_left) * (DATA_WIDTH/8);
                            
                            dma_len <= dim_w * rows_to_transfer;
                            dma_2d_mode <= 1;
                            dma_2d_stride <= dim_w + pad_left + pad_right;
                            state <= 2;
                        end
                    endcase
                end
                
                2: begin // 等待DMA完成
                    dma_req <= 0;
                    if (dma_done) begin
                        state <= 3;
                    end
                end
                
                3: begin // 更新索引
                    case (transfer_mode)
                        STRIPE_2D: begin
                            h_idx <= h_idx + stride_h;
                            h_out <= h_out + 1;
                            
                            if (h_idx >= dim_h) begin
                                h_idx <= 0;
                                h_out <= 0;
                                c_idx <= c_idx + 1;
                                
                                if (c_idx >= dim_c) begin
                                    c_idx <= 0;
                                    n_idx <= n_idx + 1;
                                    
                                    if (n_idx >= dim_n) begin
                                        state <= 5; // 完成
                                    end
                                end
                            end
                        end
                        
                        TILE_3D: begin
                            h_idx <= h_idx + 16;
                            
                            if (h_idx >= dim_h) begin
                                h_idx <= 0;
                                c_idx <= c_idx + 1;
                                
                                if (c_idx >= dim_c) begin
                                    c_idx <= 0;
                                    n_idx <= n_idx + 1;
                                    
                                    if (n_idx >= dim_n) begin
                                        state <= 5;
                                    end
                                end
                            end
                        end
                    endcase
                    
                    if (state != 5) state <= 1;
                end
                
                4: begin // 处理padding（填充0）
                    // 简化：假设硬件自动填充0
                    h_out <= h_out + 1;
                    if (h_out >= dim_h + pad_top + pad_bottom) begin
                        h_out <= 0;
                        c_idx <= c_idx + 1;
                        // ... 更新其他索引
                    end
                    state <= 1;
                end
                
                5: begin // 完成
                    // 传输完成
                end
            endcase
        end
    end
endmodule
                    </div>
                    
                    <p><strong>优化策略：</strong></p>
                    <ol>
                        <li><strong>传输模式选择：</strong>根据数据连续性选择最优传输模式</li>
                        <li><strong>2D/3D块传输：</strong>减少DMA请求次数</li>
                        <li><strong>Padding处理：</strong>硬件自动填充，避免传输padding数据</li>
                        <li><strong>Stride优化：</strong>使用2D DMA模式处理stride</li>
                    </ol>
                </div>
            </div>

            <div class="exercise">
                <h4>习题5：压缩算法选择</h4>
                <p>为不同类型的神经网络数据选择合适的压缩算法。考虑权重、激活值和梯度的特点。</p>
                <button class="toggle-answer">显示答案</button>
                <div class="answer">
                    <div class="code-block">
// 自适应压缩算法选择器
module AdaptiveCompressionSelector #(
    parameter DATA_WIDTH = 256,
    parameter SAMPLE_SIZE = 1024
)(
    input wire clk,
    input wire rst_n,
    
    // 数据类型
    input wire [1:0] data_type, // 0: Weight, 1: Activation, 2: Gradient
    input wire [2:0] layer_type, // 0: Conv, 1: FC, 2: BN, 3: Attention
    
    // 数据采样输入
    input wire sample_valid,
    input wire [DATA_WIDTH-1:0] sample_data,
    
    // 压缩算法选择输出
    output reg [2:0] selected_algorithm,
    output reg [7:0] algorithm_params,
    output reg selection_done
);

    // 算法定义
    localparam NONE = 0, QUANTIZE = 1, RLE = 2, 
               SPARSE = 3, HUFFMAN = 4, DELTA = 5;
    
    // 统计信息
    reg [31:0] zero_count;
    reg [31:0] unique_values;
    reg [31:0] max_run_length;
    reg [31:0] value_range;
    reg signed [31:0] min_value, max_value;
    reg [31:0] sample_count;
    
    // 统计收集
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            zero_count <= 0;
            sample_count <= 0;
            min_value <= 32'h7FFFFFFF;
            max_value <= 32'h80000000;
        end else if (sample_valid && sample_count < SAMPLE_SIZE) begin
            sample_count <= sample_count + 1;
            
            // 统计零值
            for (int i = 0; i < DATA_WIDTH/32; i++) begin
                if (sample_data[i*32 +: 32] == 0) begin
                    zero_count <= zero_count + 1;
                end
                
                // 更新最大最小值
                signed [31:0] val = sample_data[i*32 +: 32];
                if (val < min_value) min_value <= val;
                if (val > max_value) max_value <= val;
            end
        end
    end
    
    // 算法选择逻辑
    always @(posedge clk) begin
        if (sample_count >= SAMPLE_SIZE && !selection_done) begin
            // 计算统计指标
            reg [15:0] sparsity = (zero_count * 100) / (sample_count * DATA_WIDTH/32);
            value_range = max_value - min_value;
            
            case (data_type)
                2'b00: begin // 权重
                    case (layer_type)
                        3'b000: begin // Conv层权重
                            if (sparsity > 60) begin
                                selected_algorithm <= SPARSE;
                                algorithm_params <= 8'h24; // 2:4稀疏
                            end else begin
                                selected_algorithm <= QUANTIZE;
                                algorithm_params <= 8'h08; // INT8量化
                            end
                        end
                        
                        3'b001: begin // FC层权重
                            // FC层通常稀疏性更高
                            if (sparsity > 70) begin
                                selected_algorithm <= SPARSE;
                                algorithm_params <= 8'h48; // 4:8稀疏
                            end else if (unique_values < 256) begin
                                selected_algorithm <= HUFFMAN;
                                algorithm_params <= 8'h00;
                            end else begin
                                selected_algorithm <= QUANTIZE;
                                algorithm_params <= 8'h04; // INT4量化
                            end
                        end
                        
                        3'b011: begin // Attention层权重
                            // Attention通常需要更高精度
                            selected_algorithm <= QUANTIZE;
                            algorithm_params <= 8'h10; // INT16量化
                        end
                    endcase
                end
                
                2'b01: begin // 激活值
                    if (layer_type == 3'b000 || layer_type == 3'b001) begin
                        // ReLU后激活值有大量零
                        if (sparsity > 50) begin
                            selected_algorithm <= RLE;
                            algorithm_params <= 8'hFF; // 最大游程255
                        end else begin
                            // 动态量化
                            selected_algorithm <= QUANTIZE;
                            algorithm_params <= 8'h88; // 动态INT8
                        end
                    end else if (layer_type == 3'b010) begin // BN层
                        // BN后数据分布较均匀
                        selected_algorithm <= DELTA;
                        algorithm_params <= 8'h01; // 一阶差分
                    end
                end
                
                2'b10: begin // 梯度
                    // 梯度通常很小且稀疏
                    if (sparsity > 80) begin
                        selected_algorithm <= SPARSE;
                        algorithm_params <= 8'h11; // 1:1稀疏（只传非零）
                    end else if (value_range < 65536) begin
                        // 小范围梯度用差分编码
                        selected_algorithm <= DELTA;
                        algorithm_params <= 8'h02; // 二阶差分
                    end else begin
                        selected_algorithm <= QUANTIZE;
                        algorithm_params <= 8'h10; // FP16量化
                    end
                end
            endcase
            
            selection_done <= 1;
        end
    end
    
    // 压缩比预测
    reg [15:0] predicted_ratio;
    always @(*) begin
        case (selected_algorithm)
            QUANTIZE: begin
                case (algorithm_params[3:0])
                    4'h4: predicted_ratio = 16'h0800;  // 8x (INT4)
                    4'h8: predicted_ratio = 16'h0400;  // 4x (INT8)
                    default: predicted_ratio = 16'h0200; // 2x
                endcase
            end
            
            RLE: begin
                // 基于稀疏性预测
                if (sparsity > 75) predicted_ratio = 16'h0600; // 6x
                else if (sparsity > 50) predicted_ratio = 16'h0300; // 3x
                else predicted_ratio = 16'h0150; // 1.5x
            end
            
            SPARSE: begin
                // 基于稀疏模式
                case (algorithm_params)
                    8'h24: predicted_ratio = 16'h0200; // 2x (2:4)
                    8'h48: predicted_ratio = 16'h0200; // 2x (4:8)
                    8'h11: predicted_ratio = sparsity * 16'h0010; // 可变
                endcase
            end
            
            default: predicted_ratio = 16'h0100; // 1x
        endcase
    end
endmodule
                    </div>
                    
                    <p><strong>压缩策略总结：</strong></p>
                    <table>
                        <tr>
                            <th>数据类型</th>
                            <th>特征</th>
                            <th>推荐算法</th>
                            <th>预期压缩比</th>
                        </tr>
                        <tr>
                            <td>Conv权重</td>
                            <td>中等稀疏性，分布集中</td>
                            <td>INT8量化/2:4稀疏</td>
                            <td>2-4x</td>
                        </tr>
                        <tr>
                            <td>FC权重</td>
                            <td>高稀疏性，可剪枝</td>
                            <td>4:8稀疏/INT4量化</td>
                            <td>4-8x</td>
                        </tr>
                        <tr>
                            <td>激活值(ReLU后)</td>
                            <td>大量零值，正值分布</td>
                            <td>RLE/动态量化</td>
                            <td>3-6x</td>
                        </tr>
                        <tr>
                            <td>梯度</td>
                            <td>极稀疏，小值</td>
                            <td>Top-K稀疏/差分编码</td>
                            <td>10-100x</td>
                        </tr>
                    </table>
                </div>
            </div>

            <div class="exercise">
                <h4>习题6：存储带宽优化</h4>
                <p>设计一个存储带宽监控和优化系统，动态调整各个模块的带宽分配。</p>
                <button class="toggle-answer">显示答案</button>
                <div class="answer">
                    <div class="code-block">
module BandwidthOptimizer #(
    parameter NUM_CLIENTS = 8,
    parameter TOTAL_BANDWIDTH = 1000, // GB/s
    parameter MONITOR_WINDOW = 1024
)(
    input wire clk,
    input wire rst_n,
    
    // 客户端请求
    input wire [NUM_CLIENTS-1:0] client_req,
    input wire [31:0] client_addr [NUM_CLIENTS-1:0],
    input wire [15:0] client_len [NUM_CLIENTS-1:0],
    input wire [2:0] client_priority [NUM_CLIENTS-1:0],
    
    // 带宽分配输出
    output reg [NUM_CLIENTS-1:0] client_grant,
    output reg [9:0] client_bandwidth [NUM_CLIENTS-1:0], // MB/s
    
    // 性能监控
    output reg [31:0] total_throughput,
    output reg [15:0] bandwidth_efficiency // 0-100%
);

    // 带宽使用统计
    reg [31:0] bytes_transferred [NUM_CLIENTS-1:0];
    reg [31:0] request_count [NUM_CLIENTS-1:0];
    reg [31:0] stall_cycles [NUM_CLIENTS-1:0];
    reg [15:0] monitor_cycles;
    
    // QoS参数
    reg [9:0] min_bandwidth [NUM_CLIENTS-1:0];
    reg [9:0] max_bandwidth [NUM_CLIENTS-1:0];
    reg [15:0] burst_allowance [NUM_CLIENTS-1:0];
    
    // 初始化QoS参数
    initial begin
        for (int i = 0; i < NUM_CLIENTS; i++) begin
            min_bandwidth[i] = 50;  // 50 MB/s minimum
            max_bandwidth[i] = 300; // 300 MB/s maximum
            burst_allowance[i] = 100; // 100 MB burst
        end
    end
    
    // 带宽令牌桶
    reg [15:0] tokens [NUM_CLIENTS-1:0];
    reg [3:0] refill_counter;
    
    // 令牌补充
    always @(posedge clk) begin
        refill_counter <= refill_counter + 1;
        if (refill_counter == 0) begin // 每16周期补充一次
            for (int i = 0; i < NUM_CLIENTS; i++) begin
                if (tokens[i] < client_bandwidth[i]) begin
                    tokens[i] <= tokens[i] + (client_bandwidth[i] >> 4);
                end
            end
        end
    end
    
    // 动态带宽分配算法
    reg [2:0] allocation_state;
    reg [31:0] total_demand;
    reg [31:0] allocated_bandwidth;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            allocation_state <= 0;
            monitor_cycles <= 0;
            // 初始均分带宽
            for (int i = 0; i < NUM_CLIENTS; i++) begin
                client_bandwidth[i] <= TOTAL_BANDWIDTH / NUM_CLIENTS;
            end
        end else begin
            monitor_cycles <= monitor_cycles + 1;
            
            // 收集统计信息
            for (int i = 0; i < NUM_CLIENTS; i++) begin
                if (client_req[i]) begin
                    request_count[i] <= request_count[i] + 1;
                    if (!client_grant[i]) begin
                        stall_cycles[i] <= stall_cycles[i] + 1;
                    end
                end
                
                if (client_grant[i]) begin
                    bytes_transferred[i] <= bytes_transferred[i] + client_len[i];
                end
            end
            
            // 周期性重新分配
            if (monitor_cycles >= MONITOR_WINDOW) begin
                monitor_cycles <= 0;
                allocation_state <= 1;
            end
            
            case (allocation_state)
                1: begin // 计算需求
                    total_demand = 0;
                    for (int i = 0; i < NUM_CLIENTS; i++) begin
                        // 基于历史使用计算需求
                        reg [31:0] demand;
                        demand = (bytes_transferred[i] * 1000) / MONITOR_WINDOW;
                        
                        // 考虑停顿率
                        if (stall_cycles[i] > MONITOR_WINDOW/10) begin
                            demand = demand * 15 / 10; // 增加50%
                        end
                        
                        total_demand = total_demand + demand;
                    end
                    allocation_state <= 2;
                end
                
                2: begin // 分配带宽
                    allocated_bandwidth = 0;
                    
                    // 第一轮：保证最小带宽
                    for (int i = 0; i < NUM_CLIENTS; i++) begin
                        client_bandwidth[i] <= min_bandwidth[i];
                        allocated_bandwidth = allocated_bandwidth + min_bandwidth[i];
                    end
                    
                    allocation_state <= 3;
                end
                
                3: begin // 分配剩余带宽
                    reg [31:0] remaining = TOTAL_BANDWIDTH - allocated_bandwidth;
                    
                    // 按优先级和需求比例分配
                    for (int i = 0; i < NUM_CLIENTS; i++) begin
                        reg [31:0] extra;
                        if (total_demand > 0) begin
                            extra = (remaining * bytes_transferred[i]) / total_demand;
                            
                            // 优先级加权
                            extra = extra * (client_priority[i] + 1) / 4;
                            
                            // 限制在最大带宽内
                            if (client_bandwidth[i] + extra > max_bandwidth[i]) begin
                                extra = max_bandwidth[i] - client_bandwidth[i];
                            end
                            
                            client_bandwidth[i] <= client_bandwidth[i] + extra;
                        end
                    end
                    
                    // 清除统计
                    for (int i = 0; i < NUM_CLIENTS; i++) begin
                        bytes_transferred[i] <= 0;
                        request_count[i] <= 0;
                        stall_cycles[i] <= 0;
                    end
                    
                    allocation_state <= 0;
                end
            endcase
        end
    end
    
    // 授权仲裁器
    reg [2:0] rr_pointer;
    always @(posedge clk) begin
        client_grant <= 0;
        
        // 轮询检查有令牌的请求者
        for (int i = 0; i < NUM_CLIENTS; i++) begin
            int idx = (rr_pointer + i) % NUM_CLIENTS;
            if (client_req[idx] && tokens[idx] >= client_len[idx]) begin
                client_grant[idx] <= 1;
                tokens[idx] <= tokens[idx] - client_len[idx];
                rr_pointer <= (idx + 1) % NUM_CLIENTS;
                break;
            end
        end
    end
    
    // 性能计算
    always @(posedge clk) begin
        reg [31:0] total_bytes = 0;
        reg [31:0] total_allocated = 0;
        
        for (int i = 0; i < NUM_CLIENTS; i++) begin
            total_bytes = total_bytes + bytes_transferred[i];
            total_allocated = total_allocated + client_bandwidth[i];
        end
        
        total_throughput <= (total_bytes * 1000) / monitor_cycles;
        bandwidth_efficiency <= (total_throughput * 100) / TOTAL_BANDWIDTH;
    end
endmodule
                    </div>
                    
                    <p><strong>优化策略：</strong></p>
                    <ol>
                        <li><strong>动态带宽分配：</strong>基于历史使用和停顿率</li>
                        <li><strong>QoS保证：</strong>最小/最大带宽限制</li>
                        <li><strong>令牌桶限流：</strong>平滑突发流量</li>
                        <li><strong>优先级支持：</strong>关键路径获得更多带宽</li>
                        <li><strong>效率监控：</strong>实时跟踪带宽利用率</li>
                    </ol>
                </div>
            </div>

            <div class="exercise">
                <h4>习题7：存储层次优化</h4>
                <p>为CNN推理设计一个三级存储层次（L0/L1/L2），优化数据复用。</p>
                <button class="toggle-answer">显示答案</button>
                <div class="answer">
                    <div class="code-block">
// CNN优化的三级存储层次
module CNNMemoryHierarchy #(
    parameter PE_ARRAY_DIM = 16,
    parameter L0_SIZE = 256,      // 每个PE 256B
    parameter L1_SIZE = 16384,    // 每个PE组 16KB
    parameter L2_SIZE = 2097152,  // 全局 2MB
    parameter DATA_WIDTH = 8
)(
    input wire clk,
    input wire rst_n,
    
    // CNN层配置
    input wire [15:0] layer_h, layer_w, layer_c_in, layer_c_out,
    input wire [3:0] kernel_size,
    input wire [3:0] stride,
    
    // 数据流控制
    input wire start_layer,
    output reg layer_done,
    
    // 性能统计
    output reg [31:0] l0_hits, l0_misses,
    output reg [31:0] l1_hits, l1_misses,
    output reg [31:0] l2_hits, l2_misses,
    output reg [31:0] dram_accesses
);

    // 数据复用分析
    reg [2:0] dataflow_mode;
    localparam WEIGHT_STATIONARY = 0, OUTPUT_STATIONARY = 1, 
               ROW_STATIONARY = 2, NO_LOCAL_REUSE = 3;
    
    // 复用距离计算
    function [31:0] calc_reuse_distance(
        input [2:0] data_type, // 0: weight, 1: input, 2: output
        input [2:0] df_mode
    );
        case (df_mode)
            WEIGHT_STATIONARY: begin
                case (data_type)
                    0: calc_reuse_distance = layer_h * layer_w; // 权重复用整个特征图
                    1: calc_reuse_distance = kernel_size * kernel_size; // 输入复用卷积窗口
                    2: calc_reuse_distance = 1; // 输出无复用
                endcase
            end
            
            OUTPUT_STATIONARY: begin
                case (data_type)
                    0: calc_reuse_distance = 1; // 权重无复用
                    1: calc_reuse_distance = layer_c_out; // 输入复用所有输出通道
                    2: calc_reuse_distance = layer_c_in * kernel_size * kernel_size; // 输出累加
                endcase
            end
            
            ROW_STATIONARY: begin
                // 行固定：平衡三种数据的复用
                case (data_type)
                    0: calc_reuse_distance = layer_w / stride; // 权重复用一行
                    1: calc_reuse_distance = kernel_size; // 输入复用卷积行
                    2: calc_reuse_distance = kernel_size * layer_c_in / PE_ARRAY_DIM; // 部分累加
                endcase
            end
        endcase
    endfunction
    
    // 选择最优数据流
    always @(*) begin
        reg [31:0] weight_size = kernel_size * kernel_size * layer_c_in * layer_c_out;
        reg [31:0] input_size = layer_h * layer_w * layer_c_in;
        reg [31:0] output_size = (layer_h/stride) * (layer_w/stride) * layer_c_out;
        
        // 基于层参数选择数据流
        if (kernel_size == 1) begin
            // 1x1卷积，输出固定最优
            dataflow_mode = OUTPUT_STATIONARY;
        end else if (weight_size < L1_SIZE) begin
            // 权重能放入L1，权重固定
            dataflow_mode = WEIGHT_STATIONARY;
        end else if (layer_c_in < 16 && layer_c_out > 256) begin
            // 深度可分离卷积，行固定
            dataflow_mode = ROW_STATIONARY;
        end else begin
            // 默认行固定
            dataflow_mode = ROW_STATIONARY;
        end
    end
    
    // L0缓存管理（每个PE私有）
    reg [DATA_WIDTH-1:0] l0_weight_reg [PE_ARRAY_DIM-1:0];
    reg [DATA_WIDTH-1:0] l0_input_reg [PE_ARRAY_DIM-1:0];
    reg [31:0] l0_partial_sum [PE_ARRAY_DIM-1:0];
    
    // L1缓存管理（PE组共享）
    reg [2:0] l1_allocation_mode;
    reg [15:0] l1_weight_lines;
    reg [15:0] l1_input_lines; 
    reg [15:0] l1_output_lines;
    
    always @(posedge clk) begin
        if (start_layer) begin
            // 根据数据流模式分配L1空间
            case (dataflow_mode)
                WEIGHT_STATIONARY: begin
                    l1_weight_lines <= L1_SIZE * 7 / 10; // 70%给权重
                    l1_input_lines <= L1_SIZE * 2 / 10;  // 20%给输入
                    l1_output_lines <= L1_SIZE * 1 / 10; // 10%给输出
                end
                
                OUTPUT_STATIONARY: begin
                    l1_weight_lines <= L1_SIZE * 2 / 10; // 20%给权重
                    l1_input_lines <= L1_SIZE * 3 / 10;  // 30%给输入
                    l1_output_lines <= L1_SIZE * 5 / 10; // 50%给输出
                end
                
                ROW_STATIONARY: begin
                    l1_weight_lines <= L1_SIZE * 4 / 10; // 40%给权重
                    l1_input_lines <= L1_SIZE * 4 / 10;  // 40%给输入
                    l1_output_lines <= L1_SIZE * 2 / 10; // 20%给输出
                end
            endcase
        end
    end
    
    // L2缓存管理（全局共享）
    reg [2:0] l2_partition_mode;
    reg [20:0] l2_weight_base, l2_input_base, l2_output_base;
    
    // Tile大小计算
    reg [15:0] tile_h, tile_w, tile_c;
    
    always @(posedge clk) begin
        if (start_layer) begin
            // 计算能装入L2的最大tile
            reg [31:0] weight_per_tile, input_per_tile, output_per_tile;
            
            // 尝试不同的tile大小
            for (tile_h = layer_h; tile_h > 0; tile_h = tile_h >> 1) begin
                for (tile_w = layer_w; tile_w > 0; tile_w = tile_w >> 1) begin
                    for (tile_c = layer_c_in; tile_c > 0; tile_c = tile_c >> 1) begin
                        weight_per_tile = kernel_size * kernel_size * tile_c * layer_c_out;
                        input_per_tile = (tile_h + kernel_size - 1) * 
                                       (tile_w + kernel_size - 1) * tile_c;
                        output_per_tile = (tile_h/stride) * (tile_w/stride) * layer_c_out;
                        
                        if (weight_per_tile + input_per_tile + output_per_tile <= L2_SIZE) begin
                            // 找到合适的tile大小
                            break;
                        end
                    end
                    if (weight_per_tile + input_per_tile + output_per_tile <= L2_SIZE) break;
                end
                if (weight_per_tile + input_per_tile + output_per_tile <= L2_SIZE) break;
            end
            
            // 设置L2分区
            l2_weight_base = 0;
            l2_input_base = weight_per_tile;
            l2_output_base = weight_per_tile + input_per_tile;
        end
    end
    
    // 预取调度器
    reg [3:0] prefetch_state;
    reg [15:0] current_tile_h, current_tile_w, current_tile_c;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            prefetch_state <= 0;
            layer_done <= 0;
        end else begin
            case (prefetch_state)
                0: begin // 空闲
                    if (start_layer) begin
                        current_tile_h <= 0;
                        current_tile_w <= 0;
                        current_tile_c <= 0;
                        prefetch_state <= 1;
                    end
                end
                
                1: begin // 预取权重到L2
                    // 预取当前tile的权重
                    dram_accesses <= dram_accesses + 
                        (kernel_size * kernel_size * tile_c * layer_c_out) / 64;
                    prefetch_state <= 2;
                end
                
                2: begin // 预取输入到L2
                    // 预取当前tile的输入（考虑halo）
                    dram_accesses <= dram_accesses + 
                        ((tile_h + kernel_size - 1) * (tile_w + kernel_size - 1) * tile_c) / 64;
                    prefetch_state <= 3;
                end
                
                3: begin // L2到L1传输
                    // 根据数据流模式，将数据从L2搬到L1
                    case (dataflow_mode)
                        WEIGHT_STATIONARY: begin
                            // 权重常驻L1
                            l2_hits <= l2_hits + kernel_size * kernel_size;
                            l1_misses <= l1_misses + kernel_size * kernel_size;
                        end
                        
                        OUTPUT_STATIONARY: begin
                            // 输出块常驻L1
                            l2_hits <= l2_hits + tile_h * tile_w / (stride * stride);
                            l1_misses <= l1_misses + tile_h * tile_w / (stride * stride);
                        end
                    endcase
                    prefetch_state <= 4;
                end
                
                4: begin // L1到L0传输并计算
                    // 模拟PE阵列计算
                    // 统计L0/L1命中率
                    case (dataflow_mode)
                        WEIGHT_STATIONARY: begin
                            l0_hits <= l0_hits + tile_h * tile_w; // 权重复用
                            l1_hits <= l1_hits + tile_h * tile_w * kernel_size * kernel_size;
                        end
                        
                        OUTPUT_STATIONARY: begin
                            l0_hits <= l0_hits + layer_c_in * kernel_size * kernel_size; // 输出复用
                            l1_hits <= l1_hits + layer_c_in;
                        end
                    endcase
                    
                    // 检查是否完成当前tile
                    prefetch_state <= 5;
                end
                
                5: begin // 下一个tile
                    current_tile_w <= current_tile_w + tile_w;
                    if (current_tile_w >= layer_w) begin
                        current_tile_w <= 0;
                        current_tile_h <= current_tile_h + tile_h;
                        
                        if (current_tile_h >= layer_h) begin
                            current_tile_h <= 0;
                            current_tile_c <= current_tile_c + tile_c;
                            
                            if (current_tile_c >= layer_c_in) begin
                                // 层计算完成
                                layer_done <= 1;
                                prefetch_state <= 0;
                            end else begin
                                prefetch_state <= 1;
                            end
                        end else begin
                            prefetch_state <= 2; // 只需预取新的输入
                        end
                    end else begin
                        prefetch_state <= 2; // 只需预取新的输入
                    end
                end
            endcase
        end
    end
endmodule
                    </div>
                    
                    <p><strong>优化要点：</strong></p>
                    <ol>
                        <li><strong>自适应数据流：</strong>根据层类型选择最优数据流模式</li>
                        <li><strong>动态空间分配：</strong>L1/L2空间根据复用模式动态分配</li>
                        <li><strong>Tile优化：</strong>计算最大可容纳的tile尺寸</li>
                        <li><strong>预取流水：</strong>L2预取与L1计算重叠</li>
                        <li><strong>层次化复用：</strong>L0复用最频繁数据，L1复用中等，L2缓存tile</li>
                    </ol>
                </div>
            </div>

            <div class="exercise">
                <h4>习题8：综合设计题</h4>
                <p>设计一个完整的NPU存储子系统，支持8×8 MAC阵列，目标是在7nm工艺下达到1TOPS@1GHz。要求：
                1) 设计存储层次结构
                2) 实现高效的数据搬运
                3) 支持INT8/INT16混合精度
                4) 功耗预算2W</p>
                <button class="toggle-answer">显示答案</button>
                <div class="answer">
                    <div class="code-block">
// NPU存储子系统顶层设计
module NPUMemorySubsystem (
    input wire clk,              // 1GHz
    input wire rst_n,
    
    // 配置接口
    input wire [1:0] precision_mode, // 0: INT8, 1: INT16, 2: Mixed
    input wire [2:0] dataflow_mode,
    
    // 性能监控
    output wire [31:0] actual_tops,
    output wire [15:0] power_estimate_mw
);

    // ===== 1. 存储层次设计 =====
    // L0: 64 × 256b = 2KB (寄存器文件，每个PE)
    // L1: 8 × 8KB = 64KB (PE组本地缓存)
    // L2: 512KB (全局缓存)
    // 带宽需求：1TOPS × 3操作数 × 1B = 3TB/s
    
    // MAC阵列：8×8 = 64 MACs
    // 峰值性能：64 MACs × 2 ops/MAC × 1GHz = 128 GOPS (INT8)
    //           64 MACs × 2 ops/MAC × 0.5GHz = 64 GOPS (INT16)
    
    // ===== 2. 多级SRAM设计 =====
    // L0 Register File (每个PE)
    genvar i, j;
    generate
        for (i = 0; i < 8; i = i + 1) begin
            for (j = 0; j < 8; j = j + 1) begin
                L0_RegFile #(
                    .NUM_REGS(8),
                    .REG_WIDTH(256)
                ) pe_rf (
                    .clk(clk),
                    .rd_en(pe_rf_rd_en[i][j]),
                    .rd_addr(pe_rf_rd_addr[i][j]),
                    .rd_data(pe_rf_rd_data[i][j]),
                    .wr_en(pe_rf_wr_en[i][j]),
                    .wr_addr(pe_rf_wr_addr[i][j]),
                    .wr_data(pe_rf_wr_data[i][j])
                );
            end
        end
    endgenerate
    
    // L1 SRAM (PE行共享，8个8KB banks)
    generate
        for (i = 0; i < 8; i = i + 1) begin
            MultiPortSRAM #(
                .DEPTH(1024),      // 1K × 64B = 64KB
                .WIDTH(512),       // 64B宽
                .NUM_PORTS(8),     // 8个PE访问
                .BANK_COUNT(4)     // 4-way banked
            ) l1_sram (
                .clk(clk),
                .en(l1_en[i]),
                .wr(l1_wr[i]),
                .addr(l1_addr[i]),
                .wdata(l1_wdata[i]),
                .rdata(l1_rdata[i])
            );
        end
    endgenerate
    
    // L2 Global Buffer (512KB, 16-way banked)
    GlobalBuffer #(
        .SIZE(524288),      // 512KB
        .WIDTH(512),        // 64B接口
        .NUM_BANKS(16),
        .NUM_PORTS(8)       // 8个L1可同时访问
    ) l2_buffer (
        .clk(clk),
        .req_valid(l2_req_valid),
        .req_addr(l2_req_addr),
        .req_wr(l2_req_wr),
        .req_data(l2_req_data),
        .resp_valid(l2_resp_valid),
        .resp_data(l2_resp_data)
    );
    
    // ===== 3. 高带宽互连网络 =====
    // L0-L1互连：64个256b端口，聚合带宽 = 64×256b×1GHz = 2TB/s
    // L1-L2互连：8个512b端口，聚合带宽 = 8×512b×1GHz = 512GB/s
    
    CrossbarNetwork #(
        .NUM_MASTERS(64),   // 64个PE
        .NUM_SLAVES(8),     // 8个L1
        .DATA_WIDTH(256)
    ) l0_l1_xbar (
        .clk(clk),
        .master_req(pe_to_l1_req),
        .master_addr(pe_to_l1_addr),
        .master_data(pe_to_l1_data),
        .slave_ack(l1_to_pe_ack),
        .slave_data(l1_to_pe_data)
    );
    
    // ===== 4. 智能DMA引擎 =====
    IntelligentDMA #(
        .NUM_CHANNELS(4),
        .ADDR_WIDTH(32),
        .MAX_2D_SIZE(256)
    ) dma_engine (
        .clk(clk),
        .rst_n(rst_n),
        
        // 描述符接口
        .desc_valid(dma_desc_valid),
        .desc_2d_mode(dma_2d_mode),
        .desc_src_addr(dma_src_addr),
        .desc_dst_addr(dma_dst_addr),
        .desc_x_size(dma_x_size),
        .desc_y_size(dma_y_size),
        .desc_src_stride(dma_src_stride),
        .desc_dst_stride(dma_dst_stride),
        
        // L2接口
        .l2_req(dma_l2_req),
        .l2_addr(dma_l2_addr),
        .l2_wdata(dma_l2_wdata),
        .l2_rdata(l2_dma_rdata),
        
        // DRAM接口
        .dram_req(dma_dram_req),
        .dram_addr(dma_dram_addr),
        .dram_wdata(dma_dram_wdata),
        .dram_rdata(dram_dma_rdata)
    );
    
    // ===== 5. 混合精度支持 =====
    MixedPrecisionController #(
        .MAC_ARRAY_DIM(8)
    ) prec_ctrl (
        .clk(clk),
        .precision_mode(precision_mode),
        .weight_precision(weight_prec),
        .activation_precision(act_prec),
        
        // PE配置输出
        .pe_mode(pe_precision_mode),
        .pe_grouping(pe_group_config)
    );
    
    // ===== 6. 功耗优化控制 =====
    PowerController #(
        .NUM_DOMAINS(4)     // L0, L1, L2, DMA
    ) pwr_ctrl (
        .clk(clk),
        .rst_n(rst_n),
        
        // 活动监控
        .l0_active(|pe_rf_rd_en),
        .l1_active(|l1_en),
        .l2_active(|l2_req_valid),
        .dma_active(dma_busy),
        
        // 功耗控制
        .clock_gate_en(clk_gate_en),
        .voltage_scale(vdd_scale),
        .power_gate_en(pwr_gate_en),
        
        // 功耗估计
        .power_estimate(power_estimate_mw)
    );
    
    // ===== 7. 数据流协调器 =====
    DataflowOrchestrator orch (
        .clk(clk),
        .rst_n(rst_n),
        .dataflow_mode(dataflow_mode),
        
        // 层参数
        .layer_params(layer_params),
        
        // PE控制
        .pe_config(pe_config),
        .pe_enable(pe_enable),
        
        // 存储控制
        .l1_alloc_map(l1_allocation),
        .l2_alloc_map(l2_allocation),
        
        // DMA控制
        .dma_schedule(dma_schedule)
    );
    
    // ===== 8. 性能计数器 =====
    PerformanceCounters perf_cnt (
        .clk(clk),
        .rst_n(rst_n),
        
        // 输入事件
        .mac_active(mac_active),
        .l0_hit(l0_cache_hit),
        .l1_hit(l1_cache_hit),
        .l2_hit(l2_cache_hit),
        .dram_access(dram_access),
        
        // 输出统计
        .total_ops(total_operations),
        .actual_tops(actual_tops),
        .bandwidth_utilization(bw_util),
        .cache_hit_rate(cache_hit_rate)
    );
    
    // ===== 功耗分解（2W预算）=====
    // MAC阵列：~800mW (40%)
    // L0 (RegFile)：~200mW (10%)
    // L1 SRAM：~400mW (20%)
    // L2 SRAM：~300mW (15%)
    // 互连网络：~200mW (10%)
    // 控制逻辑：~100mW (5%)
    
endmodule

// 关键子模块：智能预取器
module SmartPrefetcher #(
    parameter ADDR_WIDTH = 32,
    parameter PATTERN_DEPTH = 8
)(
    input wire clk,
    input wire rst_n,
    
    // 访问监控
    input wire access_valid,
    input wire [ADDR_WIDTH-1:0] access_addr,
    
    // 预取输出
    output reg prefetch_req,
    output reg [ADDR_WIDTH-1:0] prefetch_addr,
    output reg [7:0] prefetch_len,
    
    // 模式识别
    output reg [2:0] detected_pattern // 0:Sequential, 1:Strided, 2:2D
);

    // 访问历史
    reg [ADDR_WIDTH-1:0] addr_history [PATTERN_DEPTH-1:0];
    reg [31:0] stride_history [PATTERN_DEPTH-2:0];
    reg [3:0] history_ptr;
    
    // 模式检测
    always @(posedge clk) begin
        if (access_valid) begin
            // 更新历史
            addr_history[history_ptr] <= access_addr;
            history_ptr <= (history_ptr + 1) % PATTERN_DEPTH;
            
            // 计算步长
            if (history_ptr > 0) begin
                stride_history[history_ptr-1] <= 
                    access_addr - addr_history[history_ptr-1];
            end
            
            // 检测模式
            if (history_ptr >= 3) begin
                if (stride_history[history_ptr-1] == stride_history[history_ptr-2] &&
                    stride_history[history_ptr-2] == stride_history[history_ptr-3]) begin
                    // 固定步长模式
                    detected_pattern <= 1;
                    prefetch_req <= 1;
                    prefetch_addr <= access_addr + stride_history[history_ptr-1];
                    prefetch_len <= 8; // 预取8个元素
                end
            end
        end
    end
endmodule
                    </div>
                    
                    <p><strong>设计总结：</strong></p>
                    <table>
                        <tr>
                            <th>组件</th>
                            <th>规格</th>
                            <th>带宽</th>
                            <th>功耗</th>
                        </tr>
                        <tr>
                            <td>MAC阵列</td>
                            <td>8×8 INT8/INT16</td>
                            <td>-</td>
                            <td>800mW</td>
                        </tr>
                        <tr>
                            <td>L0 RegFile</td>
                            <td>64×2KB</td>
                            <td>2TB/s</td>
                            <td>200mW</td>
                        </tr>
                        <tr>
                            <td>L1 SRAM</td>
                            <td>8×8KB</td>
                            <td>512GB/s</td>
                            <td>400mW</td>
                        </tr>
                        <tr>
                            <td>L2 Buffer</td>
                            <td>512KB</td>
                            <td>128GB/s</td>
                            <td>300mW</td>
                        </tr>
                        <tr>
                            <td>NoC+DMA</td>
                            <td>-</td>
                            <td>-</td>
                            <td>300mW</td>
                        </tr>
                        <tr>
                            <td><strong>总计</strong></td>
                            <td>-</td>
                            <td>-</td>
                            <td><strong>2000mW</strong></td>
                        </tr>
                    </table>
                    
                    <p><strong>关键设计决策：</strong></p>
                    <ol>
                        <li><strong>存储层次：</strong>三级结构平衡容量、带宽和功耗</li>
                        <li><strong>Banking策略：</strong>L1/L2多体设计减少冲突</li>
                        <li><strong>预取机制：</strong>模式识别的智能预取</li>
                        <li><strong>功耗优化：</strong>细粒度时钟门控和电源门控</li>
                        <li><strong>混合精度：</strong>动态配置支持INT8/INT16</li>
                    </ol>
                </div>
            </div>
        </section>

        <!-- Chapter 6: RTL设计实现 -->
        <section id="chapter6" class="chapter">
            <h2>第6章：RTL设计实现</h2>
            
            <p>本章详细介绍NPU从架构设计到RTL实现的完整流程，涵盖编码规范、时钟域设计、复位策略、低功耗设计、面积优化和时序收敛等关键技术。</p>

            <h3>6.1 设计流程</h3>
            
            <p>NPU的RTL设计是连接算法架构与物理实现的关键环节，需要遵循严格的设计流程。</p>

            <h4>6.1.1 设计流程概览</h4>
            <div class="code-block">
NPU RTL设计流程：

1. 系统级设计
   └── 定义性能指标：TOPS、精度、功耗
   └── 算法映射：支持的算子、数据流

2. 微架构设计
   └── 计算阵列规模：8×8、16×16等
   └── 存储层次：L0/L1/L2容量和带宽
   └── 数据通路：位宽、流水线级数
   └── 控制架构：指令集、调度器

3. RTL编码
   └── 模块划分和接口定义
   └── 功能实现和时序设计
   └── 参数化和可配置设计

4. 验证与仿真
   └── 功能验证：UVM测试平台
   └── 性能验证：周期精确模型
   └── 形式验证：等价性检查

5. 逻辑综合
   └── 约束定义：时序、面积、功耗
   └── 工艺映射：标准单元库
   └── 优化策略：时序/面积/功耗权衡

6. 物理实现
   └── 布局规划：模块摆放
   └── 时钟树综合：时钟偏斜控制
   └── 布线优化：拥塞和串扰

7. 签核验证
   └── STA：静态时序分析
   └── 功耗分析：IR Drop
   └── DRC/LVS：物理验证
            </div>

            <h4>6.1.2 设计迭代与优化</h4>
            <div class="code-block">
// 设计质量评估框架
module DesignQualityMonitor #(
    parameter DESIGN_NAME = "NPU_TOP"
)(
    // 综合报告输入
    input real target_freq_mhz,
    input real actual_freq_mhz,
    input real target_area_mm2,
    input real actual_area_mm2,
    input real target_power_mw,
    input real actual_power_mw,
    
    // 质量指标输出
    output reg timing_met,
    output reg area_met,
    output reg power_met,
    output reg [7:0] overall_score
);

    // 评估逻辑
    always @(*) begin
        timing_met = (actual_freq_mhz >= target_freq_mhz);
        area_met = (actual_area_mm2 <= target_area_mm2);
        power_met = (actual_power_mw <= target_power_mw);
        
        // 计算综合得分
        real timing_score = (actual_freq_mhz / target_freq_mhz) * 100;
        real area_score = (target_area_mm2 / actual_area_mm2) * 100;
        real power_score = (target_power_mw / actual_power_mw) * 100;
        
        overall_score = (timing_score * 0.4 + 
                        area_score * 0.3 + 
                        power_score * 0.3) / 100 * 255;
    end
    
    // 生成优化建议
    always @(*) begin
        if (!timing_met) begin
            $display("[%s] Timing not met. Suggestions:", DESIGN_NAME);
            $display("  - Increase pipeline stages");
            $display("  - Reduce logic levels");
            $display("  - Optimize critical paths");
        end
        
        if (!area_met) begin
            $display("[%s] Area exceeded. Suggestions:", DESIGN_NAME);
            $display("  - Enable resource sharing");
            $display("  - Reduce data width where possible");
            $display("  - Use memory instead of registers");
        end
        
        if (!power_met) begin
            $display("[%s] Power exceeded. Suggestions:", DESIGN_NAME);
            $display("  - Add more clock gating");
            $display("  - Reduce switching activity");
            $display("  - Consider voltage scaling");
        end
    end
endmodule
            </div>

            <h3>6.2 编码规范</h3>
            
            <p>统一的编码规范是保证代码质量、可读性和可维护性的基础。</p>

            <h4>6.2.1 命名规则</h4>
            <div class="code-block">
// ========== NPU RTL编码规范示例 ==========

// 1. 模块命名：使用大驼峰命名法
module NpuTopModule #(
    parameter ARRAY_SIZE = 16,
    parameter DATA_WIDTH = 8
)(
    // 2. 端口命名规则
    // 时钟信号：clk_前缀
    input  wire                     clk_sys,        // 系统时钟
    input  wire                     clk_noc,        // NoC时钟
    
    // 复位信号：rst_前缀，_n表示低有效
    input  wire                     rst_sys_n,      // 系统复位
    input  wire                     rst_noc_n,      // NoC复位
    
    // 输入信号：_i后缀
    input  wire [DATA_WIDTH-1:0]    weight_data_i,
    input  wire                     weight_valid_i,
    output wire                     weight_ready_o,
    
    // 输出信号：_o后缀
    output wire [31:0]              result_data_o,
    output wire                     result_valid_o,
    input  wire                     result_ready_i,
    
    // 配置寄存器：cfg_前缀
    input  wire [31:0]              cfg_layer_param,
    input  wire [15:0]              cfg_tile_size
);

    // 3. 内部信号命名
    // 寄存器输出：_q后缀
    reg  [DATA_WIDTH-1:0]           weight_buffer_q;
    
    // 寄存器输入：_d后缀
    wire [DATA_WIDTH-1:0]           weight_buffer_d;
    
    // 组合逻辑中间信号：_comb后缀
    wire [DATA_WIDTH-1:0]           partial_sum_comb;
    
    // 控制信号：描述性命名
    wire                            compute_enable;
    wire                            accumulate_start;
    
    // 4. 参数命名：全大写，下划线分隔
    localparam BUFFER_DEPTH = 1024;
    localparam FSM_IDLE = 3'b000;
    localparam FSM_COMPUTE = 3'b001;
    
    // 5. Generate变量：gen_前缀
    genvar gen_i, gen_j;
    
    // 6. 函数命名：小驼峰命名法
    function [7:0] calculateChecksum;
        input [31:0] data;
        begin
            calculateChecksum = data[7:0] ^ data[15:8] ^ 
                               data[23:16] ^ data[31:24];
        end
    endfunction

endmodule
            </div>

            <h4>6.2.2 模块化设计原则</h4>
            <div class="code-block">
// 良好的模块划分示例
module NpuComputeCluster #(
    parameter CLUSTER_ID = 0,
    parameter PE_ROWS = 4,
    parameter PE_COLS = 4
)(
    input  wire         clk,
    input  wire         rst_n,
    
    // 标准化接口
    NpuDataInterface.slave      data_if,
    NpuControlInterface.slave   ctrl_if,
    NpuConfigInterface.slave    cfg_if
);

    // ===== 模块化原则 =====
    // 1. 单一职责：每个模块只负责一个功能
    // 2. 接口清晰：使用SystemVerilog interface
    // 3. 参数化设计：便于复用和配置
    // 4. 层次化组织：自顶向下分解
    
    // 子模块实例化
    genvar row, col;
    generate
        for (row = 0; row < PE_ROWS; row = row + 1) begin : gen_pe_row
            for (col = 0; col < PE_COLS; col = col + 1) begin : gen_pe_col
                ProcessingElement #(
                    .PE_ID(row * PE_COLS + col),
                    .DATA_WIDTH(data_if.DATA_WIDTH)
                ) u_pe (
                    .clk        (clk),
                    .rst_n      (rst_n),
                    .north_i    (pe_north_conn[row][col]),
                    .south_o    (pe_south_conn[row][col]),
                    .west_i     (pe_west_conn[row][col]),
                    .east_o     (pe_east_conn[row][col]),
                    .config_i   (pe_config[row][col])
                );
            end
        end
    endgenerate
    
    // 本地控制器
    ClusterController #(
        .CLUSTER_ID(CLUSTER_ID)
    ) u_controller (
        .clk        (clk),
        .rst_n      (rst_n),
        .ctrl_if    (ctrl_if),
        .pe_enable  (pe_enable),
        .pe_mode    (pe_mode)
    );
    
    // 数据分发网络
    DataDistributionNetwork #(
        .NUM_PE(PE_ROWS * PE_COLS)
    ) u_data_network (
        .clk        (clk),
        .rst_n      (rst_n),
        .data_if    (data_if),
        .pe_data    (pe_data_conn)
    );

endmodule

// SystemVerilog Interface定义
interface NpuDataInterface #(
    parameter DATA_WIDTH = 256,
    parameter ADDR_WIDTH = 32
);
    logic [DATA_WIDTH-1:0]  data;
    logic [ADDR_WIDTH-1:0]  addr;
    logic                   valid;
    logic                   ready;
    
    modport master (
        output data, addr, valid,
        input  ready
    );
    
    modport slave (
        input  data, addr, valid,
        output ready
    );
endinterface
            </div>

            <h4>6.2.3 可综合RTL编码准则</h4>
            <div class="code-block">
// ===== 可综合RTL编码示例 =====

module SynthesizableDesign (
    input  wire         clk,
    input  wire         rst_n,
    input  wire [7:0]   data_in,
    input  wire         data_valid,
    output reg  [15:0]  data_out,
    output reg          data_ready
);

    // 1. 时序逻辑：统一使用非阻塞赋值
    reg [7:0] data_reg_q;
    reg [2:0] state_q;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            data_reg_q <= 8'h00;
            state_q <= 3'b000;
        end else begin
            data_reg_q <= data_in;    // 非阻塞赋值
            state_q <= next_state;     // 非阻塞赋值
        end
    end
    
    // 2. 组合逻辑：使用阻塞赋值，完整的条件覆盖
    reg [2:0] next_state;
    reg [15:0] compute_result;
    
    always @(*) begin
        // 默认赋值，避免锁存器
        next_state = state_q;
        compute_result = 16'h0000;
        data_ready = 1'b0;
        
        case (state_q)
            3'b000: begin  // IDLE
                if (data_valid) begin
                    next_state = 3'b001;
                end
            end
            
            3'b001: begin  // COMPUTE
                compute_result = {data_reg_q, data_in};  // 阻塞赋值
                next_state = 3'b010;
            end
            
            3'b010: begin  // OUTPUT
                data_ready = 1'b1;
                if (data_valid) begin
                    next_state = 3'b001;
                end else begin
                    next_state = 3'b000;
                end
            end
            
            default: begin  // 必须有default分支
                next_state = 3'b000;
            end
        endcase
    end
    
    // 3. 输出寄存器化，改善时序
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            data_out <= 16'h0000;
        end else begin
            data_out <= compute_result;
        end
    end
    
    // 4. 避免的写法示例（注释形式）
    // initial begin              // 不可综合
    //     data_out = 0;
    // end
    
    // always @(data_in) begin    // 不完整的敏感列表
    //     result = data_in + offset;
    // end
    
    // #10 data_out = result;     // 延时语句不可综合

endmodule

// 5. 推荐的参数化移位器实现
module ParametricShifter #(
    parameter WIDTH = 32,
    parameter SHIFT_WIDTH = 5
)(
    input  wire [WIDTH-1:0]         data_in,
    input  wire [SHIFT_WIDTH-1:0]   shift_amount,
    input  wire                     shift_dir,  // 0: left, 1: right
    output wire [WIDTH-1:0]         data_out
);

    // 使用generate实现可配置的移位器
    wire [WIDTH-1:0] shift_stages [SHIFT_WIDTH:0];
    assign shift_stages[0] = data_in;
    
    genvar i;
    generate
        for (i = 0; i < SHIFT_WIDTH; i = i + 1) begin : gen_shift
            assign shift_stages[i+1] = shift_amount[i] ? 
                (shift_dir ? 
                    (shift_stages[i] >> (1 << i)) : 
                    (shift_stages[i] << (1 << i))) : 
                shift_stages[i];
        end
    endgenerate
    
    assign data_out = shift_stages[SHIFT_WIDTH];

endmodule
            </div>

            <h3>6.3 时钟域设计</h3>
            
            <p>NPU通常包含多个时钟域，正确的跨时钟域(CDC)设计对系统稳定性至关重要。</p>

            <h4>6.3.1 时钟域划分</h4>
            <div class="code-block">
// NPU典型时钟域划分
module NpuClockDomains (
    // 多时钟输入
    input wire clk_sys,          // 系统时钟 (1GHz)
    input wire clk_noc,          // NoC时钟 (800MHz)
    input wire clk_ddr,          // DDR时钟 (2.4GHz)
    input wire clk_cfg,          // 配置时钟 (100MHz)
    input wire clk_dbg,          // 调试时钟 (50MHz)
    
    input wire rst_n
);

    // ===== 时钟域功能划分 =====
    // 1. 计算域 (clk_sys)
    //    - MAC阵列
    //    - 向量处理单元
    //    - 本地SRAM
    
    // 2. 互连域 (clk_noc)
    //    - 片上网络
    //    - DMA控制器
    //    - 全局缓冲区
    
    // 3. 存储域 (clk_ddr)
    //    - DDR控制器
    //    - PHY接口
    
    // 4. 低速域 (clk_cfg)
    //    - 配置寄存器
    //    - 中断控制器
    //    - 电源管理
    
    // 5. 调试域 (clk_dbg)
    //    - 调试接口
    //    - 性能计数器
    //    - Trace缓冲区

endmodule
            </div>

            <h4>6.3.2 CDC同步器设计</h4>
            <div class="code-block">
// 1. 单比特信号同步器（2级触发器）
module SyncBit #(
    parameter SYNC_STAGES = 2  // 可配置同步级数
)(
    input  wire clk_dst,
    input  wire rst_dst_n,
    input  wire data_in,
    output wire data_out
);

    reg [SYNC_STAGES-1:0] sync_regs;
    
    always @(posedge clk_dst or negedge rst_dst_n) begin
        if (!rst_dst_n) begin
            sync_regs <= {SYNC_STAGES{1'b0}};
        end else begin
            sync_regs <= {sync_regs[SYNC_STAGES-2:0], data_in};
        end
    end
    
    assign data_out = sync_regs[SYNC_STAGES-1];

endmodule

// 2. 多比特数据CDC - 握手协议
module HandshakeCDC #(
    parameter DATA_WIDTH = 32
)(
    // 源时钟域
    input  wire                     clk_src,
    input  wire                     rst_src_n,
    input  wire [DATA_WIDTH-1:0]    data_src,
    input  wire                     valid_src,
    output wire                     ready_src,
    
    // 目标时钟域
    input  wire                     clk_dst,
    input  wire                     rst_dst_n,
    output wire [DATA_WIDTH-1:0]    data_dst,
    output wire                     valid_dst,
    input  wire                     ready_dst
);

    // 源域：数据寄存和请求生成
    reg [DATA_WIDTH-1:0] data_hold_q;
    reg req_q;
    wire ack_sync_src;
    
    always @(posedge clk_src or negedge rst_src_n) begin
        if (!rst_src_n) begin
            data_hold_q <= {DATA_WIDTH{1'b0}};
            req_q <= 1'b0;
        end else begin
            if (valid_src && ready_src) begin
                data_hold_q <= data_src;
                req_q <= 1'b1;
            end else if (ack_sync_src) begin
                req_q <= 1'b0;
            end
        end
    end
    
    assign ready_src = !req_q || ack_sync_src;
    
    // 请求信号同步到目标域
    wire req_sync_dst;
    SyncBit u_req_sync (
        .clk_dst    (clk_dst),
        .rst_dst_n  (rst_dst_n),
        .data_in    (req_q),
        .data_out   (req_sync_dst)
    );
    
    // 目标域：接收数据和应答生成
    reg ack_q;
    reg req_sync_d1;
    
    always @(posedge clk_dst or negedge rst_dst_n) begin
        if (!rst_dst_n) begin
            ack_q <= 1'b0;
            req_sync_d1 <= 1'b0;
        end else begin
            req_sync_d1 <= req_sync_dst;
            
            if (req_sync_dst && !req_sync_d1) begin  // 上升沿检测
                ack_q <= 1'b1;
            end else if (!req_sync_dst) begin
                ack_q <= 1'b0;
            end
        end
    end
    
    assign data_dst = data_hold_q;  // 数据保持稳定
    assign valid_dst = req_sync_dst && !ack_q;
    
    // 应答信号同步回源域
    SyncBit u_ack_sync (
        .clk_dst    (clk_src),
        .rst_dst_n  (rst_src_n),
        .data_in    (ack_q),
        .data_out   (ack_sync_src)
    );

endmodule

// 3. 异步FIFO实现
module AsyncFIFO #(
    parameter DATA_WIDTH = 32,
    parameter ADDR_WIDTH = 4,
    parameter DEPTH = 16
)(
    // 写时钟域
    input  wire                     wr_clk,
    input  wire                     wr_rst_n,
    input  wire                     wr_en,
    input  wire [DATA_WIDTH-1:0]    wr_data,
    output wire                     wr_full,
    
    // 读时钟域
    input  wire                     rd_clk,
    input  wire                     rd_rst_n,
    input  wire                     rd_en,
    output wire [DATA_WIDTH-1:0]    rd_data,
    output wire                     rd_empty
);

    // 双端口RAM
    reg [DATA_WIDTH-1:0] mem [DEPTH-1:0];
    
    // 写指针（二进制和格雷码）
    reg [ADDR_WIDTH:0] wr_ptr_bin_q;
    reg [ADDR_WIDTH:0] wr_ptr_gray_q;
    wire [ADDR_WIDTH:0] wr_ptr_bin_next;
    wire [ADDR_WIDTH:0] wr_ptr_gray_next;
    
    // 读指针（二进制和格雷码）
    reg [ADDR_WIDTH:0] rd_ptr_bin_q;
    reg [ADDR_WIDTH:0] rd_ptr_gray_q;
    wire [ADDR_WIDTH:0] rd_ptr_bin_next;
    wire [ADDR_WIDTH:0] rd_ptr_gray_next;
    
    // 同步后的指针
    wire [ADDR_WIDTH:0] wr_ptr_gray_sync;
    wire [ADDR_WIDTH:0] rd_ptr_gray_sync;
    
    // 二进制转格雷码
    function [ADDR_WIDTH:0] bin2gray(input [ADDR_WIDTH:0] bin);
        bin2gray = bin ^ (bin >> 1);
    endfunction
    
    // 格雷码转二进制
    function [ADDR_WIDTH:0] gray2bin(input [ADDR_WIDTH:0] gray);
        integer i;
        begin
            gray2bin[ADDR_WIDTH] = gray[ADDR_WIDTH];
            for (i = ADDR_WIDTH-1; i >= 0; i = i-1) begin
                gray2bin[i] = gray2bin[i+1] ^ gray[i];
            end
        end
    endfunction
    
    // 写逻辑
    assign wr_ptr_bin_next = wr_ptr_bin_q + (wr_en && !wr_full);
    assign wr_ptr_gray_next = bin2gray(wr_ptr_bin_next);
    
    always @(posedge wr_clk or negedge wr_rst_n) begin
        if (!wr_rst_n) begin
            wr_ptr_bin_q <= 0;
            wr_ptr_gray_q <= 0;
        end else begin
            wr_ptr_bin_q <= wr_ptr_bin_next;
            wr_ptr_gray_q <= wr_ptr_gray_next;
            
            if (wr_en && !wr_full) begin
                mem[wr_ptr_bin_q[ADDR_WIDTH-1:0]] <= wr_data;
            end
        end
    end
    
    // 读逻辑
    assign rd_ptr_bin_next = rd_ptr_bin_q + (rd_en && !rd_empty);
    assign rd_ptr_gray_next = bin2gray(rd_ptr_bin_next);
    
    always @(posedge rd_clk or negedge rd_rst_n) begin
        if (!rd_rst_n) begin
            rd_ptr_bin_q <= 0;
            rd_ptr_gray_q <= 0;
        end else begin
            rd_ptr_bin_q <= rd_ptr_bin_next;
            rd_ptr_gray_q <= rd_ptr_gray_next;
        end
    end
    
    assign rd_data = mem[rd_ptr_bin_q[ADDR_WIDTH-1:0]];
    
    // 指针同步
    SyncBus #(.WIDTH(ADDR_WIDTH+1)) u_wr2rd_sync (
        .clk_dst    (rd_clk),
        .rst_dst_n  (rd_rst_n),
        .data_in    (wr_ptr_gray_q),
        .data_out   (wr_ptr_gray_sync)
    );
    
    SyncBus #(.WIDTH(ADDR_WIDTH+1)) u_rd2wr_sync (
        .clk_dst    (wr_clk),
        .rst_dst_n  (wr_rst_n),
        .data_in    (rd_ptr_gray_q),
        .data_out   (rd_ptr_gray_sync)
    );
    
    // 空满判断
    assign wr_full = (wr_ptr_gray_next == {~rd_ptr_gray_sync[ADDR_WIDTH:ADDR_WIDTH-1], 
                                            rd_ptr_gray_sync[ADDR_WIDTH-2:0]});
    assign rd_empty = (rd_ptr_gray_q == wr_ptr_gray_sync);

endmodule
            </div>

            <h3>6.4 复位策略</h3>
            
            <p>合理的复位策略对NPU的可靠性和功能正确性至关重要。需要考虑复位树的分布、同步、时序和功耗。</p>

            <h4>6.4.1 复位类型选择</h4>
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>复位类型</th>
                            <th>优点</th>
                            <th>缺点</th>
                            <th>适用场景</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>同步复位</td>
                            <td>无亚稳态问题、时序容易满足</td>
                            <td>需要时钟、复位延迟大</td>
                            <td>数据通路、状态机</td>
                        </tr>
                        <tr>
                            <td>异步复位</td>
                            <td>响应快、不需要时钟</td>
                            <td>释放时可能产生亚稳态</td>
                            <td>控制寄存器、配置模块</td>
                        </tr>
                        <tr>
                            <td>异步复位同步释放</td>
                            <td>结合两者优点</td>
                            <td>设计复杂度增加</td>
                            <td>推荐的默认选择</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h4>6.4.2 复位同步器设计</h4>
            <div class="code-block">
// 异步复位同步释放电路
module ResetSync (
    input  wire clk,
    input  wire async_rst_n,   // 异步复位输入（低有效）
    output wire sync_rst_n     // 同步复位输出（低有效）
);

    reg [1:0] rst_sync_q;
    
    always @(posedge clk or negedge async_rst_n) begin
        if (!async_rst_n) begin
            rst_sync_q <= 2'b00;   // 异步复位立即生效
        end else begin
            rst_sync_q <= {rst_sync_q[0], 1'b1};  // 同步释放
        end
    end
    
    assign sync_rst_n = rst_sync_q[1];

endmodule

// 复位域划分与管理
module ResetController #(
    parameter NUM_DOMAINS = 4
)(
    input wire clk_sys,
    input wire power_on_rst_n,      // 上电复位
    input wire soft_rst_n,          // 软件复位
    input wire wdt_rst_n,           // 看门狗复位
    
    // 各时钟域的时钟
    input wire [NUM_DOMAINS-1:0] domain_clks,
    
    // 各域的复位输出
    output wire [NUM_DOMAINS-1:0] domain_rst_n
);

    // 合并复位源
    wire global_rst_n = power_on_rst_n & soft_rst_n & wdt_rst_n;
    
    // 为每个时钟域生成同步复位
    genvar i;
    generate
        for (i = 0; i < NUM_DOMAINS; i = i + 1) begin : rst_sync_gen
            ResetSync u_rst_sync (
                .clk         (domain_clks[i]),
                .async_rst_n (global_rst_n),
                .sync_rst_n  (domain_rst_n[i])
            );
        end
    endgenerate

endmodule

// 复位顺序控制器
module ResetSequencer (
    input wire clk,
    input wire rst_n,
    
    // 模块复位输出（按顺序释放）
    output reg rst_pll_n,        // PLL复位
    output reg rst_mem_n,        // 内存控制器复位
    output reg rst_core_n,       // 计算核心复位
    output reg rst_periph_n      // 外设复位
);

    // 状态机状态
    localparam IDLE = 3'b000;
    localparam RST_PLL = 3'b001;
    localparam RST_MEM = 3'b010;
    localparam RST_CORE = 3'b011;
    localparam RST_PERIPH = 3'b100;
    localparam DONE = 3'b101;
    
    reg [2:0] state, next_state;
    reg [7:0] wait_cnt;
    
    // 状态机
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            state <= IDLE;
            wait_cnt <= 0;
        end else begin
            state <= next_state;
            if (state != next_state) begin
                wait_cnt <= 0;
            end else begin
                wait_cnt <= wait_cnt + 1;
            end
        end
    end
    
    // 下一状态逻辑
    always @(*) begin
        next_state = state;
        case (state)
            IDLE: next_state = RST_PLL;
            RST_PLL: if (wait_cnt >= 8'h10) next_state = RST_MEM;
            RST_MEM: if (wait_cnt >= 8'h20) next_state = RST_CORE;
            RST_CORE: if (wait_cnt >= 8'h10) next_state = RST_PERIPH;
            RST_PERIPH: if (wait_cnt >= 8'h08) next_state = DONE;
            DONE: next_state = DONE;
            default: next_state = IDLE;
        endcase
    end
    
    // 复位输出控制
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            rst_pll_n <= 1'b0;
            rst_mem_n <= 1'b0;
            rst_core_n <= 1'b0;
            rst_periph_n <= 1'b0;
        end else begin
            case (state)
                RST_PLL: rst_pll_n <= 1'b1;
                RST_MEM: rst_mem_n <= 1'b1;
                RST_CORE: rst_core_n <= 1'b1;
                RST_PERIPH: rst_periph_n <= 1'b1;
                default: begin
                    // 保持当前状态
                end
            endcase
        end
    end

endmodule
            </div>

            <h4>6.4.3 复位设计最佳实践</h4>
            <div class="info-box">
                <p><strong>复位设计准则：</strong></p>
                <ul>
                    <li>使用异步复位同步释放作为默认方案</li>
                    <li>复位信号要经过时序分析，满足recovery和removal时间</li>
                    <li>大规模设计需要复位树（Reset Tree）进行扇出控制</li>
                    <li>不同功能模块可以有独立的复位控制</li>
                    <li>考虑部分复位（Partial Reset）以降低功耗</li>
                    <li>关键寄存器需要显式复位，非关键路径可以不复位</li>
                </ul>
            </div>

            <div class="exercise">
                <h4>练习 6.4</h4>
                <div class="question">
                    <p><strong>题目：</strong>设计一个支持多种复位源的复位管理器，要求：
                    1) 支持上电复位、软件复位、看门狗复位
                    2) 实现复位优先级管理
                    3) 提供复位状态寄存器供软件查询</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module ResetManager (
    input wire clk,
    input wire por_n,           // Power-on reset (highest priority)
    input wire soft_rst_req,    // Software reset request
    input wire wdt_rst_n,       // Watchdog reset
    
    // APB接口用于状态查询
    input wire psel,
    input wire penable,
    input wire pwrite,
    input wire [7:0] paddr,
    input wire [31:0] pwdata,
    output reg [31:0] prdata,
    
    // 复位输出
    output wire sys_rst_n
);

    // 复位状态寄存器
    reg [2:0] rst_source;  // 记录复位源
    reg soft_rst_pending;
    
    // 复位源编码
    localparam RST_POR = 3'b001;
    localparam RST_SOFT = 3'b010;
    localparam RST_WDT = 3'b100;
    
    // 软件复位脉冲生成
    reg soft_rst_req_d1;
    wire soft_rst_pulse = soft_rst_req && !soft_rst_req_d1;
    
    always @(posedge clk or negedge por_n) begin
        if (!por_n) begin
            soft_rst_req_d1 <= 1'b0;
            soft_rst_pending <= 1'b0;
            rst_source <= RST_POR;
        end else begin
            soft_rst_req_d1 <= soft_rst_req;
            
            // 软件复位请求锁存
            if (soft_rst_pulse) begin
                soft_rst_pending <= 1'b1;
            end else if (!sys_rst_n) begin
                soft_rst_pending <= 1'b0;
            end
            
            // 复位源记录（优先级：POR > WDT > SOFT）
            if (!por_n) begin
                rst_source <= RST_POR;
            end else if (!wdt_rst_n) begin
                rst_source <= RST_WDT;
            end else if (soft_rst_pending) begin
                rst_source <= RST_SOFT;
            end
        end
    end
    
    // 复位输出生成
    wire rst_combined = por_n & wdt_rst_n & !soft_rst_pending;
    
    // 异步复位同步释放
    ResetSync u_rst_sync (
        .clk         (clk),
        .async_rst_n (rst_combined),
        .sync_rst_n  (sys_rst_n)
    );
    
    // APB读操作
    always @(posedge clk or negedge por_n) begin
        if (!por_n) begin
            prdata <= 32'h0;
        end else if (psel && !pwrite && penable) begin
            case (paddr[7:0])
                8'h00: prdata <= {29'h0, rst_source};  // 复位源状态
                8'h04: prdata <= {31'h0, sys_rst_n};   // 当前复位状态
                default: prdata <= 32'h0;
            endcase
        end
    end

endmodule
                        </div>
                    </div>
                </div>
            </div>

            <h3>6.5 低功耗设计</h3>
            
            <p>NPU的功耗优化是关键设计目标，需要从架构到实现各个层面进行优化。</p>

            <h4>6.5.1 时钟门控（Clock Gating）</h4>
            <div class="code-block">
// 细粒度时钟门控实现
module ClockGatingCell (
    input  wire clk,
    input  wire enable,
    input  wire test_en,  // DFT测试使能
    output wire gclk      // 门控后的时钟
);

    reg enable_latch;
    
    // 低电平锁存器，防止毛刺
    always @(clk or enable or test_en) begin
        if (!clk) begin
            enable_latch <= enable | test_en;
        end
    end
    
    // AND门生成门控时钟
    assign gclk = clk & enable_latch;

endmodule

// MAC阵列的层次化时钟门控
module MACArrayClockGated #(
    parameter ARRAY_SIZE = 16,
    parameter DATA_WIDTH = 8
)(
    input wire clk,
    input wire rst_n,
    input wire array_enable,
    input wire [ARRAY_SIZE-1:0] row_enable,
    input wire [ARRAY_SIZE-1:0] col_enable,
    
    // 数据接口
    input wire [DATA_WIDTH-1:0] act_in [ARRAY_SIZE-1:0],
    input wire [DATA_WIDTH-1:0] weight_in [ARRAY_SIZE-1:0][ARRAY_SIZE-1:0],
    output wire [31:0] acc_out [ARRAY_SIZE-1:0][ARRAY_SIZE-1:0]
);

    // 层次化时钟门控
    wire array_gclk;
    wire [ARRAY_SIZE-1:0] row_gclk;
    
    // 顶层时钟门控
    ClockGatingCell u_array_cg (
        .clk     (clk),
        .enable  (array_enable),
        .test_en (1'b0),
        .gclk    (array_gclk)
    );
    
    // 行级时钟门控
    genvar i, j;
    generate
        for (i = 0; i < ARRAY_SIZE; i = i + 1) begin : row_cg_gen
            ClockGatingCell u_row_cg (
                .clk     (array_gclk),
                .enable  (row_enable[i]),
                .test_en (1'b0),
                .gclk    (row_gclk[i])
            );
            
            // MAC单元实例化
            for (j = 0; j < ARRAY_SIZE; j = j + 1) begin : mac_gen
                wire mac_enable = row_enable[i] & col_enable[j];
                wire mac_gclk;
                
                // 单元级时钟门控（可选）
                ClockGatingCell u_mac_cg (
                    .clk     (row_gclk[i]),
                    .enable  (col_enable[j]),
                    .test_en (1'b0),
                    .gclk    (mac_gclk)
                );
                
                // MAC单元
                MACUnit #(.DATA_WIDTH(DATA_WIDTH)) u_mac (
                    .clk     (mac_gclk),
                    .rst_n   (rst_n),
                    .enable  (1'b1),  // 时钟已门控
                    .a_in    (act_in[i]),
                    .b_in    (weight_in[i][j]),
                    .acc_out (acc_out[i][j])
                );
            end
        end
    endgenerate

endmodule
            </div>

            <h4>6.5.2 操作数隔离（Operand Isolation）</h4>
            <div class="code-block">
// 操作数隔离减少无效翻转
module MACWithIsolation #(
    parameter DATA_WIDTH = 8,
    parameter ACC_WIDTH = 32
)(
    input wire clk,
    input wire rst_n,
    input wire enable,
    
    input wire signed [DATA_WIDTH-1:0] a_in,
    input wire signed [DATA_WIDTH-1:0] b_in,
    output reg signed [ACC_WIDTH-1:0] acc_out
);

    // 操作数隔离
    wire signed [DATA_WIDTH-1:0] a_isolated;
    wire signed [DATA_WIDTH-1:0] b_isolated;
    
    // 当不使能时，将输入置零，减少乘法器内部翻转
    assign a_isolated = enable ? a_in : {DATA_WIDTH{1'b0}};
    assign b_isolated = enable ? b_in : {DATA_WIDTH{1'b0}};
    
    // MAC运算
    wire signed [2*DATA_WIDTH-1:0] mult_result;
    assign mult_result = a_isolated * b_isolated;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            acc_out <= {ACC_WIDTH{1'b0}};
        end else if (enable) begin
            acc_out <= acc_out + {{(ACC_WIDTH-2*DATA_WIDTH){mult_result[2*DATA_WIDTH-1]}}, mult_result};
        end
        // 不使能时保持原值，无需else分支
    end

endmodule
            </div>

            <h4>6.5.3 动态电压频率调节（DVFS）</h4>
            <div class="code-block">
// DVFS控制器
module DVFSController (
    input wire clk,
    input wire rst_n,
    
    // 性能监控输入
    input wire [31:0] workload,      // 当前负载
    input wire [31:0] deadline,      // 截止时间
    
    // 电压频率控制输出
    output reg [2:0] vdd_level,      // 电压等级
    output reg [2:0] freq_level,     // 频率等级
    output reg dvfs_change_req       // 变更请求
);

    // DVFS状态
    localparam DVFS_LOW = 3'b000;    // 0.8V, 200MHz
    localparam DVFS_MID = 3'b001;    // 0.9V, 400MHz
    localparam DVFS_HIGH = 3'b010;   // 1.0V, 600MHz
    localparam DVFS_TURBO = 3'b011;  // 1.1V, 800MHz
    
    reg [2:0] current_level;
    reg [2:0] target_level;
    reg [15:0] change_delay_cnt;
    
    // 负载评估
    wire high_load = (workload > 32'h8000_0000);
    wire mid_load = (workload > 32'h4000_0000) && !high_load;
    wire low_load = (workload <= 32'h4000_0000);
    
    // 目标等级决策
    always @(*) begin
        if (high_load && (deadline < 32'h0000_1000)) begin
            target_level = DVFS_TURBO;
        end else if (high_load) begin
            target_level = DVFS_HIGH;
        end else if (mid_load) begin
            target_level = DVFS_MID;
        end else begin
            target_level = DVFS_LOW;
        end
    end
    
    // DVFS状态机
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            current_level <= DVFS_LOW;
            vdd_level <= DVFS_LOW;
            freq_level <= DVFS_LOW;
            dvfs_change_req <= 1'b0;
            change_delay_cnt <= 16'h0;
        end else begin
            if (current_level != target_level) begin
                if (change_delay_cnt == 16'h0) begin
                    // 发起DVFS变更
                    dvfs_change_req <= 1'b1;
                    change_delay_cnt <= 16'hFFFF;
                    
                    // 电压优先于频率调整
                    if (target_level > current_level) begin
                        vdd_level <= target_level;  // 先升压
                    end else begin
                        freq_level <= target_level; // 先降频
                    end
                end else if (change_delay_cnt == 16'h8000) begin
                    // 完成第二步调整
                    if (target_level > current_level) begin
                        freq_level <= target_level; // 后升频
                    end else begin
                        vdd_level <= target_level;  // 后降压
                    end
                    current_level <= target_level;
                end else if (change_delay_cnt == 16'h0001) begin
                    dvfs_change_req <= 1'b0;
                end
                
                if (change_delay_cnt > 0) begin
                    change_delay_cnt <= change_delay_cnt - 1;
                end
            end
        end
    end

endmodule
            </div>

            <h4>6.5.4 功耗优化技术总结</h4>
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>技术</th>
                            <th>功耗节省</th>
                            <th>实现复杂度</th>
                            <th>适用场景</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>时钟门控</td>
                            <td>20-40%</td>
                            <td>低</td>
                            <td>所有模块</td>
                        </tr>
                        <tr>
                            <td>操作数隔离</td>
                            <td>5-15%</td>
                            <td>低</td>
                            <td>算术单元</td>
                        </tr>
                        <tr>
                            <td>多阈值电压</td>
                            <td>10-20%</td>
                            <td>中</td>
                            <td>关键/非关键路径</td>
                        </tr>
                        <tr>
                            <td>电源门控</td>
                            <td>50-90%</td>
                            <td>高</td>
                            <td>空闲模块</td>
                        </tr>
                        <tr>
                            <td>DVFS</td>
                            <td>30-60%</td>
                            <td>高</td>
                            <td>系统级</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <div class="exercise">
                <h4>练习 6.5</h4>
                <div class="question">
                    <p><strong>题目：</strong>设计一个支持多级电源门控的NPU计算核心，要求：
                    1) 支持核心级、簇级、单元级三级电源门控
                    2) 实现电源开关时序控制
                    3) 处理隔离和状态保持</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module PowerGatedNPUCore #(
    parameter NUM_CLUSTERS = 4,
    parameter UNITS_PER_CLUSTER = 16
)(
    input wire clk,
    input wire rst_n,
    
    // 电源控制
    input wire core_power_req,
    input wire [NUM_CLUSTERS-1:0] cluster_power_req,
    input wire [NUM_CLUSTERS-1:0][UNITS_PER_CLUSTER-1:0] unit_power_req,
    
    // 电源状态
    output reg core_powered,
    output reg [NUM_CLUSTERS-1:0] cluster_powered,
    output reg [NUM_CLUSTERS-1:0][UNITS_PER_CLUSTER-1:0] unit_powered
);

    // 电源开关控制信号
    reg core_sleep_n;
    reg core_iso_n;
    reg core_ret_n;
    
    reg [NUM_CLUSTERS-1:0] cluster_sleep_n;
    reg [NUM_CLUSTERS-1:0] cluster_iso_n;
    reg [NUM_CLUSTERS-1:0] cluster_ret_n;
    
    // 电源时序状态机
    localparam PSM_OFF = 3'b000;
    localparam PSM_ISO_ON = 3'b001;
    localparam PSM_RET_ON = 3'b010;
    localparam PSM_PWR_ON = 3'b011;
    localparam PSM_ACTIVE = 3'b100;
    localparam PSM_PWR_OFF = 3'b101;
    localparam PSM_RET_OFF = 3'b110;
    localparam PSM_ISO_OFF = 3'b111;
    
    reg [2:0] core_psm_state;
    reg [7:0] core_psm_timer;
    
    // 核心级电源控制状态机
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            core_psm_state <= PSM_OFF;
            core_psm_timer <= 8'h0;
            core_sleep_n <= 1'b0;
            core_iso_n <= 1'b0;
            core_ret_n <= 1'b0;
            core_powered <= 1'b0;
        end else begin
            case (core_psm_state)
                PSM_OFF: begin
                    if (core_power_req) begin
                        core_psm_state <= PSM_ISO_ON;
                        core_iso_n <= 1'b1;  // 先开启隔离
                        core_psm_timer <= 8'h10;
                    end
                end
                
                PSM_ISO_ON: begin
                    if (core_psm_timer == 0) begin
                        core_psm_state <= PSM_RET_ON;
                        core_ret_n <= 1'b1;  // 开启状态保持
                        core_psm_timer <= 8'h10;
                    end else begin
                        core_psm_timer <= core_psm_timer - 1;
                    end
                end
                
                PSM_RET_ON: begin
                    if (core_psm_timer == 0) begin
                        core_psm_state <= PSM_PWR_ON;
                        core_sleep_n <= 1'b1;  // 开启电源
                        core_psm_timer <= 8'h40;  // 更长的稳定时间
                    end else begin
                        core_psm_timer <= core_psm_timer - 1;
                    end
                end
                
                PSM_PWR_ON: begin
                    if (core_psm_timer == 0) begin
                        core_psm_state <= PSM_ACTIVE;
                        core_powered <= 1'b1;
                    end else begin
                        core_psm_timer <= core_psm_timer - 1;
                    end
                end
                
                PSM_ACTIVE: begin
                    if (!core_power_req) begin
                        core_psm_state <= PSM_PWR_OFF;
                        core_sleep_n <= 1'b0;  // 关闭电源
                        core_powered <= 1'b0;
                        core_psm_timer <= 8'h10;
                    end
                end
                
                PSM_PWR_OFF: begin
                    if (core_psm_timer == 0) begin
                        core_psm_state <= PSM_RET_OFF;
                        core_ret_n <= 1'b0;  // 关闭状态保持
                        core_psm_timer <= 8'h10;
                    end else begin
                        core_psm_timer <= core_psm_timer - 1;
                    end
                end
                
                PSM_RET_OFF: begin
                    if (core_psm_timer == 0) begin
                        core_psm_state <= PSM_ISO_OFF;
                        core_iso_n <= 1'b0;  // 关闭隔离
                        core_psm_timer <= 8'h10;
                    end else begin
                        core_psm_timer <= core_psm_timer - 1;
                    end
                end
                
                PSM_ISO_OFF: begin
                    if (core_psm_timer == 0) begin
                        core_psm_state <= PSM_OFF;
                    end else begin
                        core_psm_timer <= core_psm_timer - 1;
                    end
                end
            endcase
        end
    end
    
    // 簇级电源控制（简化示例）
    genvar i;
    generate
        for (i = 0; i < NUM_CLUSTERS; i = i + 1) begin : cluster_pg_gen
            always @(posedge clk or negedge rst_n) begin
                if (!rst_n) begin
                    cluster_powered[i] <= 1'b0;
                    cluster_sleep_n[i] <= 1'b0;
                    cluster_iso_n[i] <= 1'b0;
                    cluster_ret_n[i] <= 1'b0;
                end else begin
                    // 只有核心上电时才能控制簇
                    if (core_powered) begin
                        if (cluster_power_req[i] && !cluster_powered[i]) begin
                            // 简化的上电序列
                            cluster_iso_n[i] <= 1'b1;
                            #10 cluster_ret_n[i] <= 1'b1;
                            #10 cluster_sleep_n[i] <= 1'b1;
                            #40 cluster_powered[i] <= 1'b1;
                        end else if (!cluster_power_req[i] && cluster_powered[i]) begin
                            // 简化的下电序列
                            cluster_powered[i] <= 1'b0;
                            cluster_sleep_n[i] <= 1'b0;
                            #10 cluster_ret_n[i] <= 1'b0;
                            #10 cluster_iso_n[i] <= 1'b0;
                        end
                    end else begin
                        cluster_powered[i] <= 1'b0;
                        cluster_sleep_n[i] <= 1'b0;
                        cluster_iso_n[i] <= 1'b0;
                        cluster_ret_n[i] <= 1'b0;
                    end
                end
            end
        end
    endgenerate

endmodule
                        </div>
                    </div>
                </div>
            </div>

            <h3>6.6 面积优化</h3>
            
            <p>面积优化对降低芯片成本至关重要。NPU设计需要在性能、功耗和面积之间找到最佳平衡点。</p>

            <h4>6.6.1 资源共享技术</h4>
            <div class="code-block">
// 乘法器资源共享示例
module SharedMultiplier #(
    parameter DATA_WIDTH = 16,
    parameter NUM_USERS = 4
)(
    input wire clk,
    input wire rst_n,
    
    // 请求接口
    input wire [NUM_USERS-1:0] req,
    input wire [DATA_WIDTH-1:0] a_in [NUM_USERS-1:0],
    input wire [DATA_WIDTH-1:0] b_in [NUM_USERS-1:0],
    
    // 响应接口
    output reg [NUM_USERS-1:0] ack,
    output reg [2*DATA_WIDTH-1:0] result_out [NUM_USERS-1:0]
);

    // 仲裁器状态
    reg [$clog2(NUM_USERS)-1:0] grant_id;
    reg busy;
    
    // 共享乘法器
    reg [DATA_WIDTH-1:0] mult_a, mult_b;
    wire [2*DATA_WIDTH-1:0] mult_result;
    assign mult_result = mult_a * mult_b;
    
    // 循环优先级仲裁
    reg [$clog2(NUM_USERS)-1:0] last_grant;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            grant_id <= 0;
            busy <= 1'b0;
            ack <= 0;
            last_grant <= 0;
        end else begin
            if (!busy) begin
                // 查找下一个请求（循环优先级）
                integer i;
                reg found;
                found = 1'b0;
                
                for (i = 0; i < NUM_USERS; i = i + 1) begin
                    if (!found) begin
                        integer check_id = (last_grant + i + 1) % NUM_USERS;
                        if (req[check_id]) begin
                            grant_id <= check_id;
                            mult_a <= a_in[check_id];
                            mult_b <= b_in[check_id];
                            busy <= 1'b1;
                            found = 1'b1;
                            last_grant <= check_id;
                        end
                    end
                end
            end else begin
                // 完成当前操作
                result_out[grant_id] <= mult_result;
                ack[grant_id] <= 1'b1;
                busy <= 1'b0;
            end
            
            // 清除应答
            if (ack != 0) begin
                ack <= 0;
            end
        end
    end

endmodule

// 存储器资源共享（双端口变单端口）
module SharedMemoryWrapper #(
    parameter ADDR_WIDTH = 10,
    parameter DATA_WIDTH = 32
)(
    input wire clk,
    input wire rst_n,
    
    // 端口A（读写）
    input wire a_en,
    input wire a_we,
    input wire [ADDR_WIDTH-1:0] a_addr,
    input wire [DATA_WIDTH-1:0] a_wdata,
    output reg [DATA_WIDTH-1:0] a_rdata,
    output reg a_ready,
    
    // 端口B（只读）
    input wire b_en,
    input wire [ADDR_WIDTH-1:0] b_addr,
    output reg [DATA_WIDTH-1:0] b_rdata,
    output reg b_ready
);

    // 单端口存储器
    reg [DATA_WIDTH-1:0] mem [(1<<ADDR_WIDTH)-1:0];
    
    // 仲裁状态机
    localparam IDLE = 2'b00;
    localparam SERVE_A = 2'b01;
    localparam SERVE_B = 2'b10;
    
    reg [1:0] state;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            state <= IDLE;
            a_ready <= 1'b0;
            b_ready <= 1'b0;
        end else begin
            case (state)
                IDLE: begin
                    // A端口优先级更高（因为可能有写操作）
                    if (a_en) begin
                        state <= SERVE_A;
                        if (a_we) begin
                            mem[a_addr] <= a_wdata;
                        end else begin
                            a_rdata <= mem[a_addr];
                        end
                    end else if (b_en) begin
                        state <= SERVE_B;
                        b_rdata <= mem[b_addr];
                    end
                end
                
                SERVE_A: begin
                    a_ready <= 1'b1;
                    state <= IDLE;
                end
                
                SERVE_B: begin
                    b_ready <= 1'b1;
                    state <= IDLE;
                end
            endcase
            
            // 清除ready信号
            if (a_ready) a_ready <= 1'b0;
            if (b_ready) b_ready <= 1'b0;
        end
    end

endmodule
            </div>

            <h4>6.6.2 数据路径优化</h4>
            <div class="code-block">
// 操作融合优化
module FusedOperation #(
    parameter DATA_WIDTH = 16
)(
    input wire clk,
    input wire rst_n,
    input wire enable,
    
    // 原始操作：Y = (A * B) + (C * D) + E
    input wire signed [DATA_WIDTH-1:0] a, b, c, d, e,
    output reg signed [DATA_WIDTH*2+1:0] y
);

    // 方案1：直接实现（4个乘法器，3个加法器）
    // wire signed [DATA_WIDTH*2-1:0] ab = a * b;
    // wire signed [DATA_WIDTH*2-1:0] cd = c * d;
    // wire signed [DATA_WIDTH*2:0] ab_cd = ab + cd;
    // assign y = ab_cd + e;

    // 方案2：资源共享（2个乘法器，流水线）
    reg signed [DATA_WIDTH-1:0] op1_a, op1_b, op2_a, op2_b;
    reg signed [DATA_WIDTH-1:0] e_reg;
    reg [1:0] state;
    
    wire signed [DATA_WIDTH*2-1:0] mult1_out = op1_a * op1_b;
    wire signed [DATA_WIDTH*2-1:0] mult2_out = op2_a * op2_b;
    
    reg signed [DATA_WIDTH*2:0] acc;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            state <= 2'b00;
            y <= 0;
            acc <= 0;
        end else if (enable) begin
            case (state)
                2'b00: begin
                    // 第一周期：计算 A*B 和 C*D
                    op1_a <= a;
                    op1_b <= b;
                    op2_a <= c;
                    op2_b <= d;
                    e_reg <= e;
                    state <= 2'b01;
                end
                
                2'b01: begin
                    // 第二周期：累加结果
                    acc <= mult1_out + mult2_out;
                    state <= 2'b10;
                end
                
                2'b10: begin
                    // 第三周期：最终结果
                    y <= acc + e_reg;
                    state <= 2'b00;
                end
            endcase
        end
    end

endmodule

// 位宽优化示例
module BitwidthOptimized #(
    parameter IN_WIDTH = 8,
    parameter WEIGHT_WIDTH = 8,
    parameter OUT_WIDTH = 24  // 优化后的位宽
)(
    input wire clk,
    input wire rst_n,
    
    // 4个输入的MAC
    input wire signed [IN_WIDTH-1:0] in0, in1, in2, in3,
    input wire signed [WEIGHT_WIDTH-1:0] w0, w1, w2, w3,
    output reg signed [OUT_WIDTH-1:0] out
);

    // 部分积
    wire signed [IN_WIDTH+WEIGHT_WIDTH-1:0] p0 = in0 * w0;
    wire signed [IN_WIDTH+WEIGHT_WIDTH-1:0] p1 = in1 * w1;
    wire signed [IN_WIDTH+WEIGHT_WIDTH-1:0] p2 = in2 * w2;
    wire signed [IN_WIDTH+WEIGHT_WIDTH-1:0] p3 = in3 * w3;
    
    // Wallace树加法器（减少加法器深度）
    wire signed [IN_WIDTH+WEIGHT_WIDTH:0] sum01 = p0 + p1;
    wire signed [IN_WIDTH+WEIGHT_WIDTH:0] sum23 = p2 + p3;
    wire signed [IN_WIDTH+WEIGHT_WIDTH+1:0] sum_all = sum01 + sum23;
    
    // 饱和逻辑
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            out <= 0;
        end else begin
            // 饱和到输出位宽
            if (sum_all > $signed({1'b0, {(OUT_WIDTH-1){1'b1}}})) begin
                out <= {1'b0, {(OUT_WIDTH-1){1'b1}}};  // 最大正值
            end else if (sum_all < $signed({1'b1, {(OUT_WIDTH-1){1'b0}}})) begin
                out <= {1'b1, {(OUT_WIDTH-1){1'b0}}};  // 最小负值
            end else begin
                out <= sum_all[OUT_WIDTH-1:0];
            end
        end
    end

endmodule
            </div>

            <h4>6.6.3 面积优化检查清单</h4>
            <div class="info-box">
                <p><strong>面积优化策略：</strong></p>
                <ul>
                    <li><strong>资源共享：</strong>
                        <ul>
                            <li>共享昂贵的运算单元（乘法器、除法器）</li>
                            <li>时分复用存储器端口</li>
                            <li>共享控制逻辑</li>
                        </ul>
                    </li>
                    <li><strong>数据路径优化：</strong>
                        <ul>
                            <li>操作融合减少中间寄存器</li>
                            <li>位宽优化，移除冗余位</li>
                            <li>使用移位代替乘以2的幂</li>
                        </ul>
                    </li>
                    <li><strong>存储优化：</strong>
                        <ul>
                            <li>使用单端口代替双端口RAM</li>
                            <li>寄存器文件改为分布式RAM</li>
                            <li>压缩存储格式</li>
                        </ul>
                    </li>
                    <li><strong>逻辑优化：</strong>
                        <ul>
                            <li>布尔优化和逻辑简化</li>
                            <li>常数传播和死代码消除</li>
                            <li>FSM编码优化</li>
                        </ul>
                    </li>
                </ul>
            </div>

            <h3>6.7 时序收敛</h3>
            
            <p>时序收敛是RTL设计到物理实现的关键挑战，需要在设计早期就考虑时序问题。</p>

            <h4>6.7.1 流水线设计</h4>
            <div class="code-block">
// 深度流水线MAC阵列
module PipelinedMACArray #(
    parameter DATA_WIDTH = 8,
    parameter ARRAY_DIM = 4,
    parameter PIPE_STAGES = 3  // 流水线级数
)(
    input wire clk,
    input wire rst_n,
    
    input wire [DATA_WIDTH-1:0] a_in [ARRAY_DIM-1:0],
    input wire [DATA_WIDTH-1:0] b_in [ARRAY_DIM-1:0][ARRAY_DIM-1:0],
    output wire [31:0] c_out [ARRAY_DIM-1:0][ARRAY_DIM-1:0]
);

    // 流水线寄存器
    reg [DATA_WIDTH-1:0] a_pipe [PIPE_STAGES-1:0][ARRAY_DIM-1:0];
    reg [DATA_WIDTH-1:0] b_pipe [PIPE_STAGES-1:0][ARRAY_DIM-1:0][ARRAY_DIM-1:0];
    
    // 输入流水线
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            for (int s = 0; s < PIPE_STAGES; s++) begin
                for (int i = 0; i < ARRAY_DIM; i++) begin
                    a_pipe[s][i] <= 0;
                    for (int j = 0; j < ARRAY_DIM; j++) begin
                        b_pipe[s][i][j] <= 0;
                    end
                end
            end
        end else begin
            // 第一级
            a_pipe[0] <= a_in;
            b_pipe[0] <= b_in;
            
            // 后续级
            for (int s = 1; s < PIPE_STAGES; s++) begin
                a_pipe[s] <= a_pipe[s-1];
                b_pipe[s] <= b_pipe[s-1];
            end
        end
    end
    
    // MAC单元实例化（使用流水线后的输入）
    genvar i, j;
    generate
        for (i = 0; i < ARRAY_DIM; i = i + 1) begin : row_gen
            for (j = 0; j < ARRAY_DIM; j = j + 1) begin : col_gen
                PipelinedMAC #(
                    .DATA_WIDTH(DATA_WIDTH),
                    .INTERNAL_PIPES(2)  // MAC内部流水线
                ) u_mac (
                    .clk(clk),
                    .rst_n(rst_n),
                    .a(a_pipe[PIPE_STAGES-1][i]),
                    .b(b_pipe[PIPE_STAGES-1][i][j]),
                    .acc_out(c_out[i][j])
                );
            end
        end
    endgenerate

endmodule

// 细粒度流水线MAC
module PipelinedMAC #(
    parameter DATA_WIDTH = 8,
    parameter ACC_WIDTH = 32,
    parameter INTERNAL_PIPES = 2
)(
    input wire clk,
    input wire rst_n,
    input wire [DATA_WIDTH-1:0] a,
    input wire [DATA_WIDTH-1:0] b,
    output wire [ACC_WIDTH-1:0] acc_out
);

    // 乘法器流水线
    reg [DATA_WIDTH-1:0] a_reg, b_reg;
    reg [2*DATA_WIDTH-1:0] mult_pipe [INTERNAL_PIPES-1:0];
    
    // 累加器
    reg [ACC_WIDTH-1:0] acc_reg;
    
    // 流水线乘法
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            a_reg <= 0;
            b_reg <= 0;
            for (int i = 0; i < INTERNAL_PIPES; i++) begin
                mult_pipe[i] <= 0;
            end
        end else begin
            // 输入寄存
            a_reg <= a;
            b_reg <= b;
            
            // 第一级乘法
            mult_pipe[0] <= a_reg * b_reg;
            
            // 乘法流水线
            for (int i = 1; i < INTERNAL_PIPES; i++) begin
                mult_pipe[i] <= mult_pipe[i-1];
            end
        end
    end
    
    // 累加
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            acc_reg <= 0;
        end else begin
            acc_reg <= acc_reg + {{(ACC_WIDTH-2*DATA_WIDTH){mult_pipe[INTERNAL_PIPES-1][2*DATA_WIDTH-1]}}, 
                                  mult_pipe[INTERNAL_PIPES-1]};
        end
    end
    
    assign acc_out = acc_reg;

endmodule
            </div>

            <h4>6.7.2 时序优化技术</h4>
            <div class="code-block">
// 重定时（Retiming）示例
module RetimingExample #(
    parameter WIDTH = 32
)(
    input wire clk,
    input wire rst_n,
    input wire [WIDTH-1:0] a, b, c, d,
    output reg [WIDTH-1:0] result
);

    // 原始设计：长组合路径
    // assign result = ((a + b) * c) + d;
    
    // 重定时后：平衡的流水线
    reg [WIDTH-1:0] sum_ab;
    reg [WIDTH-1:0] c_reg, d_reg;
    reg [WIDTH*2-1:0] product;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            sum_ab <= 0;
            c_reg <= 0;
            d_reg <= 0;
            product <= 0;
            result <= 0;
        end else begin
            // Stage 1: 加法
            sum_ab <= a + b;
            c_reg <= c;
            d_reg <= d;
            
            // Stage 2: 乘法
            product <= sum_ab * c_reg;
            
            // Stage 3: 最终加法
            result <= product[WIDTH-1:0] + d_reg;
        end
    end

endmodule

// 逻辑复制解决扇出问题
module FanoutOptimization #(
    parameter WIDTH = 8,
    parameter FANOUT = 64
)(
    input wire clk,
    input wire rst_n,
    input wire [WIDTH-1:0] data_in,
    input wire enable,
    output reg [WIDTH-1:0] data_out [FANOUT-1:0]
);

    // 扇出树：使用多级缓冲
    localparam TREE_LEVELS = 3;  // log4(64) = 3
    localparam FANOUT_PER_LEVEL = 4;
    
    // 中间缓冲级
    reg [WIDTH-1:0] buffer_l1 [3:0];
    reg [WIDTH-1:0] buffer_l2 [15:0];
    
    // 第一级：1->4
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            for (int i = 0; i < 4; i++) buffer_l1[i] <= 0;
        end else if (enable) begin
            for (int i = 0; i < 4; i++) buffer_l1[i] <= data_in;
        end
    end
    
    // 第二级：4->16
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            for (int i = 0; i < 16; i++) buffer_l2[i] <= 0;
        end else if (enable) begin
            for (int i = 0; i < 16; i++) begin
                buffer_l2[i] <= buffer_l1[i/4];
            end
        end
    end
    
    // 第三级：16->64
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            for (int i = 0; i < FANOUT; i++) data_out[i] <= 0;
        end else if (enable) begin
            for (int i = 0; i < FANOUT; i++) begin
                data_out[i] <= buffer_l2[i/4];
            end
        end
    end

endmodule
            </div>

            <h4>6.7.3 时序收敛策略</h4>
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>阶段</th>
                            <th>策略</th>
                            <th>工具/方法</th>
                            <th>影响</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>RTL设计</td>
                            <td>合理划分流水线</td>
                            <td>架构探索、性能建模</td>
                            <td>最大影响</td>
                        </tr>
                        <tr>
                            <td>综合</td>
                            <td>约束优化、逻辑重构</td>
                            <td>compile_ultra、retime</td>
                            <td>中等影响</td>
                        </tr>
                        <tr>
                            <td>布局</td>
                            <td>层次化布局、区域约束</td>
                            <td>floorplan、region</td>
                            <td>中等影响</td>
                        </tr>
                        <tr>
                            <td>时钟树</td>
                            <td>平衡时钟偏斜</td>
                            <td>CTS、useful skew</td>
                            <td>小幅改善</td>
                        </tr>
                        <tr>
                            <td>布线后</td>
                            <td>ECO修复</td>
                            <td>sizing、buffering</td>
                            <td>有限改善</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <div class="exercise">
                <h4>练习 6.6-6.7</h4>
                <div class="question">
                    <p><strong>题目：</strong>设计一个高性能矩阵乘法单元，要求：
                    1) 支持4×4矩阵乘法
                    2) 使用脉动阵列架构
                    3) 实现3级流水线
                    4) 优化面积和时序</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module SystolicMatrixMultiplier #(
    parameter DATA_WIDTH = 16,
    parameter MATRIX_SIZE = 4
)(
    input wire clk,
    input wire rst_n,
    input wire start,
    
    // 矩阵输入（按对角线输入）
    input wire [DATA_WIDTH-1:0] a_in [MATRIX_SIZE-1:0],
    input wire [DATA_WIDTH-1:0] b_in [MATRIX_SIZE-1:0],
    
    // 结果输出
    output reg [DATA_WIDTH*2-1:0] c_out [MATRIX_SIZE-1:0][MATRIX_SIZE-1:0],
    output reg done
);

    // PE阵列
    reg [DATA_WIDTH-1:0] pe_a [MATRIX_SIZE-1:0][MATRIX_SIZE-1:0];
    reg [DATA_WIDTH-1:0] pe_b [MATRIX_SIZE-1:0][MATRIX_SIZE-1:0];
    reg [DATA_WIDTH*2-1:0] pe_c [MATRIX_SIZE-1:0][MATRIX_SIZE-1:0];
    
    // 输入延迟链（实现对角线输入）
    reg [DATA_WIDTH-1:0] a_delay [MATRIX_SIZE-1:0][MATRIX_SIZE-1:0];
    reg [DATA_WIDTH-1:0] b_delay [MATRIX_SIZE-1:0][MATRIX_SIZE-1:0];
    
    // 控制计数器
    reg [4:0] cycle_count;
    wire computing = (cycle_count > 0) && (cycle_count <= 3*MATRIX_SIZE);
    
    // 输入延迟链
    genvar i, j;
    generate
        for (i = 0; i < MATRIX_SIZE; i = i + 1) begin : input_delay
            always @(posedge clk or negedge rst_n) begin
                if (!rst_n) begin
                    for (int j = 0; j <= i; j++) begin
                        a_delay[i][j] <= 0;
                        b_delay[i][j] <= 0;
                    end
                end else if (start || computing) begin
                    // A矩阵行延迟
                    a_delay[i][0] <= a_in[i];
                    for (int j = 1; j <= i; j++) begin
                        a_delay[i][j] <= a_delay[i][j-1];
                    end
                    
                    // B矩阵列延迟
                    b_delay[i][0] <= b_in[i];
                    for (int j = 1; j <= i; j++) begin
                        b_delay[i][j] <= b_delay[i][j-1];
                    end
                end
            end
        end
    endgenerate
    
    // 脉动阵列PE
    generate
        for (i = 0; i < MATRIX_SIZE; i = i + 1) begin : pe_row
            for (j = 0; j < MATRIX_SIZE; j = j + 1) begin : pe_col
                always @(posedge clk or negedge rst_n) begin
                    if (!rst_n) begin
                        pe_a[i][j] <= 0;
                        pe_b[i][j] <= 0;
                        pe_c[i][j] <= 0;
                    end else if (computing) begin
                        // A向右传播
                        if (j == 0) begin
                            pe_a[i][j] <= a_delay[i][i];
                        end else begin
                            pe_a[i][j] <= pe_a[i][j-1];
                        end
                        
                        // B向下传播
                        if (i == 0) begin
                            pe_b[i][j] <= b_delay[j][j];
                        end else begin
                            pe_b[i][j] <= pe_b[i-1][j];
                        end
                        
                        // MAC操作（3级流水线）
                        reg [DATA_WIDTH-1:0] a_reg, b_reg;
                        reg [DATA_WIDTH*2-1:0] mult_reg;
                        
                        // Pipeline stage 1: 寄存输入
                        a_reg <= pe_a[i][j];
                        b_reg <= pe_b[i][j];
                        
                        // Pipeline stage 2: 乘法
                        mult_reg <= a_reg * b_reg;
                        
                        // Pipeline stage 3: 累加
                        pe_c[i][j] <= pe_c[i][j] + mult_reg;
                    end
                end
            end
        end
    endgenerate
    
    // 控制逻辑
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            cycle_count <= 0;
            done <= 1'b0;
        end else begin
            if (start) begin
                cycle_count <= 1;
                done <= 1'b0;
                // 清零结果矩阵
                for (int i = 0; i < MATRIX_SIZE; i++) begin
                    for (int j = 0; j < MATRIX_SIZE; j++) begin
                        c_out[i][j] <= 0;
                    end
                end
            end else if (cycle_count > 0 && cycle_count < 4*MATRIX_SIZE) begin
                cycle_count <= cycle_count + 1;
            end else if (cycle_count == 4*MATRIX_SIZE) begin
                // 输出结果
                for (int i = 0; i < MATRIX_SIZE; i++) begin
                    for (int j = 0; j < MATRIX_SIZE; j++) begin
                        c_out[i][j] <= pe_c[i][j];
                    end
                end
                done <= 1'b1;
                cycle_count <= 0;
            end
        end
    end

endmodule
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <section id="chapter7" class="chapter">
            <h2>第7章：验证与测试</h2>
            
            <p>本章深入探讨NPU芯片的验证策略、测试方法和关键技术，涵盖从RTL验证到后硅验证的完整流程。</p>

            <h3>7.1 验证策略与方法学</h3>
            
            <h4>7.1.1 UVM验证环境</h4>
            <p>UVM（Universal Verification Methodology）提供了标准化的验证组件和可重用的验证环境架构。</p>
            
            <div class="code-block">
// NPU卷积模块的UVM测试环境
class conv_sequence_item extends uvm_sequence_item;
    `uvm_object_utils(conv_sequence_item)
    
    // 输入数据
    rand bit [7:0] input_data[];
    rand bit [7:0] weight_data[];
    rand int kernel_size;
    rand int stride;
    rand int padding;
    
    // 约束
    constraint valid_params_c {
        kernel_size inside {1, 3, 5, 7};
        stride inside {1, 2, 4};
        padding inside {0, 1, 2, 3};
        input_data.size() == 224*224*3;  // 假设输入是224x224x3
        weight_data.size() == kernel_size*kernel_size*3*64;  // 输出64通道
    }
    
    function new(string name = "conv_sequence_item");
        super.new(name);
    endfunction
endclass

// 卷积模块的Driver
class conv_driver extends uvm_driver #(conv_sequence_item);
    `uvm_component_utils(conv_driver)
    
    virtual conv_if vif;
    
    function new(string name, uvm_component parent);
        super.new(name, parent);
    endfunction
    
    task run_phase(uvm_phase phase);
        forever begin
            seq_item_port.get_next_item(req);
            drive_transaction(req);
            seq_item_port.item_done();
        end
    endtask
    
    task drive_transaction(conv_sequence_item trans);
        // 配置卷积参数
        vif.kernel_size <= trans.kernel_size;
        vif.stride <= trans.stride;
        vif.padding <= trans.padding;
        @(posedge vif.clk);
        
        // 加载权重
        vif.weight_valid <= 1'b1;
        foreach(trans.weight_data[i]) begin
            vif.weight_data <= trans.weight_data[i];
            @(posedge vif.clk);
        end
        vif.weight_valid <= 1'b0;
        
        // 输入数据
        vif.data_valid <= 1'b1;
        foreach(trans.input_data[i]) begin
            vif.input_data <= trans.input_data[i];
            @(posedge vif.clk);
        end
        vif.data_valid <= 1'b0;
    endtask
endclass

// Monitor和Scoreboard
class conv_monitor extends uvm_monitor;
    `uvm_component_utils(conv_monitor)
    
    virtual conv_if vif;
    uvm_analysis_port #(conv_result_item) ap;
    
    function new(string name, uvm_component parent);
        super.new(name, parent);
        ap = new("ap", this);
    endfunction
    
    task run_phase(uvm_phase phase);
        conv_result_item res;
        forever begin
            wait(vif.output_valid);
            res = conv_result_item::type_id::create("res");
            
            // 收集输出数据
            while(vif.output_valid) begin
                res.output_data.push_back(vif.output_data);
                @(posedge vif.clk);
            end
            
            ap.write(res);
        end
    endtask
endclass

// Scoreboard with Golden Model
class conv_scoreboard extends uvm_scoreboard;
    `uvm_component_utils(conv_scoreboard)
    
    uvm_analysis_export #(conv_result_item) analysis_export;
    uvm_tlm_analysis_fifo #(conv_result_item) results_fifo;
    
    // Python Golden Model接口
    protected int python_model;
    
    function new(string name, uvm_component parent);
        super.new(name, parent);
    endfunction
    
    function void build_phase(uvm_phase phase);
        super.build_phase(phase);
        analysis_export = new("analysis_export", this);
        results_fifo = new("results_fifo", this);
        
        // 初始化Python Golden Model
        python_model = init_python_model("conv_golden_model.py");
    endfunction
    
    task run_phase(uvm_phase phase);
        conv_result_item got, exp;
        forever begin
            results_fifo.get(got);
            
            // 调用Python golden model
            exp = compute_expected_result(got.input_item);
            
            // 比较结果（考虑量化误差）
            if (!compare_with_tolerance(got.output_data, exp.output_data, 1)) begin
                `uvm_error("SCOREBOARD", 
                    $sformatf("Mismatch: got=%p, exp=%p", 
                    got.output_data, exp.output_data))
            end else begin
                `uvm_info("SCOREBOARD", "Result matched!", UVM_MEDIUM)
            end
        end
    endtask
endclass
            </div>

            <h4>7.1.2 形式化验证</h4>
            <p>形式化验证通过数学方法证明设计的正确性，特别适合控制密集型逻辑。</p>
            
            <div class="code-block">
// NPU指令调度单元的形式化验证属性
module instruction_scheduler_properties (
    input clk,
    input rst_n,
    input [3:0] inst_valid,
    input [3:0] inst_ready,
    output [3:0] inst_grant
);

    // 假设和约束
    assume property (@(posedge clk) disable iff (!rst_n)
        $countones(inst_grant) <= 1  // 最多授权一个指令
    );
    
    // 属性1：没有饥饿（no starvation）
    property no_starvation(int idx);
        @(posedge clk) disable iff (!rst_n)
        inst_valid[idx] && !inst_grant[idx] |-> 
            ##[1:16] inst_grant[idx];  // 16周期内必须得到授权
    endproperty
    
    generate
        for (genvar i = 0; i < 4; i++) begin : starvation_check
            assert property (no_starvation(i))
            else $error("Instruction %0d starved", i);
        end
    endgenerate
    
    // 属性2：互斥（mutual exclusion）
    property mutual_exclusion;
        @(posedge clk) disable iff (!rst_n)
        $onehot0(inst_grant);  // 最多一位为1
    endproperty
    
    assert property (mutual_exclusion)
    else $error("Multiple grants detected");
    
    // 属性3：有效授权（valid grant）
    property valid_grant;
        @(posedge clk) disable iff (!rst_n)
        |inst_grant |-> inst_grant & inst_valid;
    endproperty
    
    assert property (valid_grant)
    else $error("Grant to invalid instruction");
    
    // 覆盖属性
    covergroup scheduler_coverage @(posedge clk);
        valid_cp: coverpoint inst_valid {
            bins no_req = {4'b0000};
            bins single_req[] = {4'b0001, 4'b0010, 4'b0100, 4'b1000};
            bins multi_req = {[4'b0011:4'b1111]};
        }
        
        grant_cp: coverpoint inst_grant {
            bins no_grant = {4'b0000};
            bins grants[] = {4'b0001, 4'b0010, 4'b0100, 4'b1000};
        }
        
        valid_grant_cross: cross valid_cp, grant_cp {
            illegal_bins invalid = binsof(valid_cp.no_req) && 
                                  !binsof(grant_cp.no_grant);
        }
    endgroup
    
    scheduler_coverage cov_inst = new();

endmodule
            </div>

            <h4>7.1.3 硬件仿真加速</h4>
            <p>使用FPGA进行硬件仿真，实现MHz级别的验证速度。</p>
            
            <div class="code-block">
// Emulation环境配置示例
class npu_emulation_env extends uvm_env;
    `uvm_component_utils(npu_emulation_env)
    
    // 仿真加速器接口
    virtual emulator_if emu_if;
    
    // 软件栈组件
    npu_driver_agent driver_agent;
    npu_runtime_agent runtime_agent;
    
    function new(string name, uvm_component parent);
        super.new(name, parent);
    endfunction
    
    function void build_phase(uvm_phase phase);
        super.build_phase(phase);
        
        // 配置仿真环境
        if (!uvm_config_db#(virtual emulator_if)::get(
            this, "", "emu_if", emu_if))
            `uvm_fatal("CONFIG", "Cannot get emulator interface")
        
        // 创建软件栈代理
        driver_agent = npu_driver_agent::type_id::create("driver_agent", this);
        runtime_agent = npu_runtime_agent::type_id::create("runtime_agent", this);
    endfunction
    
    task run_phase(uvm_phase phase);
        // 加载NPU固件
        load_firmware("npu_firmware.bin");
        
        // 运行MLPerf基准测试
        run_mlperf_benchmark("mobilenet_v2");
        run_mlperf_benchmark("resnet50");
        run_mlperf_benchmark("bert");
    endtask
    
    task load_firmware(string firmware_path);
        int firmware_data[];
        
        // 读取固件文件
        $readmemh(firmware_path, firmware_data);
        
        // 通过JTAG加载到NPU
        foreach(firmware_data[i]) begin
            emu_if.jtag_write(32'h1000_0000 + i*4, firmware_data[i]);
        end
    endtask
    
    task run_mlperf_benchmark(string model_name);
        real start_time, end_time;
        int inference_count;
        
        `uvm_info("EMULATION", $sformatf("Running %s benchmark", model_name), UVM_LOW)
        
        // 加载模型
        runtime_agent.load_model(model_name);
        
        // 预热
        repeat(10) runtime_agent.run_inference();
        
        // 性能测试
        start_time = $realtime;
        repeat(1000) begin
            runtime_agent.run_inference();
            inference_count++;
        end
        end_time = $realtime;
        
        // 报告性能
        `uvm_info("EMULATION", 
            $sformatf("%s: %0.2f inferences/sec", 
            model_name, inference_count/(end_time-start_time)), 
            UVM_LOW)
    endtask
endclass
            </div>

            <h3>7.2 功能验证层次</h3>
            
            <h4>7.2.1 IP级验证</h4>
            <div class="code-block">
// MAC单元的定向测试
module mac_unit_test;
    
    parameter DATA_WIDTH = 8;
    parameter ACC_WIDTH = 32;
    
    reg clk, rst_n;
    reg signed [DATA_WIDTH-1:0] a, b;
    reg signed [ACC_WIDTH-1:0] c_in;
    wire signed [ACC_WIDTH-1:0] c_out;
    
    // DUT实例化
    mac_unit #(
        .DATA_WIDTH(DATA_WIDTH),
        .ACC_WIDTH(ACC_WIDTH)
    ) dut (
        .clk(clk),
        .rst_n(rst_n),
        .a(a),
        .b(b),
        .c_in(c_in),
        .c_out(c_out)
    );
    
    // 时钟生成
    initial clk = 0;
    always #5 clk = ~clk;
    
    // 测试激励
    initial begin
        // 初始化
        rst_n = 0;
        a = 0; b = 0; c_in = 0;
        #20 rst_n = 1;
        
        // 测试1：基本MAC操作
        @(posedge clk);
        a = 8'd10; b = 8'd20; c_in = 32'd100;
        @(posedge clk);
        assert(c_out == 300) else $error("Basic MAC failed");
        
        // 测试2：负数处理
        a = -8'd50; b = 8'd4; c_in = 32'd0;
        @(posedge clk);
        assert(c_out == -200) else $error("Negative MAC failed");
        
        // 测试3：溢出处理
        a = 8'd127; b = 8'd127; c_in = 32'd2147483640;
        @(posedge clk);
        check_overflow();
        
        // 测试4：连续累加
        repeat(100) begin
            a = $random; b = $random;
            c_in = c_out;  // 累加
            @(posedge clk);
        end
        
        $finish;
    end
    
    // 溢出检查
    task check_overflow();
        reg signed [ACC_WIDTH+8:0] expected;
        expected = a * b + c_in;
        
        if (expected > $signed({1'b0, {(ACC_WIDTH-1){1'b1}}})) begin
            assert(c_out == {1'b0, {(ACC_WIDTH-1){1'b1}}})
            else $error("Positive overflow handling failed");
        end else if (expected < $signed({1'b1, {(ACC_WIDTH-1){1'b0}}})) begin
            assert(c_out == {1'b1, {(ACC_WIDTH-1){1'b0}}})
            else $error("Negative overflow handling failed");
        end
    endtask
    
endmodule
            </div>

            <h4>7.2.2 子系统级验证</h4>
            <div class="code-block">
// PE阵列的随机测试
class pe_array_test extends uvm_test;
    `uvm_component_utils(pe_array_test)
    
    pe_array_env env;
    
    function new(string name, uvm_component parent);
        super.new(name, parent);
    endfunction
    
    function void build_phase(uvm_phase phase);
        super.build_phase(phase);
        env = pe_array_env::type_id::create("env", this);
        
        // 配置测试参数
        uvm_config_db#(int)::set(this, "env.agent", "array_size", 16);
        uvm_config_db#(int)::set(this, "env.agent", "data_width", 8);
    endfunction
    
    task run_phase(uvm_phase phase);
        pe_array_sequence seq;
        
        phase.raise_objection(this);
        
        // 运行不同的测试序列
        
        // 1. 单位矩阵测试
        seq = identity_matrix_seq::type_id::create("seq");
        seq.start(env.agent.sequencer);
        
        // 2. 稀疏矩阵测试
        seq = sparse_matrix_seq::type_id::create("seq");
        seq.sparsity = 0.9;  // 90%稀疏
        seq.start(env.agent.sequencer);
        
        // 3. 随机矩阵测试
        seq = random_matrix_seq::type_id::create("seq");
        seq.num_iterations = 1000;
        seq.start(env.agent.sequencer);
        
        // 4. 边界条件测试
        seq = boundary_test_seq::type_id::create("seq");
        seq.start(env.agent.sequencer);
        
        phase.drop_objection(this);
    endtask
    
endclass

// 覆盖率收集
class pe_array_coverage extends uvm_subscriber #(pe_array_transaction);
    `uvm_component_utils(pe_array_coverage)
    
    covergroup pe_cg;
        // 数据模式覆盖
        data_pattern_cp: coverpoint trans.get_data_pattern() {
            bins zeros = {PATTERN_ZEROS};
            bins ones = {PATTERN_ONES};
            bins sparse = {PATTERN_SPARSE};
            bins dense = {PATTERN_DENSE};
            bins random = {PATTERN_RANDOM};
        }
        
        // 计算模式覆盖
        compute_mode_cp: coverpoint trans.compute_mode {
            bins matmul = {MODE_MATMUL};
            bins conv = {MODE_CONV};
            bins pooling = {MODE_POOLING};
        }
        
        // 精度覆盖
        precision_cp: coverpoint trans.precision {
            bins int8 = {PREC_INT8};
            bins int16 = {PREC_INT16};
            bins fp16 = {PREC_FP16};
        }
        
        // 交叉覆盖
        mode_precision_cross: cross compute_mode_cp, precision_cp;
    endgroup
    
    function new(string name, uvm_component parent);
        super.new(name, parent);
        pe_cg = new();
    endfunction
    
    function void write(pe_array_transaction t);
        trans = t;
        pe_cg.sample();
    endfunction
endclass
            </div>

            <h3>7.3 性能验证</h3>
            
            <h4>7.3.1 性能计数器设计</h4>
            <div class="code-block">
// NPU性能监控模块
module npu_performance_monitor (
    input wire clk,
    input wire rst_n,
    
    // 监控信号
    input wire mac_valid,
    input wire [15:0] mac_count,
    input wire cache_hit,
    input wire cache_miss,
    input wire dma_busy,
    input wire compute_stall,
    
    // APB接口
    input wire psel,
    input wire penable,
    input wire pwrite,
    input wire [11:0] paddr,
    output reg [31:0] prdata
);

    // 性能计数器
    reg [63:0] cycle_count;
    reg [63:0] mac_op_count;
    reg [31:0] cache_hit_count;
    reg [31:0] cache_miss_count;
    reg [31:0] dma_busy_cycles;
    reg [31:0] compute_stall_cycles;
    
    // 性能指标计算
    wire [31:0] mac_utilization;
    wire [31:0] cache_hit_rate;
    wire [31:0] bandwidth_efficiency;
    
    // 计数器更新
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            cycle_count <= 64'h0;
            mac_op_count <= 64'h0;
            cache_hit_count <= 32'h0;
            cache_miss_count <= 32'h0;
            dma_busy_cycles <= 32'h0;
            compute_stall_cycles <= 32'h0;
        end else begin
            cycle_count <= cycle_count + 1;
            
            if (mac_valid)
                mac_op_count <= mac_op_count + mac_count;
            
            if (cache_hit)
                cache_hit_count <= cache_hit_count + 1;
                
            if (cache_miss)
                cache_miss_count <= cache_miss_count + 1;
                
            if (dma_busy)
                dma_busy_cycles <= dma_busy_cycles + 1;
                
            if (compute_stall)
                compute_stall_cycles <= compute_stall_cycles + 1;
        end
    end
    
    // 性能指标计算
    assign mac_utilization = (mac_op_count * 100) / (cycle_count * 256); // 假设256个MAC单元
    assign cache_hit_rate = (cache_hit_count * 100) / (cache_hit_count + cache_miss_count);
    assign bandwidth_efficiency = ((cycle_count - dma_busy_cycles) * 100) / cycle_count;
    
    // APB读操作
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            prdata <= 32'h0;
        end else if (psel && !pwrite && penable) begin
            case (paddr[11:0])
                12'h000: prdata <= cycle_count[31:0];
                12'h004: prdata <= cycle_count[63:32];
                12'h008: prdata <= mac_op_count[31:0];
                12'h00C: prdata <= mac_op_count[63:32];
                12'h010: prdata <= cache_hit_count;
                12'h014: prdata <= cache_miss_count;
                12'h018: prdata <= cache_hit_rate;
                12'h01C: prdata <= mac_utilization;
                12'h020: prdata <= bandwidth_efficiency;
                12'h024: prdata <= compute_stall_cycles;
                12'h028: prdata <= dma_busy_cycles;
                default: prdata <= 32'h0;
            endcase
        end
    end

endmodule
            </div>

            <h4>7.3.2 性能测试基准</h4>
            <div class="code-block">
// 性能基准测试类
class npu_performance_benchmark extends uvm_sequence;
    `uvm_object_utils(npu_performance_benchmark)
    
    // 测试配置
    int num_iterations = 100;
    string model_name = "resnet50";
    
    // 性能统计
    real total_inference_time;
    int total_mac_operations;
    real power_consumption;
    
    function new(string name = "npu_performance_benchmark");
        super.new(name);
    endfunction
    
    task body();
        npu_model_config cfg;
        npu_inference_seq inference_seq;
        real start_time, end_time;
        
        // 加载模型配置
        cfg = load_model_config(model_name);
        
        // 配置NPU
        configure_npu(cfg);
        
        // 预热
        repeat(10) begin
            inference_seq = npu_inference_seq::type_id::create("inference_seq");
            inference_seq.model_cfg = cfg;
            inference_seq.start(m_sequencer);
        end
        
        // 性能测试
        start_time = $realtime;
        repeat(num_iterations) begin
            inference_seq = npu_inference_seq::type_id::create("inference_seq");
            inference_seq.model_cfg = cfg;
            inference_seq.start(m_sequencer);
        end
        end_time = $realtime;
        
        // 收集性能数据
        collect_performance_data();
        
        // 报告结果
        report_performance();
    endtask
    
    function void collect_performance_data();
        // 从性能计数器读取数据
        total_inference_time = $realtime;
        total_mac_operations = read_performance_counter(PERF_MAC_OPS);
        power_consumption = read_power_monitor();
    endfunction
    
    function void report_performance();
        real throughput, efficiency, tops;
        
        throughput = num_iterations / total_inference_time;
        tops = total_mac_operations / total_inference_time / 1e12;
        efficiency = tops / power_consumption;  // TOPS/W
        
        `uvm_info("PERF", "=== Performance Report ===", UVM_LOW)
        `uvm_info("PERF", $sformatf("Model: %s", model_name), UVM_LOW)
        `uvm_info("PERF", $sformatf("Throughput: %.2f inferences/sec", throughput), UVM_LOW)
        `uvm_info("PERF", $sformatf("Performance: %.2f TOPS", tops), UVM_LOW)
        `uvm_info("PERF", $sformatf("Power: %.2f W", power_consumption), UVM_LOW)
        `uvm_info("PERF", $sformatf("Efficiency: %.2f TOPS/W", efficiency), UVM_LOW)
    endfunction
    
endclass
            </div>

            <div class="exercise">
                <h4>练习 7.1-7.3</h4>
                <div class="question">
                    <p><strong>题目：</strong>设计一个完整的UVM验证环境来验证一个4x4 MAC阵列，要求：
                    1) 实现完整的UVM组件（Driver、Monitor、Scoreboard）
                    2) 使用Python golden model进行结果比较
                    3) 实现功能覆盖率收集
                    4) 支持随机和定向测试</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
// MAC阵列接口定义
interface mac_array_if(input clk);
    logic rst_n;
    logic enable;
    logic [7:0] a_in[3:0];
    logic [7:0] b_in[3:0][3:0];
    logic [31:0] c_out[3:0][3:0];
    logic valid_out;
    
    modport dut(
        input clk, rst_n, enable, a_in, b_in,
        output c_out, valid_out
    );
    
    modport tb(
        input clk, c_out, valid_out,
        output rst_n, enable, a_in, b_in
    );
endinterface

// Transaction定义
class mac_array_trans extends uvm_sequence_item;
    `uvm_object_utils(mac_array_trans)
    
    rand bit [7:0] a_matrix[3:0][3:0];
    rand bit [7:0] b_matrix[3:0][3:0];
    bit [31:0] c_matrix[3:0][3:0];
    
    constraint data_c {
        foreach(a_matrix[i,j]) {
            a_matrix[i][j] inside {[0:255]};
            b_matrix[i][j] inside {[0:255]};
        }
    }
    
    function new(string name = "mac_array_trans");
        super.new(name);
    endfunction
    
    function void do_copy(uvm_object rhs);
        mac_array_trans t;
        super.do_copy(rhs);
        $cast(t, rhs);
        a_matrix = t.a_matrix;
        b_matrix = t.b_matrix;
        c_matrix = t.c_matrix;
    endfunction
endclass

// Driver实现
class mac_array_driver extends uvm_driver#(mac_array_trans);
    `uvm_component_utils(mac_array_driver)
    
    virtual mac_array_if.tb vif;
    
    function new(string name, uvm_component parent);
        super.new(name, parent);
    endfunction
    
    function void build_phase(uvm_phase phase);
        super.build_phase(phase);
        if (!uvm_config_db#(virtual mac_array_if.tb)::get(
            this, "", "vif", vif))
            `uvm_fatal("NOVIF", "Virtual interface not found")
    endfunction
    
    task run_phase(uvm_phase phase);
        forever begin
            seq_item_port.get_next_item(req);
            drive_trans(req);
            seq_item_port.item_done();
        end
    endtask
    
    task drive_trans(mac_array_trans t);
        // 复位
        vif.rst_n = 0;
        vif.enable = 0;
        repeat(5) @(posedge vif.clk);
        vif.rst_n = 1;
        
        // 发送数据（脉动输入）
        for (int cycle = 0; cycle < 7; cycle++) begin
            @(posedge vif.clk);
            vif.enable = 1;
            
            // 对角线输入模式
            for (int i = 0; i < 4; i++) begin
                if (cycle >= i && cycle - i < 4) begin
                    vif.a_in[i] = t.a_matrix[i][cycle-i];
                    for (int j = 0; j < 4; j++) begin
                        if (i == 0)
                            vif.b_in[j][i] = t.b_matrix[cycle-j][j];
                    end
                end else begin
                    vif.a_in[i] = 0;
                end
            end
        end
        
        vif.enable = 0;
        
        // 等待计算完成
        wait(vif.valid_out);
        repeat(2) @(posedge vif.clk);
    endtask
endclass

// Monitor实现
class mac_array_monitor extends uvm_monitor;
    `uvm_component_utils(mac_array_monitor)
    
    virtual mac_array_if.tb vif;
    uvm_analysis_port#(mac_array_trans) ap;
    
    function new(string name, uvm_component parent);
        super.new(name, parent);
        ap = new("ap", this);
    endfunction
    
    function void build_phase(uvm_phase phase);
        super.build_phase(phase);
        if (!uvm_config_db#(virtual mac_array_if.tb)::get(
            this, "", "vif", vif))
            `uvm_fatal("NOVIF", "Virtual interface not found")
    endfunction
    
    task run_phase(uvm_phase phase);
        mac_array_trans t;
        
        forever begin
            // 监控输入
            t = mac_array_trans::type_id::create("t");
            collect_input(t);
            
            // 等待输出
            wait(vif.valid_out);
            @(posedge vif.clk);
            
            // 收集输出
            for (int i = 0; i < 4; i++) begin
                for (int j = 0; j < 4; j++) begin
                    t.c_matrix[i][j] = vif.c_out[i][j];
                end
            end
            
            ap.write(t);
        end
    endtask
    
    task collect_input(mac_array_trans t);
        // 收集输入矩阵（简化版）
        @(posedge vif.clk iff vif.enable);
        // 实际实现需要根据脉动输入模式重建完整矩阵
    endtask
endclass

// Scoreboard with Python Golden Model
class mac_array_scoreboard extends uvm_scoreboard;
    `uvm_component_utils(mac_array_scoreboard)
    
    uvm_analysis_export#(mac_array_trans) analysis_export;
    
    // Python接口
    int python_fd;
    
    function new(string name, uvm_component parent);
        super.new(name, parent);
    endfunction
    
    function void build_phase(uvm_phase phase);
        super.build_phase(phase);
        analysis_export = new("analysis_export", this);
        
        // 启动Python进程
        python_fd = $system("python3 mac_golden_model.py &");
    endfunction
    
    function void write(mac_array_trans t);
        bit [31:0] expected[3:0][3:0];
        
        // 调用Python计算期望结果
        compute_expected(t.a_matrix, t.b_matrix, expected);
        
        // 比较结果
        for (int i = 0; i < 4; i++) begin
            for (int j = 0; j < 4; j++) begin
                if (t.c_matrix[i][j] !== expected[i][j]) begin
                    `uvm_error("SCOREBOARD", 
                        $sformatf("Mismatch at [%0d][%0d]: got=%0d, exp=%0d",
                        i, j, t.c_matrix[i][j], expected[i][j]))
                end
            end
        end
        
        `uvm_info("SCOREBOARD", "Matrix multiplication passed", UVM_MEDIUM)
    endfunction
    
    function void compute_expected(
        bit [7:0] a[3:0][3:0], 
        bit [7:0] b[3:0][3:0],
        ref bit [31:0] c[3:0][3:0]
    );
        // 与Python通信计算结果
        // 简化示例：直接计算
        for (int i = 0; i < 4; i++) begin
            for (int j = 0; j < 4; j++) begin
                c[i][j] = 0;
                for (int k = 0; k < 4; k++) begin
                    c[i][j] += a[i][k] * b[k][j];
                end
            end
        end
    endfunction
endclass

// 覆盖率收集
class mac_array_coverage extends uvm_subscriber#(mac_array_trans);
    `uvm_component_utils(mac_array_coverage)
    
    mac_array_trans t;
    
    covergroup mac_cg;
        // 输入数据模式
        a_pattern: coverpoint get_pattern(t.a_matrix) {
            bins zero = {0};
            bins identity = {1};
            bins sparse = {2};
            bins dense = {3};
        }
        
        b_pattern: coverpoint get_pattern(t.b_matrix) {
            bins zero = {0};
            bins identity = {1};
            bins sparse = {2};
            bins dense = {3};
        }
        
        // 交叉覆盖
        pattern_cross: cross a_pattern, b_pattern;
        
        // 数值范围覆盖
        a_values: coverpoint t.a_matrix[0][0] {
            bins low = {[0:63]};
            bins mid = {[64:191]};
            bins high = {[192:255]};
        }
    endgroup
    
    function new(string name, uvm_component parent);
        super.new(name, parent);
        mac_cg = new();
    endfunction
    
    function void write(mac_array_trans tr);
        t = tr;
        mac_cg.sample();
    endfunction
    
    function int get_pattern(bit [7:0] matrix[3:0][3:0]);
        int zero_count = 0;
        
        // 检查零矩阵
        foreach(matrix[i,j]) if (matrix[i][j] == 0) zero_count++;
        if (zero_count == 16) return 0;
        
        // 检查单位矩阵
        bit is_identity = 1;
        foreach(matrix[i,j]) begin
            if (i == j && matrix[i][j] != 1) is_identity = 0;
            if (i != j && matrix[i][j] != 0) is_identity = 0;
        end
        if (is_identity) return 1;
        
        // 稀疏/稠密
        if (zero_count > 12) return 2;
        else return 3;
    endfunction
endclass
                        </div>
                    </div>
                </div>
            </div>

            <h3>7.4 可测试性设计（DFT）</h3>
            
            <h4>7.4.1 扫描链设计</h4>
            <p>扫描链将设计中的触发器连接成移位寄存器，实现可控性和可观测性。</p>
            
            <div class="code-block">
// 扫描触发器实现
module scan_ff (
    input wire clk,
    input wire rst_n,
    input wire d,          // 功能数据输入
    input wire si,         // 扫描输入
    input wire se,         // 扫描使能
    output reg q,          // 数据输出
    output wire so         // 扫描输出
);

    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            q <= 1'b0;
        end else begin
            q <= se ? si : d;  // 扫描模式时选择扫描输入
        end
    end
    
    assign so = q;  // 扫描输出连接到Q

endmodule

// NPU控制器的扫描链插入
module npu_controller_with_scan (
    input wire clk,
    input wire rst_n,
    
    // 功能接口
    input wire [31:0] instruction,
    input wire inst_valid,
    output reg inst_ready,
    output reg [7:0] control_signals,
    
    // DFT接口
    input wire scan_enable,
    input wire scan_in,
    output wire scan_out
);

    // 状态机寄存器（使用扫描触发器）
    wire [2:0] state_d, state_q;
    wire [2:0] state_scan_chain;
    
    scan_ff state_ff[2:0] (
        .clk(clk),
        .rst_n(rst_n),
        .d(state_d),
        .si({state_scan_chain[1:0], scan_in}),
        .se(scan_enable),
        .q(state_q),
        .so(state_scan_chain)
    );
    
    // 指令寄存器（使用扫描触发器）
    wire [31:0] inst_reg_d, inst_reg_q;
    wire [31:0] inst_scan_chain;
    
    genvar i;
    generate
        for (i = 0; i < 32; i = i + 1) begin : inst_scan_gen
            scan_ff inst_ff (
                .clk(clk),
                .rst_n(rst_n),
                .d(inst_reg_d[i]),
                .si(i == 0 ? state_scan_chain[2] : inst_scan_chain[i-1]),
                .se(scan_enable),
                .q(inst_reg_q[i]),
                .so(inst_scan_chain[i])
            );
        end
    endgenerate
    
    // 控制逻辑
    always @(*) begin
        // 状态机逻辑
        case (state_q)
            3'b000: begin  // IDLE
                if (inst_valid) begin
                    state_d = 3'b001;  // DECODE
                    inst_reg_d = instruction;
                end else begin
                    state_d = state_q;
                    inst_reg_d = inst_reg_q;
                end
            end
            // ... 其他状态
        endcase
    end
    
    assign scan_out = inst_scan_chain[31];

endmodule

// ATPG测试模式生成
module atpg_controller (
    input wire clk,
    input wire rst_n,
    
    // ATPG控制
    input wire test_mode,
    input wire scan_enable,
    input wire [3:0] test_pattern_sel,
    
    // 扫描链接口
    output reg [7:0] scan_in_ports,
    input wire [7:0] scan_out_ports,
    
    // 测试结果
    output reg test_done,
    output reg test_pass
);

    // 测试向量ROM
    reg [7:0] test_vectors [0:1023];
    reg [7:0] expected_responses [0:1023];
    
    // 测试状态机
    localparam TEST_IDLE = 2'b00;
    localparam TEST_SHIFT = 2'b01;
    localparam TEST_CAPTURE = 2'b10;
    localparam TEST_COMPARE = 2'b11;
    
    reg [1:0] test_state;
    reg [9:0] vector_cnt;
    reg [7:0] shift_cnt;
    reg [7:0] captured_data [0:127];
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            test_state <= TEST_IDLE;
            test_done <= 1'b0;
            test_pass <= 1'b1;
        end else if (test_mode) begin
            case (test_state)
                TEST_IDLE: begin
                    if (scan_enable) begin
                        test_state <= TEST_SHIFT;
                        vector_cnt <= 0;
                        shift_cnt <= 0;
                    end
                end
                
                TEST_SHIFT: begin
                    // 移入测试向量
                    scan_in_ports <= test_vectors[vector_cnt];
                    shift_cnt <= shift_cnt + 1;
                    
                    if (shift_cnt == 127) begin  // 假设链长128
                        test_state <= TEST_CAPTURE;
                    end
                end
                
                TEST_CAPTURE: begin
                    // 捕获响应
                    captured_data[shift_cnt] <= scan_out_ports;
                    shift_cnt <= shift_cnt + 1;
                    
                    if (shift_cnt == 127) begin
                        test_state <= TEST_COMPARE;
                    end
                end
                
                TEST_COMPARE: begin
                    // 比较结果
                    for (int i = 0; i < 128; i++) begin
                        if (captured_data[i] != expected_responses[vector_cnt + i]) begin
                            test_pass <= 1'b0;
                        end
                    end
                    
                    vector_cnt <= vector_cnt + 128;
                    if (vector_cnt >= 1024) begin
                        test_done <= 1'b1;
                        test_state <= TEST_IDLE;
                    end else begin
                        test_state <= TEST_SHIFT;
                        shift_cnt <= 0;
                    end
                end
            endcase
        end
    end

endmodule
            </div>

            <h4>7.4.2 内建自测试（BIST）</h4>
            <div class="code-block">
// 存储器BIST控制器
module mbist_controller #(
    parameter ADDR_WIDTH = 10,
    parameter DATA_WIDTH = 32
)(
    input wire clk,
    input wire rst_n,
    
    // BIST控制
    input wire bist_en,
    input wire bist_mode,  // 0: March C-, 1: Checkerboard
    
    // 存储器接口
    output reg mem_en,
    output reg mem_we,
    output reg [ADDR_WIDTH-1:0] mem_addr,
    output reg [DATA_WIDTH-1:0] mem_wdata,
    input wire [DATA_WIDTH-1:0] mem_rdata,
    
    // BIST状态
    output reg bist_done,
    output reg bist_fail,
    output reg [ADDR_WIDTH-1:0] fail_addr,
    output reg [DATA_WIDTH-1:0] fail_data
);

    // March C- 算法状态
    localparam IDLE = 4'b0000;
    localparam W0_UP = 4'b0001;    // 写0，地址递增
    localparam R0W1_UP = 4'b0010;  // 读0写1，地址递增
    localparam R1W0_UP = 4'b0011;  // 读1写0，地址递增
    localparam R0W1_DN = 4'b0100;  // 读0写1，地址递减
    localparam R1W0_DN = 4'b0101;  // 读1写0，地址递减
    localparam R0_UP = 4'b0110;    // 读0，地址递增
    localparam DONE = 4'b0111;
    
    reg [3:0] state, next_state;
    reg [ADDR_WIDTH-1:0] addr_cnt;
    reg addr_dir;  // 0: up, 1: down
    reg [DATA_WIDTH-1:0] expected_data;
    
    // 状态机
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            state <= IDLE;
            bist_done <= 1'b0;
            bist_fail <= 1'b0;
        end else begin
            state <= next_state;
            
            // 错误检测
            if (mem_en && !mem_we && state != IDLE) begin
                if (mem_rdata !== expected_data) begin
                    bist_fail <= 1'b1;
                    fail_addr <= mem_addr;
                    fail_data <= mem_rdata;
                end
            end
        end
    end
    
    // 下一状态逻辑
    always @(*) begin
        next_state = state;
        
        case (state)
            IDLE: begin
                if (bist_en) begin
                    if (bist_mode == 0)  // March C-
                        next_state = W0_UP;
                    else  // 其他算法
                        next_state = W0_UP;
                end
            end
            
            W0_UP: begin
                if (addr_cnt == {ADDR_WIDTH{1'b1}})
                    next_state = R0W1_UP;
            end
            
            R0W1_UP: begin
                if (addr_cnt == {ADDR_WIDTH{1'b1}})
                    next_state = R1W0_UP;
            end
            
            R1W0_UP: begin
                if (addr_cnt == {ADDR_WIDTH{1'b1}})
                    next_state = R0W1_DN;
            end
            
            R0W1_DN: begin
                if (addr_cnt == 0)
                    next_state = R1W0_DN;
            end
            
            R1W0_DN: begin
                if (addr_cnt == 0)
                    next_state = R0_UP;
            end
            
            R0_UP: begin
                if (addr_cnt == {ADDR_WIDTH{1'b1}})
                    next_state = DONE;
            end
            
            DONE: begin
                next_state = IDLE;
            end
        endcase
    end
    
    // 地址和数据生成
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            addr_cnt <= 0;
            mem_en <= 1'b0;
            mem_we <= 1'b0;
            mem_addr <= 0;
            mem_wdata <= 0;
            expected_data <= 0;
        end else begin
            case (state)
                W0_UP: begin  // 写0
                    mem_en <= 1'b1;
                    mem_we <= 1'b1;
                    mem_addr <= addr_cnt;
                    mem_wdata <= 0;
                    addr_cnt <= addr_cnt + 1;
                end
                
                R0W1_UP: begin  // 读0写1
                    mem_en <= 1'b1;
                    if (mem_we) begin  // 写周期
                        mem_we <= 1'b0;
                        expected_data <= 0;
                    end else begin  // 读周期
                        mem_we <= 1'b1;
                        mem_wdata <= {DATA_WIDTH{1'b1}};
                        addr_cnt <= addr_cnt + 1;
                    end
                    mem_addr <= addr_cnt;
                end
                
                // 类似处理其他状态...
                
                DONE: begin
                    bist_done <= 1'b1;
                    mem_en <= 1'b0;
                end
            endcase
        end
    end

endmodule

// 逻辑BIST（LBIST）
module lbist_controller (
    input wire clk,
    input wire rst_n,
    
    // LBIST控制
    input wire lbist_en,
    input wire [15:0] pattern_count,
    
    // PRPG（伪随机图形生成器）
    output reg [31:0] prpg_out,
    
    // MISR（多输入特征寄存器）
    input wire [31:0] response_in,
    output reg [31:0] signature,
    
    // 状态输出
    output reg lbist_done,
    output reg signature_valid
);

    // LFSR用于PRPG
    reg [31:0] lfsr;
    wire feedback = lfsr[31] ^ lfsr[21] ^ lfsr[1] ^ lfsr[0];
    
    // MISR寄存器
    reg [31:0] misr;
    
    // 模式计数器
    reg [15:0] pattern_cnt;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            lfsr <= 32'h12345678;  // 非零种子
            misr <= 32'h0;
            pattern_cnt <= 0;
            lbist_done <= 1'b0;
            signature_valid <= 1'b0;
        end else if (lbist_en) begin
            // PRPG: LFSR更新
            lfsr <= {lfsr[30:0], feedback};
            prpg_out <= lfsr;
            
            // MISR: 特征压缩
            misr <= {misr[30:0], misr[31]} ^ response_in;
            
            // 模式计数
            pattern_cnt <= pattern_cnt + 1;
            if (pattern_cnt == pattern_count - 1) begin
                lbist_done <= 1'b1;
                signature <= misr;
                signature_valid <= 1'b1;
            end
        end
    end

endmodule
            </div>

            <h3>7.5 后硅验证</h3>
            
            <h4>7.5.1 芯片带起（Bring-up）</h4>
            <div class="code-block">
// JTAG调试接口
module jtag_debug_interface (
    // JTAG接口
    input wire tck,
    input wire tms,
    input wire tdi,
    output reg tdo,
    input wire trst_n,
    
    // 内部调试接口
    output reg [31:0] debug_addr,
    output reg [31:0] debug_wdata,
    output reg debug_wen,
    output reg debug_ren,
    input wire [31:0] debug_rdata,
    input wire debug_ready
);

    // TAP状态机
    localparam TEST_LOGIC_RESET = 4'h0;
    localparam RUN_TEST_IDLE = 4'h1;
    localparam SELECT_DR_SCAN = 4'h2;
    localparam CAPTURE_DR = 4'h3;
    localparam SHIFT_DR = 4'h4;
    localparam EXIT1_DR = 4'h5;
    localparam PAUSE_DR = 4'h6;
    localparam EXIT2_DR = 4'h7;
    localparam UPDATE_DR = 4'h8;
    localparam SELECT_IR_SCAN = 4'h9;
    localparam CAPTURE_IR = 4'hA;
    localparam SHIFT_IR = 4'hB;
    localparam EXIT1_IR = 4'hC;
    localparam PAUSE_IR = 4'hD;
    localparam EXIT2_IR = 4'hE;
    localparam UPDATE_IR = 4'hF;
    
    reg [3:0] tap_state;
    reg [4:0] ir_reg;  // 指令寄存器
    reg [63:0] dr_reg;  // 数据寄存器
    
    // 指令定义
    localparam IDCODE = 5'b00001;
    localparam ADDR = 5'b00010;
    localparam DATA = 5'b00011;
    localparam CONTROL = 5'b00100;
    
    // TAP控制器状态机
    always @(posedge tck or negedge trst_n) begin
        if (!trst_n) begin
            tap_state <= TEST_LOGIC_RESET;
        end else begin
            case (tap_state)
                TEST_LOGIC_RESET: tap_state <= tms ? TEST_LOGIC_RESET : RUN_TEST_IDLE;
                RUN_TEST_IDLE: tap_state <= tms ? SELECT_DR_SCAN : RUN_TEST_IDLE;
                SELECT_DR_SCAN: tap_state <= tms ? SELECT_IR_SCAN : CAPTURE_DR;
                CAPTURE_DR: tap_state <= tms ? EXIT1_DR : SHIFT_DR;
                SHIFT_DR: tap_state <= tms ? EXIT1_DR : SHIFT_DR;
                EXIT1_DR: tap_state <= tms ? UPDATE_DR : PAUSE_DR;
                PAUSE_DR: tap_state <= tms ? EXIT2_DR : PAUSE_DR;
                EXIT2_DR: tap_state <= tms ? UPDATE_DR : SHIFT_DR;
                UPDATE_DR: tap_state <= tms ? SELECT_DR_SCAN : RUN_TEST_IDLE;
                SELECT_IR_SCAN: tap_state <= tms ? TEST_LOGIC_RESET : CAPTURE_IR;
                CAPTURE_IR: tap_state <= tms ? EXIT1_IR : SHIFT_IR;
                SHIFT_IR: tap_state <= tms ? EXIT1_IR : SHIFT_IR;
                EXIT1_IR: tap_state <= tms ? UPDATE_IR : PAUSE_IR;
                PAUSE_IR: tap_state <= tms ? EXIT2_IR : PAUSE_IR;
                EXIT2_IR: tap_state <= tms ? UPDATE_IR : SHIFT_IR;
                UPDATE_IR: tap_state <= tms ? SELECT_DR_SCAN : RUN_TEST_IDLE;
            endcase
        end
    end
    
    // IR和DR操作
    always @(posedge tck) begin
        case (tap_state)
            SHIFT_IR: begin
                ir_reg <= {tdi, ir_reg[4:1]};
                tdo <= ir_reg[0];
            end
            
            CAPTURE_DR: begin
                case (ir_reg)
                    IDCODE: dr_reg[31:0] <= 32'h12345678;  // 芯片ID
                    DATA: dr_reg[31:0] <= debug_rdata;
                endcase
            end
            
            SHIFT_DR: begin
                dr_reg <= {tdi, dr_reg[63:1]};
                tdo <= dr_reg[0];
            end
            
            UPDATE_DR: begin
                case (ir_reg)
                    ADDR: debug_addr <= dr_reg[31:0];
                    DATA: begin
                        debug_wdata <= dr_reg[31:0];
                        debug_wen <= dr_reg[32];
                        debug_ren <= dr_reg[33];
                    end
                endcase
            end
        endcase
    end

endmodule

// 片上调试监控器
module on_chip_debug_monitor (
    input wire clk,
    input wire rst_n,
    
    // 监控信号
    input wire [31:0] pc,
    input wire [31:0] instruction,
    input wire inst_valid,
    input wire [31:0] npu_status,
    
    // 触发控制
    input wire [31:0] trigger_pc,
    input wire trigger_en,
    
    // Trace缓冲区接口
    output reg trace_wen,
    output reg [63:0] trace_data,
    output reg [9:0] trace_addr
);

    // 触发检测
    wire trigger_hit = trigger_en && (pc == trigger_pc);
    reg triggered;
    reg [9:0] trace_cnt;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            triggered <= 1'b0;
            trace_cnt <= 0;
            trace_wen <= 1'b0;
        end else begin
            if (trigger_hit) begin
                triggered <= 1'b1;
                trace_cnt <= 0;
            end
            
            if (triggered && inst_valid) begin
                trace_wen <= 1'b1;
                trace_data <= {pc, instruction};
                trace_addr <= trace_cnt;
                trace_cnt <= trace_cnt + 1;
                
                if (trace_cnt == 1023) begin  // Trace buffer满
                    triggered <= 1'b0;
                end
            end else begin
                trace_wen <= 1'b0;
            end
        end
    end

endmodule
            </div>

            <h4>7.5.2 性能调优与Shmoo测试</h4>
            <div class="code-block">
// Shmoo测试控制器
module shmoo_test_controller (
    input wire clk,
    input wire rst_n,
    
    // 测试控制
    input wire shmoo_start,
    input wire [7:0] vdd_start,      // 起始电压（单位：10mV）
    input wire [7:0] vdd_end,        // 结束电压
    input wire [7:0] vdd_step,       // 电压步进
    input wire [9:0] freq_start,     // 起始频率（单位：MHz）
    input wire [9:0] freq_end,       // 结束频率
    input wire [9:0] freq_step,      // 频率步进
    
    // 电源和时钟控制
    output reg [7:0] vdd_ctrl,
    output reg [9:0] freq_ctrl,
    output reg pll_reconfig,
    
    // 测试执行
    output reg test_trigger,
    input wire test_done,
    input wire test_pass,
    
    // 结果存储
    output reg result_wen,
    output reg [17:0] result_addr,   // [17:10]=VDD, [9:0]=Freq
    output reg result_data,          // Pass/Fail
    
    // 状态输出
    output reg shmoo_done
);

    // 状态机
    localparam IDLE = 3'b000;
    localparam SET_VDD = 3'b001;
    localparam SET_FREQ = 3'b010;
    localparam RUN_TEST = 3'b011;
    localparam STORE_RESULT = 3'b100;
    localparam NEXT_POINT = 3'b101;
    localparam DONE = 3'b110;
    
    reg [2:0] state;
    reg [7:0] current_vdd;
    reg [9:0] current_freq;
    reg [15:0] settle_cnt;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            state <= IDLE;
            shmoo_done <= 1'b0;
        end else begin
            case (state)
                IDLE: begin
                    if (shmoo_start) begin
                        state <= SET_VDD;
                        current_vdd <= vdd_start;
                        current_freq <= freq_start;
                    end
                end
                
                SET_VDD: begin
                    vdd_ctrl <= current_vdd;
                    settle_cnt <= 16'hFFFF;  // 电压稳定时间
                    state <= SET_FREQ;
                end
                
                SET_FREQ: begin
                    if (settle_cnt == 0) begin
                        freq_ctrl <= current_freq;
                        pll_reconfig <= 1'b1;
                        settle_cnt <= 16'hFFFF;  // PLL锁定时间
                        state <= RUN_TEST;
                    end else begin
                        settle_cnt <= settle_cnt - 1;
                        pll_reconfig <= 1'b0;
                    end
                end
                
                RUN_TEST: begin
                    if (settle_cnt == 0) begin
                        test_trigger <= 1'b1;
                        if (test_done) begin
                            test_trigger <= 1'b0;
                            state <= STORE_RESULT;
                        end
                    end else begin
                        settle_cnt <= settle_cnt - 1;
                    end
                end
                
                STORE_RESULT: begin
                    result_wen <= 1'b1;
                    result_addr <= {current_vdd, current_freq};
                    result_data <= test_pass;
                    state <= NEXT_POINT;
                end
                
                NEXT_POINT: begin
                    result_wen <= 1'b0;
                    
                    if (current_freq < freq_end) begin
                        current_freq <= current_freq + freq_step;
                        state <= SET_FREQ;
                    end else if (current_vdd < vdd_end) begin
                        current_vdd <= current_vdd + vdd_step;
                        current_freq <= freq_start;
                        state <= SET_VDD;
                    end else begin
                        state <= DONE;
                    end
                end
                
                DONE: begin
                    shmoo_done <= 1'b1;
                    state <= IDLE;
                end
            endcase
        end
    end

endmodule
            </div>

            <h3>7.6 测试向量生成</h3>
            
            <h4>7.6.1 基于模型的向量生成</h4>
            <div class="code-block">
// Python脚本：从神经网络模型生成测试向量
"""
npu_test_vector_generator.py
从PyTorch/TensorFlow模型生成NPU测试向量
"""

import numpy as np
import torch
import struct

class NPUTestVectorGenerator:
    def __init__(self, model, quantization_bits=8):
        self.model = model
        self.quant_bits = quantization_bits
        self.test_vectors = []
        
    def quantize(self, tensor, scale, zero_point):
        """量化浮点张量到定点"""
        q_min = -(2**(self.quant_bits-1))
        q_max = 2**(self.quant_bits-1) - 1
        
        q_tensor = np.round(tensor / scale + zero_point)
        q_tensor = np.clip(q_tensor, q_min, q_max)
        return q_tensor.astype(np.int8)
    
    def generate_conv_test(self, layer_name, input_shape):
        """生成卷积层测试向量"""
        # 创建测试输入
        test_input = torch.randn(input_shape)
        
        # 获取层参数
        conv_layer = getattr(self.model, layer_name)
        weight = conv_layer.weight.detach().numpy()
        bias = conv_layer.bias.detach().numpy() if conv_layer.bias is not None else None
        
        # 执行前向传播获取golden输出
        with torch.no_grad():
            golden_output = conv_layer(test_input).numpy()
        
        # 量化参数计算
        input_scale = np.max(np.abs(test_input.numpy())) / 127
        weight_scale = np.max(np.abs(weight)) / 127
        output_scale = input_scale * weight_scale
        
        # 量化
        q_input = self.quantize(test_input.numpy(), input_scale, 0)
        q_weight = self.quantize(weight, weight_scale, 0)
        q_output = self.quantize(golden_output, output_scale, 0)
        
        # 生成测试向量
        test_vector = {
            'layer': layer_name,
            'operation': 'conv2d',
            'input_shape': input_shape,
            'kernel_size': conv_layer.kernel_size,
            'stride': conv_layer.stride,
            'padding': conv_layer.padding,
            'input_data': q_input.flatten().tolist(),
            'weight_data': q_weight.flatten().tolist(),
            'bias_data': bias.tolist() if bias is not None else None,
            'expected_output': q_output.flatten().tolist(),
            'scales': {
                'input': input_scale,
                'weight': weight_scale,
                'output': output_scale
            }
        }
        
        self.test_vectors.append(test_vector)
        return test_vector
    
    def generate_corner_cases(self):
        """生成边界测试用例"""
        corner_cases = []
        
        # 全零输入
        zero_input = np.zeros((1, 3, 224, 224), dtype=np.int8)
        corner_cases.append({
            'name': 'all_zeros',
            'input': zero_input,
            'expected_behavior': 'zero_output'
        })
        
        # 最大值输入
        max_input = np.full((1, 3, 224, 224), 127, dtype=np.int8)
        corner_cases.append({
            'name': 'max_values',
            'input': max_input,
            'expected_behavior': 'saturation_check'
        })
        
        # 稀疏输入（90%零值）
        sparse_input = np.random.choice([0, 1], size=(1, 3, 224, 224), p=[0.9, 0.1])
        sparse_input = sparse_input.astype(np.int8) * 127
        corner_cases.append({
            'name': 'sparse_input',
            'input': sparse_input,
            'expected_behavior': 'sparse_optimization'
        })
        
        return corner_cases
    
    def export_to_npu_format(self, filename):
        """导出为NPU可读的二进制格式"""
        with open(filename, 'wb') as f:
            # 文件头
            f.write(struct.pack('I', 0x4E505554))  # 'NPUT' magic
            f.write(struct.pack('I', len(self.test_vectors)))
            
            for vector in self.test_vectors:
                # 向量头
                layer_name = vector['layer'].encode('utf-8')
                f.write(struct.pack('I', len(layer_name)))
                f.write(layer_name)
                
                # 操作类型
                op_type = vector['operation'].encode('utf-8')
                f.write(struct.pack('I', len(op_type)))
                f.write(op_type)
                
                # 数据
                input_data = vector['input_data']
                f.write(struct.pack('I', len(input_data)))
                for val in input_data:
                    f.write(struct.pack('b', val))
                
                # 权重
                weight_data = vector['weight_data']
                f.write(struct.pack('I', len(weight_data)))
                for val in weight_data:
                    f.write(struct.pack('b', val))
                
                # 期望输出
                output_data = vector['expected_output']
                f.write(struct.pack('I', len(output_data)))
                for val in output_data:
                    f.write(struct.pack('b', val))

# 使用示例
if __name__ == "__main__":
    # 加载模型
    model = torch.load('mobilenet_v2.pth')
    model.eval()
    
    # 创建测试向量生成器
    generator = NPUTestVectorGenerator(model)
    
    # 生成各层测试向量
    generator.generate_conv_test('features.0.0', (1, 3, 224, 224))
    generator.generate_conv_test('features.1.conv.0', (1, 32, 112, 112))
    
    # 生成边界测试
    corner_cases = generator.generate_corner_cases()
    
    # 导出测试向量
    generator.export_to_npu_format('npu_test_vectors.bin')
            </div>

            <h4>7.6.2 测试向量验证框架</h4>
            <div class="code-block">
// SystemVerilog测试向量加载和验证框架
class test_vector_loader extends uvm_component;
    `uvm_component_utils(test_vector_loader)
    
    // 测试向量数据结构
    typedef struct {
        string layer_name;
        string operation;
        int input_size;
        int weight_size;
        int output_size;
        byte input_data[];
        byte weight_data[];
        byte expected_output[];
        real input_scale;
        real weight_scale;
        real output_scale;
    } test_vector_t;
    
    test_vector_t test_vectors[$];
    
    function new(string name, uvm_component parent);
        super.new(name, parent);
    endfunction
    
    // 从文件加载测试向量
    function void load_vectors(string filename);
        int fd;
        bit [31:0] magic, num_vectors;
        
        fd = $fopen(filename, "rb");
        if (fd == 0) begin
            `uvm_fatal("LOADER", $sformatf("Cannot open file %s", filename))
        end
        
        // 读取文件头
        $fread(magic, fd);
        if (magic != 32'h4E505554) begin  // 'NPUT'
            `uvm_fatal("LOADER", "Invalid file format")
        end
        
        $fread(num_vectors, fd);
        `uvm_info("LOADER", $sformatf("Loading %0d test vectors", num_vectors), UVM_LOW)
        
        // 读取每个测试向量
        for (int i = 0; i < num_vectors; i++) begin
            test_vector_t vec;
            int name_len, op_len;
            
            // 读取层名称
            $fread(name_len, fd);
            vec.layer_name = "";
            for (int j = 0; j < name_len; j++) begin
                byte ch;
                $fread(ch, fd);
                vec.layer_name = {vec.layer_name, ch};
            end
            
            // 读取操作类型
            $fread(op_len, fd);
            vec.operation = "";
            for (int j = 0; j < op_len; j++) begin
                byte ch;
                $fread(ch, fd);
                vec.operation = {vec.operation, ch};
            end
            
            // 读取数据
            $fread(vec.input_size, fd);
            vec.input_data = new[vec.input_size];
            for (int j = 0; j < vec.input_size; j++) begin
                $fread(vec.input_data[j], fd);
            end
            
            $fread(vec.weight_size, fd);
            vec.weight_data = new[vec.weight_size];
            for (int j = 0; j < vec.weight_size; j++) begin
                $fread(vec.weight_data[j], fd);
            end
            
            $fread(vec.output_size, fd);
            vec.expected_output = new[vec.output_size];
            for (int j = 0; j < vec.output_size; j++) begin
                $fread(vec.expected_output[j], fd);
            end
            
            test_vectors.push_back(vec);
        end
        
        $fclose(fd);
    endfunction
    
    // 获取下一个测试向量
    function test_vector_t get_next_vector();
        if (test_vectors.size() > 0) begin
            return test_vectors.pop_front();
        end else begin
            `uvm_warning("LOADER", "No more test vectors")
            return null;
        end
    endfunction
    
endclass

// 测试执行序列
class npu_test_vector_sequence extends uvm_sequence;
    `uvm_object_utils(npu_test_vector_sequence)
    
    test_vector_loader loader;
    
    function new(string name = "npu_test_vector_sequence");
        super.new(name);
    endfunction
    
    task body();
        test_vector_loader::test_vector_t vec;
        npu_layer_config_seq config_seq;
        npu_data_load_seq data_seq;
        npu_compute_seq compute_seq;
        npu_result_check_seq check_seq;
        
        // 加载测试向量
        loader = test_vector_loader::type_id::create("loader");
        loader.load_vectors("npu_test_vectors.bin");
        
        // 执行每个测试向量
        while (1) begin
            vec = loader.get_next_vector();
            if (vec == null) break;
            
            `uvm_info("TEST", $sformatf("Testing layer: %s", vec.layer_name), UVM_LOW)
            
            // 配置NPU层参数
            config_seq = npu_layer_config_seq::type_id::create("config_seq");
            config_seq.layer_name = vec.layer_name;
            config_seq.operation = vec.operation;
            config_seq.start(m_sequencer);
            
            // 加载输入数据和权重
            data_seq = npu_data_load_seq::type_id::create("data_seq");
            data_seq.input_data = vec.input_data;
            data_seq.weight_data = vec.weight_data;
            data_seq.start(m_sequencer);
            
            // 执行计算
            compute_seq = npu_compute_seq::type_id::create("compute_seq");
            compute_seq.start(m_sequencer);
            
            // 检查结果
            check_seq = npu_result_check_seq::type_id::create("check_seq");
            check_seq.expected_output = vec.expected_output;
            check_seq.tolerance = 1;  // INT8量化容差
            check_seq.start(m_sequencer);
        end
    endtask
    
endclass
            </div>

            <div class="exercise">
                <h4>练习 7.4-7.6</h4>
                <div class="question">
                    <p><strong>题目：</strong>设计一个完整的MBIST控制器用于测试NPU中的SRAM，要求：
                    1) 支持March C-和Checkerboard算法
                    2) 支持多个SRAM并行测试
                    3) 实现故障诊断和修复
                    4) 提供测试结果统计</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module npu_mbist_top #(
    parameter NUM_SRAMS = 4,
    parameter ADDR_WIDTH = 10,
    parameter DATA_WIDTH = 32,
    parameter REPAIR_WIDTH = 4  // 修复行数
)(
    input wire clk,
    input wire rst_n,
    
    // MBIST控制
    input wire mbist_en,
    input wire [1:0] mbist_mode,  // 00: March C-, 01: Checkerboard, 10: Walking 1/0
    input wire repair_en,
    
    // SRAM接口（简化）
    output wire [NUM_SRAMS-1:0] sram_en,
    output wire [NUM_SRAMS-1:0] sram_we,
    output wire [ADDR_WIDTH-1:0] sram_addr [NUM_SRAMS-1:0],
    output wire [DATA_WIDTH-1:0] sram_wdata [NUM_SRAMS-1:0],
    input wire [DATA_WIDTH-1:0] sram_rdata [NUM_SRAMS-1:0],
    
    // 测试结果
    output reg mbist_done,
    output reg [NUM_SRAMS-1:0] mbist_fail,
    output reg [31:0] total_faults,
    output reg [31:0] repaired_faults,
    
    // 诊断接口
    output reg diag_valid,
    output reg [7:0] diag_sram_id,
    output reg [ADDR_WIDTH-1:0] diag_addr,
    output reg [DATA_WIDTH-1:0] diag_expected,
    output reg [DATA_WIDTH-1:0] diag_actual
);

    // MBIST FSM状态
    localparam IDLE = 4'h0;
    localparam INIT = 4'h1;
    localparam MARCH_W0 = 4'h2;
    localparam MARCH_R0W1_UP = 4'h3;
    localparam MARCH_R1W0_UP = 4'h4;
    localparam MARCH_R0W1_DN = 4'h5;
    localparam MARCH_R1W0_DN = 4'h6;
    localparam MARCH_R0 = 4'h7;
    localparam CHECKER_W0 = 4'h8;
    localparam CHECKER_W1 = 4'h9;
    localparam CHECKER_R = 4'hA;
    localparam DIAGNOSE = 4'hB;
    localparam REPAIR = 4'hC;
    localparam DONE = 4'hD;
    
    reg [3:0] state, next_state;
    reg [ADDR_WIDTH-1:0] addr_cnt;
    reg addr_dir;  // 0: up, 1: down
    reg [1:0] phase;
    
    // 每个SRAM的独立控制
    reg [NUM_SRAMS-1:0] sram_fail_flag;
    reg [ADDR_WIDTH-1:0] fail_addr [NUM_SRAMS-1:0];
    reg [DATA_WIDTH-1:0] fail_data [NUM_SRAMS-1:0];
    
    // 修复信息
    reg [ADDR_WIDTH-1:0] repair_rows [NUM_SRAMS-1:0][REPAIR_WIDTH-1:0];
    reg [REPAIR_WIDTH-1:0] repair_used [NUM_SRAMS-1:0];
    
    // 生成期望数据
    function [DATA_WIDTH-1:0] generate_pattern;
        input [1:0] mode;
        input [ADDR_WIDTH-1:0] addr;
        input [1:0] phase;
        
        case (mode)
            2'b00: begin  // March C-
                case (phase)
                    2'b00: generate_pattern = {DATA_WIDTH{1'b0}};
                    2'b01: generate_pattern = {DATA_WIDTH{1'b1}};
                    default: generate_pattern = {DATA_WIDTH{1'b0}};
                endcase
            end
            
            2'b01: begin  // Checkerboard
                generate_pattern = {DATA_WIDTH/2{addr[0] ? 2'b10 : 2'b01}};
            end
            
            2'b10: begin  // Walking 1/0
                generate_pattern = phase[0] ? (1 << (addr % DATA_WIDTH)) : 
                                             ~(1 << (addr % DATA_WIDTH));
            end
            
            default: generate_pattern = {DATA_WIDTH{1'b0}};
        endcase
    endfunction
    
    // 主状态机
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            state <= IDLE;
            mbist_done <= 1'b0;
            total_faults <= 0;
        end else begin
            state <= next_state;
        end
    end
    
    // 下一状态逻辑
    always @(*) begin
        next_state = state;
        
        case (state)
            IDLE: begin
                if (mbist_en) begin
                    case (mbist_mode)
                        2'b00: next_state = MARCH_W0;
                        2'b01: next_state = CHECKER_W0;
                        2'b10: next_state = INIT;
                    endcase
                end
            end
            
            MARCH_W0: begin
                if (addr_cnt == {ADDR_WIDTH{1'b1}})
                    next_state = MARCH_R0W1_UP;
            end
            
            MARCH_R0W1_UP: begin
                if (addr_cnt == {ADDR_WIDTH{1'b1}} && phase == 2'b01)
                    next_state = MARCH_R1W0_UP;
            end
            
            MARCH_R1W0_UP: begin
                if (addr_cnt == {ADDR_WIDTH{1'b1}} && phase == 2'b01)
                    next_state = MARCH_R0W1_DN;
            end
            
            MARCH_R0W1_DN: begin
                if (addr_cnt == 0 && phase == 2'b01)
                    next_state = MARCH_R1W0_DN;
            end
            
            MARCH_R1W0_DN: begin
                if (addr_cnt == 0 && phase == 2'b01)
                    next_state = MARCH_R0;
            end
            
            MARCH_R0: begin
                if (addr_cnt == {ADDR_WIDTH{1'b1}})
                    next_state = repair_en ? DIAGNOSE : DONE;
            end
            
            DIAGNOSE: begin
                if (total_faults == 0)
                    next_state = DONE;
                else
                    next_state = REPAIR;
            end
            
            REPAIR: begin
                next_state = DONE;
            end
            
            DONE: begin
                next_state = IDLE;
            end
        endcase
    end
    
    // 地址生成和SRAM控制
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            addr_cnt <= 0;
            phase <= 0;
            for (int i = 0; i < NUM_SRAMS; i++) begin
                sram_fail_flag[i] <= 1'b0;
                repair_used[i] <= 0;
            end
        end else begin
            case (state)
                MARCH_W0: begin
                    // 所有SRAM并行写0
                    for (int i = 0; i < NUM_SRAMS; i++) begin
                        sram_en[i] <= 1'b1;
                        sram_we[i] <= 1'b1;
                        sram_addr[i] <= addr_cnt;
                        sram_wdata[i] <= {DATA_WIDTH{1'b0}};
                    end
                    addr_cnt <= addr_cnt + 1;
                end
                
                MARCH_R0W1_UP: begin
                    for (int i = 0; i < NUM_SRAMS; i++) begin
                        sram_en[i] <= 1'b1;
                        if (phase == 0) begin  // 读阶段
                            sram_we[i] <= 1'b0;
                            // 检查读出数据
                            if (sram_rdata[i] !== {DATA_WIDTH{1'b0}}) begin
                                sram_fail_flag[i] <= 1'b1;
                                fail_addr[i] <= addr_cnt;
                                fail_data[i] <= sram_rdata[i];
                                total_faults <= total_faults + 1;
                            end
                        end else begin  // 写阶段
                            sram_we[i] <= 1'b1;
                            sram_wdata[i] <= {DATA_WIDTH{1'b1}};
                        end
                        sram_addr[i] <= addr_cnt;
                    end
                    
                    if (phase == 1) begin
                        addr_cnt <= addr_cnt + 1;
                        phase <= 0;
                    end else begin
                        phase <= 1;
                    end
                end
                
                // 类似处理其他状态...
                
                DIAGNOSE: begin
                    // 输出诊断信息
                    for (int i = 0; i < NUM_SRAMS; i++) begin
                        if (sram_fail_flag[i]) begin
                            diag_valid <= 1'b1;
                            diag_sram_id <= i;
                            diag_addr <= fail_addr[i];
                            diag_expected <= {DATA_WIDTH{1'b0}};  // 根据状态确定
                            diag_actual <= fail_data[i];
                            break;
                        end
                    end
                end
                
                REPAIR: begin
                    // 简单的行修复策略
                    for (int i = 0; i < NUM_SRAMS; i++) begin
                        if (sram_fail_flag[i] && repair_used[i] < REPAIR_WIDTH) begin
                            repair_rows[i][repair_used[i]] <= fail_addr[i];
                            repair_used[i] <= repair_used[i] + 1;
                            repaired_faults <= repaired_faults + 1;
                            sram_fail_flag[i] <= 1'b0;
                        end
                    end
                end
                
                DONE: begin
                    mbist_done <= 1'b1;
                    mbist_fail <= sram_fail_flag;
                    diag_valid <= 1'b0;
                end
            endcase
        end
    end
    
    // 地址重映射（修复后）
    function [ADDR_WIDTH-1:0] remap_address;
        input [7:0] sram_id;
        input [ADDR_WIDTH-1:0] addr;
        
        remap_address = addr;
        
        // 检查是否需要重映射
        for (int i = 0; i < REPAIR_WIDTH; i++) begin
            if (repair_used[sram_id] > i && 
                repair_rows[sram_id][i] == addr) begin
                // 重映射到备用行
                remap_address = {ADDR_WIDTH{1'b1}} - i;
                break;
            end
        end
    endfunction

endmodule
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <div id="chapter8" class="chapter">
            <h2>第8章：物理设计</h2>
            
            <p>物理设计是将RTL设计转化为可制造芯片版图的关键步骤。对于NPU这样的高性能、高密度芯片，物理设计面临着功耗、性能、面积等多方面的挑战。本章将详细介绍NPU物理设计的完整流程、关键技术和优化方法。</p>

            <h3>8.1 物理设计流程概述</h3>
            
            <p>NPU的物理设计流程涵盖从逻辑综合到版图验证的完整过程。每个阶段都需要在性能、功耗、面积之间进行精细的权衡，以满足设计目标。</p>

            <h4>8.1.1 设计输入与约束</h4>
            <div class="info-box">
                <p><strong>NPU物理设计的输入：</strong></p>
                <ul>
                    <li>RTL代码和网表</li>
                    <li>工艺库文件（.lib, .lef）</li>
                    <li>设计约束（SDC）</li>
                    <li>功耗意图（UPF/CPF）</li>
                    <li>物理约束（DEF）</li>
                </ul>
            </div>

            <div class="code-block">
# 典型的NPU设计约束示例 (SDC)
# 时钟定义
create_clock -name sys_clk -period 1.0 [get_ports clk]
create_clock -name noc_clk -period 0.8 [get_ports noc_clk]

# 时钟不确定性
set_clock_uncertainty -setup 0.05 [get_clocks sys_clk]
set_clock_uncertainty -hold 0.03 [get_clocks sys_clk]

# 输入/输出延迟
set_input_delay -clock sys_clk -max 0.2 [all_inputs]
set_output_delay -clock sys_clk -max 0.15 [all_outputs]

# 多周期路径（针对MAC阵列）
set_multicycle_path -setup 2 -from [get_pins mac_array/*/mult_reg*] \
                    -to [get_pins mac_array/*/acc_reg*]

# 伪路径（跨时钟域）
set_false_path -from [get_clocks sys_clk] -to [get_clocks noc_clk]

# 最大过渡时间和电容
set_max_transition 0.1 [current_design]
set_max_capacitance 0.05 [all_outputs]
            </div>

            <h4>8.1.2 物理设计主要步骤</h4>
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>设计阶段</th>
                            <th>主要任务</th>
                            <th>关键指标</th>
                            <th>NPU特殊考虑</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Floorplan</td>
                            <td>芯片布局规划</td>
                            <td>利用率、引脚分配</td>
                            <td>MAC阵列规则布局</td>
                        </tr>
                        <tr>
                            <td>Power Planning</td>
                            <td>电源网络设计</td>
                            <td>IR Drop、EM</td>
                            <td>高功耗密度区域</td>
                        </tr>
                        <tr>
                            <td>Placement</td>
                            <td>标准单元布局</td>
                            <td>拥塞度、时序</td>
                            <td>数据通路对齐</td>
                        </tr>
                        <tr>
                            <td>CTS</td>
                            <td>时钟树综合</td>
                            <td>Skew、功耗</td>
                            <td>多时钟域处理</td>
                        </tr>
                        <tr>
                            <td>Routing</td>
                            <td>信号线布线</td>
                            <td>DRC、时序收敛</td>
                            <td>高密度互连</td>
                        </tr>
                        <tr>
                            <td>Sign-off</td>
                            <td>最终验证</td>
                            <td>时序、功耗、DRC</td>
                            <td>全芯片验证</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h3>8.2 布局规划（Floorplan）</h3>
            
            <p>布局规划是物理设计的第一步，决定了芯片的整体架构和性能上限。对于NPU，合理的布局规划对于实现高性能和低功耗至关重要。</p>

            <h4>8.2.1 NPU典型布局架构</h4>
            <div class="code-block">
// NPU芯片典型布局
+----------------------------------------------------------+
|                      IO Ring / Pad                       |
|  +--------------------------------------------------+    |
|  |          Global Control & Configuration          |    |
|  +--------------------------------------------------+    |
|  |                                                  |    |
|  |   +----------+  +----------+  +----------+      |    |
|  |   | MAC      |  | MAC      |  | MAC      | ... |    |
|  |   | Cluster  |  | Cluster  |  | Cluster  |     |    |
|  |   | 0        |  | 1        |  | 2        |     |    |
|  |   +----------+  +----------+  +----------+      |    |
|  |                                                  |    |
|  |   +---------------------------------------+      |    |
|  |   |          Global SRAM Buffer          |      |    |
|  |   +---------------------------------------+      |    |
|  |                                                  |    |
|  |   +----------+  +----------+  +----------+      |    |
|  |   | NoC      |  | DMA      |  | Memory   |     |    |
|  |   | Router   |  | Engine   |  | Control  |     |    |
|  |   +----------+  +----------+  +----------+      |    |
|  |                                                  |    |
|  +--------------------------------------------------+    |
|                      IO Ring / Pad                       |
+----------------------------------------------------------+
            </div>

            <h4>8.2.2 布局优化策略</h4>
            <div class="warning-box">
                <p><strong>NPU布局的关键挑战：</strong></p>
                <ul>
                    <li>MAC阵列的规则性布局要求</li>
                    <li>高带宽数据通路的布线资源</li>
                    <li>功耗密度的均匀分布</li>
                    <li>时钟域的物理隔离</li>
                </ul>
            </div>

            <div class="code-block">
# Floorplan TCL脚本示例
# 设置芯片尺寸和利用率
create_floorplan -die_size {0 0 5000 5000} \
                 -core_offset {100 100 100 100} \
                 -utilization 0.7

# 创建电压域
create_voltage_area -name CORE_PD -coordinate {500 500 4500 4500}
create_voltage_area -name AON_PD -coordinate {100 100 500 4900}

# 放置硬宏（Hard Macro）
# MAC集群规则排列
set mac_width 800
set mac_height 600
set mac_spacing 50

for {set i 0} {$i < 8} {incr i} {
    for {set j 0} {$j < 8} {incr j} {
        set x_loc [expr 600 + $i * ($mac_width + $mac_spacing)]
        set y_loc [expr 600 + $j * ($mac_height + $mac_spacing)]
        create_macro_placement -inst_name mac_cluster_${i}_${j} \
                             -coordinate [list $x_loc $y_loc] \
                             -orientation N
    }
}

# 放置SRAM
create_macro_placement -inst_name global_buffer_sram \
                      -coordinate {1500 3500} \
                      -orientation N

# 创建placement blockage
create_placement_blockage -name mac_blockage \
                         -type hard \
                         -coordinate {600 600 4400 3400}

# 设置Halo
create_keepout_margin -type hard -outer {20 20 20 20} \
                     [get_cells -hier -filter "is_hard_macro==true"]
            </div>

            <h3>8.3 电源规划与实现</h3>
            
            <p>NPU的高功耗密度对电源网络设计提出了严苛要求。良好的电源规划不仅影响芯片的功能正确性，还直接决定了性能和可靠性。</p>

            <h4>8.3.1 电源网格设计</h4>
            <div class="code-block">
# 电源网格规划脚本
# 定义电源网络
create_net -power VDD
create_net -ground VSS

# 创建电源环（Power Ring）
create_power_ring -nets {VDD VSS} \
                  -layers {M9 M10} \
                  -widths {20 20} \
                  -spacings {5 5} \
                  -core_offset 10

# 创建电源条带（Power Stripe）
# 垂直条带 - M9
create_power_stripes -nets {VDD VSS} \
                     -layer M9 \
                     -direction vertical \
                     -width 10 \
                     -spacing 5 \
                     -pitch 100 \
                     -start_x 100 \
                     -stop_x 4900

# 水平条带 - M10  
create_power_stripes -nets {VDD VSS} \
                     -layer M10 \
                     -direction horizontal \
                     -width 10 \
                     -spacing 5 \
                     -pitch 100 \
                     -start_y 100 \
                     -stop_y 4900

# MAC阵列区域加密电源网格
create_power_stripes -nets {VDD VSS} \
                     -layer M9 \
                     -direction vertical \
                     -width 5 \
                     -spacing 2.5 \
                     -pitch 25 \
                     -region {600 600 4400 3400}
            </div>

            <h4>8.3.2 IR Drop分析与优化</h4>
            <div class="info-box">
                <p><strong>IR Drop优化技术：</strong></p>
                <ol>
                    <li><strong>电源网格加密：</strong>在高功耗区域增加电源条带密度</li>
                    <li><strong>Via阵列优化：</strong>增加层间连接via数量，降低电阻</li>
                    <li><strong>去耦电容插入：</strong>在空白区域填充去耦电容</li>
                    <li><strong>电源门控优化：</strong>合理规划电源开关位置</li>
                </ol>
            </div>

            <h3>8.4 布局优化（Placement）</h3>
            
            <p>布局阶段将标准单元和宏单元放置在芯片上的合适位置。NPU的布局优化需要特别关注数据通路的规则性和时序关键路径。</p>

            <h4>8.4.1 分层布局策略</h4>
            <div class="code-block">
# 布局优化脚本
# 设置布局选项
set_placement_options -congestion_effort high \
                     -timing_driven true \
                     -global_route_based true

# 数据通路规则化布局
# 创建相对布局约束
create_relative_placement -name mac_datapath \
                         -pattern {
                             {mult_stage_0 mult_stage_1 mult_stage_2}
                             {add_stage_0  add_stage_1  add_stage_2}
                             {acc_stage_0  acc_stage_1  acc_stage_2}
                         } \
                         -x_pitch 50 \
                         -y_pitch 40

# 关键路径优化
set_critical_path_groups -from [get_pins mac_array/*/data_in*] \
                        -to [get_pins mac_array/*/data_out*]

# 执行布局
place_design -concurrent_optimization \
            -incremental \
            -density_gradient

# 布局后优化
optimize_placement -critical_path \
                  -congestion \
                  -setup_target_slack 0.05
            </div>

            <h4>8.4.2 拥塞分析与缓解</h4>
            <div class="warning-box">
                <p><strong>NPU布局常见拥塞问题：</strong></p>
                <ul>
                    <li>MAC阵列间的密集互连</li>
                    <li>控制信号的扇出过大</li>
                    <li>数据总线的布线资源竞争</li>
                    <li>时钟网络与信号线的冲突</li>
                </ul>
            </div>

            <h3>8.5 时钟树综合（CTS）</h3>
            
            <p>时钟树综合是确保时序收敛的关键步骤。NPU通常包含多个时钟域，需要精心设计时钟树结构以最小化时钟偏斜和功耗。</p>

            <h4>8.5.1 时钟树规划</h4>
            <div class="code-block">
# CTS配置脚本
# 定义时钟树约束
create_clock_tree_spec -name clk_spec \
                      -period 1.0 \
                      -root_pin clk \
                      -leaf_pins [get_pins -hier */clk] \
                      -buffers {CKBUF_X16 CKBUF_X32} \
                      -inverters {CKINV_X16 CKINV_X32}

# 设置时钟树目标
set_clock_tree_options -target_skew 0.02 \
                      -target_latency 0.3 \
                      -max_transition 0.08 \
                      -max_capacitance 0.1

# 多时钟域处理
foreach clk [get_clocks] {
    set_clock_tree_options -clock $clk \
                          -routing_rule clk_routing_rule \
                          -use_inverters true \
                          -buffer_sizing true
}

# 时钟门控感知CTS
set_clock_gating_options -max_fanout 32 \
                        -min_bitwidth 8

# 执行CTS
clock_tree_synthesis -propagate_all_clocks \
                    -timing_driven \
                    -balance_groups
            </div>

            <h4>8.5.2 时钟域交叉（CDC）处理</h4>
            <div class="code-block">
// CDC同步器设计
module cdc_sync #(
    parameter WIDTH = 1,
    parameter SYNC_STAGES = 2
)(
    input wire src_clk,
    input wire dst_clk,
    input wire src_rst_n,
    input wire dst_rst_n,
    input wire [WIDTH-1:0] src_data,
    output reg [WIDTH-1:0] dst_data
);
    
    // 多级同步器
    reg [WIDTH-1:0] sync_regs[SYNC_STAGES-1:0];
    
    // 目标时钟域同步
    always @(posedge dst_clk or negedge dst_rst_n) begin
        if (!dst_rst_n) begin
            for (int i = 0; i < SYNC_STAGES; i++) begin
                sync_regs[i] <= '0;
            end
            dst_data <= '0;
        end else begin
            sync_regs[0] <= src_data;
            for (int i = 1; i < SYNC_STAGES; i++) begin
                sync_regs[i] <= sync_regs[i-1];
            end
            dst_data <= sync_regs[SYNC_STAGES-1];
        end
    end
    
    // 时序约束
    // synthesis attribute ASYNC_REG of sync_regs is TRUE
    
endmodule
            </div>

            <h3>8.6 布线与优化（Routing）</h3>
            
            <p>布线阶段完成所有信号的物理连接。NPU的高密度和高性能要求使得布线变得极具挑战性，需要采用先进的布线策略和优化技术。</p>

            <h4>8.6.1 全局布线策略</h4>
            <div class="code-block">
# 布线配置脚本
# 设置布线规则
define_routing_rule high_speed_rule \
                   -widths {M1:0.1 M2:0.1 M3:0.15 M4:0.15 M5:0.2 M6:0.2} \
                   -spacings {M1:0.1 M2:0.1 M3:0.15 M4:0.15 M5:0.2 M6:0.2} \
                   -vias {VIA12_FAT VIA23_FAT VIA34_FAT}

# 关键信号布线约束
set_net_routing_rule [get_nets -of [get_pins mac_array/*/clk]] \
                     high_speed_rule

# 设置布线选项
set_route_options -groute_timing_driven true \
                  -groute_incremental true \
                  -track_assign_timing_driven true \
                  -droute_ECO_mode true

# 屏蔽层设置（针对噪声敏感信号）
create_shield -nets {clk rst_n} \
              -with_net VSS \
              -side_spacing 0.2

# 执行全局布线
route_global -congestion_map_only false \
            -timing_driven true \
            -effort_level high

# 详细布线
route_detail -incremental true \
            -timing_driven true \
            -si_driven true
            </div>

            <h4>8.6.2 信号完整性优化</h4>
            <div class="info-box">
                <p><strong>SI优化技术：</strong></p>
                <ol>
                    <li><strong>串扰避免：</strong>增加关键信号间距</li>
                    <li><strong>屏蔽插入：</strong>在敏感信号两侧添加地线屏蔽</li>
                    <li><strong>驱动优化：</strong>调整驱动强度减少噪声</li>
                    <li><strong>时序修复：</strong>考虑SI影响的时序优化</li>
                </ol>
            </div>

            <h3>8.7 物理验证与签收</h3>
            
            <p>物理验证确保设计满足所有制造规则和性能要求。这是流片前的最后关卡，必须严格把关。</p>

            <h4>8.7.1 DRC/LVS检查</h4>
            <div class="code-block">
# DRC检查脚本
# 加载规则文件
load_tech_file ./tech/drc_rules.tf

# 运行DRC
run_drc -cell TOP \
        -report drc_report.txt \
        -error_view drc_errors

# 常见DRC违例类型
# 1. 最小宽度违例 (Min Width)
# 2. 最小间距违例 (Min Spacing)  
# 3. 最小面积违例 (Min Area)
# 4. Via覆盖违例 (Via Enclosure)
# 5. 密度违例 (Density)

# LVS检查
run_lvs -schematic ../netlist/npu_top.v \
        -layout ./npu_top.gds \
        -report lvs_report.txt \
        -extract_rc true
            </div>

            <h4>8.7.2 时序签收</h4>
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>检查项目</th>
                            <th>目标值</th>
                            <th>检查方法</th>
                            <th>修复策略</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Setup时序</td>
                            <td>slack > 0</td>
                            <td>STA分析</td>
                            <td>插入buffer、调整尺寸</td>
                        </tr>
                        <tr>
                            <td>Hold时序</td>
                            <td>slack > 0</td>
                            <td>STA分析</td>
                            <td>插入delay buffer</td>
                        </tr>
                        <tr>
                            <td>转换时间</td>
                            <td>< 100ps</td>
                            <td>Transition检查</td>
                            <td>调整驱动强度</td>
                        </tr>
                        <tr>
                            <td>时钟偏斜</td>
                            <td>< 20ps</td>
                            <td>时钟报告</td>
                            <td>CTS重新平衡</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h3>8.8 低功耗物理设计</h3>
            
            <p>NPU的功耗优化贯穿整个物理设计流程。从架构级到晶体管级，每个层次都有相应的优化技术。</p>

            <h4>8.8.1 多阈值电压优化</h4>
            <div class="code-block">
# 多Vt优化脚本
# 定义Vt类型
set_attribute [get_libs */LVT] default_threshold_voltage_group LVT
set_attribute [get_libs */RVT] default_threshold_voltage_group RVT  
set_attribute [get_libs */HVT] default_threshold_voltage_group HVT

# 设置优化策略
set_power_optimization_options -leakage_power true \
                              -dynamic_power true \
                              -total_power true

# Vt分配策略
# 关键路径使用LVT
set_threshold_voltage_group [get_cells -of [all_critical_paths]] LVT

# 非关键路径使用HVT
set_threshold_voltage_group [get_cells -of [all_non_critical_paths]] HVT

# 执行功耗优化
optimize_power -multi_vt \
               -size_only false \
               -preserve_paths [all_critical_paths]
            </div>

            <h4>8.8.2 电源门控实现</h4>
            <div class="code-block">
// 电源门控控制器
module power_gating_controller (
    input wire clk,
    input wire rst_n,
    input wire sleep_req,
    output reg sleep_ack,
    output reg isolate_n,
    output reg pwr_switch_n,
    output reg reset_n
);

    // 状态机定义
    typedef enum logic [2:0] {
        ACTIVE,
        ISOLATE,
        POWER_DOWN,
        SLEEP,
        POWER_UP,
        RESET,
        WAKE_UP
    } state_t;
    
    state_t current_state, next_state;
    
    // 状态转换
    always_ff @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            current_state <= ACTIVE;
        end else begin
            current_state <= next_state;
        end
    end
    
    // 状态机逻辑
    always_comb begin
        next_state = current_state;
        
        case (current_state)
            ACTIVE: begin
                if (sleep_req) next_state = ISOLATE;
            end
            
            ISOLATE: begin
                next_state = POWER_DOWN;
            end
            
            POWER_DOWN: begin
                next_state = SLEEP;
            end
            
            SLEEP: begin
                if (!sleep_req) next_state = POWER_UP;
            end
            
            POWER_UP: begin
                next_state = RESET;
            end
            
            RESET: begin
                next_state = WAKE_UP;
            end
            
            WAKE_UP: begin
                next_state = ACTIVE;
            end
        endcase
    end
    
    // 输出控制
    always_comb begin
        isolate_n = 1'b1;
        pwr_switch_n = 1'b0;
        reset_n = 1'b1;
        sleep_ack = 1'b0;
        
        case (current_state)
            ISOLATE: begin
                isolate_n = 1'b0;  // 激活隔离
            end
            
            POWER_DOWN, SLEEP: begin
                isolate_n = 1'b0;
                pwr_switch_n = 1'b1;  // 关闭电源
                sleep_ack = 1'b1;
            end
            
            POWER_UP: begin
                isolate_n = 1'b0;
                pwr_switch_n = 1'b0;  // 打开电源
            end
            
            RESET: begin
                isolate_n = 1'b0;
                reset_n = 1'b0;  // 复位
            end
        endcase
    end

endmodule
            </div>

            <div class="exercise">
                <h4>练习题集 8</h4>
                
                <div class="question">
                    <p><strong>题目8.1：</strong>某NPU芯片采用7nm工艺，芯片面积100mm²，功耗50W。计算功耗密度，并分析可能的散热挑战。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p>功耗密度计算：</p>
                        <ul>
                            <li>功耗密度 = 50W / 100mm² = 0.5 W/mm²</li>
                            <li>这是非常高的功耗密度，接近现代处理器的极限</li>
                        </ul>
                        <p>散热挑战：</p>
                        <ol>
                            <li><strong>热点问题：</strong>MAC阵列区域可能出现局部热点，温度可能超过100°C</li>
                            <li><strong>封装要求：</strong>需要高性能封装，如flip-chip + 热界面材料</li>
                            <li><strong>散热方案：</strong>可能需要主动散热（风扇）或液冷</li>
                            <li><strong>可靠性影响：</strong>高温会加速电迁移，影响芯片寿命</li>
                        </ol>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目8.2：</strong>设计一个简单的电源网格，为16×16的MAC阵列供电。每个MAC单元功耗100mW，电源电压0.8V。计算所需的电源线宽度。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p>计算步骤：</p>
                        <ol>
                            <li>总功耗：16 × 16 × 100mW = 25.6W</li>
                            <li>总电流：I = P/V = 25.6W / 0.8V = 32A</li>
                            <li>假设金属层电流密度限制：2mA/μm</li>
                            <li>所需总宽度：32A / 2mA/μm = 16,000μm = 16mm</li>
                            <li>使用多条电源线分布：假设使用32条电源线</li>
                            <li>每条宽度：16mm / 32 = 500μm</li>
                        </ol>
                        <p><strong>设计建议：</strong>使用网格状电源分布，垂直和水平各16条500μm宽的电源线。</p>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目8.3：</strong>某NPU设计中，关键路径延迟为900ps，其中逻辑延迟400ps，互连延迟500ps。如何优化以达到1GHz的目标频率？</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p>当前时序裕量：1000ps - 900ps = 100ps（已满足1GHz）</p>
                        <p>但裕量太小，建议优化：</p>
                        <ol>
                            <li><strong>逻辑优化（减少100ps）：</strong>
                                <ul>
                                    <li>使用低Vt单元替换关键路径</li>
                                    <li>逻辑重构，减少级数</li>
                                    <li>使用复合门减少延迟</li>
                                </ul>
                            </li>
                            <li><strong>互连优化（减少150ps）：</strong>
                                <ul>
                                    <li>增加驱动buffer尺寸</li>
                                    <li>使用更高金属层（低电阻）</li>
                                    <li>插入中继器（repeater）</li>
                                    <li>减少线长（布局优化）</li>
                                </ul>
                            </li>
                            <li><strong>目标：</strong>总延迟650ps，时序裕量350ps（35%）</li>
                        </ol>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目8.4：</strong>编写一个简单的时钟门控单元（Clock Gating Cell），并说明其在NPU中的应用。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module clock_gating_cell (
    input wire clk,
    input wire enable,
    input wire test_enable,  // DFT信号
    output wire gclk
);
    
    reg enable_latch;
    
    // Latch防止毛刺
    always @(clk or enable or test_enable) begin
        if (!clk) begin
            enable_latch <= enable | test_enable;
        end
    end
    
    // AND门输出门控时钟
    assign gclk = clk & enable_latch;
    
    // 综合指令
    // synthesis attribute clock_gating_cell of clock_gating_cell is true
    
endmodule

// NPU中的应用示例
module mac_unit_with_cg (
    input wire clk,
    input wire rst_n,
    input wire enable,      // 计算使能
    input wire [7:0] a,
    input wire [7:0] b,
    output reg [15:0] result
);
    
    wire gclk;
    
    // 实例化时钟门控
    clock_gating_cell cg_inst (
        .clk(clk),
        .enable(enable),
        .test_enable(1'b0),
        .gclk(gclk)
    );
    
    // 使用门控时钟
    always @(posedge gclk or negedge rst_n) begin
        if (!rst_n) begin
            result <= 16'd0;
        end else begin
            result <= a * b;
        end
    end
    
endmodule
                        </div>
                        <p><strong>NPU应用场景：</strong></p>
                        <ul>
                            <li>MAC阵列的动态关断：当某些MAC单元空闲时关闭时钟</li>
                            <li>层级时钟门控：整个计算簇的时钟控制</li>
                            <li>功耗节省：可节省20-40%的动态功耗</li>
                        </ul>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目8.5：</strong>分析并设计一个NPU芯片的IO规划，需要支持：DDR4接口（128位）、PCIe Gen4 x16、千兆以太网、JTAG调试。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p><strong>IO需求分析：</strong></p>
                        <table>
                            <tr>
                                <th>接口</th>
                                <th>信号数量</th>
                                <th>IO类型</th>
                                <th>位置建议</th>
                            </tr>
                            <tr>
                                <td>DDR4-3200</td>
                                <td>~280 pins</td>
                                <td>SSTL</td>
                                <td>芯片一侧（最短走线）</td>
                            </tr>
                            <tr>
                                <td>PCIe Gen4 x16</td>
                                <td>~164 pins</td>
                                <td>差分对</td>
                                <td>靠近边缘（易于走线）</td>
                            </tr>
                            <tr>
                                <td>千兆以太网</td>
                                <td>~16 pins</td>
                                <td>LVDS</td>
                                <td>任意角落</td>
                            </tr>
                            <tr>
                                <td>JTAG</td>
                                <td>5 pins</td>
                                <td>LVCMOS</td>
                                <td>便于访问的位置</td>
                            </tr>
                            <tr>
                                <td>电源/地</td>
                                <td>~200 pins</td>
                                <td>Power</td>
                                <td>均匀分布</td>
                            </tr>
                        </table>
                        
                        <p><strong>IO规划方案：</strong></p>
                        <div class="code-block">
芯片IO布局（俯视图）：
        North (DDR4接口)
     +-------------------+
     |  D D D ... D D D  |
     |D                 P|  East
West |D    NPU Core     C| (PCIe)
     |R                 I|
     |4                 e|
     |  G G J J J E E E  |
     +-------------------+
        South (GPIO/JTAG/Ethernet)

布局原则：
1. DDR4放北侧：最短距离到内存控制器
2. PCIe放东侧：便于板级走线到插槽
3. 低速IO放南侧：JTAG方便调试访问
4. 电源均匀分布四周：降低IR drop
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <div id="chapter9" class="chapter">
            <h2>第9章：软件栈与编译优化</h2>
            
            <p>NPU的硬件性能再强，也需要优秀的软件栈才能充分发挥。本章深入探讨NPU软件栈的架构设计、编译优化技术，以及如何实现高效的软硬件协同。</p>

            <h3>9.1 NPU软件栈架构</h3>
            
            <p>NPU软件栈是连接上层AI框架和底层硬件的桥梁。一个完整的软件栈需要处理模型解析、图优化、算子映射、内存管理、指令生成等复杂任务。</p>

            <h4>9.1.1 软件栈分层架构</h4>
            <div class="code-block">
// NPU软件栈典型架构
┌─────────────────────────────────────────┐
│      AI Frameworks (TensorFlow/PyTorch) │
├─────────────────────────────────────────┤
│         Graph Representation            │
│         (ONNX, TorchScript)            │
├─────────────────────────────────────────┤
│         High-Level IR (HIR)            │
│     (Graph Optimization Pass)          │
├─────────────────────────────────────────┤
│         Mid-Level IR (MIR)             │
│    (Operator Fusion, Tiling)          │
├─────────────────────────────────────────┤
│         Low-Level IR (LIR)             │
│   (Memory Allocation, Scheduling)      │
├─────────────────────────────────────────┤
│      Code Generation Backend           │
│    (NPU Instruction Generation)        │
├─────────────────────────────────────────┤
│         Runtime Library                │
│    (Execution, Memory Management)      │
├─────────────────────────────────────────┤
│         NPU Hardware                   │
└─────────────────────────────────────────┘
            </div>

            <h4>9.1.2 关键组件功能</h4>
            <div class="info-box">
                <p><strong>软件栈核心组件：</strong></p>
                <ul>
                    <li><strong>前端解析器：</strong>支持多种框架模型格式，转换为统一的内部表示</li>
                    <li><strong>图优化器：</strong>执行算子融合、常量折叠、死代码消除等优化</li>
                    <li><strong>量化工具：</strong>支持训练后量化和量化感知训练</li>
                    <li><strong>内存分配器：</strong>优化片上内存使用，最小化数据搬移</li>
                    <li><strong>指令调度器：</strong>生成高效的指令序列，最大化硬件利用率</li>
                    <li><strong>运行时系统：</strong>管理任务执行、内存管理、多核调度</li>
                </ul>
            </div>

            <h3>9.2 计算图优化</h3>
            
            <p>计算图优化是NPU编译器的核心功能，通过各种变换技术，将原始的计算图转换为更适合硬件执行的形式。</p>

            <h4>9.2.1 算子融合技术</h4>
            <div class="code-block">
// 算子融合示例：Conv + BN + ReLU融合
// 原始计算图
class OriginalGraph:
    def forward(self, x):
        # 卷积操作
        conv_out = self.conv2d(x)  # 需要写回内存
        # 批归一化
        bn_out = self.batch_norm(conv_out)  # 需要读写内存
        # 激活函数
        relu_out = self.relu(bn_out)  # 需要读写内存
        return relu_out

// 融合后的计算图
class FusedGraph:
    def forward(self, x):
        # 融合的算子，一次内存读写完成三个操作
        return self.conv_bn_relu_fused(x)

// 融合实现（伪代码）
def conv_bn_relu_fused(input, conv_weight, bn_params):
    # 在NPU内部完成所有计算
    for (oc in output_channels):
        for (oh, ow in output_positions):
            # 卷积计算
            acc = 0
            for (ic, kh, kw in kernel):
                acc += input[ic][oh+kh][ow+kw] * conv_weight[oc][ic][kh][kw]
            
            # BN计算（在线融合）
            acc = (acc - bn_mean[oc]) / sqrt(bn_var[oc] + eps)
            acc = acc * bn_scale[oc] + bn_bias[oc]
            
            # ReLU计算
            output[oc][oh][ow] = max(0, acc)
    
    return output
            </div>

            <h4>9.2.2 图优化策略</h4>
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>优化技术</th>
                            <th>描述</th>
                            <th>收益</th>
                            <th>适用场景</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>算子融合</td>
                            <td>将多个算子合并为一个</td>
                            <td>减少内存访问</td>
                            <td>连续的element-wise操作</td>
                        </tr>
                        <tr>
                            <td>常量折叠</td>
                            <td>预计算常量表达式</td>
                            <td>减少运行时计算</td>
                            <td>包含常量的子图</td>
                        </tr>
                        <tr>
                            <td>公共子表达式消除</td>
                            <td>复用相同计算结果</td>
                            <td>减少重复计算</td>
                            <td>重复的计算模式</td>
                        </tr>
                        <tr>
                            <td>死代码消除</td>
                            <td>删除无用计算</td>
                            <td>减少计算量</td>
                            <td>条件分支、未使用输出</td>
                        </tr>
                        <tr>
                            <td>布局转换优化</td>
                            <td>优化数据布局</td>
                            <td>提高访存效率</td>
                            <td>不同算子间的数据传递</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h3>9.3 内存优化技术</h3>
            
            <p>内存带宽是NPU的主要瓶颈。高效的内存管理和优化技术对于发挥NPU性能至关重要。</p>

            <h4>9.3.1 内存分配策略</h4>
            <div class="code-block">
// 内存池管理器
class MemoryPoolManager {
public:
    struct MemoryBlock {
        size_t offset;
        size_t size;
        int lifetime_start;
        int lifetime_end;
        bool is_allocated;
    };
    
    // 内存分配算法
    size_t allocate(size_t size, int start_time, int end_time) {
        // 1. 首先尝试复用已释放的内存块
        for (auto& block : memory_blocks) {
            if (!block.is_allocated && 
                block.size >= size &&
                (block.lifetime_end < start_time || 
                 block.lifetime_start > end_time)) {
                block.is_allocated = true;
                block.lifetime_start = start_time;
                block.lifetime_end = end_time;
                return block.offset;
            }
        }
        
        // 2. 分配新的内存块
        size_t offset = findFreeSpace(size);
        memory_blocks.push_back({
            offset, size, start_time, end_time, true
        });
        
        return offset;
    }
    
    // 内存碎片整理
    void defragment() {
        // 基于生命周期的内存压缩
        std::sort(memory_blocks.begin(), memory_blocks.end(),
            [](const MemoryBlock& a, const MemoryBlock& b) {
                return a.lifetime_start < b.lifetime_start;
            });
        
        // 重新排列内存布局
        size_t current_offset = 0;
        for (auto& block : memory_blocks) {
            if (block.is_allocated) {
                block.offset = current_offset;
                current_offset += block.size;
            }
        }
    }
    
private:
    std::vector<MemoryBlock> memory_blocks;
    size_t total_memory_size;
};
            </div>

            <h4>9.3.2 数据布局优化</h4>
            <div class="info-box">
                <p><strong>常见数据布局格式：</strong></p>
                <ul>
                    <li><strong>NCHW：</strong>批次-通道-高度-宽度，适合卷积运算</li>
                    <li><strong>NHWC：</strong>批次-高度-宽度-通道，适合深度可分离卷积</li>
                    <li><strong>NC/HW[n]c：</strong>分块布局，适合SIMD指令</li>
                    <li><strong>Custom Layout：</strong>NPU特定的优化布局</li>
                </ul>
            </div>

            <div class="code-block">
// 数据布局转换优化
class LayoutOptimizer {
public:
    // 分析最优布局
    Layout analyzeOptimalLayout(const Graph& graph) {
        std::map<Layout, float> layout_costs;
        
        // 遍历所有可能的布局
        for (auto layout : {NCHW, NHWC, NCHW16c, CUSTOM}) {
            float cost = 0;
            
            // 计算每个算子的执行成本
            for (auto& op : graph.operators) {
                cost += getOperatorCost(op, layout);
            }
            
            // 计算布局转换成本
            for (auto& edge : graph.edges) {
                if (requiresTranspose(edge, layout)) {
                    cost += getTransposeCost(edge);
                }
            }
            
            layout_costs[layout] = cost;
        }
        
        // 返回成本最低的布局
        return std::min_element(layout_costs.begin(), layout_costs.end(),
            [](const auto& a, const auto& b) {
                return a.second < b.second;
            })->first;
    }
    
    // 插入布局转换节点
    void insertLayoutTransforms(Graph& graph, const Layout& target_layout) {
        for (auto& edge : graph.edges) {
            if (edge.src_layout != target_layout || 
                edge.dst_layout != target_layout) {
                // 插入转换节点
                auto transform_op = createTransformOp(
                    edge.src_layout, target_layout
                );
                graph.insertOperator(transform_op, edge);
            }
        }
    }
};
            </div>

            <h3>9.4 指令生成与调度</h3>
            
            <p>将优化后的计算图转换为NPU可执行的指令序列，需要考虑指令级并行、数据依赖关系和硬件资源约束。</p>

            <h4>9.4.1 指令调度算法</h4>
            <div class="code-block">
// NPU指令调度器
class InstructionScheduler {
public:
    struct Instruction {
        enum Type { LOAD, STORE, COMPUTE, SYNC };
        Type type;
        int cycle_start;
        int cycle_end;
        std::vector<int> dependencies;
        std::vector<int> resources;  // 使用的硬件资源
    };
    
    // 基于资源约束的指令调度
    std::vector<Instruction> schedule(const std::vector<Instruction>& instructions) {
        // 构建依赖图
        DependencyGraph dep_graph(instructions);
        
        // 初始化就绪队列
        std::priority_queue<int, std::vector<int>, ComparePriority> ready_queue;
        std::vector<bool> scheduled(instructions.size(), false);
        std::vector<int> finish_time(instructions.size(), 0);
        
        // 将无依赖的指令加入就绪队列
        for (int i = 0; i < instructions.size(); i++) {
            if (dep_graph.getPredecessors(i).empty()) {
                ready_queue.push(i);
            }
        }
        
        // 资源使用表
        ResourceTable resource_table;
        int current_cycle = 0;
        
        // 调度主循环
        while (!ready_queue.empty()) {
            int inst_id = ready_queue.top();
            ready_queue.pop();
            
            // 找到最早可以执行的时间
            int earliest_start = current_cycle;
            for (int pred : dep_graph.getPredecessors(inst_id)) {
                earliest_start = std::max(earliest_start, finish_time[pred]);
            }
            
            // 检查资源冲突
            int start_cycle = resource_table.findAvailableSlot(
                instructions[inst_id].resources, 
                earliest_start,
                instructions[inst_id].cycle_end - instructions[inst_id].cycle_start
            );
            
            // 分配资源并调度
            instructions[inst_id].cycle_start = start_cycle;
            instructions[inst_id].cycle_end = start_cycle + 
                (instructions[inst_id].cycle_end - instructions[inst_id].cycle_start);
            
            resource_table.allocate(instructions[inst_id]);
            scheduled[inst_id] = true;
            finish_time[inst_id] = instructions[inst_id].cycle_end;
            
            // 更新就绪队列
            for (int succ : dep_graph.getSuccessors(inst_id)) {
                bool ready = true;
                for (int pred : dep_graph.getPredecessors(succ)) {
                    if (!scheduled[pred]) {
                        ready = false;
                        break;
                    }
                }
                if (ready) {
                    ready_queue.push(succ);
                }
            }
        }
        
        return instructions;
    }
};
            </div>

            <h4>9.4.2 指令级优化</h4>
            <div class="warning-box">
                <p><strong>NPU指令优化技术：</strong></p>
                <ul>
                    <li><strong>指令合并：</strong>将多个简单指令合并为复合指令</li>
                    <li><strong>软件流水线：</strong>重叠不同迭代的指令执行</li>
                    <li><strong>双缓冲：</strong>计算与数据传输并行</li>
                    <li><strong>向量化：</strong>利用SIMD指令处理多个数据</li>
                </ul>
            </div>

            <h3>9.5 量化与精度优化</h3>
            
            <p>量化是将浮点模型转换为低精度定点模型的过程，对于NPU的性能和功耗优化至关重要。</p>

            <h4>9.5.1 量化方法</h4>
            <div class="code-block">
// 量化框架实现
class QuantizationFramework {
public:
    // 对称量化
    struct SymmetricQuantizer {
        float scale;
        int bit_width;
        
        int quantize(float value) {
            int q_max = (1 << (bit_width - 1)) - 1;
            int q_min = -(1 << (bit_width - 1));
            
            int q_value = std::round(value / scale);
            return std::clamp(q_value, q_min, q_max);
        }
        
        float dequantize(int q_value) {
            return q_value * scale;
        }
        
        // 计算量化参数
        void calibrate(const std::vector<float>& values) {
            float max_abs = 0;
            for (float v : values) {
                max_abs = std::max(max_abs, std::abs(v));
            }
            
            int q_max = (1 << (bit_width - 1)) - 1;
            scale = max_abs / q_max;
        }
    };
    
    // 非对称量化
    struct AsymmetricQuantizer {
        float scale;
        int zero_point;
        int bit_width;
        
        int quantize(float value) {
            int q_max = (1 << bit_width) - 1;
            int q_min = 0;
            
            int q_value = std::round(value / scale + zero_point);
            return std::clamp(q_value, q_min, q_max);
        }
        
        float dequantize(int q_value) {
            return (q_value - zero_point) * scale;
        }
        
        // 计算量化参数
        void calibrate(const std::vector<float>& values) {
            float min_val = *std::min_element(values.begin(), values.end());
            float max_val = *std::max_element(values.begin(), values.end());
            
            int q_max = (1 << bit_width) - 1;
            scale = (max_val - min_val) / q_max;
            zero_point = std::round(-min_val / scale);
        }
    };
    
    // 混合精度量化
    void mixedPrecisionQuantize(Graph& graph) {
        // 敏感度分析
        std::map<std::string, float> layer_sensitivity;
        
        for (auto& layer : graph.layers) {
            // 计算每层对精度的敏感度
            float sensitivity = analyzeSensitivity(layer);
            layer_sensitivity[layer.name] = sensitivity;
        }
        
        // 基于敏感度分配位宽
        for (auto& layer : graph.layers) {
            if (layer_sensitivity[layer.name] > 0.9) {
                layer.quantization_bits = 16;  // 高敏感度层使用高精度
            } else if (layer_sensitivity[layer.name] > 0.5) {
                layer.quantization_bits = 8;
            } else {
                layer.quantization_bits = 4;   // 低敏感度层使用低精度
            }
        }
    }
};
            </div>

            <h4>9.5.2 量化感知训练</h4>
            <div class="code-block">
// 量化感知训练（QAT）实现
class QuantizationAwareTraining {
public:
    // 伪量化操作
    class FakeQuantize : public torch::nn::Module {
    public:
        FakeQuantize(int num_bits, bool symmetric = true) 
            : num_bits_(num_bits), symmetric_(symmetric) {
            if (symmetric_) {
                q_max_ = (1 << (num_bits_ - 1)) - 1;
                q_min_ = -(1 << (num_bits_ - 1));
            } else {
                q_max_ = (1 << num_bits_) - 1;
                q_min_ = 0;
            }
        }
        
        torch::Tensor forward(torch::Tensor x) {
            // 计算scale和zero_point
            torch::Tensor scale, zero_point;
            
            if (symmetric_) {
                auto max_val = x.abs().max();
                scale = max_val / q_max_;
                zero_point = torch::zeros_like(scale);
            } else {
                auto min_val = x.min();
                auto max_val = x.max();
                scale = (max_val - min_val) / (q_max_ - q_min_);
                zero_point = torch::round(-min_val / scale);
            }
            
            // 量化和反量化
            auto x_int = torch::round(x / scale + zero_point);
            x_int = torch::clamp(x_int, q_min_, q_max_);
            auto x_dequant = (x_int - zero_point) * scale;
            
            // 直通估计器（STE）用于反向传播
            return x + (x_dequant - x).detach();
        }
        
    private:
        int num_bits_;
        bool symmetric_;
        float q_max_, q_min_;
    };
    
    // 量化感知的卷积层
    class QuantizedConv2d : public torch::nn::Module {
    public:
        QuantizedConv2d(int in_channels, int out_channels, 
                       int kernel_size, int weight_bits = 8, 
                       int activation_bits = 8) {
            conv_ = torch::nn::Conv2d(
                torch::nn::Conv2dOptions(in_channels, out_channels, kernel_size)
            );
            
            weight_quantizer_ = FakeQuantize(weight_bits, true);
            activation_quantizer_ = FakeQuantize(activation_bits, false);
            
            register_module("conv", conv_);
        }
        
        torch::Tensor forward(torch::Tensor x) {
            // 量化输入激活
            x = activation_quantizer_->forward(x);
            
            // 量化权重
            auto quantized_weight = weight_quantizer_->forward(conv_->weight);
            
            // 执行量化卷积
            return torch::nn::functional::conv2d(
                x, quantized_weight, conv_->bias,
                conv_->options.stride(),
                conv_->options.padding()
            );
        }
        
    private:
        torch::nn::Conv2d conv_{nullptr};
        std::shared_ptr<FakeQuantize> weight_quantizer_;
        std::shared_ptr<FakeQuantize> activation_quantizer_;
    };
};
            </div>

            <h3>9.6 运行时系统设计</h3>
            
            <p>运行时系统负责在NPU上执行编译后的模型，管理内存、调度任务、处理异常等。</p>

            <h4>9.6.1 运行时架构</h4>
            <div class="code-block">
// NPU运行时系统
class NPURuntime {
public:
    // 执行上下文
    class ExecutionContext {
    public:
        ExecutionContext(NPUDevice* device) : device_(device) {
            // 初始化内存池
            memory_pool_ = std::make_unique<MemoryPool>(
                device->getMemorySize()
            );
            
            // 创建命令队列
            cmd_queue_ = device->createCommandQueue();
            
            // 初始化性能计数器
            perf_counter_ = std::make_unique<PerformanceCounter>();
        }
        
        // 执行推理
        void execute(const CompiledModel& model, 
                    const std::vector<Tensor>& inputs,
                    std::vector<Tensor>& outputs) {
            // 1. 分配输入/输出内存
            auto input_buffers = allocateBuffers(inputs);
            auto output_buffers = allocateBuffers(model.getOutputShapes());
            
            // 2. 拷贝输入数据到设备
            for (size_t i = 0; i < inputs.size(); i++) {
                device_->copyHostToDevice(
                    inputs[i].data(), 
                    input_buffers[i],
                    inputs[i].size()
                );
            }
            
            // 3. 构建执行命令
            CommandBuffer cmd_buffer;
            buildCommandBuffer(cmd_buffer, model, input_buffers, output_buffers);
            
            // 4. 提交执行
            auto fence = cmd_queue_->submit(cmd_buffer);
            
            // 5. 等待完成
            fence->wait();
            
            // 6. 拷贝输出数据
            outputs.resize(output_buffers.size());
            for (size_t i = 0; i < outputs.size(); i++) {
                outputs[i].resize(model.getOutputShapes()[i]);
                device_->copyDeviceToHost(
                    output_buffers[i],
                    outputs[i].data(),
                    outputs[i].size()
                );
            }
            
            // 7. 更新性能统计
            perf_counter_->update(fence->getTimingInfo());
        }
        
    private:
        NPUDevice* device_;
        std::unique_ptr<MemoryPool> memory_pool_;
        std::unique_ptr<CommandQueue> cmd_queue_;
        std::unique_ptr<PerformanceCounter> perf_counter_;
        
        void buildCommandBuffer(CommandBuffer& cmd_buffer,
                              const CompiledModel& model,
                              const std::vector<DeviceBuffer>& inputs,
                              const std::vector<DeviceBuffer>& outputs) {
            // 遍历所有指令
            for (const auto& inst : model.getInstructions()) {
                switch (inst.opcode) {
                    case OPCODE_CONV:
                        cmd_buffer.addConvCommand(inst.params, 
                            inputs[inst.input_idx],
                            outputs[inst.output_idx]);
                        break;
                    
                    case OPCODE_GEMM:
                        cmd_buffer.addGemmCommand(inst.params,
                            inputs[inst.input_idx],
                            outputs[inst.output_idx]);
                        break;
                    
                    case OPCODE_ACTIVATION:
                        cmd_buffer.addActivationCommand(inst.params,
                            inputs[inst.input_idx],
                            outputs[inst.output_idx]);
                        break;
                    
                    case OPCODE_SYNC:
                        cmd_buffer.addSyncCommand();
                        break;
                }
            }
        }
    };
    
    // 多核调度器
    class MultiCoreScheduler {
    public:
        void scheduleSubgraphs(const Graph& graph, 
                             std::vector<NPUCore*>& cores) {
            // 1. 图分割
            auto subgraphs = partitionGraph(graph, cores.size());
            
            // 2. 负载均衡
            balanceWorkload(subgraphs, cores);
            
            // 3. 生成同步点
            insertSynchronization(subgraphs);
            
            // 4. 分配到各个核心
            for (size_t i = 0; i < cores.size(); i++) {
                cores[i]->loadSubgraph(subgraphs[i]);
            }
        }
        
    private:
        std::vector<Subgraph> partitionGraph(const Graph& graph, int num_cores) {
            // 基于最小割的图分割算法
            GraphPartitioner partitioner;
            return partitioner.partition(graph, num_cores);
        }
        
        void balanceWorkload(std::vector<Subgraph>& subgraphs,
                           const std::vector<NPUCore*>& cores) {
            // 估算每个子图的计算量
            std::vector<float> workloads(subgraphs.size());
            for (size_t i = 0; i < subgraphs.size(); i++) {
                workloads[i] = estimateWorkload(subgraphs[i]);
            }
            
            // 动态调整分割边界
            while (!isBalanced(workloads)) {
                adjustPartitionBoundaries(subgraphs, workloads);
            }
        }
    };
};
            </div>

            <h3>9.7 性能分析与调优</h3>
            
            <p>性能分析工具帮助开发者理解模型在NPU上的执行情况，找出性能瓶颈并进行优化。</p>

            <h4>9.7.1 性能分析框架</h4>
            <div class="code-block">
// 性能分析器
class NPUProfiler {
public:
    struct LayerProfile {
        std::string name;
        float compute_time_ms;
        float memory_read_mb;
        float memory_write_mb;
        float utilization;
        std::map<std::string, float> metrics;
    };
    
    // 开始性能分析
    void startProfiling() {
        // 清空之前的数据
        layer_profiles_.clear();
        
        // 启用硬件性能计数器
        enableHardwareCounters();
        
        // 记录开始时间
        start_time_ = getCurrentTime();
        is_profiling_ = true;
    }
    
    // 记录层执行信息
    void recordLayer(const std::string& layer_name,
                    const ExecutionStats& stats) {
        if (!is_profiling_) return;
        
        LayerProfile profile;
        profile.name = layer_name;
        profile.compute_time_ms = stats.compute_cycles / clock_freq_ * 1000;
        profile.memory_read_mb = stats.memory_read_bytes / (1024.0 * 1024.0);
        profile.memory_write_mb = stats.memory_write_bytes / (1024.0 * 1024.0);
        
        // 计算硬件利用率
        profile.utilization = calculateUtilization(stats);
        
        // 收集详细指标
        profile.metrics["mac_efficiency"] = 
            stats.mac_operations / (stats.compute_cycles * max_mac_per_cycle_);
        profile.metrics["memory_bandwidth_utilization"] = 
            (stats.memory_read_bytes + stats.memory_write_bytes) / 
            (stats.compute_cycles / clock_freq_ * memory_bandwidth_);
        profile.metrics["cache_hit_rate"] = 
            stats.cache_hits / float(stats.cache_hits + stats.cache_misses);
        
        layer_profiles_.push_back(profile);
    }
    
    // 生成性能报告
    void generateReport(const std::string& filename) {
        std::ofstream report(filename);
        
        report << "NPU Performance Analysis Report\n";
        report << "================================\n\n";
        
        // 总体统计
        float total_time = 0;
        float total_memory = 0;
        for (const auto& profile : layer_profiles_) {
            total_time += profile.compute_time_ms;
            total_memory += profile.memory_read_mb + profile.memory_write_mb;
        }
        
        report << "Total Execution Time: " << total_time << " ms\n";
        report << "Total Memory Transfer: " << total_memory << " MB\n";
        report << "Average Throughput: " << 
                  (total_ops_ / total_time / 1e6) << " GOPS\n\n";
        
        // 层级详细信息
        report << "Layer-wise Breakdown:\n";
        report << std::setw(30) << "Layer" 
               << std::setw(15) << "Time (ms)"
               << std::setw(15) << "Time %"
               << std::setw(15) << "Utilization"
               << std::setw(20) << "Memory (MB)\n";
        
        for (const auto& profile : layer_profiles_) {
            report << std::setw(30) << profile.name
                   << std::setw(15) << std::fixed << std::setprecision(2) 
                   << profile.compute_time_ms
                   << std::setw(15) << std::fixed << std::setprecision(1)
                   << (profile.compute_time_ms / total_time * 100) << "%"
                   << std::setw(15) << std::fixed << std::setprecision(1)
                   << (profile.utilization * 100) << "%"
                   << std::setw(20) << std::fixed << std::setprecision(2)
                   << (profile.memory_read_mb + profile.memory_write_mb) << "\n";
        }
        
        // 性能瓶颈分析
        report << "\nPerformance Bottlenecks:\n";
        identifyBottlenecks(report);
        
        // 优化建议
        report << "\nOptimization Suggestions:\n";
        generateOptimizationSuggestions(report);
    }
    
private:
    std::vector<LayerProfile> layer_profiles_;
    bool is_profiling_ = false;
    double start_time_;
    float clock_freq_;
    float memory_bandwidth_;
    int max_mac_per_cycle_;
    int64_t total_ops_;
    
    void identifyBottlenecks(std::ofstream& report) {
        // 找出执行时间最长的层
        auto max_time_layer = std::max_element(
            layer_profiles_.begin(), layer_profiles_.end(),
            [](const LayerProfile& a, const LayerProfile& b) {
                return a.compute_time_ms < b.compute_time_ms;
            });
        
        report << "- Slowest layer: " << max_time_layer->name 
               << " (" << max_time_layer->compute_time_ms << " ms)\n";
        
        // 找出内存带宽受限的层
        for (const auto& profile : layer_profiles_) {
            if (profile.metrics.at("memory_bandwidth_utilization") > 0.8) {
                report << "- Memory bandwidth bottleneck in layer: " 
                       << profile.name << "\n";
            }
        }
        
        // 找出利用率低的层
        for (const auto& profile : layer_profiles_) {
            if (profile.utilization < 0.5) {
                report << "- Low utilization in layer: " << profile.name 
                       << " (" << (profile.utilization * 100) << "%)\n";
            }
        }
    }
};
            </div>

            <div class="exercise">
                <h4>练习题集 9</h4>
                
                <div class="question">
                    <p><strong>题目9.1：</strong>解释算子融合的原理，并举例说明Conv+BN+ReLU融合能带来多少内存访问的节省。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p>算子融合原理：将多个连续的算子合并为一个复合算子，在片上完成所有计算，避免中间结果写回内存。</p>
                        
                        <p>Conv+BN+ReLU融合的内存访问分析：</p>
                        <p>假设特征图大小为H×W×C，数据类型为FP16（2字节）</p>
                        
                        <p><strong>未融合时：</strong></p>
                        <ul>
                            <li>Conv输出写内存：H×W×C×2 字节</li>
                            <li>BN读Conv输出：H×W×C×2 字节</li>
                            <li>BN输出写内存：H×W×C×2 字节</li>
                            <li>ReLU读BN输出：H×W×C×2 字节</li>
                            <li>ReLU输出写内存：H×W×C×2 字节</li>
                            <li>总计：5×H×W×C×2 字节</li>
                        </ul>
                        
                        <p><strong>融合后：</strong></p>
                        <ul>
                            <li>只有最终结果写内存：H×W×C×2 字节</li>
                            <li>节省：80%的内存访问</li>
                        </ul>
                        
                        <p>实际例子：224×224×64的特征图，可节省约24.5MB的内存访问。</p>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目9.2：</strong>设计一个简单的内存分配算法，支持tensor的生命周期管理和内存复用。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
class SimpleMemoryAllocator {
private:
    struct Allocation {
        size_t offset;
        size_t size;
        int start_time;
        int end_time;
    };
    
    size_t total_size;
    std::vector<Allocation> allocations;
    
public:
    SimpleMemoryAllocator(size_t size) : total_size(size) {}
    
    size_t allocate(size_t size, int start, int end) {
        // 按结束时间排序现有分配
        std::sort(allocations.begin(), allocations.end(),
            [](const Allocation& a, const Allocation& b) {
                return a.end_time < b.end_time;
            });
        
        // 尝试找到可复用的内存块
        for (auto& alloc : allocations) {
            if (alloc.end_time <= start && alloc.size >= size) {
                // 复用这块内存
                size_t offset = alloc.offset;
                alloc.start_time = start;
                alloc.end_time = end;
                alloc.size = size;
                return offset;
            }
        }
        
        // 找不到可复用的，分配新的
        size_t offset = 0;
        if (!allocations.empty()) {
            // 找到第一个空闲位置
            std::sort(allocations.begin(), allocations.end(),
                [](const Allocation& a, const Allocation& b) {
                    return a.offset < b.offset;
                });
            
            for (size_t i = 0; i < allocations.size(); i++) {
                if (i == 0 && allocations[i].offset >= size) {
                    offset = 0;
                    break;
                }
                if (i < allocations.size() - 1) {
                    size_t gap_start = allocations[i].offset + allocations[i].size;
                    size_t gap_end = allocations[i+1].offset;
                    if (gap_end - gap_start >= size) {
                        offset = gap_start;
                        break;
                    }
                } else {
                    offset = allocations[i].offset + allocations[i].size;
                }
            }
        }
        
        // 检查是否超出总内存
        if (offset + size > total_size) {
            throw std::runtime_error("Out of memory");
        }
        
        allocations.push_back({offset, size, start, end});
        return offset;
    }
    
    size_t getMaxMemoryUsage() {
        size_t max_usage = 0;
        
        // 对每个时间点计算内存使用
        std::set<int> time_points;
        for (const auto& alloc : allocations) {
            time_points.insert(alloc.start_time);
            time_points.insert(alloc.end_time);
        }
        
        for (int t : time_points) {
            size_t usage = 0;
            for (const auto& alloc : allocations) {
                if (alloc.start_time <= t && t < alloc.end_time) {
                    usage = std::max(usage, alloc.offset + alloc.size);
                }
            }
            max_usage = std::max(max_usage, usage);
        }
        
        return max_usage;
    }
};
                        </div>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目9.3：</strong>实现一个简单的INT8量化函数，支持对称和非对称量化模式。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
#include <vector>
#include <algorithm>
#include <cmath>

class INT8Quantizer {
public:
    enum Mode { SYMMETRIC, ASYMMETRIC };
    
private:
    Mode mode;
    float scale;
    int zero_point;
    
public:
    INT8Quantizer(Mode m = SYMMETRIC) : mode(m), scale(1.0f), zero_point(0) {}
    
    // 校准：计算量化参数
    void calibrate(const std::vector<float>& data) {
        if (data.empty()) return;
        
        float min_val = *std::min_element(data.begin(), data.end());
        float max_val = *std::max_element(data.begin(), data.end());
        
        if (mode == SYMMETRIC) {
            // 对称量化：zero_point = 0
            float max_abs = std::max(std::abs(min_val), std::abs(max_val));
            scale = max_abs / 127.0f;
            zero_point = 0;
        } else {
            // 非对称量化
            scale = (max_val - min_val) / 255.0f;
            zero_point = std::round(-min_val / scale);
            zero_point = std::clamp(zero_point, 0, 255);
        }
    }
    
    // 量化单个值
    int8_t quantize(float value) const {
        int quantized = std::round(value / scale + zero_point);
        
        if (mode == SYMMETRIC) {
            return static_cast<int8_t>(std::clamp(quantized, -128, 127));
        } else {
            // 非对称量化结果需要转换到int8范围
            quantized = std::clamp(quantized, 0, 255);
            return static_cast<int8_t>(quantized - 128);
        }
    }
    
    // 反量化
    float dequantize(int8_t qvalue) const {
        if (mode == SYMMETRIC) {
            return qvalue * scale;
        } else {
            // 非对称量化需要先转换回uint8范围
            int value = static_cast<int>(qvalue) + 128;
            return (value - zero_point) * scale;
        }
    }
    
    // 量化向量
    std::vector<int8_t> quantizeVector(const std::vector<float>& input) const {
        std::vector<int8_t> output(input.size());
        for (size_t i = 0; i < input.size(); i++) {
            output[i] = quantize(input[i]);
        }
        return output;
    }
    
    // 计算量化误差
    float calculateError(const std::vector<float>& original) const {
        float total_error = 0;
        for (float val : original) {
            float dequantized = dequantize(quantize(val));
            total_error += std::pow(val - dequantized, 2);
        }
        return std::sqrt(total_error / original.size());
    }
    
    // 获取量化参数
    float getScale() const { return scale; }
    int getZeroPoint() const { return zero_point; }
};

// 使用示例
void testQuantization() {
    std::vector<float> weights = {-1.5, -0.5, 0.0, 0.5, 1.5, 2.0};
    
    // 对称量化
    INT8Quantizer sym_quantizer(INT8Quantizer::SYMMETRIC);
    sym_quantizer.calibrate(weights);
    
    std::cout << "Symmetric Quantization:\n";
    std::cout << "Scale: " << sym_quantizer.getScale() << "\n";
    for (float w : weights) {
        int8_t q = sym_quantizer.quantize(w);
        float dq = sym_quantizer.dequantize(q);
        std::cout << w << " -> " << (int)q << " -> " << dq << "\n";
    }
    
    // 非对称量化
    INT8Quantizer asym_quantizer(INT8Quantizer::ASYMMETRIC);
    asym_quantizer.calibrate(weights);
    
    std::cout << "\nAsymmetric Quantization:\n";
    std::cout << "Scale: " << asym_quantizer.getScale() 
              << ", Zero Point: " << asym_quantizer.getZeroPoint() << "\n";
    for (float w : weights) {
        int8_t q = asym_quantizer.quantize(w);
        float dq = asym_quantizer.dequantize(q);
        std::cout << w << " -> " << (int)q << " -> " << dq << "\n";
    }
}
                        </div>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目9.4：</strong>设计一个简单的指令调度算法，考虑数据依赖和硬件资源限制。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
#include <vector>
#include <queue>
#include <unordered_set>

class SimpleScheduler {
public:
    struct Instruction {
        int id;
        std::string type;  // "LOAD", "COMPUTE", "STORE"
        std::vector<int> dependencies;
        int cycles;        // 执行所需周期数
        int resource;      // 所需资源类型
    };
    
    struct ScheduledInst {
        int id;
        int start_cycle;
        int end_cycle;
    };
    
private:
    // 资源使用表
    std::vector<std::vector<bool>> resource_table;
    int num_resources;
    int max_cycles;
    
public:
    SimpleScheduler(int resources, int cycles) 
        : num_resources(resources), max_cycles(cycles) {
        resource_table.resize(resources, std::vector<bool>(cycles, false));
    }
    
    std::vector<ScheduledInst> schedule(const std::vector<Instruction>& instructions) {
        std::vector<ScheduledInst> result;
        std::vector<int> finish_time(instructions.size(), -1);
        std::vector<bool> scheduled(instructions.size(), false);
        
        // 构建依赖关系图
        std::vector<std::vector<int>> dependents(instructions.size());
        std::vector<int> in_degree(instructions.size(), 0);
        
        for (size_t i = 0; i < instructions.size(); i++) {
            in_degree[i] = instructions[i].dependencies.size();
            for (int dep : instructions[i].dependencies) {
                dependents[dep].push_back(i);
            }
        }
        
        // 初始化就绪队列（使用贪心策略：优先调度执行时间长的）
        auto cmp = [&](int a, int b) {
            return instructions[a].cycles < instructions[b].cycles;
        };
        std::priority_queue<int, std::vector<int>, decltype(cmp)> ready_queue(cmp);
        
        // 将无依赖的指令加入就绪队列
        for (size_t i = 0; i < instructions.size(); i++) {
            if (in_degree[i] == 0) {
                ready_queue.push(i);
            }
        }
        
        // 调度主循环
        while (!ready_queue.empty()) {
            int inst_id = ready_queue.top();
            ready_queue.pop();
            
            const auto& inst = instructions[inst_id];
            
            // 计算最早开始时间
            int earliest_start = 0;
            for (int dep : inst.dependencies) {
                if (finish_time[dep] != -1) {
                    earliest_start = std::max(earliest_start, finish_time[dep]);
                }
            }
            
            // 找到可用的资源时间槽
            int start_cycle = findAvailableSlot(inst.resource, 
                                               earliest_start, 
                                               inst.cycles);
            
            if (start_cycle == -1 || start_cycle + inst.cycles > max_cycles) {
                // 资源不足或超出最大周期限制
                continue;
            }
            
            // 分配资源
            for (int c = start_cycle; c < start_cycle + inst.cycles; c++) {
                resource_table[inst.resource][c] = true;
            }
            
            // 记录调度结果
            finish_time[inst_id] = start_cycle + inst.cycles;
            scheduled[inst_id] = true;
            result.push_back({inst_id, start_cycle, start_cycle + inst.cycles});
            
            // 更新依赖关系，将新的就绪指令加入队列
            for (int dependent : dependents[inst_id]) {
                in_degree[dependent]--;
                if (in_degree[dependent] == 0) {
                    ready_queue.push(dependent);
                }
            }
        }
        
        return result;
    }
    
private:
    int findAvailableSlot(int resource, int start_time, int duration) {
        for (int t = start_time; t <= max_cycles - duration; t++) {
            bool available = true;
            for (int d = 0; d < duration; d++) {
                if (resource_table[resource][t + d]) {
                    available = false;
                    break;
                }
            }
            if (available) {
                return t;
            }
        }
        return -1;
    }
};

// 使用示例
void testScheduler() {
    SimpleScheduler scheduler(3, 20);  // 3个资源，20个周期
    
    std::vector<SimpleScheduler::Instruction> instructions = {
        {0, "LOAD", {}, 2, 0},          // 加载数据
        {1, "LOAD", {}, 2, 0},          // 加载权重
        {2, "COMPUTE", {0, 1}, 5, 1},   // 计算，依赖0和1
        {3, "COMPUTE", {0, 1}, 5, 1},   // 并行计算
        {4, "STORE", {2}, 2, 2},        // 存储结果
        {5, "STORE", {3}, 2, 2}         // 存储结果
    };
    
    auto scheduled = scheduler.schedule(instructions);
    
    std::cout << "Scheduled Instructions:\n";
    for (const auto& s : scheduled) {
        std::cout << "Instruction " << s.id 
                  << ": Cycle " << s.start_cycle 
                  << " - " << s.end_cycle << "\n";
    }
}
                        </div>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目9.5：</strong>分析并优化一个简单的神经网络层在NPU上的内存访问模式。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p>以1×1卷积层为例（通常用于通道数变换）：</p>
                        
                        <p><strong>原始实现的内存访问模式：</strong></p>
                        <div class="code-block">
// 朴素实现
for (int n = 0; n < N; n++) {           // batch
    for (int oc = 0; oc < C_out; oc++) { // 输出通道
        for (int h = 0; h < H; h++) {     // 高度
            for (int w = 0; w < W; w++) { // 宽度
                float sum = 0;
                for (int ic = 0; ic < C_in; ic++) { // 输入通道
                    sum += input[n][ic][h][w] * weight[oc][ic];
                }
                output[n][oc][h][w] = sum;
            }
        }
    }
}

// 内存访问分析：
// - Input: 每个元素被读取C_out次
// - Weight: 每个元素被读取N×H×W次
// - 缓存不友好：跳跃式访问input的通道维度
                        </div>
                        
                        <p><strong>优化后的实现：</strong></p>
                        <div class="code-block">
// 优化1：循环重排序，提高数据局部性
for (int n = 0; n < N; n++) {
    for (int h = 0; h < H; h++) {
        for (int w = 0; w < W; w++) {
            // 将输入数据加载到本地缓存
            float local_input[C_in];
            for (int ic = 0; ic < C_in; ic++) {
                local_input[ic] = input[n][ic][h][w];
            }
            
            // 计算所有输出通道
            for (int oc = 0; oc < C_out; oc++) {
                float sum = 0;
                // 向量化计算
                #pragma unroll 8
                for (int ic = 0; ic < C_in; ic++) {
                    sum += local_input[ic] * weight[oc][ic];
                }
                output[n][oc][h][w] = sum;
            }
        }
    }
}

// 优化2：分块（tiling）处理
const int TILE_H = 8, TILE_W = 8, TILE_OC = 32;

for (int n = 0; n < N; n++) {
    for (int h_tile = 0; h_tile < H; h_tile += TILE_H) {
        for (int w_tile = 0; w_tile < W; w_tile += TILE_W) {
            for (int oc_tile = 0; oc_tile < C_out; oc_tile += TILE_OC) {
                // 预加载权重到片上缓存
                float local_weight[TILE_OC][C_in];
                for (int oc = 0; oc < TILE_OC && oc_tile + oc < C_out; oc++) {
                    for (int ic = 0; ic < C_in; ic++) {
                        local_weight[oc][ic] = weight[oc_tile + oc][ic];
                    }
                }
                
                // 处理tile内的计算
                for (int h = 0; h < TILE_H && h_tile + h < H; h++) {
                    for (int w = 0; w < TILE_W && w_tile + w < W; w++) {
                        // 加载输入到寄存器
                        float local_input[C_in];
                        for (int ic = 0; ic < C_in; ic++) {
                            local_input[ic] = input[n][ic][h_tile + h][w_tile + w];
                        }
                        
                        // 计算输出
                        for (int oc = 0; oc < TILE_OC && oc_tile + oc < C_out; oc++) {
                            float sum = 0;
                            for (int ic = 0; ic < C_in; ic++) {
                                sum += local_input[ic] * local_weight[oc][ic];
                            }
                            output[n][oc_tile + oc][h_tile + h][w_tile + w] = sum;
                        }
                    }
                }
            }
        }
    }
}
                        </div>
                        
                        <p><strong>优化效果分析：</strong></p>
                        <ul>
                            <li>输入数据复用：从C_out次降低到C_out/TILE_OC次</li>
                            <li>权重数据复用：在每个tile内复用TILE_H×TILE_W次</li>
                            <li>缓存友好：连续访问，提高缓存命中率</li>
                            <li>向量化友好：内层循环可以SIMD并行</li>
                        </ul>
                    </div>
                </div>
            </div>
        </section>
        
    </div>

    <script>
        // JavaScript for collapsible answers
        function toggleAnswer(button) {
            const answer = button.nextElementSibling;
            if (answer.classList.contains('show')) {
                answer.classList.remove('show');
                button.textContent = '显示答案';
            } else {
                answer.classList.add('show');
                button.textContent = '隐藏答案';
            }
        }

        // Add event listeners to all toggle buttons
        document.addEventListener('DOMContentLoaded', function() {
            const toggleButtons = document.querySelectorAll('.toggle-answer');
            toggleButtons.forEach(button => {
                button.addEventListener('click', function() {
                    toggleAnswer(this);
                });
            });
        });

        // Smooth scrolling for navigation links
        document.querySelectorAll('nav a').forEach(anchor => {
            anchor.addEventListener('click', function(e) {
                e.preventDefault();
                const target = document.querySelector(this.getAttribute('href'));
                if (target) {
                    target.scrollIntoView({
                        behavior: 'smooth',
                        block: 'start'
                    });
                }
            });
        });
    </script>
</body>
</html>