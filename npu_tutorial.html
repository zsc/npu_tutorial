<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Neural Processing Unit (NPU) 设计教程</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'PingFang SC', 'Microsoft YaHei', sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: #f5f5f5;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }

        header {
            background: linear-gradient(135deg, #2c3e50 0%, #3498db 100%);
            color: white;
            padding: 40px 0;
            text-align: center;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }

        header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
        }

        nav {
            background: #34495e;
            padding: 15px 0;
            position: sticky;
            top: 0;
            z-index: 100;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }

        nav ul {
            list-style: none;
            display: flex;
            flex-wrap: wrap;
            justify-content: center;
            max-width: 1200px;
            margin: 0 auto;
        }

        nav li {
            margin: 5px 15px;
        }

        nav a {
            color: white;
            text-decoration: none;
            padding: 5px 10px;
            border-radius: 4px;
            transition: background 0.3s;
        }

        nav a:hover {
            background: #2c3e50;
        }
        
        /* Hamburger menu button */
        .nav-toggle {
            display: none;
            background: none;
            border: none;
            cursor: pointer;
            padding: 10px;
            position: absolute;
            right: 20px;
            top: 50%;
            transform: translateY(-50%);
        }
        
        .nav-toggle span {
            display: block;
            width: 25px;
            height: 3px;
            background: white;
            margin: 5px 0;
            transition: all 0.3s;
        }
        
        .nav-toggle.active span:nth-child(1) {
            transform: rotate(45deg) translate(5px, 5px);
        }
        
        .nav-toggle.active span:nth-child(2) {
            opacity: 0;
        }
        
        .nav-toggle.active span:nth-child(3) {
            transform: rotate(-45deg) translate(7px, -6px);
        }

        .chapter {
            background: white;
            margin: 20px 0;
            padding: 30px;
            border-radius: 8px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }

        .chapter h2 {
            color: #2c3e50;
            font-size: 2em;
            margin-bottom: 20px;
            padding-bottom: 10px;
            border-bottom: 3px solid #3498db;
        }

        .chapter h3 {
            color: #34495e;
            font-size: 1.5em;
            margin: 25px 0 15px 0;
        }

        .chapter h4 {
            color: #7f8c8d;
            font-size: 1.2em;
            margin: 20px 0 10px 0;
        }

        .code-block {
            background: #2c3e50;
            color: #ecf0f1;
            padding: 20px;
            border-radius: 5px;
            margin: 15px 0;
            overflow-x: auto;
            font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
            font-size: 14px;
            line-height: 1.5;
            white-space: pre-wrap;
            word-wrap: break-word;
            position: relative;
        }
        
        /* Language label */
        .code-block::before {
            content: attr(data-language);
            position: absolute;
            top: 5px;
            right: 10px;
            font-size: 12px;
            color: #95a5a6;
            text-transform: uppercase;
        }
        
        /* Syntax highlighting for different languages */
        /* Verilog/SystemVerilog */
        .code-block.verilog .keyword,
        .code-block.systemverilog .keyword {
            color: #e74c3c;
            font-weight: bold;
        }
        
        .code-block.verilog .type,
        .code-block.systemverilog .type {
            color: #3498db;
        }
        
        .code-block.verilog .comment,
        .code-block.systemverilog .comment,
        .code-block.python .comment,
        .code-block.c .comment,
        .code-block.cpp .comment {
            color: #95a5a6;
            font-style: italic;
        }
        
        .code-block.verilog .number,
        .code-block.systemverilog .number,
        .code-block.python .number,
        .code-block.c .number,
        .code-block.cpp .number {
            color: #e67e22;
        }
        
        /* Python */
        .code-block.python .keyword {
            color: #e74c3c;
            font-weight: bold;
        }
        
        .code-block.python .function {
            color: #3498db;
        }
        
        .code-block.python .string {
            color: #2ecc71;
        }
        
        /* C/C++ */
        .code-block.c .keyword,
        .code-block.cpp .keyword {
            color: #e74c3c;
            font-weight: bold;
        }
        
        .code-block.c .type,
        .code-block.cpp .type {
            color: #3498db;
        }
        
        /* General string highlighting */
        .code-block .string {
            color: #2ecc71;
        }

        .exercise {
            background: #ecf0f1;
            padding: 20px;
            border-radius: 5px;
            margin: 20px 0;
            border-left: 5px solid #3498db;
        }

        .exercise h4 {
            color: #2c3e50;
            margin-bottom: 10px;
        }

        .question {
            margin: 15px 0;
            padding: 15px;
            background: white;
            border-radius: 5px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
        }

        .answer {
            margin-top: 10px;
            padding: 15px;
            background: #e8f5e9;
            border-radius: 5px;
            display: none;
            border-left: 4px solid #4caf50;
        }

        .answer.show {
            display: block;
        }
        
        .hint {
            margin: 10px 0;
            padding: 10px 15px;
            background: #fff8dc;
            border-left: 4px solid #ffa500;
            border-radius: 5px;
            font-size: 0.95em;
        }
        
        .hint summary {
            cursor: pointer;
            font-weight: bold;
            color: #ff8c00;
            outline: none;
        }
        
        .hint summary:hover {
            color: #ff6347;
        }
        
        .hint p {
            margin-top: 10px;
            color: #666;
        }

        .toggle-answer {
            background: #3498db;
            color: white;
            border: none;
            padding: 8px 15px;
            border-radius: 4px;
            cursor: pointer;
            font-size: 14px;
            margin-top: 10px;
            transition: background 0.3s;
        }

        .toggle-answer:hover {
            background: #2980b9;
        }

        .figure {
            text-align: center;
            margin: 20px 0;
        }

        .figure img {
            max-width: 100%;
            height: auto;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }

        .figure-caption {
            color: #7f8c8d;
            font-size: 0.9em;
            margin-top: 10px;
        }

        .table-wrapper {
            overflow-x: auto;
            margin: 20px 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }

        th, td {
            padding: 12px;
            text-align: left;
            border-bottom: 1px solid #ddd;
        }

        th {
            background: #34495e;
            color: white;
            font-weight: bold;
        }

        tr:hover {
            background: #f5f5f5;
        }

        .highlight {
            background: #fff3cd;
            padding: 2px 5px;
            border-radius: 3px;
        }

        .info-box {
            background: #e3f2fd;
            border-left: 5px solid #2196f3;
            padding: 15px;
            margin: 20px 0;
            border-radius: 5px;
        }

        .warning-box {
            background: #fff3cd;
            border-left: 5px solid #ff9800;
            padding: 15px;
            margin: 20px 0;
            border-radius: 5px;
        }

        /* Mobile Responsive Design */
        @media (max-width: 768px) {
            .container {
                padding: 10px;
            }
            
            header {
                padding: 20px 10px;
            }
            
            header h1 {
                font-size: 1.5em;
            }
            
            header p {
                font-size: 0.9em;
            }
            
            .chapter {
                padding: 15px;
                margin: 10px 0;
            }
            
            .chapter h2 {
                font-size: 1.5em;
            }
            
            .chapter h3 {
                font-size: 1.2em;
            }
            
            .chapter h4 {
                font-size: 1.1em;
            }
            
            nav {
                padding: 10px 0;
                position: relative;
            }
            
            .nav-toggle {
                display: block;
            }
            
            .nav-menu {
                position: fixed;
                top: 60px;
                right: -100%;
                width: 80%;
                max-width: 300px;
                height: calc(100vh - 60px);
                background: #34495e;
                transition: right 0.3s ease;
                overflow-y: auto;
                flex-direction: column;
                padding: 20px 0;
                box-shadow: -2px 0 10px rgba(0,0,0,0.3);
            }
            
            .nav-menu.active {
                right: 0;
            }
            
            nav ul {
                flex-direction: column;
                align-items: stretch;
                padding: 0 10px;
            }
            
            nav li {
                margin: 2px 0;
            }
            
            nav a {
                display: block;
                text-align: center;
                padding: 15px;
                border-bottom: 1px solid rgba(255,255,255,0.1);
            }
            
            .code-block {
                padding: 10px;
                font-size: 12px;
                overflow-x: auto;
                -webkit-overflow-scrolling: touch; /* Smooth scrolling on iOS */
            }
            
            .table-wrapper {
                overflow-x: auto;
                -webkit-overflow-scrolling: touch;
            }
            
            table {
                font-size: 14px;
                min-width: 600px; /* Force horizontal scroll for wide tables */
            }
            
            th, td {
                padding: 8px;
            }
            
            .exercise, .info-box, .warning-box {
                padding: 10px;
                margin: 15px 0;
            }
            
            .toggle-answer {
                font-size: 12px;
                padding: 6px 12px;
            }
            
            .question {
                padding: 10px;
            }
            
            .answer {
                padding: 10px;
            }
        }
        
        /* Small mobile devices */
        @media (max-width: 480px) {
            header h1 {
                font-size: 1.2em;
            }
            
            .chapter h2 {
                font-size: 1.3em;
            }
            
            .code-block {
                font-size: 11px;
                padding: 8px;
            }
            
            table {
                font-size: 12px;
            }
            
            th, td {
                padding: 6px;
            }
        }
        
        /* Improve touch targets */
        @media (hover: none) and (pointer: coarse) {
            nav a {
                min-height: 44px; /* iOS recommended touch target size */
                display: flex;
                align-items: center;
                justify-content: center;
            }
            
            .toggle-answer {
                min-height: 44px;
                min-width: 100px;
            }
        }
        
        /* Prevent horizontal overflow */
        html, body {
            overflow-x: hidden;
            width: 100%;
        }
        
        /* Ensure code blocks don't break layout */
        pre, code {
            max-width: 100%;
            overflow-wrap: break-word;
        }
        
        /* Overlay for mobile menu */
        .nav-overlay {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.5);
            z-index: 99;
        }
        
        .nav-overlay.active {
            display: block;
        }
        
        /* Improve readability on mobile */
        @media (max-width: 768px) {
            body {
                font-size: 16px; /* Prevent zoom on iOS */
            }
            
            p, li {
                line-height: 1.8;
            }
            
            /* Make sure images are responsive */
            img {
                max-width: 100%;
                height: auto;
            }
            
            /* Better spacing for mobile */
            .chapter p {
                margin-bottom: 1.5em;
            }
            
            /* Ensure buttons are easily tappable */
            button, a {
                min-height: 44px;
                min-width: 44px;
            }
        }
    </style>
    <script>
        // Helper function to escape HTML
        function escapeHtml(text) {
            const map = {
                '&': '&amp;',
                '<': '&lt;',
                '>': '&gt;',
                '"': '&quot;',
                "'": '&#039;'
            };
            return text.replace(/[&<>"']/g, m => map[m]);
        }
        
        // Simple syntax highlighting
        function highlightSyntax() {
            const codeBlocks = document.querySelectorAll('.code-block');
            
            codeBlocks.forEach(block => {
                const content = block.textContent;
                let language = 'text';
                let highlighted = content;
                
                // Auto-detect language based on content
                if (content.includes('module ') || content.includes('always @') || content.includes('wire ') || content.includes('reg ') || content.includes('endmodule') || content.includes('assign ')) {
                    language = 'verilog';
                    highlighted = highlightVerilog(content);
                } else if (content.includes('import ') || content.includes('def ') || content.includes('class ') || content.includes('numpy') || content.includes('torch') || content.includes('self.') || content.includes('__init__')) {
                    language = 'python';
                    highlighted = highlightPython(content);
                } else if (content.includes('#include') || content.includes('int main') || content.includes('void ') || content.includes('float ') || content.includes('double ') || content.includes('struct ')) {
                    language = 'c';
                    highlighted = highlightC(content);
                } else if (content.match(/^\s*\/\//)) {
                    // Comment-based detection
                    if (content.includes('实现') || content.includes('硬件') || content.includes('时钟')) {
                        language = 'verilog';
                        highlighted = highlightVerilog(content);
                    } else if (content.includes('Step') || content.includes('Load') || content.includes('Forward')) {
                        language = 'python';
                        highlighted = highlightPython(content);
                    }
                }
                
                block.innerHTML = highlighted;
                block.classList.add(language);
                block.setAttribute('data-language', language);
            });
        }
        
        function highlightVerilog(code) {
            // First, protect comments and strings from further processing
            const placeholders = [];
            let placeholderIndex = 0;
            
            // Replace comments with placeholders
            code = code.replace(/(\/\/.*$|\/\*[\s\S]*?\*\/)/gm, (match) => {
                const placeholder = `__COMMENT_${placeholderIndex}__`;
                placeholders[placeholderIndex] = `<span class="comment">${escapeHtml(match)}</span>`;
                placeholderIndex++;
                return placeholder;
            });
            
            // Replace strings with placeholders
            code = code.replace(/("[^"]*")/g, (match) => {
                const placeholder = `__STRING_${placeholderIndex}__`;
                placeholders[placeholderIndex] = `<span class="string">${escapeHtml(match)}</span>`;
                placeholderIndex++;
                return placeholder;
            });
            
            // Now apply other highlights
            const keywords = /\b(module|endmodule|input|output|wire|reg|always|assign|begin|end|if|else|for|while|parameter|localparam|posedge|negedge|case|endcase|default|function|endfunction|task|endtask|initial|forever|repeat)\b/g;
            const types = /\b(bit|logic|byte|shortint|int|longint|integer|time|real|shortreal|chandle|string|event|signed|unsigned)\b/g;
            const numbers = /\b(\d+'[hbdo][\da-fA-F_]+|\d+)\b/g;
            
            code = code.replace(keywords, '<span class="keyword">$1</span>');
            code = code.replace(types, '<span class="type">$1</span>');
            code = code.replace(numbers, '<span class="number">$1</span>');
            
            // Restore placeholders
            for (let i = 0; i < placeholderIndex; i++) {
                code = code.replace(new RegExp(`__COMMENT_${i}__`, 'g'), placeholders[i]);
                code = code.replace(new RegExp(`__STRING_${i}__`, 'g'), placeholders[i]);
            }
            
            return code;
        }
        
        function highlightPython(code) {
            const placeholders = [];
            let placeholderIndex = 0;
            
            // Replace comments with placeholders
            code = code.replace(/(#.*$)/gm, (match) => {
                const placeholder = `__COMMENT_${placeholderIndex}__`;
                placeholders[placeholderIndex] = `<span class="comment">${escapeHtml(match)}</span>`;
                placeholderIndex++;
                return placeholder;
            });
            
            // Replace strings with placeholders
            code = code.replace(/("[^"]*"|'[^']*')/g, (match) => {
                const placeholder = `__STRING_${placeholderIndex}__`;
                placeholders[placeholderIndex] = `<span class="string">${escapeHtml(match)}</span>`;
                placeholderIndex++;
                return placeholder;
            });
            
            // Apply other highlights
            const keywords = /\b(and|as|assert|break|class|continue|def|del|elif|else|except|False|finally|for|from|global|if|import|in|is|lambda|None|nonlocal|not|or|pass|raise|return|True|try|while|with|yield|async|await)\b/g;
            const builtins = /\b(abs|all|any|ascii|bin|bool|breakpoint|bytearray|bytes|callable|chr|classmethod|compile|complex|delattr|dict|dir|divmod|enumerate|eval|exec|filter|float|format|frozenset|getattr|globals|hasattr|hash|help|hex|id|input|int|isinstance|issubclass|iter|len|list|locals|map|max|memoryview|min|next|object|oct|open|ord|pow|print|property|range|repr|reversed|round|set|setattr|slice|sorted|staticmethod|str|sum|super|tuple|type|vars|zip)\b/g;
            const numbers = /\b(\d+\.?\d*)\b/g;
            
            code = code.replace(keywords, '<span class="keyword">$1</span>');
            code = code.replace(builtins, '<span class="function">$1</span>');
            code = code.replace(numbers, '<span class="number">$1</span>');
            
            // Restore placeholders
            for (let i = 0; i < placeholderIndex; i++) {
                code = code.replace(new RegExp(`__COMMENT_${i}__`, 'g'), placeholders[i]);
                code = code.replace(new RegExp(`__STRING_${i}__`, 'g'), placeholders[i]);
            }
            
            return code;
        }
        
        function highlightC(code) {
            const placeholders = [];
            let placeholderIndex = 0;
            
            // Replace comments with placeholders
            code = code.replace(/(\/\/.*$|\/\*[\s\S]*?\*\/)/gm, (match) => {
                const placeholder = `__COMMENT_${placeholderIndex}__`;
                placeholders[placeholderIndex] = `<span class="comment">${escapeHtml(match)}</span>`;
                placeholderIndex++;
                return placeholder;
            });
            
            // Replace strings with placeholders
            code = code.replace(/("[^"]*")/g, (match) => {
                const placeholder = `__STRING_${placeholderIndex}__`;
                placeholders[placeholderIndex] = `<span class="string">${escapeHtml(match)}</span>`;
                placeholderIndex++;
                return placeholder;
            });
            
            // Replace preprocessor with placeholders
            code = code.replace(/(#\s*\w+.*$)/gm, (match) => {
                const placeholder = `__PREPROC_${placeholderIndex}__`;
                placeholders[placeholderIndex] = `<span class="keyword">${escapeHtml(match)}</span>`;
                placeholderIndex++;
                return placeholder;
            });
            
            // Apply other highlights
            const keywords = /\b(auto|break|case|char|const|continue|default|do|double|else|enum|extern|float|for|goto|if|int|long|register|return|short|signed|sizeof|static|struct|switch|typedef|union|unsigned|void|volatile|while|class|namespace|template|public|private|protected|virtual|override|new|delete|try|catch|throw)\b/g;
            const types = /\b(bool|true|false|NULL|nullptr)\b/g;
            const numbers = /\b(\d+\.?\d*[fFlLuU]?)\b/g;
            
            code = code.replace(keywords, '<span class="keyword">$1</span>');
            code = code.replace(types, '<span class="type">$1</span>');
            code = code.replace(numbers, '<span class="number">$1</span>');
            
            // Restore placeholders
            for (let i = 0; i < placeholderIndex; i++) {
                code = code.replace(new RegExp(`__COMMENT_${i}__`, 'g'), placeholders[i]);
                code = code.replace(new RegExp(`__STRING_${i}__`, 'g'), placeholders[i]);
                code = code.replace(new RegExp(`__PREPROC_${i}__`, 'g'), placeholders[i]);
            }
            
            return code;
        }
        
        // Run syntax highlighting when page loads
        // Mobile navigation functions
        function toggleNav() {
            const navMenu = document.querySelector('.nav-menu');
            const navToggle = document.querySelector('.nav-toggle');
            const navOverlay = document.querySelector('.nav-overlay');
            
            navMenu.classList.toggle('active');
            navToggle.classList.toggle('active');
            navOverlay.classList.toggle('active');
            
            // Prevent body scroll when menu is open
            if (navMenu.classList.contains('active')) {
                document.body.style.overflow = 'hidden';
            } else {
                document.body.style.overflow = '';
            }
        }
        
        function closeNav() {
            const navMenu = document.querySelector('.nav-menu');
            const navToggle = document.querySelector('.nav-toggle');
            const navOverlay = document.querySelector('.nav-overlay');
            
            navMenu.classList.remove('active');
            navToggle.classList.remove('active');
            navOverlay.classList.remove('active');
            document.body.style.overflow = '';
        }
        
        // Close menu when clicking outside
        document.addEventListener('click', function(event) {
            const nav = document.getElementById('navigation');
            const navMenu = document.querySelector('.nav-menu');
            const navToggle = document.querySelector('.nav-toggle');
            
            if (navMenu && navMenu.classList.contains('active')) {
                if (!nav.contains(event.target)) {
                    closeNav();
                }
            }
        });
        
        document.addEventListener('DOMContentLoaded', function() {
            highlightSyntax();
        });
    </script>
</head>
<body>
    <header>
        <h1>Neural Processing Unit (NPU) 设计教程</h1>
        <p>从基础到高级的完整NPU芯片设计指南</p>
    </header>

    <div class="nav-overlay" onclick="closeNav()"></div>
    <nav id="navigation">
        <button class="nav-toggle" aria-label="Toggle navigation" onclick="toggleNav()">
            <span></span>
            <span></span>
            <span></span>
        </button>
        <ul class="nav-menu">
            <li><a href="#intro" onclick="closeNav()">课程介绍</a></li>
            <li><a href="#chapter1" onclick="closeNav()">1. NPU简介</a></li>
            <li><a href="#chapter2" onclick="closeNav()">2. 神经网络基础</a></li>
            <li><a href="#chapter3" onclick="closeNav()">3. NPU架构</a></li>
            <li><a href="#chapter4" onclick="closeNav()">4. 计算核心</a></li>
            <li><a href="#chapter5" onclick="closeNav()">5. 存储系统</a></li>
            <li><a href="#chapter6" onclick="closeNav()">6. RTL设计</a></li>
            <li><a href="#chapter7" onclick="closeNav()">7. 验证方法</a></li>
            <li><a href="#chapter8" onclick="closeNav()">8. 物理设计</a></li>
            <li><a href="#chapter9" onclick="closeNav()">9. 先进工艺与封装技术</a></li>
            <li><a href="#chapter10" onclick="closeNav()">10. 软件栈与编译优化</a></li>
            <li><a href="#chapter11" onclick="closeNav()">11. 性能优化</a></li>
            <li><a href="#chapter12" onclick="closeNav()">12. 实战项目</a></li>
            <li><a href="#conclusion" onclick="closeNav()">总结与展望</a></li>
        </ul>
    </nav>

    <div class="container">
        <div id="intro" class="chapter">
            <h2>课程介绍</h2>
            <p>欢迎来到Neural Processing Unit (NPU)设计教程！本教程将带您从零开始，逐步深入了解NPU的设计原理和实现技术。</p>
            
            <h3>课程目标</h3>
            <ul>
                <li>理解NPU的基本原理和架构</li>
                <li>掌握NPU前端设计技术（RTL设计和验证）</li>
                <li>学习NPU后端设计流程（综合、布局布线）</li>
                <li>了解软硬件协同设计方法</li>
                <li>通过实战项目巩固所学知识</li>
            </ul>

            <h3>学习建议</h3>
            <div class="info-box">
                <p><strong>提示：</strong>本教程采用渐进式学习方式，建议按章节顺序学习。每章都包含理论讲解、代码示例和练习题，请确保完成每章的练习题后再进入下一章。</p>
            </div>

            <h3>先修知识</h3>
            <ul>
                <li>数字电路基础</li>
                <li>Verilog/SystemVerilog编程基础</li>
                <li>计算机体系结构基础</li>
                <li>基本的深度学习概念</li>
            </ul>
        </div>

        <div id="chapter1" class="chapter">
            <h2>第1章：NPU简介与发展历程</h2>
            
            <h3>1.1 什么是NPU</h3>
            <p>Neural Processing Unit (NPU) 是一种专门为加速人工智能和机器学习工作负载而设计的处理器。与传统的CPU和GPU不同，NPU针对神经网络计算进行了特殊优化，能够高效执行矩阵运算、卷积运算等AI相关操作。</p>
            
            <p>NPU的诞生源于深度学习计算的特殊需求。随着深度神经网络模型规模的快速增长，从早期的LeNet（约6万参数）到现代的GPT-3（1750亿参数），计算需求呈指数级增长。传统处理器架构在面对这种计算密集型任务时暴露出诸多不足：CPU的串行架构限制了并行计算能力，GPU虽然提供了大规模并行计算，但其通用并行架构并非为神经网络量身定制，存在功耗高、内存带宽利用率低等问题。</p>
            
            <p>NPU通过领域专用架构（Domain-Specific Architecture，DSA）设计理念，从根本上解决了这些问题。DSA的核心思想是：放弃通用性，换取在特定领域的极致性能。NPU正是这一理念在人工智能领域的成功实践。通过深入分析神经网络的计算特征，NPU在硬件层面实现了多项关键优化：</p>
            
            <div class="info-box">
                <p><strong>NPU的核心设计特征：</strong></p>
                <ul>
                    <li><strong>专用硬件加速器：</strong>NPU内部集成了专门为神经网络运算优化的硬件单元。最典型的是脉动阵列（Systolic Array），它通过规律的数据流动模式，实现了计算和数据传输的完美重叠。每个处理单元（PE）只与相邻单元通信，大大简化了互连复杂度。</li>
                    <li><strong>高效的矩阵运算单元（MAC阵列）：</strong>MAC（Multiply-Accumulate）运算占据了神经网络计算的90%以上。NPU通过大规模并行的MAC阵列（如Google TPU的256×256阵列），可以在单个时钟周期内完成数万次乘累加运算。这种设计将芯片面积的大部分用于计算，而非控制逻辑。</li>
                    <li><strong>专门的数据流架构：</strong>NPU采用了多种数据流优化策略，如权重固定（Weight Stationary）、输出固定（Output Stationary）和行固定（Row Stationary）等。这些策略通过最大化数据复用，将外部内存访问降到最低。例如，在权重固定模式下，卷积核参数可以在PE中驻留数千个周期，极大地减少了数据移动开销。</li>
                    <li><strong>支持低精度计算：</strong>研究表明，神经网络具有很强的数值鲁棒性，推理阶段使用INT8甚至INT4精度几乎不影响准确率。NPU原生支持这些低精度格式，相比FP32可以实现4-8倍的吞吐量提升和能效改善。更重要的是，低精度计算大幅减少了存储需求和内存带宽压力。</li>
                    <li><strong>多级存储层次：</strong>NPU通常集成了大容量的片上SRAM（如TPU v3的32MB），配合精心设计的多级缓存结构（L0寄存器文件、L1局部缓存、L2全局缓存），有效缓解了"内存墙"问题。片上存储的访问能耗仅为片外DRAM的1/100。</li>
                </ul>
            </div>

            <h3>1.2 NPU vs CPU vs GPU</h3>
            
            <p>要深入理解NPU的价值，必须将其与CPU和GPU进行比较。这三种处理器代表了不同的设计理念和优化方向，各有其适用场景。通过对比分析，我们可以更好地理解NPU在AI计算领域的独特优势。</p>
            
            <h4>CPU：通用计算的王者</h4>
            <p>CPU（Central Processing Unit）是计算机系统的核心，其设计目标是提供最大的灵活性和通用性。现代CPU采用了复杂的乱序执行、分支预测、多级缓存等技术，能够高效处理各种类型的计算任务。然而，这种通用性是以牺牲专用性能为代价的。</p>
            
            <div class="code-block">
// CPU架构特征分析
架构特征          典型值           AI计算影响
------------------------------------------------------
核心数量          8-64核          并行度受限
SIMD宽度          256-512位       单指令处理8-16个FP32
时钟频率          2-5GHz          高频但利用率低
功耗              65-280W         能效比差
晶体管用途分布：
- 控制逻辑       ~30%            开销大
- 缓存           ~50%            对AI不够优化
- 计算单元       ~20%            实际计算资源少

// 典型CPU执行神经网络的性能
Intel Xeon (28核): ~100 GFLOPS (FP32)
功耗效率: ~0.4 GFLOPS/W
            </div>
            
            <p>在神经网络计算中，CPU的劣势明显：</p>
            <ul>
                <li><strong>有限的并行能力：</strong>即使是最先进的服务器CPU，核心数也仅有几十个，远不足以应对动辄百万级的矩阵运算</li>
                <li><strong>复杂的控制逻辑：</strong>大量晶体管用于指令解码、乱序执行、分支预测等，真正用于计算的比例仅约20%</li>
                <li><strong>缓存层次不匹配：</strong>CPU的缓存设计针对随机访问和代码/数据局部性优化，而神经网络计算具有流式的、可预测的访问模式</li>
                <li><strong>向量化限制：</strong>虽然支持AVX-512等SIMD指令，但宽度有限，且编程复杂</li>
            </ul>
            
            <h4>GPU：并行计算的先驱</h4>
            <p>GPU（Graphics Processing Unit）最初为图形渲染设计，后来演化为通用并行计算平台。GPU拥有数千个简单的计算核心，非常适合数据并行任务。在深度学习早期，GPU成为了训练神经网络的主力。</p>
            
            <div class="code-block">
// GPU架构特征分析（以NVIDIA A100为例）
架构特征          典型值           设计理念
------------------------------------------------------
SM数量            108个           大规模并行
CUDA核心          6912个          简单但数量多
Tensor Core       432个           专门矩阵运算
时钟频率          1.4GHz          相对较低
内存带宽          1.6TB/s (HBM2)  高带宽设计
功耗              400W            功耗密度高

// GPU执行神经网络的性能
NVIDIA A100: 
- FP32: 19.5 TFLOPS
- FP16 (Tensor Core): 312 TFLOPS
- INT8 (Tensor Core): 624 TOPS
功耗效率: ~1.5 TFLOPS/W (INT8)
            </div>
            
            <p>GPU在AI计算中的优势与局限：</p>
            <p><strong>优势：</strong></p>
            <ul>
                <li><strong>大规模并行：</strong>数千个核心可同时工作，适合数据并行的神经网络计算</li>
                <li><strong>成熟生态：</strong>CUDA、cuDNN等软件栈完善，框架支持好</li>
                <li><strong>通用性：</strong>除了AI，还能处理其他并行计算任务</li>
            </ul>
            <p><strong>局限性：</strong></p>
            <ul>
                <li><strong>功耗问题：</strong>高端GPU功耗动辄400W以上，数据中心需要专门的散热设计</li>
                <li><strong>内存层次复杂：</strong>寄存器、共享内存、L1/L2缓存、全局内存的层次需要手动管理</li>
                <li><strong>编程复杂：</strong>需要深入理解线程块、线程束（Warp）、内存合并等概念</li>
                <li><strong>架构开销：</strong>为保持通用性，仍有相当部分晶体管用于图形渲染等非AI功能</li>
            </ul>
            
            <h4>NPU：AI计算的专家</h4>
            <p>NPU代表了一种全新的设计思路：针对特定应用领域进行极致优化。通过深入分析神经网络的计算特征，NPU在架构层面实现了多项创新，在AI推理任务上展现出显著优势。</p>
            
            <div class="code-block">
// NPU架构特征分析（典型设计）
架构特征          典型值           优化重点
------------------------------------------------------
MAC阵列           256×256         专为矩阵运算设计
数据位宽          INT8/INT16      量化优化
片上缓存          10-100MB        减少外存访问
数据流架构        脉动阵列         数据复用最大化
功耗              10-75W          边缘到云端可扩展

// 典型NPU性能指标
Google TPU v4i: 
- INT8: 275 TOPS
- 功耗: 75W
- 能效: 3.7 TOPS/W

华为Ascend 310:
- INT8: 22 TOPS
- 功耗: 8W
- 能效: 2.8 TOPS/W
            </div>
            
            <p><strong>NPU的核心优势：</strong></p>
            <ul>
                <li><strong>专用架构：</strong>晶体管主要用于MAC运算，控制逻辑简单，计算密度极高</li>
                <li><strong>数据流优化：</strong>脉动阵列等架构最大化数据复用，减少内存访问</li>
                <li><strong>低精度计算：</strong>原生支持INT8/INT4等量化计算，大幅提升性能和能效</li>
                <li><strong>确定性延迟：</strong>没有缓存失效、分支预测失败等问题，延迟可预测</li>
                <li><strong>领域专用指令：</strong>提供矩阵乘法、卷积等高级指令，一条指令完成复杂运算</li>
            </ul>
            
            <div class="table-wrapper">
                <table>
                    <caption>CPU vs GPU vs NPU 详细对比</caption>
                    <thead>
                        <tr>
                            <th>特性</th>
                            <th>CPU</th>
                            <th>GPU</th>
                            <th>NPU</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>设计理念</td>
                            <td>通用计算，灵活性优先</td>
                            <td>并行计算，吞吐量优先</td>
                            <td>AI专用，能效优先</td>
                        </tr>
                        <tr>
                            <td>架构特点</td>
                            <td>复杂核心，深度流水线</td>
                            <td>简单核心，大规模并行</td>
                            <td>MAC阵列，数据流架构</td>
                        </tr>
                        <tr>
                            <td>计算单元</td>
                            <td>8-64个复杂核心</td>
                            <td>数千个CUDA核心</td>
                            <td>数万个MAC单元</td>
                        </tr>
                        <tr>
                            <td>内存系统</td>
                            <td>多级缓存，优化局部性</td>
                            <td>高带宽显存，复杂层次</td>
                            <td>大片上缓存，简单层次</td>
                        </tr>
                        <tr>
                            <td>数据类型</td>
                            <td>FP64/FP32为主</td>
                            <td>FP32/FP16/INT8</td>
                            <td>INT8/INT4为主</td>
                        </tr>
                        <tr>
                            <td>功耗范围</td>
                            <td>65-280W</td>
                            <td>75-400W</td>
                            <td>1-75W</td>
                        </tr>
                        <tr>
                            <td>AI推理性能</td>
                            <td>~0.1 TOPS</td>
                            <td>~600 TOPS</td>
                            <td>~300 TOPS</td>
                        </tr>
                        <tr>
                            <td>能效(TOPS/W)</td>
                            <td>~0.001</td>
                            <td>~1.5</td>
                            <td>~4.0</td>
                        </tr>
                        <tr>
                            <td>编程模型</td>
                            <td>C/C++，串行为主</td>
                            <td>CUDA/OpenCL，并行</td>
                            <td>图编译器，自动优化</td>
                        </tr>
                        <tr>
                            <td>适用场景</td>
                            <td>控制密集，串行任务</td>
                            <td>图形渲染，科学计算</td>
                            <td>AI推理，边缘计算</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>特性</th>
                            <th>CPU</th>
                            <th>GPU</th>
                            <th>NPU</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>设计目标</td>
                            <td>通用计算</td>
                            <td>并行图形/计算</td>
                            <td>AI/ML专用</td>
                        </tr>
                        <tr>
                            <td>架构特点</td>
                            <td>少量复杂核心</td>
                            <td>大量简单核心</td>
                            <td>专用MAC阵列</td>
                        </tr>
                        <tr>
                            <td>内存层次</td>
                            <td>多级缓存</td>
                            <td>高带宽显存</td>
                            <td>片上SRAM为主</td>
                        </tr>
                        <tr>
                            <td>功耗效率</td>
                            <td>中等（~0.1 TOPS/W）</td>
                            <td>较低（~0.5 TOPS/W）</td>
                            <td>高（~10 TOPS/W）</td>
                        </tr>
                        <tr>
                            <td>编程模型</td>
                            <td>串行为主</td>
                            <td>SIMD/SIMT</td>
                            <td>数据流</td>
                        </tr>
                        <tr>
                            <td>典型应用</td>
                            <td>操作系统、控制逻辑</td>
                            <td>图形渲染、科学计算</td>
                            <td>AI推理、边缘智能</td>
                        </tr>
                        <tr>
                            <td>灵活性</td>
                            <td>极高</td>
                            <td>高</td>
                            <td>低（专用）</td>
                        </tr>
                        <tr>
                            <td>成本效益（AI任务）</td>
                            <td>低</td>
                            <td>中</td>
                            <td>高</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            
            <div class="warning-box">
                <p><strong>重要提示：</strong>NPU并不是要取代CPU或GPU，而是作为协处理器与它们协同工作。在典型的AI系统中，CPU负责控制和预处理，GPU负责训练，NPU负责推理，三者各司其职，共同构建高效的计算平台。</p>
            </div>

            <h3>1.3 NPU的应用场景</h3>
            
            <p>NPU的应用场景广泛分布在从边缘到云端的各个领域。根据部署位置和应用特点，可以将NPU的应用场景分为边缘端和数据中心两大类。每类场景对NPU的设计提出了不同的要求，推动了NPU架构的多样化发展。</p>
            
            <h4>边缘端应用</h4>
            <p>边缘计算是NPU最重要的应用领域之一。在边缘设备上部署AI能力，可以实现低延迟、保护隐私、节省带宽等优势。边缘端NPU面临的主要挑战是在极其有限的功耗和成本预算下提供足够的计算能力。</p>
            
            <ul>
                <li><strong>智能手机：</strong>现代智能手机中的NPU已经成为标配，支撑着丰富的AI应用：
                    <ul>
                        <li>人脸识别：3D结构光或ToF深度信息处理，活体检测，表情识别</li>
                        <li>计算摄影：夜景模式、HDR+、人像模式、超分辨率</li>
                        <li>语音助手：唤醒词检测、语音识别、自然语言理解</li>
                        <li>系统优化：应用预测、电池管理、性能调度</li>
                    </ul>
                </li>
                
                <li><strong>智能摄像头：</strong>安防和智能家居领域的核心设备，NPU使其具备本地智能分析能力：
                    <ul>
                        <li>实时物体检测：人、车、动物等目标的检测和跟踪</li>
                        <li>行为分析：异常行为检测、人流统计、热力图生成</li>
                        <li>特征识别：人脸识别、车牌识别、商品识别</li>
                        <li>隐私保护：本地处理避免视频上传，保护用户隐私</li>
                    </ul>
                </li>
                
                <li><strong>自动驾驶：</strong>车载NPU是实现高级辅助驾驶（ADAS）和自动驾驶的关键：
                    <ul>
                        <li>感知融合：摄像头、激光雷达、毫米波雷达数据融合</li>
                        <li>目标检测：车辆、行人、交通标志、车道线识别</li>
                        <li>路径规划：实时轨迹预测和决策</li>
                        <li>功能安全：满足ISO 26262等汽车安全标准</li>
                    </ul>
                </li>
                
                <li><strong>IoT设备：</strong>物联网设备通过集成NPU实现边缘智能：
                    <ul>
                        <li>语音唤醒：超低功耗always-on语音检测</li>
                        <li>异常检测：工业设备预测性维护</li>
                        <li>环境感知：智能传感器数据处理</li>
                        <li>边缘推理：本地决策，减少云端依赖</li>
                    </ul>
                </li>
            </ul>

            <h4>数据中心应用</h4>
            <p>数据中心NPU追求的是极致的性能和吞吐量。与边缘端不同，数据中心可以提供充足的功耗和散热条件，使得NPU可以采用更激进的设计，集成更多的计算资源。</p>
            
            <ul>
                <li><strong>推理服务器：</strong>为大规模在线AI服务提供高性能推理：
                    <ul>
                        <li>搜索排序：实时处理数十亿级别的查询请求</li>
                        <li>推荐系统：个性化推荐，CTR预估</li>
                        <li>内容理解：图像分类、视频分析、文本理解</li>
                        <li>多租户支持：硬件虚拟化，资源隔离</li>
                    </ul>
                </li>
                
                <li><strong>训练加速：</strong>虽然GPU仍是训练的主力，但专用NPU在某些场景下更有优势：
                    <ul>
                        <li>分布式训练：高速互联支持模型并行和数据并行</li>
                        <li>混合精度训练：FP16/BF16/FP32灵活切换</li>
                        <li>稀疏化训练：结构化稀疏支持</li>
                        <li>定制化优化：针对特定模型架构的硬件优化</li>
                    </ul>
                </li>
                
                <li><strong>AI超算：</strong>构建专用的AI超级计算机：
                    <ul>
                        <li>大模型训练：支持万亿参数级别的模型</li>
                        <li>科学计算：蛋白质折叠、气象预测、分子动力学</li>
                        <li>强化学习：大规模并行环境模拟</li>
                        <li>联邦学习：分布式隐私保护学习</li>
                    </ul>
                </li>
            </ul>
            
            <div class="info-box">
                <p><strong>发展趋势：</strong>随着AI应用的普及，NPU正在向更多领域扩展。未来我们将看到NPU在可穿戴设备、AR/VR、机器人、卫星等领域的广泛应用。同时，软硬件协同设计、存内计算、光计算等新技术也在不断推动NPU架构的创新。</p>
            </div>

            <h3>1.4 主流NPU架构概览</h3>
            
            <p>了解主流NPU架构的设计理念和技术特点，对于深入理解NPU设计至关重要。本节将详细介绍几种代表性的NPU架构，分析它们的设计思路、技术创新和应用特点。每种架构都代表了不同的设计哲学和技术路线，通过比较分析，我们可以更好地理解NPU设计的多样性和演进方向。</p>
            
            <h4>1.4.1 Google TPU</h4>
            <p>Google的Tensor Processing Unit (TPU)是业界最早大规模部署的专用AI加速器之一。TPU的设计充分体现了"领域专用架构"的理念，通过针对性优化获得了极高的性能功耗比。Google从2013年开始TPU项目，最初的目标是加速数据中心的推理工作负载，特别是语音识别和图像搜索等应用。</p>
            
            <p><strong>TPU v1的创新设计：</strong></p>
            <p>TPU v1采用了革命性的脉动阵列架构，这是其最核心的创新。脉动阵列的设计灵感来自于生物学中的心脏跳动，数据像血液一样有节奏地在处理单元间流动。在256×256的脉动阵列中，权重从上到下流动并在每个PE中驻留，激活值从左到右流动，部分和在垂直方向累积。这种设计极大地减少了数据移动，提高了能效。</p>
            
            <div class="code-block">
// TPU v1 架构特点
- 脉动阵列（Systolic Array）：256x256 MACs
- 片上缓存：24MB Unified Buffer
- 主频：700MHz
- 峰值性能：92 TOPS (INT8)
- 内存带宽：34 GB/s
- 工艺节点：28nm
- 功耗：40W（典型）
- 面积：331 mm²

// 脉动阵列的优势
1. 数据复用率高：每个数据可被多个PE使用
2. 简单的控制逻辑：规律的数据流动模式
3. 高利用率：几乎100%的计算单元利用率
4. 低功耗：减少了数据搬移的能耗开销
            </div>
            
            <p>TPU v1的另一个重要创新是采用了专用的指令集架构（ISA）。与传统的RISC或CISC不同，TPU的指令集专门为神经网络设计，包括矩阵乘法指令、激活函数指令、归一化指令等。一条矩阵乘法指令可以触发数十万次MAC运算，极大地提高了指令效率。</p>
            
            <p><strong>TPU演进历程：</strong></p>
            <p>从TPU v1到最新的TPU v4，Google持续推动着架构创新。TPU v2引入了浮点运算支持，使其能够进行模型训练；TPU v3大幅提升了内存容量和带宽；TPU v4则引入了稀疏计算加速，进一步提高了效率。这种持续的演进反映了AI工作负载的快速变化和硬件设计的不断创新。</p>
            
            <div class="table-wrapper">
                <table>
                    <caption>Google TPU v1-v4 架构参数对比</caption>
                    <thead>
                        <tr>
                            <th>规格参数</th>
                            <th>TPU v1</th>
                            <th>TPU v2</th>
                            <th>TPU v3</th>
                            <th>TPU v4</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>发布年份</strong></td>
                            <td>2016</td>
                            <td>2017</td>
                            <td>2018</td>
                            <td>2021</td>
                        </tr>
                        <tr>
                            <td><strong>工艺节点</strong></td>
                            <td>28nm</td>
                            <td>16nm</td>
                            <td>16nm</td>
                            <td>7nm</td>
                        </tr>
                        <tr>
                            <td><strong>芯片面积</strong></td>
                            <td>331 mm²</td>
                            <td>625 mm²</td>
                            <td>700 mm²</td>
                            <td>400 mm²</td>
                        </tr>
                        <tr>
                            <td><strong>MXU尺寸</strong></td>
                            <td>256×256</td>
                            <td>128×128</td>
                            <td>128×128</td>
                            <td>128×128</td>
                        </tr>
                        <tr>
                            <td><strong>核心数量</strong></td>
                            <td>1个MXU</td>
                            <td>2个核心</td>
                            <td>2个核心</td>
                            <td>1个核心</td>
                        </tr>
                        <tr>
                            <td><strong>主频</strong></td>
                            <td>700 MHz</td>
                            <td>700 MHz</td>
                            <td>940 MHz</td>
                            <td>1.05 GHz</td>
                        </tr>
                        <tr>
                            <td><strong>内存类型</strong></td>
                            <td>DDR3</td>
                            <td>HBM</td>
                            <td>HBM2</td>
                            <td>HBM2E</td>
                        </tr>
                        <tr>
                            <td><strong>内存容量</strong></td>
                            <td>8 GB DDR3</td>
                            <td>16 GB HBM</td>
                            <td>32 GB HBM2</td>
                            <td>32 GB HBM2E</td>
                        </tr>
                        <tr>
                            <td><strong>内存带宽</strong></td>
                            <td>34 GB/s</td>
                            <td>600 GB/s</td>
                            <td>900 GB/s</td>
                            <td>1.2 TB/s</td>
                        </tr>
                        <tr>
                            <td><strong>片上SRAM</strong></td>
                            <td>24 MB</td>
                            <td>32 MB</td>
                            <td>32 MB</td>
                            <td>144 MB</td>
                        </tr>
                        <tr>
                            <td><strong>INT8性能</strong></td>
                            <td>92 TOPS</td>
                            <td>45 TOPS</td>
                            <td>123 TOPS</td>
                            <td>275 TOPS</td>
                        </tr>
                        <tr>
                            <td><strong>BF16性能</strong></td>
                            <td>不支持</td>
                            <td>45 TFLOPS</td>
                            <td>123 TFLOPS</td>
                            <td>275 TFLOPS</td>
                        </tr>
                        <tr>
                            <td><strong>FP32性能</strong></td>
                            <td>不支持</td>
                            <td>22.5 TFLOPS</td>
                            <td>62 TFLOPS</td>
                            <td>138 TFLOPS</td>
                        </tr>
                        <tr>
                            <td><strong>TDP功耗</strong></td>
                            <td>40W</td>
                            <td>250W</td>
                            <td>450W</td>
                            <td>170W</td>
                        </tr>
                        <tr>
                            <td><strong>用途</strong></td>
                            <td>推理专用</td>
                            <td>训练+推理</td>
                            <td>训练+推理</td>
                            <td>训练+推理</td>
                        </tr>
                        <tr>
                            <td><strong>互联技术</strong></td>
                            <td>PCIe 3.0</td>
                            <td>自定义2D环</td>
                            <td>2D环形网络</td>
                            <td>3D环形网络</td>
                        </tr>
                        <tr>
                            <td><strong>稀疏计算</strong></td>
                            <td>不支持</td>
                            <td>不支持</td>
                            <td>不支持</td>
                            <td>支持2:4稀疏</td>
                        </tr>
                        <tr>
                            <td><strong>Pod配置</strong></td>
                            <td>单芯片</td>
                            <td>64芯片Pod</td>
                            <td>1024芯片Pod</td>
                            <td>4096芯片Pod</td>
                        </tr>
                        <tr>
                            <td><strong>能效比</strong></td>
                            <td>2.3 TOPS/W</td>
                            <td>0.18 TOPS/W</td>
                            <td>0.27 TOPS/W</td>
                            <td>1.6 TOPS/W</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            
            <div class="info-box">
                <h5>TPU架构演进的关键洞察</h5>
                <ul>
                    <li><strong>从推理到训练：</strong>TPU v1专注于推理，从v2开始支持浮点训练，体现了Google从部署到开发的全栈优化思路</li>
                    <li><strong>内存系统革新：</strong>从DDR3到HBM的转变使内存带宽提升35倍，解决了AI计算的内存墙问题</li>
                    <li><strong>能效优化：</strong>TPU v4通过7nm工艺和架构优化，能效比v3提升6倍，展现了持续的技术进步</li>
                    <li><strong>规模化设计：</strong>从单芯片到4096芯片Pod，体现了大规模AI训练的需求驱动</li>
                    <li><strong>稀疏计算：</strong>v4引入2:4结构化稀疏，在保持精度的同时实现2倍性能提升</li>
                </ul>
            </div>

            <h4>1.4.2 华为Ascend</h4>
            <p>华为Ascend系列NPU是业界领先的AI芯片解决方案之一。Ascend采用了达芬奇架构（Da Vinci Architecture），这是一种专门为AI计算设计的架构，从底层针对AI工作负载进行了优化。达芬奇架构的核心理念是"全场景覆盖"，从端侧的Ascend 310到云端的Ascend 910，采用统一的架构设计，大大简化了软件栈的复杂度。</p>
            
            <p><strong>达芬奇架构的核心创新：</strong></p>
            <p>达芬奇架构最重要的创新是3D Cube计算引擎。与传统的2D脉动阵列不同，Cube引擎在三个维度上组织计算单元，能够更高效地处理多维张量运算。这种设计特别适合处理卷积神经网络中的多通道特征图，可以在一个时钟周期内完成整个卷积核的计算。</p>
            
            <div class="code-block">
// Ascend 910 架构特点
- 达芬奇架构：3D Cube计算单元
- AI Core数量：32个
- 片上缓存：多级缓存体系（L0/L1/L2）
- 峰值性能：256 TFLOPS (FP16) / 512 TOPS (INT8)
- HBM内存：32GB HBM2
- 内存带宽：1.2 TB/s
- 互联：高速片间互联，支持多芯片扩展
- 工艺：7nm EUV
- 功耗：310W（最大）

// 3D Cube引擎特点
1. 16x16x16的计算矩阵
2. 支持混合精度计算（FP16/INT8/INT4）
3. 硬件级稀疏计算加速
4. 灵活的数据流控制
            </div>
            
            <p>Ascend的另一个重要特性是其完整的软件生态系统。华为提供了CANN（Compute Architecture for Neural Networks）软件栈，包括图编译器、算子库、运行时系统等。CANN支持主流深度学习框架，如TensorFlow、PyTorch等，大大降低了开发者的使用门槛。</p>
            
            <p><strong>端云协同设计：</strong></p>
            <p>Ascend系列的一个独特优势是端云协同能力。Ascend 310针对边缘推理优化，功耗仅8W，而Ascend 910则面向数据中心训练。两者采用相同的达芬奇架构和软件栈，使得模型可以无缝地在端侧和云端之间迁移，这对于实际应用部署具有重要意义。</p>

            <h4>1.4.3 寒武纪MLU</h4>
            <p>寒武纪是中国最早专注于AI芯片的公司之一，其MLU（Machine Learning Unit）系列产品在国内外都有广泛应用。寒武纪的创始团队来自中科院计算所，在神经网络处理器架构研究方面有深厚积累。MLU架构的设计理念是"通用性与专用性的平衡"，既要保证对各类神经网络的良好支持，又要实现高效的计算性能。</p>
            
            <p><strong>MLUv02架构创新：</strong></p>
            <p>MLUv02是寒武纪第二代架构，相比第一代有了重大改进。最核心的创新是引入了更灵活的计算核心设计，每个MLU Core内部包含多个处理集群，可以独立执行不同的任务。这种设计提高了硬件利用率，特别是在处理不规则网络结构时表现优异。</p>
            
            <div class="code-block">
// MLU 290 架构特点
- MLUv02架构：第二代AI处理器架构
- MLU Core数量：16个
- 处理集群：每个Core包含4个集群
- 片上缓存：48MB SRAM（分布式设计）
- 内存：32GB LPDDR4x
- 内存带宽：307.2 GB/s
- 峰值性能：1024 TOPS (INT4) / 256 TOPS (INT8)
- 工艺：7nm
- 功耗：75W（典型负载）

// MLU Core内部结构
1. 向量处理单元（VPU）：处理向量运算
2. 矩阵处理单元（MPU）：专门的矩阵运算
3. 内存处理单元（MLU）：管理数据搬移
4. 控制单元（CU）：指令调度和控制
            </div>
            
            <p>MLU的一个独特优势是其强大的稀疏计算能力。随着模型剪枝和稀疏化技术的发展，如何高效处理稀疏张量成为一个重要课题。MLU 290通过硬件级的稀疏检测和跳过机制，可以在处理稀疏模型时获得2-4倍的性能提升。</p>
            
            <p><strong>软件生态与易用性：</strong></p>
            <p>寒武纪提供了完整的软件开发工具链Cambricon Neuware，包括编程框架、编译器、性能分析工具等。特别值得一提的是其BANG语言（类似于CUDA），允许开发者直接编写MLU上的并行程序，为高级用户提供了更大的优化空间。同时，寒武纪也支持主流框架的模型直接部署，降低了普通用户的使用门槛。</p>

            <h4>1.4.4 Groq TSP</h4>
            <p>Groq的Tensor Streaming Processor (TSP)代表了一种全新的AI计算架构思路——通过消除片上存储瓶颈和实现确定性性能来革新AI推理。Groq由前Google TPU团队成员创立，其TSP架构体现了对传统冯·诺依曼架构的彻底反思。</p>
            
            <p><strong>TSP的革命性设计：</strong></p>
            <p>TSP最大的创新在于其"无缓存"设计理念。传统处理器依赖多级缓存来缓解内存墙问题，但这带来了性能的不确定性。TSP通过软件编译时确定所有数据移动路径，硬件上实现了一个巨大的、完全确定性的数据流网络。每个计算单元都确切知道数据何时到达，无需等待或猜测。</p>
            
            <div class="code-block">
// Groq TSP 架构特点
- 芯片规模：14nm工艺，面积约700mm²
- 计算单元：超过100万个MAC单元
- 片上存储：220MB SRAM（分布式）
- 互连网络：确定性的芯片级数据流网络
- 主频：1GHz
- 峰值性能：1 POPS (INT8) / 250 TFLOPS (FP16)
- 功耗：300W（数据中心版本）

// 确定性执行的优势
1. 零等待时间：数据准时到达，无需缓存miss
2. 100%硬件利用率：每个周期都在执行有效计算
3. 极低延迟：批大小为1时仍保持高性能
4. 可预测性：性能完全由编译器决定
            </div>
            
            <p>TSP的另一个关键创新是其编译器技术。Groq的编译器不仅负责将神经网络映射到硬件，更是整个系统的"大脑"。它在编译时就确定了每个数据的精确移动路径和时间，生成的是一个精确到时钟周期的执行计划。这种"软件定义硬件"的理念使得TSP能够为每个特定模型实现最优的数据流。</p>

            <h4>1.4.5 Wave Computing DPU</h4>
            <p>Wave Computing（现已被MIPS收购）的Dataflow Processing Unit (DPU)是基于数据流计算模型的AI处理器。与传统的控制流架构不同，DPU采用了异步数据流执行模型，这种架构特别适合处理具有大量并行性的深度学习工作负载。</p>
            
            <p><strong>DPU的数据流架构：</strong></p>
            <p>DPU的核心是其粗粒度可重构阵列（CGRA）。与FPGA的细粒度可重构不同，DPU的处理单元是完整的算术逻辑单元，可以高效执行深度学习所需的运算。数据流架构意味着指令的执行完全由数据的可用性驱动，当所有输入操作数准备就绪时，运算自动触发。</p>
            
            <div class="code-block">
// Wave DPU 架构特点
- 处理单元：16,384个处理元素（PE）
- 架构类型：粗粒度可重构阵列（CGRA）
- 执行模型：异步数据流
- 片上内存：分布式SRAM，总计数十MB
- 支持精度：FP16/INT8/INT16
- 互连：可编程的数据流网络

// 数据流执行的特点
1. 无需程序计数器：运算由数据驱动
2. 自然的流水线：不同阶段自动重叠
3. 动态调度：硬件自动处理依赖关系
4. 高并行度：数千个运算可同时进行
            </div>
            
            <p>DPU的一个独特优势是其对稀疏性的原生支持。在数据流模型中，零值可以被自然地"跳过"——如果某个运算的输入是零，该运算可以不被触发，从而节省功耗。这使得DPU在处理剪枝后的稀疏模型时特别高效。</p>

            <h4>1.4.6 SambaNova RDU</h4>
            <p>SambaNova Systems的Reconfigurable Dataflow Unit (RDU)代表了可重构计算在AI领域的最新进展。RDU结合了ASIC的高性能和FPGA的灵活性，通过软件定义的方式实现硬件的动态重构，特别适合大规模模型的训练和推理。</p>
            
            <p><strong>RDU的分层架构：</strong></p>
            <p>RDU采用了分层的可重构架构。最底层是计算和内存单元，中间层是可编程的互连网络，顶层是控制和调度逻辑。这种分层设计使得RDU可以针对不同的工作负载进行优化，从密集的矩阵运算到稀疏的图计算都能高效处理。</p>
            
            <div class="code-block">
// SambaNova RDU 架构特点
- 工艺节点：7nm
- 计算单元：数千个可重构数据流单元
- 内存系统：分层内存，包括HBM和片上SRAM
- 互连：三维环面（3D Torus）拓扑
- 支持精度：BF16/FP32/TF32
- 系统扩展：支持多芯片互连

// RDU的关键创新
1. 数据流图映射：直接将计算图映射到硬件
2. 动态重构：运行时可改变硬件配置
3. 内存计算融合：计算单元紧邻内存
4. 编译器协同：编译器和硬件深度集成
            </div>
            
            <p>SambaNova的独特之处在于其"全栈"方法。公司不仅提供硬件，还提供完整的软件栈和预优化的模型。其SambaFlow软件能够自动将PyTorch或TensorFlow模型映射到RDU硬件上，并进行深度优化。这种端到端的解决方案大大降低了用户的使用门槛。</p>

            <h4>1.4.7 爱芯元智 AiPU</h4>
            <p>爱芯元智（AXera）是中国新兴的AI芯片公司，其AiPU产品线专注于边缘AI计算。AiPU的设计理念是在有限的功耗和成本预算下，提供最优的AI推理性能，特别针对视觉AI应用进行了深度优化。</p>
            
            <p><strong>AiPU的混合精度架构：</strong></p>
            <p>AiPU最大的特色是其灵活的混合精度计算能力。芯片内部集成了多种计算单元，可以同时支持INT4、INT8、INT16和FP16等多种精度。更重要的是，AiPU支持层级精度配置——同一个模型的不同层可以使用不同的精度，从而在保证精度的前提下最大化性能。</p>
            
            <div class="code-block">
// 爱芯元智 AX630A 架构特点
- 工艺：12nm
- NPU算力：14.4 TOPS (INT8)
- CPU：四核Cortex-A53
- ISP：支持4K@30fps
- 视频编解码：H.264/H.265
- 内存接口：LPDDR4/4x
- 功耗：3-5W（典型）

// 混合精度计算特性
1. 动态精度切换：运行时可调整精度
2. 层级精度优化：每层独立配置精度
3. 量化引擎：硬件加速的量化/反量化
4. 精度感知训练：支持QAT模型部署
            </div>
            
            <p>AiPU的另一个亮点是其强大的视觉处理能力。芯片集成了高性能ISP（图像信号处理器）和视频编解码单元，可以直接处理来自摄像头的原始数据。这种"端到端"的设计避免了数据在不同处理单元间的搬移，大大提高了系统效率。对于智能摄像头、无人机等应用场景，AiPU提供了理想的解决方案。</p>
            
            <h4>1.4.8 Tesla FSD (Full Self-Driving) 芯片</h4>
            <p>Tesla的FSD（Full Self-Driving）芯片是专为自动驾驶设计的车载AI处理器，代表了车载AI芯片的最高水平。Tesla选择自研芯片而非使用通用方案，体现了对自动驾驶场景的深度理解和极致优化。FSD芯片不仅要处理大量的实时视觉数据，还要满足车规级的安全和可靠性要求。</p>
            
            <p><strong>FSD芯片的双核冗余架构：</strong></p>
            <p>安全是自动驾驶的第一要务。FSD芯片采用了完全冗余的双芯片设计，两个独立的SoC并行运行相同的神经网络，实时比较输出结果。这种设计确保即使一个芯片出现故障，系统仍能安全运行。每个SoC都包含CPU、GPU和专用的神经网络加速器，形成一个完整的计算系统。</p>
            
            <div class="code-block">
// Tesla FSD 芯片架构特点（HW 3.0）
- 工艺节点：14nm FinFET（三星）
- 芯片数量：2个独立SoC（完全冗余）
- 每个SoC包含：
  - CPU：12核ARM Cortex-A72（2.2GHz）
  - GPU：1GHz，600 GFLOPS
  - NPU：2个神经网络处理器
  - SRAM：32MB
- 系统性能：
  - 总算力：144 TOPS（INT8）
  - 内存：LPDDR4，68GB/s带宽
  - 功耗：72W（整个系统）
  - 处理能力：2300帧/秒

// FSD HW 4.0 升级
- 工艺提升至7nm
- 算力提升至超过300 TOPS
- 支持更高分辨率摄像头
- 增强的视频处理能力
            </div>
            
            <p><strong>针对自动驾驶的优化设计：</strong></p>
            <p>FSD芯片的NPU专门针对Tesla的自动驾驶神经网络进行了优化。其核心是一个96×96的MAC阵列，采用了特殊的数据流设计，能够高效处理卷积、反卷积和点云处理等自动驾驶特有的运算。芯片还集成了专门的ISP，可以直接处理来自8个摄像头的原始数据流。</p>
            
            <div class="info-box">
                <h5>FSD芯片的关键创新</h5>
                <ul>
                    <li><strong>软硬件协同设计：</strong>Tesla同时开发芯片和自动驾驶算法，实现了深度的软硬件协同优化</li>
                    <li><strong>实时性保证：</strong>从感知到决策的端到端延迟控制在100ms以内，满足自动驾驶的实时性要求</li>
                    <li><strong>多传感器融合：</strong>硬件级支持摄像头、毫米波雷达等多种传感器的数据融合</li>
                    <li><strong>OTA升级能力：</strong>预留了足够的计算冗余，支持通过OTA持续改进算法</li>
                    <li><strong>成本优化：</strong>相比购买通用方案，自研芯片在量产后成本更低</li>
                </ul>
            </div>
            
            <p>Tesla FSD芯片的成功证明了垂直整合的价值。通过同时掌控硬件和软件，Tesla能够实现其他厂商难以达到的性能和效率。这种模式正在被越来越多的科技公司采用，预示着AI芯片设计的新趋势。</p>
            
            <h4>1.4.9 地平线 Journey系列</h4>
            <p>地平线（Horizon Robotics）是中国领先的车载AI芯片公司，其Journey（征程）系列芯片专注于智能驾驶场景。与Tesla的全栈自研不同，地平线采用了开放生态的策略，为汽车制造商提供灵活可定制的AI计算平台。Journey系列从J2到最新的J5，展现了车载AI芯片的快速演进。</p>
            
            <p><strong>BPU（Brain Processing Unit）架构：</strong></p>
            <p>地平线自研的BPU架构是Journey系列的核心。BPU采用了创新的"计算近数据"设计理念，将计算单元分布在存储周围，最大限度地减少数据搬移。这种架构特别适合处理自动驾驶中的实时视频流，能够在低功耗下实现高性能。</p>
            
            <div class="code-block">
// Horizon Journey 5 架构特点
- 工艺节点：16nm
- BPU架构：第三代贝叶斯架构
- AI算力：128 TOPS（INT8）
- CPU：8核ARM Cortex-A55
- 支持传感器：
  - 摄像头：最多16路，支持8MP
  - 毫米波雷达：最多6路
  - 激光雷达：支持主流激光雷达接入
- 内存：
  - LPDDR4/LPDDR4X
  - 带宽：64GB/s
- 功能安全：ASIL-B/D
- 功耗：30W（典型）

// BPU架构特点
1. 计算近数据：减少数据搬移开销
2. 稀疏加速：硬件级稀疏检测和跳过
3. 动态精度：支持INT8/INT16混合计算
4. 多任务并行：可同时运行多个神经网络
            </div>
            
            <p><strong>开放生态与工具链：</strong></p>
            <p>地平线提供了完整的开发工具链——天工开物（Horizon OpenExplorer）。这套工具链支持从模型训练、量化、优化到部署的全流程，兼容主流深度学习框架。更重要的是，地平线提供了丰富的参考算法和预训练模型，帮助客户快速构建自动驾驶系统。</p>
            
            <div class="table-wrapper">
                <table>
                    <caption>Journey系列芯片演进对比</caption>
                    <thead>
                        <tr>
                            <th>型号</th>
                            <th>Journey 2</th>
                            <th>Journey 3</th>
                            <th>Journey 5</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>发布时间</strong></td>
                            <td>2019</td>
                            <td>2020</td>
                            <td>2021</td>
                        </tr>
                        <tr>
                            <td><strong>工艺</strong></td>
                            <td>28nm</td>
                            <td>16nm</td>
                            <td>16nm</td>
                        </tr>
                        <tr>
                            <td><strong>算力</strong></td>
                            <td>4 TOPS</td>
                            <td>5 TOPS</td>
                            <td>128 TOPS</td>
                        </tr>
                        <tr>
                            <td><strong>功耗</strong></td>
                            <td>2W</td>
                            <td>2.5W</td>
                            <td>30W</td>
                        </tr>
                        <tr>
                            <td><strong>应用场景</strong></td>
                            <td>ADAS</td>
                            <td>L2级自动驾驶</td>
                            <td>L2+至L4级</td>
                        </tr>
                        <tr>
                            <td><strong>摄像头支持</strong></td>
                            <td>4路</td>
                            <td>4路</td>
                            <td>16路</td>
                        </tr>
                        <tr>
                            <td><strong>特色功能</strong></td>
                            <td>基础感知</td>
                            <td>多传感器融合</td>
                            <td>高精地图、预测规划</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            
            <p><strong>面向量产的设计理念：</strong></p>
            <p>与一些追求极致性能的方案不同，Journey系列始终坚持"可量产"的设计理念。这体现在：采用成熟的工艺节点降低成本；提供车规级认证（AEC-Q100）；支持-40°C到125°C的工作温度范围；提供长达15年的供货保证。这些特点使得Journey系列成为众多车企的首选方案。</p>
            
            <p>地平线的成功经验表明，在车载AI芯片领域，技术领先只是成功的一部分。理解汽车行业的特殊需求，提供完整的解决方案，建立开放的生态系统，同样至关重要。随着自动驾驶技术的快速发展，车载AI芯片将继续是最具挑战和机遇的领域之一。</p>

            <div class="exercise">
                <h4>练习题集 1</h4>
                <p>通过以下练习题，你可以检验对NPU基础概念的理解程度。这些题目涵盖了理论知识、计算分析和实践编程等多个方面。建议先独立思考，再查看参考答案。记住，理解原理比记忆答案更重要。</p>
                
                <div class="question">
                    <p><strong>题目1.1：</strong>简述NPU相比GPU在AI推理任务上的三个主要优势。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：从硬件架构专用性、能效比、数据精度支持三个角度考虑。NPU是专门为AI设计的，去除了哪些GPU中不必要的部分？</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <ol>
                            <li><strong>功耗效率更高：</strong>NPU采用专用硬件设计，去除了GPU中用于图形渲染的部分，并针对神经网络运算进行优化，在相同性能下功耗可降低50%以上。</li>
                            <li><strong>推理延迟更低：</strong>NPU的数据流架构和片上存储设计减少了内存访问延迟，批处理大小为1时性能优势明显。</li>
                            <li><strong>支持低精度计算：</strong>NPU原生支持INT8、INT4等低精度格式，可在保持精度的同时大幅提升吞吐量。</li>
                        </ol>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目1.2：</strong>解释什么是脉动阵列（Systolic Array），以及它为什么适合神经网络计算？</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>脉动阵列的名字来源于心脏跳动。想象数据如何在处理单元之间有节奏地流动。考虑：1) 数据复用的优势 2) 规则结构带来的好处 3) 神经网络中大量的矩阵运算</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p>脉动阵列是一种规则的处理单元阵列，数据像心脏跳动一样有节奏地在阵列中流动。其特点包括：</p>
                        <ul>
                            <li><strong>数据复用：</strong>输入数据在多个PE间传递，减少内存访问</li>
                            <li><strong>规则结构：</strong>易于实现和扩展，面积利用率高</li>
                            <li><strong>高并行度：</strong>可同时执行大量MAC运算</li>
                        </ul>
                        <p>适合神经网络的原因：</p>
                        <ol>
                            <li>神经网络主要是矩阵乘法运算，与脉动阵列的计算模式匹配</li>
                            <li>权重可以预加载并保持静止，提高数据复用率</li>
                            <li>规则的计算模式便于流水线设计</li>
                        </ol>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目1.3：</strong>某NPU的MAC阵列为16x16，主频为1GHz，每个周期每个MAC可完成2次INT8运算。计算该NPU的理论峰值性能（TOPS）。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>计算公式：峰值性能 = MAC单元数 × 每MAC每周期运算数 × 主频。注意单位转换：1 TOPS = 10^12 operations/second</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p>计算步骤：</p>
                        <ol>
                            <li>MAC单元总数 = 16 × 16 = 256</li>
                            <li>每秒周期数 = 1GHz = 10^9 cycles/s</li>
                            <li>每周期运算次数 = 256 × 2 = 512 ops/cycle</li>
                            <li>峰值性能 = 10^9 × 512 = 512 × 10^9 ops/s = 512 GOPS = 0.512 TOPS</li>
                        </ol>
                        <p><strong>答案：0.512 TOPS</strong></p>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目1.4：</strong>设计一个简单的4x4脉动阵列，用Verilog描述其中一个PE（Processing Element）的基本结构。PE需要支持乘累加操作。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>PE需要包含：1) 数据输入/输出端口（横向和纵向） 2) 权重寄存器用于保存权重 3) 乘法器和加法器 4) 部分和的传递。考虑Weight Stationary模式下的数据流动。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module PE #(
    parameter DATA_WIDTH = 8,
    parameter ACC_WIDTH = 32
)(
    input wire clk,
    input wire rst_n,
    input wire en,
    
    // 数据输入
    input wire [DATA_WIDTH-1:0] data_in,    // 从左边PE传入
    input wire [DATA_WIDTH-1:0] weight_in,  // 从上边PE传入
    
    // 数据输出
    output reg [DATA_WIDTH-1:0] data_out,   // 传给右边PE
    output reg [DATA_WIDTH-1:0] weight_out, // 传给下边PE
    
    // 部分和
    input wire [ACC_WIDTH-1:0] psum_in,     // 从上边PE传入
    output reg [ACC_WIDTH-1:0] psum_out     // 传给下边PE
);

    // 内部寄存器
    reg [DATA_WIDTH-1:0] weight_reg;
    wire [2*DATA_WIDTH-1:0] mult_result;
    wire [ACC_WIDTH-1:0] acc_result;
    
    // 乘法器
    assign mult_result = data_in * weight_reg;
    
    // 加法器
    assign acc_result = psum_in + {{(ACC_WIDTH-2*DATA_WIDTH){mult_result[2*DATA_WIDTH-1]}}, mult_result};
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            data_out <= 0;
            weight_out <= 0;
            psum_out <= 0;
            weight_reg <= 0;
        end else if (en) begin
            // 数据向右传递
            data_out <= data_in;
            
            // 权重向下传递并保存
            weight_out <= weight_in;
            weight_reg <= weight_in;
            
            // 累加结果向下传递
            psum_out <= acc_result;
        end
    end
endmodule
                        </div>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目1.5：</strong>分析边缘端NPU和云端NPU在设计上的主要差异，至少列举4个方面。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>从以下角度比较：功耗限制、内存容量和带宽、计算精度要求、成本敏感度、应用场景（推理vs训练）、实时性要求等。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <table>
                            <tr>
                                <th>设计方面</th>
                                <th>边缘端NPU</th>
                                <th>云端NPU</th>
                            </tr>
                            <tr>
                                <td>功耗预算</td>
                                <td>通常&lt;5W，需要极致的功耗优化</td>
                                <td>可达100W以上，更关注性能</td>
                            </tr>
                            <tr>
                                <td>内存系统</td>
                                <td>小容量片上SRAM，有限的外部带宽</td>
                                <td>大容量HBM/GDDR，高带宽</td>
                            </tr>
                            <tr>
                                <td>计算精度</td>
                                <td>主要INT8/INT4，追求高压缩比</td>
                                <td>FP16/FP32/INT8混合精度</td>
                            </tr>
                            <tr>
                                <td>芯片面积</td>
                                <td>&lt;50mm²，成本敏感</td>
                                <td>可达800mm²，性能优先</td>
                            </tr>
                            <tr>
                                <td>应用场景</td>
                                <td>推理为主，实时性要求高</td>
                                <td>训练和推理，吞吐量优先</td>
                            </tr>
                        </table>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目1.6：</strong>计算题：某手机NPU需要实时处理1080p@30fps的视频流进行物体检测。假设每帧需要100M次MAC运算，计算所需的最小算力（GOPS）。如果NPU效率为70%，实际需要多少GOPS的峰值性能？</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p>计算步骤：</p>
                        <ol>
                            <li>每秒帧数：30 fps</li>
                            <li>每帧运算量：100M = 10^8 ops</li>
                            <li>每秒运算量：30 × 10^8 = 3 × 10^9 ops = 3 GOPS</li>
                            <li>考虑70%效率，实际需要：3 ÷ 0.7 ≈ 4.29 GOPS</li>
                        </ol>
                        <p><strong>答案：最小算力需求为3 GOPS，考虑效率后需要4.29 GOPS的峰值性能。</strong></p>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目1.7：</strong>编程题：用Python实现一个简单的脉动阵列模拟器，计算两个4x4矩阵的乘法。要求展示数据在阵列中的流动过程。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
import numpy as np

class SystolicArray:
    def __init__(self, size=4):
        self.size = size
        self.array = [[{'a': 0, 'b': 0, 'c': 0} for _ in range(size)] for _ in range(size)]
        self.cycle = 0
        
    def reset(self):
        """重置脉动阵列"""
        self.array = [[{'a': 0, 'b': 0, 'c': 0} for _ in range(size)] for _ in range(size)]
        self.cycle = 0
    
    def step(self, a_inputs, b_inputs):
        """执行一个时钟周期"""
        # 创建新的阵列状态
        new_array = [[{'a': 0, 'b': 0, 'c': 0} for _ in range(self.size)] for _ in range(self.size)]
        
        # 更新每个PE
        for i in range(self.size):
            for j in range(self.size):
                # 获取输入
                if j == 0:
                    a_in = a_inputs[i] if i < len(a_inputs) else 0
                else:
                    a_in = self.array[i][j-1]['a']
                    
                if i == 0:
                    b_in = b_inputs[j] if j < len(b_inputs) else 0
                else:
                    b_in = self.array[i-1][j]['b']
                
                # 计算MAC
                new_array[i][j]['c'] = self.array[i][j]['c'] + a_in * b_in
                
                # 传递数据
                new_array[i][j]['a'] = a_in
                new_array[i][j]['b'] = b_in
        
        self.array = new_array
        self.cycle += 1
        
    def get_result(self):
        """获取计算结果"""
        result = np.zeros((self.size, self.size))
        for i in range(self.size):
            for j in range(self.size):
                result[i][j] = self.array[i][j]['c']
        return result
    
    def print_state(self):
        """打印当前状态"""
        print(f"\n周期 {self.cycle}:")
        for i in range(self.size):
            for j in range(self.size):
                pe = self.array[i][j]
                print(f"({pe['a']},{pe['b']},{pe['c']:3})", end=" ")
            print()

# 使用示例
def matrix_multiply_systolic(A, B):
    """使用脉动阵列计算矩阵乘法"""
    size = len(A)
    sa = SystolicArray(size)
    
    # 准备输入数据（需要错开时序）
    a_streams = []
    b_streams = []
    
    for i in range(size):
        # A矩阵的行需要错开输入
        a_stream = [0] * i + list(A[i]) + [0] * (size - 1)
        a_streams.append(a_stream)
        
        # B矩阵的列需要错开输入
        b_stream = [0] * i + [B[j][i] for j in range(size)] + [0] * (size - 1)
        b_streams.append(b_stream)
    
    # 执行计算
    max_cycles = 3 * size - 2  # 完成计算需要的周期数
    
    for cycle in range(max_cycles):
        # 准备这个周期的输入
        a_inputs = []
        b_inputs = []
        
        for i in range(size):
            if cycle < len(a_streams[i]):
                a_inputs.append(a_streams[i][cycle])
            else:
                a_inputs.append(0)
                
            if cycle < len(b_streams[i]):
                b_inputs.append(b_streams[i][cycle])
            else:
                b_inputs.append(0)
        
        sa.step(a_inputs[:size], b_inputs[:size])
        sa.print_state()
    
    return sa.get_result()

# 测试
if __name__ == "__main__":
    A = np.array([[1, 2, 3, 4],
                  [5, 6, 7, 8],
                  [9, 10, 11, 12],
                  [13, 14, 15, 16]])
    
    B = np.array([[1, 0, 0, 0],
                  [0, 1, 0, 0],
                  [0, 0, 1, 0],
                  [0, 0, 0, 1]])
    
    print("矩阵A:")
    print(A)
    print("\n矩阵B:")
    print(B)
    
    result = matrix_multiply_systolic(A, B)
    print("\n脉动阵列计算结果:")
    print(result)
    
    print("\nNumPy验证结果:")
    print(np.matmul(A, B))
                        </div>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目1.8：</strong>分析题：为什么大多数NPU采用INT8而不是FP32进行推理？从硬件实现角度分析其优势。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>从四个角度分析：1) 硬件面积（乘法器和加法器的面积对比） 2) 功耗（动态功耗与位宽的关系） 3) 内存带宽（数据传输量） 4) 时序优化（运算延迟）。记住：硬件成本与位宽往往是平方或立方关系。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p>NPU采用INT8进行推理的硬件优势：</p>
                        <ol>
                            <li><strong>硬件面积：</strong>
                                <ul>
                                    <li>INT8乘法器面积约为FP32的1/8</li>
                                    <li>INT8加法器面积约为FP32的1/4</li>
                                    <li>相同面积可集成4-8倍的计算单元</li>
                                </ul>
                            </li>
                            <li><strong>功耗效率：</strong>
                                <ul>
                                    <li>INT8运算功耗约为FP32的1/4</li>
                                    <li>数据位宽减少，总线功耗降低75%</li>
                                </ul>
                            </li>
                            <li><strong>内存带宽：</strong>
                                <ul>
                                    <li>数据量减少4倍，缓解内存瓶颈</li>
                                    <li>片上缓存可存储更多数据</li>
                                </ul>
                            </li>
                            <li><strong>时序优化：</strong>
                                <ul>
                                    <li>INT8运算延迟更低，便于提高主频</li>
                                    <li>流水线级数减少，控制逻辑简化</li>
                                </ul>
                            </li>
                        </ol>
                        <p><strong>实际应用中通过量化感知训练，INT8精度损失通常小于1%，是性能功耗比的最佳选择。</strong></p>
                    </div>
                </div>
            </div>
            
            <div class="exercise">
                <h4>练习题集 1</h4>
                <p>本章的练习题旨在加深你对NPU基本概念、架构特点和发展趋势的理解。通过这些练习，你将更好地掌握NPU与CPU/GPU的本质区别，以及不同NPU架构的设计权衡。</p>
                
                <div class="question">
                    <p><strong>题目1.1：</strong>计算并比较在执行一个1024×1024的矩阵乘法时，CPU、GPU和NPU的理论性能差异。假设：</p>
                    <ul>
                        <li>CPU：Intel Xeon，32核，AVX-512（每核每周期16个FP32 MAC），主频3GHz</li>
                        <li>GPU：NVIDIA V100，5120个CUDA核心，主频1.5GHz，每核每周期1个FP32 MAC</li>
                        <li>NPU：256×256 MAC阵列，主频1GHz，INT8运算</li>
                    </ul>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>计算步骤：1) 先算每个处理器每秒能执行多少MAC操作 2) 1024×1024矩阵乘法需要1024³次MAC操作 3) 用总操作数除以每秒操作数得到时间。注意：NPU使用INT8，其他使用FP32，但在计算理论性能时可以直接比较MAC数。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p><strong>1. CPU性能计算：</strong></p>
                        <ul>
                            <li>每周期MAC数：32核 × 16 MAC/核 = 512 MAC</li>
                            <li>每秒MAC数：512 × 3GHz = 1.536 TFLOPS</li>
                            <li>矩阵乘法需要：1024³ = 1,073,741,824 次MAC</li>
                            <li>理论时间：1,073,741,824 / (1.536×10¹²) = 0.698ms</li>
                        </ul>
                        
                        <p><strong>2. GPU性能计算：</strong></p>
                        <ul>
                            <li>每周期MAC数：5120核 × 1 MAC/核 = 5120 MAC</li>
                            <li>每秒MAC数：5120 × 1.5GHz = 7.68 TFLOPS</li>
                            <li>理论时间：1,073,741,824 / (7.68×10¹²) = 0.140ms</li>
                        </ul>
                        
                        <p><strong>3. NPU性能计算：</strong></p>
                        <ul>
                            <li>每周期MAC数：256 × 256 = 65,536 MAC</li>
                            <li>每秒MAC数：65,536 × 1GHz = 65.536 TOPS（INT8）</li>
                            <li>理论时间：1,073,741,824 / (65.536×10¹²) = 0.016ms</li>
                        </ul>
                        
                        <p><strong>性能对比：</strong></p>
                        <table>
                            <tr>
                                <th>处理器</th>
                                <th>理论时间</th>
                                <th>相对性能</th>
                                <th>能效考虑</th>
                            </tr>
                            <tr>
                                <td>CPU</td>
                                <td>0.698ms</td>
                                <td>1×</td>
                                <td>~150W</td>
                            </tr>
                            <tr>
                                <td>GPU</td>
                                <td>0.140ms</td>
                                <td>5×</td>
                                <td>~300W</td>
                            </tr>
                            <tr>
                                <td>NPU</td>
                                <td>0.016ms</td>
                                <td>43.6×</td>
                                <td>~50W</td>
                            </tr>
                        </table>
                        
                        <p><strong>关键洞察：</strong>NPU通过专用架构和低精度计算，在矩阵运算上实现了数量级的性能和能效提升。</p>
                    </div>
                </div>
                
                <div class="question">
                    <p><strong>题目1.2：</strong>分析Google TPU v1的脉动阵列架构。如果要计算一个矩阵乘法 C[4×4] = A[4×3] × B[3×4]，描述数据在4×4脉动阵列中的流动过程。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>脉动阵列中，A矩阵从左侧输入（每行错开一个时钟），B矩阵从顶部输入（每列错开一个时钟）。PE[i][j]负责计算C[i][j]。思考：1) 数据如何斜向流入阵列？ 2) 每个PE何时开始计算？ 3) 总共需要多少个时钟周期？</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p>脉动阵列的核心思想是让数据像心脏搏动一样有节奏地在处理单元间流动。对于矩阵乘法，采用输出固定（Output Stationary）模式：</p>
                        
                        <div class="code-block">
// 脉动阵列布局（每个PE计算一个输出元素）
PE[0][0] → PE[0][1] → PE[0][2] → PE[0][3]
   ↓          ↓          ↓          ↓
PE[1][0] → PE[1][1] → PE[1][2] → PE[1][3]
   ↓          ↓          ↓          ↓
PE[2][0] → PE[2][1] → PE[2][2] → PE[2][3]
   ↓          ↓          ↓          ↓
PE[3][0] → PE[3][1] → PE[3][2] → PE[3][3]

// PE[i][j]负责计算C[i][j] = Σ A[i][k] × B[k][j]
                        </div>
                        
                        <p><strong>数据流动时序：</strong></p>
                        <ul>
                            <li><strong>时刻0：</strong>A[0][0]进入PE[0][0]，B[0][0]进入PE[0][0]</li>
                            <li><strong>时刻1：</strong>
                                <ul>
                                    <li>A[0][0]→PE[0][1]，A[1][0]→PE[1][0]</li>
                                    <li>B[0][0]→PE[1][0]，B[0][1]→PE[0][1]</li>
                                    <li>A[0][1]和B[1][0]进入边界PE</li>
                                </ul>
                            </li>
                            <li><strong>时刻2-5：</strong>数据继续按对角线方向流动</li>
                            <li><strong>时刻6：</strong>所有PE完成计算，C矩阵就绪</li>
                        </ul>
                        
                        <p><strong>关键特性：</strong></p>
                        <ul>
                            <li>每个数据只从内存读取一次</li>
                            <li>数据在PE间传递，最大化复用</li>
                            <li>所有PE同时工作，利用率接近100%</li>
                            <li>延迟确定：M+N+K-2个周期</li>
                        </ul>
                    </div>
                </div>
                
                <div class="question">
                    <p><strong>题目1.3：</strong>某边缘设备需要运行一个轻量级CNN模型，推理延迟要求<10ms，功耗预算<5W。请分析应该选择哪种处理器，并说明理由。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>分析每种处理器的特点：1) CPU - 灵活但AI性能有限 2) GPU - 性能强但功耗高 3) NPU - 专用AI加速，功耗低。考虑轻量级CNN（如MobileNet）的计算量约300MOPS，需要什么级别的算力才能在10ms内完成？</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p>对于边缘AI推理场景，NPU是最佳选择。具体分析如下：</p>
                        
                        <p><strong>1. 排除CPU：</strong></p>
                        <ul>
                            <li>移动CPU（如ARM Cortex-A78）AI性能约10 GOPS</li>
                            <li>运行轻量CNN（如MobileNet）需要约300 MOPS</li>
                            <li>推理时间：30ms+，无法满足延迟要求</li>
                        </ul>
                        
                        <p><strong>2. 排除GPU：</strong></p>
                        <ul>
                            <li>移动GPU功耗通常>10W（如移动版RTX）</li>
                            <li>即使是集成GPU，全速运行也会超过5W预算</li>
                            <li>且GPU在低功耗模式下性能急剧下降</li>
                        </ul>
                        
                        <p><strong>3. NPU方案：</strong></p>
                        <ul>
                            <li>选择：高通Hexagon DSP或华为NPU</li>
                            <li>性能：2-4 TOPS @ INT8</li>
                            <li>功耗：1-3W</li>
                            <li>推理延迟：3-5ms（MobileNet v2）</li>
                        </ul>
                        
                        <p><strong>优化建议：</strong></p>
                        <ul>
                            <li>模型量化到INT8，性能提升4倍</li>
                            <li>使用深度可分离卷积减少计算量</li>
                            <li>启用NPU的动态功耗管理</li>
                            <li>批处理大小设为1，优化延迟</li>
                        </ul>
                    </div>
                </div>
                
                <div class="question">
                    <p><strong>题目1.4：</strong>比较分析Systolic Array（脉动阵列）和Dataflow Architecture（数据流架构）两种NPU设计范式的优缺点。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>从以下方面比较：1) 规则性（哪个更规则，更容易实现） 2) 灵活性（对不同神经网络层的适应性） 3) 数据复用率 4) 控制复杂度 5) 面积利用率。思考：脉动阵列的数据流动是如何的？数据流架构的灵活性体现在哪里？</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        
                        <div class="table-wrapper">
                            <table>
                                <thead>
                                    <tr>
                                        <th>特性</th>
                                        <th>脉动阵列</th>
                                        <th>数据流架构</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td>基本原理</td>
                                        <td>数据在PE阵列中有节奏地流动</td>
                                        <td>计算由数据可用性驱动</td>
                                    </tr>
                                    <tr>
                                        <td>控制复杂度</td>
                                        <td>简单，全局同步</td>
                                        <td>复杂，分布式控制</td>
                                    </tr>
                                    <tr>
                                        <td>数据复用</td>
                                        <td>高，系统性复用</td>
                                        <td>灵活，按需复用</td>
                                    </tr>
                                    <tr>
                                        <td>硬件利用率</td>
                                        <td>规则运算接近100%</td>
                                        <td>取决于数据依赖</td>
                                    </tr>
                                    <tr>
                                        <td>灵活性</td>
                                        <td>低，固定数据流模式</td>
                                        <td>高，支持不规则计算</td>
                                    </tr>
                                    <tr>
                                        <td>功耗特性</td>
                                        <td>稳定，易预测</td>
                                        <td>动态，细粒度控制</td>
                                    </tr>
                                    <tr>
                                        <td>适用场景</td>
                                        <td>密集矩阵运算</td>
                                        <td>稀疏/不规则运算</td>
                                    </tr>
                                    <tr>
                                        <td>典型代表</td>
                                        <td>Google TPU</td>
                                        <td>Graphcore IPU</td>
                                    </tr>
                                </tbody>
                            </table>
                        </div>
                        
                        <p><strong>设计选择建议：</strong></p>
                        <ul>
                            <li><strong>选择脉动阵列：</strong>当工作负载以密集矩阵运算为主，如CNN推理</li>
                            <li><strong>选择数据流架构：</strong>当需要支持动态图、稀疏网络或新型算子</li>
                            <li><strong>混合架构：</strong>结合两者优点，如华为达芬奇架构</li>
                        </ul>
                    </div>
                </div>
                
                <div class="question">
                    <p><strong>题目1.5：</strong>设计一个简化的NPU指令集架构（ISA），需要支持矩阵乘法、卷积、激活函数和数据搬运。列出关键指令并说明设计理由。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p>NPU ISA设计原则：高层抽象、以张量为操作单位、隐藏硬件细节。</p>
                        
                        <div class="code-block">
// NPU指令集架构设计
// 指令格式：[OPCODE(8)] [DEST(8)] [SRC1(8)] [SRC2(8)] [PARAMS(32)]

// 1. 计算指令
TMUL    dest, src1, src2, [M, K, N]      // 张量矩阵乘法
TCONV   dest, input, weight, [params]     // 张量卷积
TPOOL   dest, src, [type, kernel, stride] // 池化操作
TACT    dest, src, [function_id]          // 激活函数

// 2. 数据传输指令  
TLOAD   dest, [mem_addr, shape, layout]   // 从内存加载张量
TSTORE  src, [mem_addr, shape, layout]    // 存储张量到内存
TMOVE   dest, src                          // 片上张量搬移
TCAST   dest, src, [from_type, to_type]   // 数据类型转换

// 3. 控制指令
TSYNC                                      // 同步屏障
TLOOP   count, [body_addr]                // 张量操作循环
TJUMP   condition, [target_addr]          // 条件跳转

// 4. 配置指令
TCONF   [param_type, value]               // 配置硬件参数
TQUANT  [scale, zero_point]               // 配置量化参数
                        </div>
                        
                        <p><strong>设计理由：</strong></p>
                        <ol>
                            <li><strong>张量级操作：</strong>一条指令完成整个张量运算，减少指令数量</li>
                            <li><strong>参数化设计：</strong>通过参数字段支持不同大小和配置</li>
                            <li><strong>内存抽象：</strong>自动处理数据布局转换和对齐</li>
                            <li><strong>硬件加速：</strong>每条指令映射到专门的硬件单元</li>
                            <li><strong>简化编程：</strong>编译器容易生成，硬件容易解码</li>
                        </ol>
                        
                        <p><strong>示例程序：</strong></p>
                        <div class="code-block">
// 执行一个卷积层
TLOAD   T0, [input_addr, (1,224,224,3), NHWC]    // 加载输入
TLOAD   T1, [weight_addr, (64,3,3,3), OIHW]      // 加载权重  
TCONV   T2, T0, T1, [stride=1, pad=1]            // 卷积运算
TACT    T3, T2, [RELU]                            // ReLU激活
TSTORE  T3, [output_addr, (1,224,224,64), NHWC]  // 存储结果
                        </div>
                    </div>
                </div>
            </div>
            
            <div class="section-summary">
                <h4>本章小结</h4>
                <ul>
                    <li><strong>NPU是AI时代的专用处理器，</strong>通过领域专用架构设计实现了极致的性能和能效</li>
                    <li><strong>相比CPU和GPU，</strong>NPU在AI推理任务上有10-100倍的能效优势</li>
                    <li><strong>脉动阵列、数据流架构、3D堆叠</strong>等创新技术推动了NPU的快速发展</li>
                    <li><strong>主流NPU产品</strong>包括Google TPU、华为Ascend、寒武纪MLU等，各有特色</li>
                    <li><strong>NPU的未来</strong>将向着更高能效、更大规模、更智能化的方向发展</li>
                </ul>
            </div>
        </div>

        <div id="chapter2" class="chapter">
            <h2>第2章：神经网络计算基础</h2>
            
            <p>要设计高效的NPU，必须深入理解神经网络的计算本质。本章将从硬件设计者的视角，详细分析神经网络的基本运算、数据流特征和优化机会。通过对计算模式的深入剖析，我们能够识别出硬件加速的关键点，为后续的NPU架构设计奠定基础。</p>
            
            <h3>2.1 神经网络基本运算</h3>
            
            <p>神经网络虽然结构复杂，但其底层运算却相对简单和规律。这种"复杂系统由简单元素构成"的特性，正是硬件加速的机会所在。通过对基本运算的深入分析，我们可以设计出高效的硬件加速单元。</p>
            
            <h4>2.1.1 神经元计算模型</h4>
            <p>神经元是神经网络的基本计算单元，其灵感来源于生物神经元。从数学角度看，一个神经元执行的是加权求和后的非线性变换。虽然概念简单，但当数百万个神经元协同工作时，就能展现出强大的学习和推理能力。</p>
            
            <p>人工神经元的数学模型可以表示为：</p>
            <div class="code-block">
y = f(Σ(wi * xi) + b)

其中：
- xi：输入信号（来自上一层神经元的输出）
- wi：连接权重（通过学习得到的参数）
- wi * xi：加权输入 (Weighted Input)
- Σ(...)：对所有输入的求和 (Summation)  
- b：偏置项 (Bias)，用于调节神经元的激活阈值
- f(...)：激活函数 (Activation Function)，引入非线性
- y：神经元的输出
            </div>
            
            <p>从硬件实现的角度，我们需要关注这个计算过程的几个关键特征：</p>
            
            <div class="info-box">
                <p><strong>硬件视角：计算分解</strong></p>
                <p>神经元的计算可以分解为以下几个阶段，每个阶段对应不同的硬件需求：</p>
                <ol>
                    <li><strong>乘法运算阶段：</strong>wi * xi
                        <ul>
                            <li>需要大量并行乘法器</li>
                            <li>数据类型通常为定点数（INT8/INT16）或浮点数（FP16/FP32）</li>
                            <li>乘法器的位宽直接影响芯片面积和功耗</li>
                        </ul>
                    </li>
                    <li><strong>累加运算阶段：</strong>Σ(wi * xi)
                        <ul>
                            <li>需要加法树或累加器</li>
                            <li>要考虑累加过程中的位宽增长</li>
                            <li>流水线设计可以提高吞吐量</li>
                        </ul>
                    </li>
                    <li><strong>偏置加法：</strong>+ b
                        <ul>
                            <li>简单的加法运算</li>
                            <li>可以与累加阶段合并</li>
                        </ul>
                    </li>
                    <li><strong>激活函数：</strong>f(...)
                        <ul>
                            <li>不同激活函数的硬件复杂度差异很大</li>
                            <li>可以使用查找表（LUT）或分段线性近似</li>
                            <li>某些函数（如ReLU）可以用简单逻辑实现</li>
                        </ul>
                    </li>
                </ol>
            </div>
            
            <p><strong>计算密度分析：</strong></p>
            <p>在典型的全连接层中，假设输入维度为N，输出维度为M，则需要：</p>
            <ul>
                <li>乘法运算：N × M 次</li>
                <li>加法运算：(N-1) × M 次（累加）+ M 次（偏置）</li>
                <li>激活函数：M 次</li>
            </ul>
            
            <p>可以看出，乘累加（MAC）运算占据了绝大部分的计算量。这就是为什么MAC阵列成为NPU设计的核心。一个高效的MAC阵列设计，可以在单个时钟周期内完成大量的乘累加运算，这是NPU相比通用处理器的主要优势来源。</p>

            <p><strong>量化（Quantization）：NPU设计的关键优化</strong></p>
            <p>在传统的深度学习训练中，通常使用32位浮点数（FP32）来保证精度。然而，在推理阶段，这种精度往往是过度的。量化技术通过降低数值精度来换取显著的硬件效率提升：</p>
            
            <p><strong>1. 量化的动机：</strong></p>
            <ul>
                <li><strong>功耗降低：</strong>INT8乘法器的功耗仅为FP32的1/30</li>
                <li><strong>面积缩减：</strong>INT8乘法器面积约为FP32的1/16</li>
                <li><strong>带宽节省：</strong>数据位宽减少4倍，内存带宽需求相应降低</li>
                <li><strong>性能提升：</strong>同样的硬件面积可以部署更多的INT8 MAC单元</li>
            </ul>
            
            <p><strong>2. 量化的挑战与硬件支持：</strong></p>
            <ul>
                <li><strong>精度损失：</strong>需要精心的量化策略（如感知量化训练QAT）</li>
                <li><strong>溢出风险：</strong>累加过程中需要防止整数溢出</li>
                <li><strong>非对称量化支持：</strong>硬件需要支持零点（Zero-Point）和缩放因子（Scale Factor）的计算</li>
            </ul>
            
            <div class="code-block">
// 非对称量化的硬件实现
quantized_value = round((float_value / scale) + zero_point)
dequantized_value = (quantized_value - zero_point) * scale

// 硬件需要高效实现：
// 1. 缩放因子的乘法（通常使用移位近似）
// 2. 零点的加减运算
// 3. 饱和运算防止溢出
            </div>
            
            <p><strong>3. 动态定点数（Dynamic Fixed-Point）：</strong></p>
            <p>现代NPU通常支持动态调整定点数的小数位，在不同层使用不同的量化参数，以在精度和效率间取得最佳平衡。硬件需要支持：</p>
            <ul>
                <li>可配置的移位器（Configurable Shifters）</li>
                <li>饱和逻辑（Saturation Logic）</li>
                <li>溢出检测（Overflow Detection）</li>
            </ul>

            <h4>2.1.2 激活函数的硬件实现</h4>
            <p>激活函数是神经网络的关键组成部分，它为网络引入非线性，使得网络能够学习复杂的函数映射关系。从硬件设计的角度，不同激活函数的实现复杂度差异巨大。选择合适的激活函数，不仅影响模型的准确性，还直接影响NPU的面积、功耗和性能。</p>
            
            <p><strong>激活函数的硬件实现策略：</strong></p>
            <p>在NPU设计中，激活函数的实现通常采用以下几种策略：</p>
            <ol>
                <li><strong>直接计算法：</strong>对于简单的函数如ReLU，使用基本逻辑门即可实现</li>
                <li><strong>查找表法（LUT）：</strong>预先计算函数值存储在ROM中，通过查表获得结果</li>
                <li><strong>分段线性逼近：</strong>将复杂函数分段用直线逼近，平衡精度和硬件成本</li>
                <li><strong>多项式逼近：</strong>使用泰勒级数或其他多项式逼近复杂函数</li>
                <li><strong>CORDIC算法：</strong>用于计算三角函数和指数函数的迭代算法</li>
            </ol>
            
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>激活函数</th>
                            <th>公式</th>
                            <th>硬件实现方式</th>
                            <th>硬件成本</th>
                            <th>设计考虑</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>ReLU</td>
                            <td>max(0, x)</td>
                            <td>比较器 + 选择器</td>
                            <td>极低</td>
                            <td>最简单高效，广泛使用</td>
                        </tr>
                        <tr>
                            <td>Leaky ReLU</td>
                            <td>max(αx, x)</td>
                            <td>乘法器 + 比较器 + 选择器</td>
                            <td>低</td>
                            <td>需要额外的乘法器</td>
                        </tr>
                        <tr>
                            <td>Sigmoid</td>
                            <td>1/(1+e^(-x))</td>
                            <td>查找表(LUT) / 分段线性逼近</td>
                            <td>高</td>
                            <td>需要大容量存储或复杂逻辑</td>
                        </tr>
                        <tr>
                            <td>Tanh</td>
                            <td>(e^x - e^(-x))/(e^x + e^(-x))</td>
                            <td>查找表(LUT) / 分段线性逼近</td>
                            <td>高</td>
                            <td>与Sigmoid类似的复杂度</td>
                        </tr>
                        <tr>
                            <td>GeLU</td>
                            <td>x * Φ(x)</td>
                            <td>多级查找表 + 插值</td>
                            <td>很高</td>
                            <td>需要高精度实现</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h3>2.2 矩阵乘法与卷积运算</h3>
            
            <p>矩阵运算是神经网络的计算核心。据统计，在典型的深度学习模型中，超过90%的计算时间都花费在矩阵乘法和卷积运算上。深入理解这些运算的特点，对于设计高效的NPU至关重要。本节将从算法原理、硬件映射和优化策略等多个角度，全面分析这些核心运算。</p>
            
            <h4>2.2.1 通用矩阵乘法（GEMM）</h4>
            <p>通用矩阵乘法（General Matrix Multiplication, GEMM）是线性代数的基础运算，也是全连接层、循环神经网络等结构的核心。在深度学习中，GEMM通常表示为：<code>Y = αXW + βY</code>，其中α和β是标量系数。</p>
            
            <p><strong>GEMM的计算特征分析：</strong></p>
            <p>考虑矩阵乘法 C = A × B，其中A的维度为M×K，B的维度为K×N，结果C的维度为M×N。这个运算具有以下特征：</p>
            <ul>
                <li><strong>计算密度：</strong>需要M×N×K次乘法和M×N×(K-1)次加法</li>
                <li><strong>数据复用：</strong>A的每个元素被复用N次，B的每个元素被复用M次</li>
                <li><strong>并行性：</strong>输出矩阵的每个元素可以独立计算，具有天然的并行性</li>
                <li><strong>访存比：</strong>计算访存比为O(MNK)/O(MK+KN+MN) = O(K)，K越大越有利</li>
            </ul>
            
            <div class="code-block">
// 矩阵乘法的基本实现
for (int i = 0; i < M; i++) {
    for (int j = 0; j < N; j++) {
        float sum = 0;
        for (int k = 0; k < K; k++) {
            sum += A[i][k] * B[k][j];  // MAC运算
        }
        C[i][j] = sum;
    }
}

// 硬件视角的优化考虑：
// 1. 内层循环是MAC运算，适合并行化
// 2. 数据复用：A的每一行被复用N次，B的每一列被复用M次
// 3. 访存模式：顺序访问A，跳跃访问B（缓存不友好）
// 4. 可以通过分块（tiling）提高缓存利用率
            </div>
            
            <p><strong>GEMM的硬件加速策略：</strong></p>
            <p>NPU通过以下策略加速GEMM运算：</p>
            <ol>
                <li><strong>空间并行化：</strong>使用二维MAC阵列，同时计算多个输出元素</li>
                <li><strong>时间流水线：</strong>将乘法和加法操作流水线化，提高吞吐量</li>
                <li><strong>数据分块：</strong>将大矩阵分解为小块，适配片上缓存大小</li>
                <li><strong>双缓冲技术：</strong>计算和数据传输重叠，隐藏内存延迟</li>
            </ol>

            <h4>2.2.2 卷积运算的实现方式</h4>
            
            <p>卷积是卷积神经网络（CNN）的核心运算，负责提取局部特征。与全连接层不同，卷积利用了参数共享和局部连接的特性，大大减少了参数量。然而，卷积的多维特性和复杂的数据访问模式，给硬件实现带来了独特的挑战。</p>
            
            <div class="warning-box">
                <p><strong>核心挑战：</strong>卷积运算涉及多维数据和复杂的访存模式，如何高效地映射到硬件是NPU设计的关键。主要挑战包括：</p>
                <ul>
                    <li>多重嵌套循环，循环边界复杂</li>
                    <li>数据复用模式不规则</li>
                    <li>需要处理边界填充（padding）</li>
                    <li>步长（stride）可能导致不规则访问</li>
                </ul>
            </div>

            <p><strong>方法1：Im2Col + GEMM</strong></p>
            <p>Im2Col（Image to Column）是将卷积转换为矩阵乘法的经典方法。这种方法通过数据重组，将卷积运算转化为标准的GEMM运算，从而可以复用已有的矩阵乘法硬件。</p>
            
            <div class="code-block">
// Im2Col转换示例
// 输入: [H, W, C_in]
// 卷积核: [K_h, K_w, C_in, C_out]
// 输出: [H_out, W_out, C_out]

// Step 1: Im2Col展开
// 将每个卷积窗口展开成一列
// 展开后矩阵大小: [K_h * K_w * C_in, H_out * W_out]

// Step 2: 矩阵乘法
// 权重矩阵: [C_out, K_h * K_w * C_in]
// 结果 = 权重矩阵 × Im2Col矩阵

// 优点：
// - 可以复用高效的GEMM硬件
// - 实现简单，易于优化
// - 适合大batch size的场景

// 缺点：
// - 内存开销大（K_h * K_w倍的数据冗余）
// - 数据重组本身需要时间
// - 对缓存不友好
            </div>
            
            <p><strong>Im2Col的内存开销分析：</strong></p>
            <p>假设输入特征图大小为224×224×3（典型的ImageNet输入），使用3×3卷积核，则Im2Col后的数据量为：</p>
            <ul>
                <li>原始数据：224 × 224 × 3 = 150,528 个元素</li>
                <li>Im2Col后：3 × 3 × 3 × 224 × 224 = 1,354,752 个元素</li>
                <li>数据膨胀：9倍</li>
            </ul>

            <p><strong>方法2：直接卷积</strong></p>
            <p>直接卷积是专门为卷积运算设计的硬件架构，避免了Im2Col的内存开销。这种方法通过巧妙的数据流设计和缓存策略，直接在输入数据上执行卷积运算。</p>
            
            <p><strong>直接卷积的数据流模式：</strong></p>
            <p>在硬件实现上，直接卷积有不同的数据流派，每种流派针对不同的优化目标：</p>
            <ul>
                <li><strong>输入固定流（Input Stationary）：</strong>最大化输入数据复用，适合大卷积核</li>
                <li><strong>权重固定流（Weight Stationary）：</strong>最小化权重读取，适合深度可分离卷积</li>
                <li><strong>输出固定流（Output Stationary）：</strong>最小化部分和的读写，适合标准卷积</li>
            </ul>
            
            <p><strong>直接卷积的关键组件：</strong></p>
            <ol>
                <li><strong>Line Buffer：</strong>缓存多行输入数据，支持垂直方向的数据复用</li>
                <li><strong>Window Buffer：</strong>提取当前卷积窗口的所有像素</li>
                <li><strong>MAC阵列：</strong>并行执行卷积窗口内的所有乘累加运算</li>
                <li><strong>控制逻辑：</strong>管理数据流动、处理边界条件</li>
            </ol>
            
            <div class="code-block">
// 直接卷积的硬件实现示例
module ConvolutionEngine #(
    parameter IN_WIDTH = 8,        // 输入数据位宽
    parameter WEIGHT_WIDTH = 8,    // 权重位宽
    parameter OUT_WIDTH = 32,      // 输出位宽（考虑累加后的位宽增长）
    parameter KERNEL_SIZE = 3,     // 卷积核大小
    parameter IN_CHANNELS = 64,    // 输入通道数
    parameter OUT_CHANNELS = 128   // 输出通道数
)(
    input clk,
    input rst_n,
    input [IN_WIDTH-1:0] pixel_in,
    input [WEIGHT_WIDTH-1:0] weight,
    input valid_in,
    output [OUT_WIDTH-1:0] conv_out,
    output valid_out
);
    // Line Buffer：缓存KERNEL_SIZE-1行数据
    // 每行包含图像宽度个像素
    reg [IN_WIDTH-1:0] line_buffer[KERNEL_SIZE-1][IMAGE_WIDTH];
    
    // Window Buffer：提取KERNEL_SIZE×KERNEL_SIZE的卷积窗口
    reg [IN_WIDTH-1:0] window[KERNEL_SIZE][KERNEL_SIZE];
    
    // MAC阵列：KERNEL_SIZE×KERNEL_SIZE个MAC单元
    // 可以在一个周期内完成一个卷积窗口的计算
    wire [OUT_WIDTH-1:0] mac_results[KERNEL_SIZE][KERNEL_SIZE];
    
    // 累加树：将所有MAC结果累加
    wire [OUT_WIDTH-1:0] conv_result;
    
    // 数据流控制逻辑
    // - 管理Line Buffer的更新
    // - 控制Window Buffer的滑动
    // - 处理padding和stride
endmodule
            </div>
            
            <p><strong>直接卷积的优化技术：</strong></p>
            <ul>
                <li><strong>循环展开：</strong>将内层循环完全展开，用硬件并行实现</li>
                <li><strong>流水线设计：</strong>将卷积计算分解为多个流水级</li>
                <li><strong>数据预取：</strong>提前加载下一个卷积窗口的数据</li>
                <li><strong>部分和累加：</strong>跨输入通道的部分和可以流水线累加</li>
            </ul>

            <p><strong>方法3：Winograd算法</strong></p>
            <p>Winograd算法是一种通过数学变换减少乘法次数的快速卷积方法，特别适合小卷积核（如3×3）的实现。其核心思想是将卷积域的计算转换到变换域，在变换域中用更少的乘法完成等效计算。</p>
            
            <p><strong>Winograd F(2,3)算法示例：</strong></p>
            <p>对于3×3卷积，输出2×2的块，Winograd可以将原本需要的36次乘法减少到16次：</p>
            
            <div class="code-block">
// Winograd F(2,3)变换矩阵
// 输入变换矩阵 B^T
B^T = [1   0  -1   0]
      [0   1   1   0]
      [0  -1   1   0]
      [0   1   0  -1]

// 权重变换矩阵 G
G = [1    0    0]
    [0.5  0.5  0.5]
    [0.5 -0.5  0.5]
    [0    0    1]

// 输出变换矩阵 A^T
A^T = [1  1  1  0]
      [0  1 -1 -1]

// 计算流程：
// 1. 变换输入：V = B^T × d × B  (d是4×4输入块)
// 2. 变换权重：U = G × g × G^T  (g是3×3卷积核)
// 3. 元素乘法：M = U ⊙ V       (只需16次乘法)
// 4. 逆变换：Y = A^T × M × A   (得到2×2输出)
            </div>
            
            <p><strong>Winograd的硬件实现考虑：</strong></p>
            <ul>
                <li><strong>优点：</strong>
                    <ul>
                        <li>显著减少乘法次数（3×3卷积可减少2.25倍）</li>
                        <li>适合小卷积核，特别是3×3和5×5</li>
                        <li>可以与量化技术结合，进一步提升效率</li>
                    </ul>
                </li>
                <li><strong>缺点：</strong>
                    <ul>
                        <li>需要额外的变换运算（主要是加法）</li>
                        <li>数值稳定性问题，可能需要更高的中间精度</li>
                        <li>对大卷积核或步长>1的情况效果不佳</li>
                        <li>硬件实现复杂度较高</li>
                    </ul>
                </li>
            </ul>
            
            <p><strong>适用场景：</strong></p>
            <p>Winograd算法在以下场景中特别有效：</p>
            <ul>
                <li>卷积核大小固定（通常是3×3）</li>
                <li>步长为1的卷积层</li>
                <li>对功耗敏感的边缘设备</li>
                <li>批量大小较小的推理场景</li>
            </ul>

            <h4>2.2.3 池化层的硬件实现</h4>
            <p>池化（Pooling）是CNN中的下采样操作，虽然计算量远小于卷积，但其特殊的数据访问模式对硬件设计仍有一定要求。池化层通过聚合局部区域的特征来减少特征图的空间维度，既减少了后续层的计算量，又提供了一定的平移不变性。</p>
            
            <p><strong>常见池化类型的硬件实现：</strong></p>
            
            <p><strong>1. 最大池化（Max Pooling）</strong></p>
            <p>最大池化选择窗口内的最大值，硬件实现非常简单，主要使用比较器树：</p>
            
            <div class="code-block">
// 2×2 最大池化的硬件实现
module MaxPool2x2 #(
    parameter DATA_WIDTH = 8
)(
    input wire [DATA_WIDTH-1:0] in0, in1, in2, in3,
    output wire [DATA_WIDTH-1:0] out
);
    wire [DATA_WIDTH-1:0] max_01, max_23;
    
    // 第一级比较
    assign max_01 = (in0 > in1) ? in0 : in1;
    assign max_23 = (in2 > in3) ? in2 : in3;
    
    // 第二级比较
    assign out = (max_01 > max_23) ? max_01 : max_23;
endmodule

// 对于更大的池化窗口，可以构建比较器树
// 例如3×3需要log2(9)≈4级比较
            </div>
            
            <p><strong>2. 平均池化（Average Pooling）</strong></p>
            <p>平均池化计算窗口内所有值的平均，需要加法器和除法器（或移位器）：</p>
            
            <div class="code-block">
// 2×2 平均池化的硬件实现
module AvgPool2x2 #(
    parameter DATA_WIDTH = 8
)(
    input wire [DATA_WIDTH-1:0] in0, in1, in2, in3,
    output wire [DATA_WIDTH-1:0] out
);
    wire [DATA_WIDTH+1:0] sum;
    
    // 求和（位宽增加2位防止溢出）
    assign sum = in0 + in1 + in2 + in3;
    
    // 除以4（右移2位）
    assign out = sum[DATA_WIDTH+1:2];
endmodule

// 对于非2的幂次的池化窗口，需要真正的除法器
// 或使用乘法器配合预计算的倒数
            </div>
            
            <p><strong>池化层的优化策略：</strong></p>
            <ul>
                <li><strong>与激活函数集成：</strong>池化通常紧跟在ReLU之后，可以将两者合并在一个硬件模块中</li>
                <li><strong>行缓冲复用：</strong>池化的行缓冲可以与卷积共享，减少硬件开销</li>
                <li><strong>流水线设计：</strong>虽然池化计算简单，但仍需要流水线化以匹配卷积的吞吐率</li>
                <li><strong>可配置设计：</strong>支持不同的池化窗口大小和步长，提高硬件灵活性</li>
            </ul>

            <h3>2.3 数据流与并行计算</h3>
            
            <p>数据流架构是NPU设计的核心，它决定了数据如何在计算单元间流动、如何被复用，以及如何实现计算与数据传输的重叠。良好的数据流设计可以最大化硬件利用率，最小化内存访问，从而实现高性能和高能效。本节将深入探讨NPU中的数据流模式和并行计算策略。</p>
            
            <h4>2.3.1 数据流架构</h4>
            <p>在NPU设计中，数据流架构定义了数据在处理单元阵列中的移动模式。不同的数据流架构有不同的优缺点，适用于不同的应用场景。理解这些架构的特点，对于选择合适的NPU设计方案至关重要。</p>
            
            <p><strong>数据流架构的设计目标：</strong></p>
            <ul>
                <li><strong>最大化数据复用：</strong>减少对外部内存的访问次数</li>
                <li><strong>最小化数据移动：</strong>降低功耗，提高能效</li>
                <li><strong>平衡计算和访存：</strong>避免计算单元空闲等待数据</li>
                <li><strong>支持灵活的网络结构：</strong>适应不同大小的层和不同类型的运算</li>
            </ul>
            
            <p><strong>主流数据流架构详解：</strong></p>
            
            <p><strong>1. 权重固定流（Weight Stationary, WS）</strong></p>
            <p>权重固定流是最直观的数据流模式之一。在这种架构中，每个处理单元（PE）预先加载并保存一个或多个权重值，输入激活值和部分和在PE阵列中流动。</p>
            
            <div class="code-block">
// 权重固定流示例（2×2 PE阵列）
// PE[i][j]存储权重W[i][j]
PE[0][0]: W[0][0]  PE[0][1]: W[0][1]
PE[1][0]: W[1][0]  PE[1][1]: W[1][1]

// 时刻1：输入X[0]广播到第一行
PE[0][0]: X[0]×W[0][0]  PE[0][1]: X[0]×W[0][1]

// 时刻2：输入X[1]广播到第二行，部分和向下传递
PE[0][0]: X[1]×W[0][0]  PE[0][1]: X[1]×W[0][1]
PE[1][0]: P[0]+X[0]×W[1][0]  PE[1][1]: P[1]+X[0]×W[1][1]
            </div>
            
            <p>优势：权重只需加载一次，大大减少了权重内存带宽需求。特别适合批处理场景，可以对同一批次的多个样本复用权重。</p>
            
            <p><strong>2. 输出固定流（Output Stationary, OS）</strong></p>
            <p>输出固定流中，每个PE负责计算输出特征图的一个或多个固定位置。权重和输入数据流经PE阵列，部分和在PE内部累积直到计算完成。Google TPU的脉动阵列（Systolic Array）是这种架构的经典实现。</p>
            
            <div class="code-block">
// 脉动阵列示例
// 每个PE计算一个输出元素C[i][j] = Σ A[i][k] × B[k][j]

// PE阵列布局
PE[0][0] → PE[0][1] → PE[0][2]
   ↓          ↓          ↓
PE[1][0] → PE[1][1] → PE[1][2]
   ↓          ↓          ↓
PE[2][0] → PE[2][1] → PE[2][2]

// 数据流动：
// - A矩阵的行从左向右流动
// - B矩阵的列从上向下流动
// - 每个PE在本地累积部分和
            </div>
            
            <p>优势：最小化部分和的移动，减少了寄存器文件的读写。规则的数据流动模式使得控制逻辑简单，易于实现高频率设计。</p>
            
            <p><strong>3. 行固定流（Row Stationary, RS）</strong></p>
            <p>行固定流是MIT Eyeriss提出的一种更灵活的数据流模式。它试图在一行PE中最大化所有类型数据（输入、权重、部分和）的复用，是一种折中的设计。</p>
            
            <p>优势：能够同时利用多种数据的局部性，在不同的网络层配置下都能保持较好的性能。支持灵活的映射策略，可以适应不同大小的卷积核和特征图。</p>
            
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>数据流类型</th>
                            <th>固定数据</th>
                            <th>移动数据</th>
                            <th>优势</th>
                            <th>适用场景</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>权重固定(WS)</td>
                            <td>权重</td>
                            <td>输入、部分和</td>
                            <td>权重复用率高</td>
                            <td>权重大、批处理小</td>
                        </tr>
                        <tr>
                            <td>输出固定(OS)</td>
                            <td>部分和</td>
                            <td>权重、输入</td>
                            <td>减少部分和读写</td>
                            <td>输出通道多</td>
                        </tr>
                        <tr>
                            <td>输入固定(IS)</td>
                            <td>输入</td>
                            <td>权重、部分和</td>
                            <td>输入复用率高</td>
                            <td>输入大、权重小</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h4>2.3.2 并行计算维度</h4>
            <div class="code-block">
// 卷积运算的7个循环维度
for (n = 0; n < N; n++)         // Batch
  for (k = 0; k < K; k++)       // 输出通道
    for (c = 0; c < C; c++)     // 输入通道
      for (y = 0; y < Y; y++)   // 输出高度
        for (x = 0; x < X; x++) // 输出宽度
          for (fy = 0; fy < FY; fy++)   // 卷积核高度
            for (fx = 0; fx < FX; fx++) // 卷积核宽度
              out[n][k][y][x] += in[n][c][y+fy][x+fx] * w[k][c][fy][fx]

// NPU可以选择在不同维度上并行化：
// 1. 空间并行：在Y、X维度展开
// 2. 通道并行：在K、C维度展开
// 3. 批处理并行：在N维度展开
            </div>

            <h3>2.4 量化与数据格式</h3>
            
            <h4>2.4.1 量化原理</h4>
            <p>量化是将高精度浮点数转换为低精度定点数的过程，是NPU提升效率的关键技术。</p>
            
            <div class="code-block">
// 对称量化
int8_value = round(fp32_value / scale)
fp32_value = int8_value * scale

// 非对称量化
int8_value = round(fp32_value / scale) + zero_point
fp32_value = (int8_value - zero_point) * scale

// 量化参数计算
scale = (max_val - min_val) / (2^bits - 1)
zero_point = round(-min_val / scale)
            </div>

            <h4>2.4.2 不同精度的硬件开销对比</h4>
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>数据类型</th>
                            <th>位宽</th>
                            <th>乘法器面积</th>
                            <th>加法器面积</th>
                            <th>功耗比例</th>
                            <th>内存带宽</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>FP32</td>
                            <td>32-bit</td>
                            <td>1.0x</td>
                            <td>1.0x</td>
                            <td>1.0x</td>
                            <td>1.0x</td>
                        </tr>
                        <tr>
                            <td>FP16</td>
                            <td>16-bit</td>
                            <td>~0.25x</td>
                            <td>~0.5x</td>
                            <td>~0.4x</td>
                            <td>0.5x</td>
                        </tr>
                        <tr>
                            <td>INT8</td>
                            <td>8-bit</td>
                            <td>~0.125x</td>
                            <td>~0.25x</td>
                            <td>~0.25x</td>
                            <td>0.25x</td>
                        </tr>
                        <tr>
                            <td>INT4</td>
                            <td>4-bit</td>
                            <td>~0.06x</td>
                            <td>~0.125x</td>
                            <td>~0.1x</td>
                            <td>0.125x</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <div class="exercise">
                <h4>练习题集 2</h4>
                <p>本章的练习题旨在加深你对神经网络计算原理和硬件实现的理解。这些题目涵盖了MAC运算、矩阵乘法、卷积实现和数据流分析等关键概念。通过解决这些问题，你将更好地理解NPU设计中的权衡和优化策略。</p>
                
                <div class="question">
                    <p><strong>题目2.1：</strong>某NPU的MAC阵列大小为32×32，计算一个[512, 1024] × [1024, 2048]的矩阵乘法需要多少个计算周期？假设每个周期可以完成阵列大小的MAC运算。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>矩阵乘法需要分块计算。先计算：1) 结果矩阵的大小 2) 总MAC运算次数（M×N×K） 3) 每个维度需要多少个32×32的块 4) 总块数就是总周期数。注意边界处理使用向上取整。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p>矩阵分块计算：</p>
                        <ol>
                            <li>结果矩阵大小：[512, 2048]</li>
                            <li>总MAC运算次数：512 × 1024 × 2048 = 1,073,741,824</li>
                            <li>MAC阵列每周期运算次数：32 × 32 = 1,024</li>
                            <li>分块数量：
                                <ul>
                                    <li>M维度分块：⌈512/32⌉ = 16</li>
                                    <li>N维度分块：⌈2048/32⌉ = 64</li>
                                    <li>K维度分块：⌈1024/32⌉ = 32</li>
                                </ul>
                            </li>
                            <li>总周期数：16 × 64 × 32 = 32,768 周期</li>
                        </ol>
                        <p><strong>验证：</strong>32,768 × 1,024 = 33,554,432 ≈ 1,073,741,824 / 32（考虑边界填充）</p>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目2.2：</strong>设计一个支持ReLU和Sigmoid激活函数的硬件模块。对于Sigmoid，使用4段分段线性逼近。给出RTL设计框架。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>ReLU很简单：max(0, x)。Sigmoid的分段线性逼近需要：1) 划分区间（如[-8,-2.5], [-2.5,0], [0,2.5], [2.5,8]） 2) 每个区间用y=ax+b逼近 3) 使用比较器和选择器选择对应区间的参数。考虑定点数表示。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module ActivationUnit #(
    parameter DATA_WIDTH = 16,
    parameter FRAC_WIDTH = 8
)(
    input wire clk,
    input wire rst_n,
    input wire [DATA_WIDTH-1:0] data_in,
    input wire [1:0] act_type,  // 00: bypass, 01: ReLU, 10: Sigmoid
    input wire valid_in,
    output reg [DATA_WIDTH-1:0] data_out,
    output reg valid_out
);

    // Sigmoid分段线性逼近参数（4段）
    // 区间: [-8, -2.5], [-2.5, 0], [0, 2.5], [2.5, 8]
    localparam signed [DATA_WIDTH-1:0] SIGMOID_X1 = -16'd2048;  // -8 (Q8.8)
    localparam signed [DATA_WIDTH-1:0] SIGMOID_X2 = -16'd640;   // -2.5
    localparam signed [DATA_WIDTH-1:0] SIGMOID_X3 = 16'd0;      // 0
    localparam signed [DATA_WIDTH-1:0] SIGMOID_X4 = 16'd640;    // 2.5
    localparam signed [DATA_WIDTH-1:0] SIGMOID_X5 = 16'd2048;   // 8
    
    // 斜率和截距（根据Sigmoid曲线拟合得出）
    localparam [DATA_WIDTH-1:0] SLOPE1 = 16'd13;    // 0.05
    localparam [DATA_WIDTH-1:0] SLOPE2 = 16'd51;    // 0.2
    localparam [DATA_WIDTH-1:0] SLOPE3 = 16'd64;    // 0.25
    localparam [DATA_WIDTH-1:0] SLOPE4 = 16'd51;    // 0.2
    
    wire signed [DATA_WIDTH-1:0] data_in_signed;
    reg [DATA_WIDTH-1:0] relu_out;
    reg [DATA_WIDTH-1:0] sigmoid_out;
    reg [2*DATA_WIDTH-1:0] mult_result;
    
    assign data_in_signed = data_in;
    
    // ReLU实现
    always @(*) begin
        if (data_in_signed < 0)
            relu_out = 0;
        else
            relu_out = data_in;
    end
    
    // Sigmoid分段线性逼近
    always @(*) begin
        if (data_in_signed <= SIGMOID_X1) begin
            sigmoid_out = 16'd0;  // 0
        end else if (data_in_signed <= SIGMOID_X2) begin
            mult_result = (data_in_signed - SIGMOID_X1) * SLOPE1;
            sigmoid_out = mult_result[DATA_WIDTH+FRAC_WIDTH-1:FRAC_WIDTH];
        end else if (data_in_signed <= SIGMOID_X3) begin
            mult_result = (data_in_signed - SIGMOID_X2) * SLOPE2;
            sigmoid_out = 16'd26 + mult_result[DATA_WIDTH+FRAC_WIDTH-1:FRAC_WIDTH];  // 0.1 + ...
        end else if (data_in_signed <= SIGMOID_X4) begin
            mult_result = data_in_signed * SLOPE3;
            sigmoid_out = 16'd128 + mult_result[DATA_WIDTH+FRAC_WIDTH-1:FRAC_WIDTH];  // 0.5 + ...
        end else if (data_in_signed <= SIGMOID_X5) begin
            mult_result = (data_in_signed - SIGMOID_X4) * SLOPE4;
            sigmoid_out = 16'd230 + mult_result[DATA_WIDTH+FRAC_WIDTH-1:FRAC_WIDTH];  // 0.9 + ...
        end else begin
            sigmoid_out = 16'd256;  // 1.0
        end
    end
    
    // 输出选择
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            data_out <= 0;
            valid_out <= 0;
        end else if (valid_in) begin
            case (act_type)
                2'b00: data_out <= data_in;      // Bypass
                2'b01: data_out <= relu_out;     // ReLU
                2'b10: data_out <= sigmoid_out;  // Sigmoid
                default: data_out <= data_in;
            endcase
            valid_out <= 1;
        end else begin
            valid_out <= 0;
        end
    end
endmodule
                        </div>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目2.3：</strong>比较Im2Col+GEMM和直接卷积两种实现方式。对于一个输入[224,224,3]、卷积核[3,3,3,64]的卷积层，计算Im2Col的内存开销。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>Im2Col将卷积转换为矩阵乘法。内存开销计算：1) 每个输出位置对应的输入元素数 = 卷积核大小×输入通道数 2) 输出位置总数 = 输出特征图高×宽 3) Im2Col矩阵大小 = [卷积核元素数, 输出位置数]。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p><strong>1. Im2Col内存开销计算：</strong></p>
                        <ol>
                            <li>输出特征图大小（假设stride=1, padding=1）：[224, 224, 64]</li>
                            <li>Im2Col展开后每个位置：3×3×3 = 27个元素</li>
                            <li>总位置数：224×224 = 50,176</li>
                            <li>Im2Col矩阵大小：[27, 50,176]</li>
                            <li>内存占用（FP32）：27 × 50,176 × 4 bytes = 5.42 MB</li>
                            <li>原始输入大小：224 × 224 × 3 × 4 bytes = 0.60 MB</li>
                            <li><strong>内存扩展比例：9.0倍</strong></li>
                        </ol>
                        
                        <p><strong>2. 两种方式对比：</strong></p>
                        <table>
                            <tr>
                                <th>特性</th>
                                <th>Im2Col + GEMM</th>
                                <th>直接卷积</th>
                            </tr>
                            <tr>
                                <td>内存开销</td>
                                <td>高（9倍扩展）</td>
                                <td>低（仅需Line Buffer）</td>
                            </tr>
                            <tr>
                                <td>计算效率</td>
                                <td>高（复用GEMM优化）</td>
                                <td>中等</td>
                            </tr>
                            <tr>
                                <td>硬件复杂度</td>
                                <td>简单（复用GEMM单元）</td>
                                <td>复杂（需要专用控制）</td>
                            </tr>
                            <tr>
                                <td>适用场景</td>
                                <td>大卷积核、服务器端</td>
                                <td>小卷积核、边缘设备</td>
                            </tr>
                        </table>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目2.4：</strong>设计一个简单的脉动阵列数据流控制器，支持权重固定（Weight Stationary）模式。要求能够处理8×8的MAC阵列。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>权重固定模式下：1) 权重先加载到PE中并保持不变 2) 输入数据在PE间流动 3) 部分和累加在PE内部。控制器需要：状态机（加载权重、计算、存储结果）、地址生成、数据分配。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module WeightStationaryController #(
    parameter ARRAY_SIZE = 8,
    parameter DATA_WIDTH = 8,
    parameter ADDR_WIDTH = 16
)(
    input wire clk,
    input wire rst_n,
    input wire start,
    
    // 配置接口
    input wire [ADDR_WIDTH-1:0] input_base_addr,
    input wire [ADDR_WIDTH-1:0] weight_base_addr,
    input wire [ADDR_WIDTH-1:0] output_base_addr,
    input wire [15:0] M, N, K,  // 矩阵维度
    
    // SRAM接口
    output reg [ADDR_WIDTH-1:0] input_addr,
    output reg input_rd_en,
    input wire [DATA_WIDTH*ARRAY_SIZE-1:0] input_data,
    
    output reg [ADDR_WIDTH-1:0] weight_addr,
    output reg weight_rd_en,
    input wire [DATA_WIDTH*ARRAY_SIZE-1:0] weight_data,
    
    output reg [ADDR_WIDTH-1:0] output_addr,
    output reg output_wr_en,
    output reg [DATA_WIDTH*ARRAY_SIZE-1:0] output_data,
    
    // MAC阵列接口
    output reg [DATA_WIDTH-1:0] input_to_array [0:ARRAY_SIZE-1],
    output reg [DATA_WIDTH-1:0] weight_to_array [0:ARRAY_SIZE-1][0:ARRAY_SIZE-1],
    output reg weight_load,
    output reg compute_en,
    input wire [DATA_WIDTH-1:0] output_from_array [0:ARRAY_SIZE-1],
    
    // 状态输出
    output reg busy,
    output reg done
);

    // 状态机定义
    localparam IDLE = 3'd0;
    localparam LOAD_WEIGHT = 3'd1;
    localparam COMPUTE = 3'd2;
    localparam STORE_OUTPUT = 3'd3;
    localparam NEXT_TILE = 3'd4;
    
    reg [2:0] state, next_state;
    reg [15:0] tile_m, tile_n, tile_k;  // 当前处理的分块索引
    reg [15:0] cycle_cnt;                // 周期计数器
    reg [15:0] k_iter;                   // K维度迭代计数
    
    // 计算分块数量
    wire [15:0] num_tile_m = (M + ARRAY_SIZE - 1) / ARRAY_SIZE;
    wire [15:0] num_tile_n = (N + ARRAY_SIZE - 1) / ARRAY_SIZE;
    wire [15:0] num_tile_k = (K + ARRAY_SIZE - 1) / ARRAY_SIZE;
    
    // 状态机
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n)
            state <= IDLE;
        else
            state <= next_state;
    end
    
    // 状态转换逻辑
    always @(*) begin
        next_state = state;
        case (state)
            IDLE: begin
                if (start)
                    next_state = LOAD_WEIGHT;
            end
            
            LOAD_WEIGHT: begin
                if (cycle_cnt == ARRAY_SIZE - 1)
                    next_state = COMPUTE;
            end
            
            COMPUTE: begin
                if (k_iter == K - 1)
                    next_state = STORE_OUTPUT;
            end
            
            STORE_OUTPUT: begin
                if (cycle_cnt == ARRAY_SIZE - 1)
                    next_state = NEXT_TILE;
            end
            
            NEXT_TILE: begin
                if (tile_n == num_tile_n - 1 && 
                    tile_m == num_tile_m - 1)
                    next_state = IDLE;
                else
                    next_state = LOAD_WEIGHT;
            end
        endcase
    end
    
    // 控制逻辑
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            tile_m <= 0;
            tile_n <= 0;
            tile_k <= 0;
            cycle_cnt <= 0;
            k_iter <= 0;
            weight_load <= 0;
            compute_en <= 0;
            busy <= 0;
            done <= 0;
        end else begin
            case (state)
                IDLE: begin
                    if (start) begin
                        tile_m <= 0;
                        tile_n <= 0;
                        tile_k <= 0;
                        busy <= 1;
                        done <= 0;
                    end
                end
                
                LOAD_WEIGHT: begin
                    // 加载权重到阵列
                    weight_load <= 1;
                    weight_rd_en <= 1;
                    weight_addr <= weight_base_addr + 
                                  (tile_n * ARRAY_SIZE + cycle_cnt) * K + 
                                  tile_k * ARRAY_SIZE;
                    
                    // 将权重数据分配到阵列
                    for (int i = 0; i < ARRAY_SIZE; i++) begin
                        for (int j = 0; j < ARRAY_SIZE; j++) begin
                            weight_to_array[i][j] <= weight_data[j*DATA_WIDTH +: DATA_WIDTH];
                        end
                    end
                    
                    cycle_cnt <= cycle_cnt + 1;
                    if (cycle_cnt == ARRAY_SIZE - 1) begin
                        cycle_cnt <= 0;
                        weight_load <= 0;
                        weight_rd_en <= 0;
                    end
                end
                
                COMPUTE: begin
                    // 启动计算
                    compute_en <= 1;
                    input_rd_en <= 1;
                    
                    // 读取输入数据
                    input_addr <= input_base_addr + 
                                 (tile_m * ARRAY_SIZE) * K + 
                                 k_iter;
                    
                    // 将输入数据送入阵列
                    for (int i = 0; i < ARRAY_SIZE; i++) begin
                        input_to_array[i] <= input_data[i*DATA_WIDTH +: DATA_WIDTH];
                    end
                    
                    k_iter <= k_iter + 1;
                    if (k_iter == K - 1) begin
                        k_iter <= 0;
                        compute_en <= 0;
                        input_rd_en <= 0;
                    end
                end
                
                STORE_OUTPUT: begin
                    // 存储输出结果
                    output_wr_en <= 1;
                    output_addr <= output_base_addr + 
                                  (tile_m * ARRAY_SIZE + cycle_cnt) * N + 
                                  tile_n * ARRAY_SIZE;
                    
                    // 从阵列收集输出
                    for (int i = 0; i < ARRAY_SIZE; i++) begin
                        output_data[i*DATA_WIDTH +: DATA_WIDTH] <= output_from_array[i];
                    end
                    
                    cycle_cnt <= cycle_cnt + 1;
                    if (cycle_cnt == ARRAY_SIZE - 1) begin
                        cycle_cnt <= 0;
                        output_wr_en <= 0;
                    end
                end
                
                NEXT_TILE: begin
                    // 移动到下一个分块
                    if (tile_n < num_tile_n - 1) begin
                        tile_n <= tile_n + 1;
                    end else begin
                        tile_n <= 0;
                        tile_m <= tile_m + 1;
                    end
                    
                    if (tile_n == num_tile_n - 1 && 
                        tile_m == num_tile_m - 1) begin
                        busy <= 0;
                        done <= 1;
                    end
                end
            endcase
        end
    end
endmodule
                        </div>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目2.5：</strong>分析深度可分离卷积（Depthwise Separable Convolution）的计算特点，说明为什么它对NPU的内存带宽要求更高。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>深度可分离卷积分为：1) Depthwise：每个输入通道单独卷积 2) Pointwise：1×1卷积。计算计算强度（计算量/内存访问量），与普通卷积对比。考虑数据复用的机会。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p><strong>深度可分离卷积分解为两步：</strong></p>
                        <ol>
                            <li><strong>Depthwise Convolution：</strong>每个输入通道独立卷积
                                <ul>
                                    <li>计算量：H×W×C×K×K</li>
                                    <li>参数量：C×K×K</li>
                                </ul>
                            </li>
                            <li><strong>Pointwise Convolution (1×1卷积)：</strong>跨通道混合
                                <ul>
                                    <li>计算量：H×W×C×M</li>
                                    <li>参数量：C×M</li>
                                </ul>
                            </li>
                        </ol>
                        
                        <p><strong>计算强度分析（Compute-to-Memory Ratio）：</strong></p>
                        <table>
                            <tr>
                                <th>卷积类型</th>
                                <th>计算量</th>
                                <th>内存访问量</th>
                                <th>计算强度</th>
                            </tr>
                            <tr>
                                <td>标准卷积</td>
                                <td>H×W×C×M×K×K</td>
                                <td>H×W×(C+M) + C×M×K×K</td>
                                <td>O(K×K)</td>
                            </tr>
                            <tr>
                                <td>Depthwise</td>
                                <td>H×W×C×K×K</td>
                                <td>H×W×C×2 + C×K×K</td>
                                <td>O(1)</td>
                            </tr>
                            <tr>
                                <td>Pointwise</td>
                                <td>H×W×C×M</td>
                                <td>H×W×(C+M) + C×M</td>
                                <td>O(1)</td>
                            </tr>
                        </table>
                        
                        <p><strong>为什么内存带宽要求更高：</strong></p>
                        <ol>
                            <li><strong>计算强度低：</strong>Depthwise卷积的计算强度为O(1)，而标准卷积为O(K²)。这意味着每次内存访问只能支撑很少的计算。</li>
                            <li><strong>数据复用率低：</strong>
                                <ul>
                                    <li>标准卷积中，每个输入被M个输出通道复用</li>
                                    <li>Depthwise中，每个输入只被1个输出通道使用</li>
                                </ul>
                            </li>
                            <li><strong>Memory Bound：</strong>NPU的计算单元经常处于空闲状态，等待数据从内存加载。</li>
                        </ol>
                        
                        <p><strong>优化策略：</strong></p>
                        <ul>
                            <li>增加片上缓存容量</li>
                            <li>使用更宽的内存接口</li>
                            <li>将Depthwise和Pointwise融合执行，减少中间结果的存储</li>
                            <li>使用专门的DMA引擎进行数据预取</li>
                        </ul>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目2.6：</strong>实现一个简单的INT8量化模块，支持对称量化和非对称量化两种模式。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>对称量化：q = round(x/scale)，反量化：x = q*scale。非对称量化：q = round(x/scale) + zero_point。硬件实现需要：1) 除法器或移位器 2) 舍入单元 3) 饱和处理（防止溢出）。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module Quantizer #(
    parameter IN_WIDTH = 32,    // FP32输入
    parameter OUT_WIDTH = 8,    // INT8输出
    parameter SCALE_WIDTH = 16  // 定点scale表示
)(
    input wire clk,
    input wire rst_n,
    input wire [IN_WIDTH-1:0] fp_in,      // 浮点输入
    input wire [SCALE_WIDTH-1:0] scale,   // 量化尺度
    input wire [OUT_WIDTH-1:0] zero_point,// 零点（非对称量化）
    input wire symmetric_mode,            // 0: 非对称, 1: 对称
    input wire valid_in,
    
    output reg signed [OUT_WIDTH-1:0] int_out,  // 量化输出
    output reg valid_out
);

    // 内部信号
    reg [IN_WIDTH+SCALE_WIDTH-1:0] scaled_value;
    reg signed [IN_WIDTH-1:0] rounded_value;
    reg signed [IN_WIDTH-1:0] shifted_value;
    wire signed [OUT_WIDTH-1:0] saturated_value;
    
    // 饱和边界
    localparam signed [IN_WIDTH-1:0] MAX_INT8 = 127;
    localparam signed [IN_WIDTH-1:0] MIN_INT8 = -128;
    
    // Step 1: 缩放
    always @(*) begin
        // 假设scale是定点表示 (Q8.8格式)
        // 实际硬件中需要浮点转定点单元
        scaled_value = fp_in * scale;
    end
    
    // Step 2: 四舍五入
    always @(*) begin
        // 简化的四舍五入：加0.5后截断
        rounded_value = scaled_value[IN_WIDTH+SCALE_WIDTH-1:SCALE_WIDTH] + 
                       (scaled_value[SCALE_WIDTH-1] ? 1 : 0);
    end
    
    // Step 3: 加零点（非对称量化）
    always @(*) begin
        if (symmetric_mode)
            shifted_value = rounded_value;
        else
            shifted_value = rounded_value + {{(IN_WIDTH-OUT_WIDTH){1'b0}}, zero_point};
    end
    
    // Step 4: 饱和处理
    assign saturated_value = (shifted_value > MAX_INT8) ? MAX_INT8 :
                            (shifted_value < MIN_INT8) ? MIN_INT8 :
                            shifted_value[OUT_WIDTH-1:0];
    
    // 输出寄存
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            int_out <= 0;
            valid_out <= 0;
        end else if (valid_in) begin
            int_out <= saturated_value;
            valid_out <= 1;
        end else begin
            valid_out <= 0;
        end
    end
endmodule

// 反量化模块
module Dequantizer #(
    parameter IN_WIDTH = 8,     // INT8输入
    parameter OUT_WIDTH = 32,   // FP32输出
    parameter SCALE_WIDTH = 16
)(
    input wire clk,
    input wire rst_n,
    input wire signed [IN_WIDTH-1:0] int_in,
    input wire [SCALE_WIDTH-1:0] scale,
    input wire [IN_WIDTH-1:0] zero_point,
    input wire symmetric_mode,
    input wire valid_in,
    
    output reg [OUT_WIDTH-1:0] fp_out,
    output reg valid_out
);

    // 内部信号
    reg signed [OUT_WIDTH-1:0] shifted_value;
    reg [OUT_WIDTH+SCALE_WIDTH-1:0] scaled_value;
    
    // Step 1: 减去零点
    always @(*) begin
        if (symmetric_mode)
            shifted_value = {{(OUT_WIDTH-IN_WIDTH){int_in[IN_WIDTH-1]}}, int_in};
        else
            shifted_value = {{(OUT_WIDTH-IN_WIDTH){int_in[IN_WIDTH-1]}}, int_in} - 
                           {{(OUT_WIDTH-IN_WIDTH){1'b0}}, zero_point};
    end
    
    // Step 2: 乘以scale
    always @(*) begin
        scaled_value = shifted_value * scale;
    end
    
    // 输出寄存
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            fp_out <= 0;
            valid_out <= 0;
        end else if (valid_in) begin
            // 提取定点结果的整数部分
            fp_out <= scaled_value[OUT_WIDTH+SCALE_WIDTH-1:SCALE_WIDTH];
            valid_out <= 1;
        end else begin
            valid_out <= 0;
        end
    end
endmodule
                        </div>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目2.7：</strong>计算并比较不同批处理大小（batch size）对NPU效率的影响。假设处理一个ResNet50的第一个卷积层，输入[N,224,224,3]，卷积核[7,7,3,64]。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>考虑：1) 批处理增加数据复用（权重只加载一次） 2) MAC利用率（边界填充的影响） 3) 内存带宽需求 4) 延迟 vs 吞吐量的权衡。计算不同batch size下的计算/内存比。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p><strong>不同batch size的影响分析：</strong></p>
                        
                        <table>
                            <tr>
                                <th>Batch Size</th>
                                <th>计算量(GFLOPs)</th>
                                <th>内存占用(MB)</th>
                                <th>并行度</th>
                                <th>数据复用率</th>
                            </tr>
                            <tr>
                                <td>1</td>
                                <td>0.118</td>
                                <td>输入: 0.6<br>输出: 3.2</td>
                                <td>低</td>
                                <td>权重复用率: 1x</td>
                            </tr>
                            <tr>
                                <td>8</td>
                                <td>0.944</td>
                                <td>输入: 4.8<br>输出: 25.6</td>
                                <td>中</td>
                                <td>权重复用率: 8x</td>
                            </tr>
                            <tr>
                                <td>32</td>
                                <td>3.776</td>
                                <td>输入: 19.2<br>输出: 102.4</td>
                                <td>高</td>
                                <td>权重复用率: 32x</td>
                            </tr>
                            <tr>
                                <td>128</td>
                                <td>15.104</td>
                                <td>输入: 76.8<br>输出: 409.6</td>
                                <td>很高</td>
                                <td>权重复用率: 128x</td>
                            </tr>
                        </table>
                        
                        <p><strong>计算过程：</strong></p>
                        <ol>
                            <li>输出大小：(224-7+2*3)/2+1 = 112，即[N,112,112,64]</li>
                            <li>每个输出像素的计算量：7×7×3×2 = 294 FLOPs</li>
                            <li>总计算量：N×112×112×64×294</li>
                        </ol>
                        
                        <p><strong>NPU效率影响：</strong></p>
                        <ol>
                            <li><strong>小batch size (1-8)：</strong>
                                <ul>
                                    <li>权重复用率低，需要频繁重新加载权重</li>
                                    <li>MAC阵列利用率低，很多PE空闲</li>
                                    <li>适合边缘设备，响应延迟低</li>
                                </ul>
                            </li>
                            <li><strong>中等batch size (16-32)：</strong>
                                <ul>
                                    <li>权重复用率适中</li>
                                    <li>MAC阵列利用率较好</li>
                                    <li>内存占用在可接受范围</li>
                                </ul>
                            </li>
                            <li><strong>大batch size (64-128)：</strong>
                                <ul>
                                    <li>权重复用率高，摊销权重加载开销</li>
                                    <li>MAC阵列充分利用</li>
                                    <li>可能受限于片上SRAM容量</li>
                                    <li>适合云端训练场景</li>
                                </ul>
                            </li>
                        </ol>
                        
                        <p><strong>优化建议：</strong></p>
                        <ul>
                            <li>边缘NPU：优化batch=1的性能，采用权重固定数据流</li>
                            <li>云端NPU：支持大batch，增加片上SRAM容量</li>
                            <li>动态批处理：根据负载自适应调整batch size</li>
                        </ul>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目2.8：</strong>设计一个简单的稀疏计算单元，能够跳过零值计算。给出零检测和地址生成的RTL框架。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>稀疏计算的关键：1) 零检测逻辑（并行检测多个元素） 2) 压缩存储格式（如CSR、COO） 3) 地址计算（跳过零元素） 4) 动态调度（非零元素分配给MAC）。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module SparseComputeUnit #(
    parameter DATA_WIDTH = 8,
    parameter ADDR_WIDTH = 16,
    parameter PE_NUM = 16       // 并行PE数量
)(
    input wire clk,
    input wire rst_n,
    
    // 输入数据和索引
    input wire [DATA_WIDTH-1:0] activation_data [0:PE_NUM-1],
    input wire [DATA_WIDTH-1:0] weight_data [0:PE_NUM-1],
    input wire [PE_NUM-1:0] activation_valid,  // 非零标志
    input wire [PE_NUM-1:0] weight_valid,      // 非零标志
    input wire data_valid,
    
    // 稀疏索引
    input wire [ADDR_WIDTH-1:0] activation_indices [0:PE_NUM-1],
    input wire [ADDR_WIDTH-1:0] weight_indices [0:PE_NUM-1],
    
    // 输出接口
    output reg [2*DATA_WIDTH-1:0] result_data [0:PE_NUM-1],
    output reg [ADDR_WIDTH-1:0] result_indices [0:PE_NUM-1],
    output reg [PE_NUM-1:0] result_valid,
    output reg output_valid
);

    // 内部信号
    reg [PE_NUM-1:0] compute_mask;
    wire [2*DATA_WIDTH-1:0] mult_results [0:PE_NUM-1];
    reg [4:0] valid_count;
    reg [4:0] compact_indices [0:PE_NUM-1];
    
    // 生成计算掩码（只有当激活值和权重都非零时才计算）
    always @(*) begin
        compute_mask = activation_valid & weight_valid;
    end
    
    // 并行乘法器
    genvar i;
    generate
        for (i = 0; i < PE_NUM; i = i + 1) begin : mult_gen
            assign mult_results[i] = activation_data[i] * weight_data[i];
        end
    endgenerate
    
    // 计算有效结果数量
    always @(*) begin
        valid_count = 0;
        for (int j = 0; j < PE_NUM; j = j + 1) begin
            if (compute_mask[j])
                valid_count = valid_count + 1;
        end
    end
    
    // 压缩有效结果（去除零值结果）
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            output_valid <= 0;
            result_valid <= 0;
        end else if (data_valid) begin
            int compact_idx = 0;
            
            // 压缩非零结果
            for (int j = 0; j < PE_NUM; j = j + 1) begin
                if (compute_mask[j]) begin
                    result_data[compact_idx] <= mult_results[j];
                    result_indices[compact_idx] <= activation_indices[j];
                    result_valid[compact_idx] <= 1'b1;
                    compact_idx = compact_idx + 1;
                end
            end
            
            // 清空未使用的输出
            for (int j = compact_idx; j < PE_NUM; j = j + 1) begin
                result_data[j] <= 0;
                result_indices[j] <= 0;
                result_valid[j] <= 1'b0;
            end
            
            output_valid <= 1;
        end else begin
            output_valid <= 0;
        end
    end
endmodule

// 稀疏数据加载器
module SparseDataLoader #(
    parameter DATA_WIDTH = 8,
    parameter ADDR_WIDTH = 16,
    parameter SPARSE_FORMAT = "CSR"  // CSR或COO格式
)(
    input wire clk,
    input wire rst_n,
    
    // 内存接口
    output reg [ADDR_WIDTH-1:0] mem_addr,
    output reg mem_rd_en,
    input wire [31:0] mem_data,
    
    // 稀疏数据输出
    output reg [DATA_WIDTH-1:0] value_out,
    output reg [ADDR_WIDTH-1:0] row_idx_out,
    output reg [ADDR_WIDTH-1:0] col_idx_out,
    output reg data_valid_out,
    
    // 控制接口
    input wire start,
    input wire [ADDR_WIDTH-1:0] base_addr,
    input wire [15:0] nnz,  // 非零元素数量
    output reg done
);

    // CSR格式存储结构
    // values[nnz]: 非零值数组
    // col_indices[nnz]: 列索引数组
    // row_ptrs[rows+1]: 行指针数组
    
    reg [15:0] element_cnt;
    reg [2:0] load_state;
    
    localparam IDLE = 3'd0;
    localparam LOAD_VALUE = 3'd1;
    localparam LOAD_COL_IDX = 3'd2;
    localparam OUTPUT = 3'd3;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            load_state <= IDLE;
            element_cnt <= 0;
            done <= 0;
            mem_rd_en <= 0;
            data_valid_out <= 0;
        end else begin
            case (load_state)
                IDLE: begin
                    if (start) begin
                        element_cnt <= 0;
                        load_state <= LOAD_VALUE;
                        done <= 0;
                    end
                end
                
                LOAD_VALUE: begin
                    mem_rd_en <= 1;
                    mem_addr <= base_addr + element_cnt;
                    load_state <= LOAD_COL_IDX;
                end
                
                LOAD_COL_IDX: begin
                    value_out <= mem_data[DATA_WIDTH-1:0];
                    mem_addr <= base_addr + nnz + element_cnt;
                    load_state <= OUTPUT;
                end
                
                OUTPUT: begin
                    col_idx_out <= mem_data[ADDR_WIDTH-1:0];
                    data_valid_out <= 1;
                    mem_rd_en <= 0;
                    
                    element_cnt <= element_cnt + 1;
                    if (element_cnt == nnz - 1) begin
                        load_state <= IDLE;
                        done <= 1;
                    end else begin
                        load_state <= LOAD_VALUE;
                    end
                end
            endcase
        end
    end
endmodule
                        </div>
                    </div>
                </div>
                
                <div class="question">
                    <p><strong>题目2.4：</strong>分析不同数据流架构的特点。给定一个16×16的PE阵列，分别计算在权重固定流(WS)、输出固定流(OS)和行固定流(RS)下，执行一个[64,64]×[64,64]矩阵乘法所需的数据传输量。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p><strong>1. 权重固定流（WS）：</strong></p>
                        <ul>
                            <li>权重加载：每个PE加载一次权重，共16×16×(64/16)×(64/16) = 4,096次权重读取</li>
                            <li>输入广播：每个输入需要广播到16个PE，共64×64×16 = 65,536次输入读取</li>
                            <li>部分和传递：在PE间传递，共64×64×15 = 61,440次部分和传输</li>
                            <li>总数据传输：131,072次</li>
                        </ul>
                        
                        <p><strong>2. 输出固定流（OS）：</strong></p>
                        <ul>
                            <li>每个PE负责计算一个输出元素</li>
                            <li>输入流动：64×64×16×16 = 1,048,576次</li>
                            <li>权重流动：64×64×16×16 = 1,048,576次</li>
                            <li>部分和：在PE内部累积，无需传输</li>
                            <li>总数据传输：2,097,152次（但数据流动规则，易于控制）</li>
                        </ul>
                        
                        <p><strong>3. 行固定流（RS）：</strong></p>
                        <ul>
                            <li>每行PE复用部分输入和权重</li>
                            <li>输入复用率：约4倍</li>
                            <li>权重复用率：约4倍</li>
                            <li>部分和传递：部分在行内，部分跨行</li>
                            <li>总数据传输：约524,288次（取决于具体映射策略）</li>
                        </ul>
                        
                        <p><strong>结论：</strong>WS在权重复用上最优，OS在控制简单性上最优，RS在整体数据复用上较为平衡。</p>
                    </div>
                </div>
                
                <div class="question">
                    <p><strong>题目2.5：</strong>设计一个支持INT8量化的MAC单元。要求：(1)支持对称和非对称量化；(2)防止累加溢出；(3)支持动态缩放。给出关键设计要点。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <div class="code-block">
module QuantizedMAC #(
    parameter IN_WIDTH = 8,      // INT8输入
    parameter ACC_WIDTH = 32,    // 累加器位宽
    parameter SCALE_WIDTH = 16   // 缩放因子位宽
)(
    input wire clk,
    input wire rst_n,
    input wire signed [IN_WIDTH-1:0] activation,
    input wire signed [IN_WIDTH-1:0] weight,
    input wire signed [IN_WIDTH-1:0] zero_point_act,    // 激活值零点
    input wire signed [IN_WIDTH-1:0] zero_point_wgt,    // 权重零点
    input wire [SCALE_WIDTH-1:0] scale_act,             // 激活值缩放
    input wire [SCALE_WIDTH-1:0] scale_wgt,             // 权重缩放
    input wire acc_en,           // 累加使能
    input wire clear_acc,        // 清除累加器
    output reg signed [ACC_WIDTH-1:0] acc_out,
    output reg overflow_flag
);

    // 内部信号
    wire signed [IN_WIDTH:0] act_adjusted;
    wire signed [IN_WIDTH:0] wgt_adjusted;
    wire signed [2*IN_WIDTH+1:0] mult_result;
    wire signed [ACC_WIDTH:0] acc_next;
    
    // 1. 零点调整（支持非对称量化）
    assign act_adjusted = activation - zero_point_act;
    assign wgt_adjusted = weight - zero_point_wgt;
    
    // 2. 乘法运算
    assign mult_result = act_adjusted * wgt_adjusted;
    
    // 3. 累加与溢出检测
    assign acc_next = acc_out + mult_result;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            acc_out <= 0;
            overflow_flag <= 0;
        end else if (clear_acc) begin
            acc_out <= 0;
            overflow_flag <= 0;
        end else if (acc_en) begin
            // 溢出检测
            if ((acc_out[ACC_WIDTH-1] == mult_result[2*IN_WIDTH+1]) && 
                (acc_next[ACC_WIDTH] != acc_out[ACC_WIDTH-1])) begin
                overflow_flag <= 1;
                // 饱和处理
                acc_out <= acc_out[ACC_WIDTH-1] ? {1'b1, {(ACC_WIDTH-1){1'b0}}} : 
                                                  {1'b0, {(ACC_WIDTH-1){1'b1}}};
            end else begin
                acc_out <= acc_next[ACC_WIDTH-1:0];
            end
        end
    end
    
    // 4. 动态缩放模块（可选，用于最终输出）
    // 实际实现中，缩放通常在MAC阵列外部进行
    // scale_final = scale_act * scale_wgt
    
endmodule

// 设计要点：
// 1. 位宽管理：累加器位宽要足够大，防止溢出
// 2. 零点处理：支持非对称量化的零点偏移
// 3. 溢出保护：实时检测并饱和处理
// 4. 流水线：可在乘法和加法间插入寄存器提高频率
// 5. 缩放延迟：将缩放操作延迟到累加完成后
                        </div>
                    </div>
                </div>
            </div>
            
            <h3>2.5 Transformer计算特征</h3>
            
            <p>Transformer架构自2017年提出以来，已经成为自然语言处理和计算机视觉的主流架构。与CNN不同，Transformer的计算模式带来了新的硬件设计挑战和机遇。</p>
            
            <h4>2.5.1 自注意力机制</h4>
            <p>自注意力（Self-Attention）是Transformer的核心，其计算过程包含三个主要步骤：</p>
            
            <div class="code-block">
// 自注意力计算公式
Attention(Q, K, V) = softmax(QK^T / √d_k)V

其中：
- Q (Query): [seq_len, d_model] 查询矩阵
- K (Key): [seq_len, d_model] 键矩阵  
- V (Value): [seq_len, d_model] 值矩阵
- d_k: 键向量的维度（通常等于d_model/num_heads）
- seq_len: 序列长度
- d_model: 模型维度
            </div>
            
            <p><strong>计算复杂度分析：</strong></p>
            <ul>
                <li><strong>QK^T计算：</strong>O(seq_len² × d_k) - 序列长度的平方复杂度</li>
                <li><strong>Softmax计算：</strong>O(seq_len²) - 需要指数运算和归一化</li>
                <li><strong>Attention×V计算：</strong>O(seq_len² × d_k) - 又一次大规模矩阵乘法</li>
            </ul>
            
            <div class="info-box">
                <p><strong>硬件挑战：长序列的内存瓶颈</strong></p>
                <p>当序列长度增大时，注意力矩阵（seq_len × seq_len）会快速增长：</p>
                <ul>
                    <li>seq_len = 512: 需要256K个元素存储</li>
                    <li>seq_len = 2048: 需要4M个元素存储</li>
                    <li>seq_len = 8192: 需要64M个元素存储</li>
                </ul>
                <p>这对片上存储提出了巨大挑战，需要精心的分块和数据流设计。</p>
            </div>
            
            <h4>2.5.2 多头注意力硬件映射</h4>
            <p>多头注意力（Multi-Head Attention）将注意力计算并行化，非常适合硬件加速：</p>
            
            <div class="code-block">
// 多头注意力并行计算
MultiHead(Q, K, V) = Concat(head_1, ..., head_h)W^O
其中 head_i = Attention(QW_i^Q, KW_i^K, VW_i^V)

硬件并行化机会：
1. 不同头之间完全独立，可以并行计算
2. 每个头的维度较小（d_k = d_model / num_heads）
3. 投影矩阵W可以预先融合，减少内存访问
            </div>
            
            <h4>2.5.3 Softmax硬件实现挑战</h4>
            <p>Softmax是Transformer中的计算瓶颈之一，其计算包含指数运算和归一化：</p>
            
            <div class="code-block">
// Softmax计算步骤
softmax(x_i) = exp(x_i) / Σ(exp(x_j))

硬件实现策略：
1. 数值稳定性：先减去最大值避免溢出
   x_i' = x_i - max(x)
   
2. 指数近似：使用查找表或多项式近似
   exp(x) ≈ 1 + x + x²/2! + x³/3! + ...
   
3. 流式计算：使用两遍扫描
   - 第一遍：计算max和exp的和
   - 第二遍：执行归一化
            </div>
            
            <h4>2.5.4 位置编码与长序列优化</h4>
            <p>Transformer使用位置编码来引入序列信息，常见的实现方式包括：</p>
            
            <div class="info-box">
                <p><strong>旋转位置编码（RoPE）的硬件友好性：</strong></p>
                <ul>
                    <li>只需要复数乘法，避免了额外的加法</li>
                    <li>可以在注意力计算时动态应用</li>
                    <li>支持可变长度序列，无需预计算</li>
                    <li>适合融合到QK计算中</li>
                </ul>
            </div>
            
            <h4>2.5.5 Flash Attention：算法与硬件协同设计</h4>
            <p>Flash Attention是专门为GPU/NPU设计的高效注意力算法，其核心思想是通过分块计算减少内存访问：</p>
            
            <div class="code-block">
// Flash Attention的分块策略
将Q、K、V分成块：Q_blocks, K_blocks, V_blocks
块大小由SRAM容量决定：block_size = sqrt(SRAM_size / 4d)

for q_block in Q_blocks:
    // 在线计算，避免存储完整的注意力矩阵
    for k_block, v_block in zip(K_blocks, V_blocks):
        1. 计算局部注意力分数：S_local = q_block @ k_block.T
        2. 更新运行时统计量（max, sum）
        3. 计算局部输出并累加
        
优势：
- 内存访问从O(seq_len²) 降到 O(seq_len)
- 完全利用片上SRAM，减少DRAM访问
- 支持反向传播，训练友好
            </div>
            
            <div class="exercise">
                <h4>练习 2.5</h4>
                <div class="question">
                    <p><strong>题目：</strong>设计一个支持Flash Attention的硬件加速器，要求：
                    1) 支持可配置的块大小（32/64/128）
                    2) 实现在线softmax计算（不存储完整注意力矩阵）
                    3) 支持多头并行处理
                    4) 考虑数值稳定性</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module FlashAttentionAccelerator #(
    parameter MAX_SEQ_LEN = 2048,
    parameter D_MODEL = 768,
    parameter NUM_HEADS = 12,
    parameter BLOCK_SIZE = 64,
    parameter DATA_WIDTH = 16  // FP16
)(
    input wire clk,
    input wire rst_n,
    
    // 配置接口
    input wire [10:0] seq_len,
    input wire [6:0] actual_block_size,  // 32/64/128
    input wire start,
    
    // 数据接口（简化）
    input wire [DATA_WIDTH-1:0] q_data,
    input wire [DATA_WIDTH-1:0] k_data,
    input wire [DATA_WIDTH-1:0] v_data,
    input wire data_valid,
    
    // 输出接口
    output reg [DATA_WIDTH-1:0] output_data,
    output reg output_valid,
    output reg done
);
    
    // 每个头的维度
    localparam D_HEAD = D_MODEL / NUM_HEADS;
    
    // 片上存储
    reg [DATA_WIDTH-1:0] q_block_mem [BLOCK_SIZE-1:0][D_HEAD-1:0];
    reg [DATA_WIDTH-1:0] k_block_mem [BLOCK_SIZE-1:0][D_HEAD-1:0];
    reg [DATA_WIDTH-1:0] v_block_mem [BLOCK_SIZE-1:0][D_HEAD-1:0];
    reg [DATA_WIDTH-1:0] o_block_mem [BLOCK_SIZE-1:0][D_HEAD-1:0];
    
    // Softmax统计量（每行）
    reg [DATA_WIDTH-1:0] row_max [BLOCK_SIZE-1:0];
    reg [DATA_WIDTH-1:0] row_sum [BLOCK_SIZE-1:0];
    
    // 控制状态机
    reg [3:0] state;
    localparam IDLE = 4'd0;
    localparam LOAD_Q = 4'd1;
    localparam PROCESS_KV = 4'd2;
    localparam COMPUTE_QK = 4'd3;
    localparam UPDATE_STATS = 4'd4;
    localparam COMPUTE_PV = 4'd5;
    localparam RESCALE = 4'd6;
    localparam STORE_OUT = 4'd7;
    
    // 块索引
    reg [10:0] q_block_idx;
    reg [10:0] kv_block_idx;
    reg [6:0] block_row;
    reg [6:0] block_col;
    
    // 矩阵乘法单元实例
    wire [DATA_WIDTH-1:0] qk_result [BLOCK_SIZE-1:0][BLOCK_SIZE-1:0];
    wire mm_done;
    
    // QK^T矩阵乘法单元
    BlockMatMul #(
        .M(BLOCK_SIZE),
        .N(BLOCK_SIZE), 
        .K(D_HEAD),
        .DATA_WIDTH(DATA_WIDTH)
    ) qk_matmul (
        .clk(clk),
        .rst_n(rst_n),
        .a_data(q_block_mem),
        .b_data(k_block_mem),  // 自动转置
        .start(state == COMPUTE_QK),
        .result(qk_result),
        .done(mm_done)
    );
    
    // 在线Softmax计算
    reg [DATA_WIDTH-1:0] local_max [BLOCK_SIZE-1:0];
    reg [DATA_WIDTH-1:0] local_sum [BLOCK_SIZE-1:0];
    reg [DATA_WIDTH-1:0] attention_scores [BLOCK_SIZE-1:0][BLOCK_SIZE-1:0];
    
    // Softmax更新逻辑
    integer i, j;
    always @(posedge clk) begin
        if (state == UPDATE_STATS) begin
            for (i = 0; i < BLOCK_SIZE; i = i + 1) begin
                // 1. 找到当前块的最大值
                local_max[i] = qk_result[i][0];
                for (j = 1; j < actual_block_size; j = j + 1) begin
                    if (qk_result[i][j] > local_max[i]) begin
                        local_max[i] = qk_result[i][j];
                    end
                end
                
                // 2. 更新全局最大值和补偿之前的sum
                if (kv_block_idx == 0) begin
                    // 第一个块，直接赋值
                    row_max[i] = local_max[i];
                end else begin
                    // 后续块，需要补偿
                    if (local_max[i] > row_max[i]) begin
                        // 补偿因子：exp(old_max - new_max)
                        row_sum[i] = row_sum[i] * exp_approx(row_max[i] - local_max[i]);
                        row_max[i] = local_max[i];
                    end
                end
                
                // 3. 计算当前块的exp和sum
                local_sum[i] = 0;
                for (j = 0; j < actual_block_size; j = j + 1) begin
                    attention_scores[i][j] = exp_approx(qk_result[i][j] - row_max[i]);
                    local_sum[i] = local_sum[i] + attention_scores[i][j];
                end
                
                // 4. 更新全局sum
                if (kv_block_idx == 0) begin
                    row_sum[i] = local_sum[i];
                end else begin
                    row_sum[i] = row_sum[i] + local_sum[i];
                end
            end
        end
    end
    
    // exp近似函数（简化实现）
    function [DATA_WIDTH-1:0] exp_approx;
        input [DATA_WIDTH-1:0] x;
        begin
            // 使用泰勒级数近似或查找表
            // 这里简化处理
            exp_approx = x; // 实际需要实现指数函数
        end
    endfunction
    
    // PV矩阵乘法和输出累加
    wire [DATA_WIDTH-1:0] pv_result [BLOCK_SIZE-1:0][D_HEAD-1:0];
    wire pv_done;
    
    BlockMatMul #(
        .M(BLOCK_SIZE),
        .N(D_HEAD),
        .K(BLOCK_SIZE),
        .DATA_WIDTH(DATA_WIDTH)
    ) pv_matmul (
        .clk(clk),
        .rst_n(rst_n),
        .a_data(attention_scores),
        .b_data(v_block_mem),
        .start(state == COMPUTE_PV),
        .result(pv_result),
        .done(pv_done)
    );
    
    // 输出累加和重缩放
    always @(posedge clk) begin
        if (state == COMPUTE_PV && pv_done) begin
            for (i = 0; i < BLOCK_SIZE; i = i + 1) begin
                for (j = 0; j < D_HEAD; j = j + 1) begin
                    if (kv_block_idx == 0) begin
                        o_block_mem[i][j] <= pv_result[i][j];
                    end else begin
                        // 累加，考虑之前块的缩放
                        o_block_mem[i][j] <= o_block_mem[i][j] + pv_result[i][j];
                    end
                end
            end
        end
    end
    
    // 最终重缩放
    always @(posedge clk) begin
        if (state == RESCALE) begin
            for (i = 0; i < BLOCK_SIZE; i = i + 1) begin
                for (j = 0; j < D_HEAD; j = j + 1) begin
                    o_block_mem[i][j] <= o_block_mem[i][j] / row_sum[i];
                end
            end
        end
    end
    
    // 主状态机
    always @(posedge clk) begin
        if (!rst_n) begin
            state <= IDLE;
            done <= 1'b0;
        end else begin
            case (state)
                IDLE: begin
                    if (start) begin
                        state <= LOAD_Q;
                        q_block_idx <= 0;
                        done <= 1'b0;
                    end
                end
                
                LOAD_Q: begin
                    // 加载Q块
                    if (block_row == actual_block_size - 1) begin
                        state <= PROCESS_KV;
                        kv_block_idx <= 0;
                        block_row <= 0;
                    end else begin
                        block_row <= block_row + 1;
                    end
                end
                
                PROCESS_KV: begin
                    // 处理所有KV块
                    state <= COMPUTE_QK;
                end
                
                COMPUTE_QK: begin
                    if (mm_done) begin
                        state <= UPDATE_STATS;
                    end
                end
                
                UPDATE_STATS: begin
                    state <= COMPUTE_PV;
                end
                
                COMPUTE_PV: begin
                    if (pv_done) begin
                        if (kv_block_idx == (seq_len / actual_block_size) - 1) begin
                            state <= RESCALE;
                        end else begin
                            kv_block_idx <= kv_block_idx + 1;
                            state <= PROCESS_KV;
                        end
                    end
                end
                
                RESCALE: begin
                    state <= STORE_OUT;
                end
                
                STORE_OUT: begin
                    // 输出当前Q块的结果
                    if (q_block_idx == (seq_len / actual_block_size) - 1) begin
                        done <= 1'b1;
                        state <= IDLE;
                    end else begin
                        q_block_idx <= q_block_idx + 1;
                        state <= LOAD_Q;
                    end
                end
            endcase
        end
    end
endmodule
                        </div>
                        <p><strong>设计要点：</strong></p>
                        <ul>
                            <li>在线Softmax避免存储完整注意力矩阵</li>
                            <li>增量更新max和sum，支持数值稳定计算</li>
                            <li>块内使用SRAM，块间流式处理</li>
                            <li>多头可以通过复制该模块实现并行</li>
                        </ul>
                    </div>
                </div>
            </div>
            
            <div class="section-summary">
                <h4>本章小结</h4>
                <ul>
                    <li><strong>神经网络的核心计算是MAC运算，</strong>这决定了NPU以MAC阵列为计算核心</li>
                    <li><strong>量化技术是NPU效率提升的关键，</strong>INT8相比FP32可带来16倍面积效率和30倍功耗效率的提升</li>
                    <li><strong>卷积实现有三种主要方法：</strong>Im2Col适合复用GEMM硬件但内存开销大，直接卷积内存效率高但控制复杂，Winograd减少乘法但增加加法</li>
                    <li><strong>Transformer带来新的计算模式：</strong>自注意力的O(n²)复杂度需要精心的分块策略，Flash Attention通过算法创新大幅降低内存带宽需求</li>
                    <li><strong>数据流架构决定了NPU的效率：</strong>权重固定流最小化权重访问，输出固定流简化控制逻辑，行固定流平衡各种数据复用</li>
                    <li><strong>硬件设计需要考虑多种权衡：</strong>计算密度vs灵活性、内存带宽vs计算能力、功耗vs性能</li>
                </ul>
            </div>
        </div>

        <div id="chapter3" class="chapter">
            <h2>第3章：NPU系统架构</h2>
            
            <h3>3.1 整体架构设计</h3>
            
            <h4>3.1.1 NPU系统组成</h4>
            <p>现代NPU系统通常包含以下核心组件：</p>
            
            <div class="code-block">
NPU系统架构层次：
┌─────────────────────────────────────────┐
│          Host Interface (PCIe/AXI)       │
├─────────────────────────────────────────┤
│         Command Processor & Scheduler    │
├─────────────────────────────────────────┤
│  ┌─────────┐  ┌─────────┐  ┌─────────┐ │
│  │ Compute │  │ Memory  │  │  DMA    │ │
│  │ Cluster │  │ System  │  │ Engine  │ │
│  └─────────┘  └─────────┘  └─────────┘ │
├─────────────────────────────────────────┤
│         On-chip Interconnect (NoC)      │
├─────────────────────────────────────────┤
│         External Memory Interface        │
└─────────────────────────────────────────┘
            </div>

            <h4>3.1.2 设计考虑因素</h4>
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>设计维度</th>
                            <th>关键指标</th>
                            <th>架构影响</th>
                            <th>优化方向</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>算力</td>
                            <td>TOPS/TFLOPS</td>
                            <td>MAC阵列规模</td>
                            <td>增加PE数量、提高频率</td>
                        </tr>
                        <tr>
                            <td>能效</td>
                            <td>TOPS/W</td>
                            <td>数据复用、电压调节</td>
                            <td>减少数据移动、低功耗设计</td>
                        </tr>
                        <tr>
                            <td>灵活性</td>
                            <td>支持的算子类型</td>
                            <td>可编程性</td>
                            <td>VLIW/SIMD混合架构</td>
                        </tr>
                        <tr>
                            <td>成本</td>
                            <td>$/TOPS</td>
                            <td>芯片面积</td>
                            <td>架构简化、工艺选择</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h3>3.2 计算单元设计</h3>
            
            <h4>3.2.1 计算集群架构</h4>
            <p>NPU的计算能力主要来自于大规模并行的计算集群：</p>
            
            <div class="code-block">
// 典型的计算集群组织
Compute Cluster
├── MAC Array (脉动阵列或其他拓扑)
│   ├── PE[0][0] ... PE[0][N-1]
│   ├── PE[1][0] ... PE[1][N-1]
│   └── PE[M-1][0] ... PE[M-1][N-1]
├── Vector Unit (向量处理单元)
│   ├── SIMD ALU
│   ├── Special Function Unit
│   └── Reduction Unit
├── Local Memory
│   ├── Weight Buffer
│   ├── Input Buffer
│   └── Output Buffer
└── Control Unit
    ├── Instruction Decoder
    ├── Address Generator
    └── Synchronization Logic
            </div>

            <h4>3.2.2 处理单元(PE)设计</h4>
            <div class="info-box">
                <p><strong>PE设计原则：</strong></p>
                <ul>
                    <li>面积效率：最大化MAC密度</li>
                    <li>功耗优化：时钟门控、操作数隔离</li>
                    <li>数据通路：支持多种精度(INT8/16, FP16/32)</li>
                    <li>流水线：平衡延迟和吞吐量</li>
                </ul>
            </div>

            <h3>3.3 存储层次结构</h3>
            
            <h4>3.3.1 存储层次设计</h4>
            <div class="code-block">
存储层次（从快到慢）：
1. Register File (RF)
   - 容量: ~1KB per PE
   - 延迟: 1 cycle
   - 带宽: 极高
   
2. L1 Buffer (私有)
   - 容量: 16-64KB per cluster
   - 延迟: 2-4 cycles
   - 用途: 权重/激活值缓存

3. L2 Buffer (共享)
   - 容量: 256KB-2MB
   - 延迟: 8-16 cycles
   - 用途: 跨cluster数据共享

4. Global Buffer
   - 容量: 4-32MB
   - 延迟: 20-40 cycles
   - 用途: 大型特征图存储

5. External Memory (DDR/HBM)
   - 容量: GB级别
   - 延迟: 100+ cycles
   - 带宽: 受限（关键瓶颈）
            </div>

            <h4>3.3.2 内存访问优化</h4>
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>优化技术</th>
                            <th>原理</th>
                            <th>硬件支持</th>
                            <th>效果</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>数据预取</td>
                            <td>提前加载数据到片上</td>
                            <td>硬件预取器</td>
                            <td>隐藏内存延迟</td>
                        </tr>
                        <tr>
                            <td>双缓冲</td>
                            <td>计算与数据传输重叠</td>
                            <td>乒乓Buffer</td>
                            <td>提高利用率</td>
                        </tr>
                        <tr>
                            <td>数据压缩</td>
                            <td>减少传输数据量</td>
                            <td>压缩/解压单元</td>
                            <td>节省带宽</td>
                        </tr>
                        <tr>
                            <td>地址映射</td>
                            <td>优化数据布局</td>
                            <td>可编程DMA</td>
                            <td>提高局部性</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h3>3.4 互连网络设计</h3>
            
            <h4>3.4.1 片上网络拓扑</h4>
            <div class="code-block">
常见的NoC拓扑结构：

1. Mesh (网格)
   优点：规则、可扩展
   缺点：跳数多、延迟大
   
   [R]--[R]--[R]--[R]
    |    |    |    |
   [R]--[R]--[R]--[R]
    |    |    |    |
   [R]--[R]--[R]--[R]

2. Torus (环面)
   优点：降低平均跳数
   缺点：布线复杂
   
3. Tree (树形)
   优点：层次化、易于广播
   缺点：根节点瓶颈

4. Crossbar (交叉开关)
   优点：单跳连接
   缺点：面积O(N²)，不可扩展
            </div>

            <h4>3.4.2 数据通信模式</h4>
            <p>NPU中的典型通信模式：</p>
            <ul>
                <li><strong>单播(Unicast)：</strong>点对点数据传输</li>
                <li><strong>多播(Multicast)：</strong>权重广播到多个PE</li>
                <li><strong>归约(Reduction)：</strong>部分和累加</li>
                <li><strong>全局同步：</strong>barrier同步</li>
            </ul>

            <div class="warning-box">
                <p><strong>设计挑战：</strong>如何在保证高带宽的同时控制功耗和面积开销是NoC设计的核心挑战。</p>
            </div>

            <div class="exercise">
                <h4>练习题集 3</h4>
                
                <div class="question">
                    <p><strong>题目3.1：</strong>设计一个NPU的存储层次结构。给定：MAC阵列32×32，主频1GHz，外部内存带宽100GB/s。计算各级存储的容量和带宽需求。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：从MAC阵列的数据需求出发，考虑每个MAC单元每周期需要的输入输出数据量，然后设计多级缓存来逐步降低带宽压力。记住带宽需求应该逐级递减。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p><strong>1. 计算MAC阵列带宽需求：</strong></p>
                        <ul>
                            <li>MAC阵列规模：32×32 = 1024个MAC</li>
                            <li>每个MAC每周期需要：2个输入(weight, activation) + 1个输出</li>
                            <li>假设INT8精度：每个数据1字节</li>
                            <li>总带宽需求：1024 × 3 × 1B × 1GHz = 3.072 TB/s</li>
                        </ul>
                        
                        <p><strong>2. 存储层次设计：</strong></p>
                        <table>
                            <tr>
                                <th>存储级别</th>
                                <th>容量</th>
                                <th>带宽</th>
                                <th>设计理由</th>
                            </tr>
                            <tr>
                                <td>L0 (Register)</td>
                                <td>1KB/PE</td>
                                <td>3TB/s</td>
                                <td>直接供给MAC运算</td>
                            </tr>
                            <tr>
                                <td>L1 Buffer</td>
                                <td>64KB</td>
                                <td>1TB/s</td>
                                <td>存储当前tile的数据</td>
                            </tr>
                            <tr>
                                <td>L2 Buffer</td>
                                <td>2MB</td>
                                <td>400GB/s</td>
                                <td>预取下一个tile</td>
                            </tr>
                            <tr>
                                <td>Global Buffer</td>
                                <td>16MB</td>
                                <td>200GB/s</td>
                                <td>存储整层的部分数据</td>
                            </tr>
                            <tr>
                                <td>External Mem</td>
                                <td>16GB</td>
                                <td>100GB/s</td>
                                <td>给定约束</td>
                            </tr>
                        </table>
                        
                        <p><strong>3. 带宽逐级递减原理：</strong></p>
                        <ul>
                            <li>数据复用降低上级需求</li>
                            <li>时分复用共享带宽</li>
                            <li>预取隐藏延迟</li>
                        </ul>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目3.2：</strong>比较Weight Stationary、Output Stationary和Row Stationary三种数据流的优缺点，并给出适用场景。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：每种数据流的核心区别在于哪种数据被固定在PE中。分析不同神经网络层（全连接层、1×1卷积、3×3卷积）的数据复用特性，来判断最适合的数据流。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <table>
                            <tr>
                                <th>数据流</th>
                                <th>固定数据</th>
                                <th>优点</th>
                                <th>缺点</th>
                                <th>适用场景</th>
                            </tr>
                            <tr>
                                <td>Weight Stationary (WS)</td>
                                <td>权重</td>
                                <td>• 权重复用最大化<br>• 减少权重读取能耗<br>• 实现简单</td>
                                <td>• 输入/输出需要大量移动<br>• 对大feature map不友好</td>
                                <td>• 全连接层<br>• 小batch推理<br>• 权重>>激活值</td>
                            </tr>
                            <tr>
                                <td>Output Stationary (OS)</td>
                                <td>部分和</td>
                                <td>• 减少部分和读写<br>• 累加在PE本地完成<br>• 适合深度网络</td>
                                <td>• 权重和输入都需移动<br>• 控制复杂度高</td>
                                <td>• 深度卷积<br>• 输出通道数多<br>• ResNet类结构</td>
                            </tr>
                            <tr>
                                <td>Row Stationary (RS)</td>
                                <td>卷积行</td>
                                <td>• 所有数据类型都有复用<br>• 能量效率最优<br>• 适应性强</td>
                                <td>• 实现最复杂<br>• 需要复杂的控制器<br>• 面积开销大</td>
                                <td>• 通用场景<br>• 各种卷积层<br>• 需要灵活性</td>
                            </tr>
                        </table>
                        
                        <p><strong>具体例子：</strong></p>
                        <p>对于1×1卷积（Pointwise）：</p>
                        <ul>
                            <li>WS最优：因为没有空间维度的复用</li>
                            <li>RS退化为WS</li>
                        </ul>
                        <p>对于3×3卷积：</p>
                        <ul>
                            <li>RS最优：可以复用所有维度的数据</li>
                            <li>OS次优：如果输出通道很多</li>
                        </ul>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目3.3：</strong>设计一个4×4 Mesh NoC的路由器。要求支持XY路由算法，包含5个端口（东南西北+本地）。给出RTL框架。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：路由器需要包含输入缓冲（FIFO）、路由计算（XY算法先X后Y）、仲裁器（处理冲突）、交叉开关（5×5连接矩阵）。注意处理背压和流控。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module MeshRouter #(
    parameter DATA_WIDTH = 32,
    parameter ADDR_WIDTH = 8,
    parameter X_COORD = 0,
    parameter Y_COORD = 0,
    parameter FIFO_DEPTH = 4
)(
    input wire clk,
    input wire rst_n,
    
    // 5个输入端口 (North, South, East, West, Local)
    input wire [DATA_WIDTH-1:0] data_in_n, data_in_s, data_in_e, data_in_w, data_in_l,
    input wire valid_in_n, valid_in_s, valid_in_e, valid_in_w, valid_in_l,
    output wire ready_out_n, ready_out_s, ready_out_e, ready_out_w, ready_out_l,
    
    // 5个输出端口
    output wire [DATA_WIDTH-1:0] data_out_n, data_out_s, data_out_e, data_out_w, data_out_l,
    output wire valid_out_n, valid_out_s, valid_out_e, valid_out_w, valid_out_l,
    input wire ready_in_n, ready_in_s, ready_in_e, ready_in_w, ready_in_l
);

    // 数据包格式：[DATA | SRC_Y | SRC_X | DST_Y | DST_X]
    localparam DST_X_START = 0;
    localparam DST_X_END = 3;
    localparam DST_Y_START = 4;
    localparam DST_Y_END = 7;
    
    // 内部信号
    wire [4:0] route_req_n, route_req_s, route_req_e, route_req_w, route_req_l;
    wire [4:0] grant_n, grant_s, grant_e, grant_w, grant_l;
    
    // 输入FIFO
    wire [DATA_WIDTH-1:0] fifo_data_n, fifo_data_s, fifo_data_e, fifo_data_w, fifo_data_l;
    wire fifo_empty_n, fifo_empty_s, fifo_empty_e, fifo_empty_w, fifo_empty_l;
    wire fifo_rd_en_n, fifo_rd_en_s, fifo_rd_en_e, fifo_rd_en_w, fifo_rd_en_l;
    
    // FIFO实例化（每个输入端口一个）
    genvar i;
    generate
        // North port FIFO
        FIFO #(.WIDTH(DATA_WIDTH), .DEPTH(FIFO_DEPTH)) fifo_n (
            .clk(clk), .rst_n(rst_n),
            .wr_en(valid_in_n), .wr_data(data_in_n),
            .rd_en(fifo_rd_en_n), .rd_data(fifo_data_n),
            .empty(fifo_empty_n), .full(~ready_out_n)
        );
        // 类似地实例化其他4个FIFO...
    endgenerate
    
    // XY路由计算模块
    XYRouteCompute route_comp_n (
        .current_x(X_COORD), .current_y(Y_COORD),
        .dest_x(fifo_data_n[DST_X_END:DST_X_START]),
        .dest_y(fifo_data_n[DST_Y_END:DST_Y_START]),
        .valid(!fifo_empty_n),
        .route_request(route_req_n)  // 5-bit one-hot
    );
    // 为其他端口实例化路由计算...
    
    // 5×5交叉开关仲裁器
    SwitchAllocator allocator (
        .clk(clk), .rst_n(rst_n),
        // 来自5个输入端口的请求
        .req_n(route_req_n), .req_s(route_req_s), 
        .req_e(route_req_e), .req_w(route_req_w), .req_l(route_req_l),
        // 授权信号
        .grant_n(grant_n), .grant_s(grant_s),
        .grant_e(grant_e), .grant_w(grant_w), .grant_l(grant_l)
    );
    
    // 交叉开关矩阵
    Crossbar5x5 xbar (
        // 输入数据
        .data_in({fifo_data_l, fifo_data_w, fifo_data_e, fifo_data_s, fifo_data_n}),
        // 控制信号
        .sel_n(grant_n), .sel_s(grant_s), 
        .sel_e(grant_e), .sel_w(grant_w), .sel_l(grant_l),
        // 输出数据
        .data_out_n(data_out_n), .data_out_s(data_out_s),
        .data_out_e(data_out_e), .data_out_w(data_out_w), .data_out_l(data_out_l)
    );
    
    // 输出valid信号生成
    assign valid_out_n = |grant_n & ready_in_n;
    assign valid_out_s = |grant_s & ready_in_s;
    assign valid_out_e = |grant_e & ready_in_e;
    assign valid_out_w = |grant_w & ready_in_w;
    assign valid_out_l = |grant_l & ready_in_l;
    
    // FIFO读使能
    assign fifo_rd_en_n = |(grant_n & {ready_in_l, ready_in_w, ready_in_e, ready_in_s, ready_in_n});
    // 类似处理其他端口...

endmodule

// XY路由计算模块
module XYRouteCompute #(
    parameter COORD_WIDTH = 4
)(
    input [COORD_WIDTH-1:0] current_x, current_y,
    input [COORD_WIDTH-1:0] dest_x, dest_y,
    input valid,
    output reg [4:0] route_request  // [Local, West, East, South, North]
);
    always @(*) begin
        route_request = 5'b00000;
        if (valid) begin
            if (dest_x == current_x && dest_y == current_y) begin
                route_request[4] = 1'b1;  // Local
            end else if (dest_x < current_x) begin
                route_request[3] = 1'b1;  // West
            end else if (dest_x > current_x) begin
                route_request[2] = 1'b1;  // East
            end else if (dest_y < current_y) begin
                route_request[1] = 1'b1;  // South
            end else begin
                route_request[0] = 1'b1;  // North
            end
        end
    end
endmodule
                        </div>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目3.4：</strong>计算一个NPU执行ResNet50一个残差块所需的片上存储容量。假设特征图大小为56×56×256，使用3×3卷积。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：ResNet残差块包含多个卷积层和shortcut连接。计算每层的输入、输出、权重大小，考虑流水线执行时的数据重叠，以及双缓冲需求。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p><strong>ResNet50残差块结构：</strong></p>
                        <pre>
Input (56×56×256)
    │
    ├─────────────────────┐
    │                     │
    ▼                     │
Conv1 (1×1, 64)          │
    │                     │
    ▼                     │
Conv2 (3×3, 64)          │
    │                     │
    ▼                     │
Conv3 (1×1, 256)         │
    │                     │
    ▼                     │
    + ←──────────────────┘
    │
Output (56×56×256)
                        </pre>
                        
                        <p><strong>存储需求计算（INT8）：</strong></p>
                        <table>
                            <tr>
                                <th>数据类型</th>
                                <th>尺寸</th>
                                <th>容量(KB)</th>
                                <th>说明</th>
                            </tr>
                            <tr>
                                <td>输入特征图</td>
                                <td>56×56×256</td>
                                <td>784</td>
                                <td>需要保存用于残差连接</td>
                            </tr>
                            <tr>
                                <td>Conv1权重</td>
                                <td>1×1×256×64</td>
                                <td>16</td>
                                <td>Pointwise卷积</td>
                            </tr>
                            <tr>
                                <td>Conv1输出</td>
                                <td>56×56×64</td>
                                <td>196</td>
                                <td>中间特征图</td>
                            </tr>
                            <tr>
                                <td>Conv2权重</td>
                                <td>3×3×64×64</td>
                                <td>36</td>
                                <td>Depthwise卷积</td>
                            </tr>
                            <tr>
                                <td>Conv2输出</td>
                                <td>56×56×64</td>
                                <td>196</td>
                                <td>中间特征图</td>
                            </tr>
                            <tr>
                                <td>Conv3权重</td>
                                <td>1×1×64×256</td>
                                <td>16</td>
                                <td>Pointwise卷积</td>
                            </tr>
                            <tr>
                                <td>Conv3输出</td>
                                <td>56×56×256</td>
                                <td>784</td>
                                <td>用于残差加法</td>
                            </tr>
                            <tr>
                                <td><strong>总计</strong></td>
                                <td>-</td>
                                <td><strong>2028</strong></td>
                                <td>约2MB</td>
                            </tr>
                        </table>
                        
                        <p><strong>优化策略：</strong></p>
                        <ol>
                            <li><strong>层融合：</strong>将Conv1输出直接送入Conv2，节省196KB</li>
                            <li><strong>流水线执行：</strong>分块处理，每块只需存储部分特征图</li>
                            <li><strong>权重压缩：</strong>使用稀疏或量化技术减少权重存储</li>
                            <li><strong>双缓冲：</strong>计算当前块时预取下一块数据</li>
                        </ol>
                        
                        <p><strong>实际需求：</strong>考虑优化后，片上存储约需1MB即可高效执行。</p>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目3.5：</strong>设计一个DMA控制器，支持2D数据传输和简单的数据重排。要求支持stride访问模式。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：DMA需要支持2D数据传输（宽度×高度），包括源和目标的stride跨步。考虑不同传输模式：线性、2D块、转置、交织等。使用状态机管理传输流程。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module DMA2D #(
    parameter ADDR_WIDTH = 32,
    parameter DATA_WIDTH = 128,  // 128-bit宽接口
    parameter BURST_LEN = 16     // 最大突发长度
)(
    input wire clk,
    input wire rst_n,
    
    // 配置接口
    input wire [ADDR_WIDTH-1:0] src_addr,      // 源地址
    input wire [ADDR_WIDTH-1:0] dst_addr,      // 目标地址
    input wire [15:0] width,                   // 2D传输宽度（字节）
    input wire [15:0] height,                  // 2D传输高度
    input wire [15:0] src_stride,              // 源跨步（字节）
    input wire [15:0] dst_stride,              // 目标跨步（字节）
    input wire [2:0] transfer_mode,            // 传输模式
    input wire start,
    output reg done,
    output reg busy,
    
    // 源内存接口（AXI-like）
    output reg [ADDR_WIDTH-1:0] src_araddr,
    output reg src_arvalid,
    input wire src_arready,
    input wire [DATA_WIDTH-1:0] src_rdata,
    input wire src_rvalid,
    output reg src_rready,
    
    // 目标内存接口
    output reg [ADDR_WIDTH-1:0] dst_awaddr,
    output reg dst_awvalid,
    input wire dst_awready,
    output reg [DATA_WIDTH-1:0] dst_wdata,
    output reg dst_wvalid,
    input wire dst_wready,
    input wire dst_bvalid,
    output reg dst_bready
);

    // 传输模式定义
    localparam MODE_LINEAR = 3'd0;      // 线性传输
    localparam MODE_2D_BLOCK = 3'd1;    // 2D块传输
    localparam MODE_TRANSPOSE = 3'd2;   // 转置
    localparam MODE_INTERLEAVE = 3'd3;  // 交织
    
    // 状态机
    localparam IDLE = 3'd0;
    localparam CALC_ADDR = 3'd1;
    localparam READ_REQ = 3'd2;
    localparam READ_DATA = 3'd3;
    localparam WRITE_REQ = 3'd4;
    localparam WRITE_DATA = 3'd5;
    localparam WRITE_RESP = 3'd6;
    localparam NEXT_LINE = 3'd7;
    
    reg [2:0] state, next_state;
    
    // 内部计数器
    reg [15:0] row_cnt, col_cnt;
    reg [15:0] burst_cnt;
    reg [ADDR_WIDTH-1:0] current_src_addr, current_dst_addr;
    
    // 数据缓冲（支持突发传输）
    reg [DATA_WIDTH-1:0] data_buffer [0:BURST_LEN-1];
    reg [4:0] buffer_wr_ptr, buffer_rd_ptr;
    reg [4:0] buffer_count;
    
    // 地址计算单元
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            current_src_addr <= 0;
            current_dst_addr <= 0;
        end else if (state == CALC_ADDR) begin
            case (transfer_mode)
                MODE_LINEAR: begin
                    current_src_addr <= src_addr + (row_cnt * src_stride) + col_cnt;
                    current_dst_addr <= dst_addr + (row_cnt * dst_stride) + col_cnt;
                end
                MODE_2D_BLOCK: begin
                    current_src_addr <= src_addr + (row_cnt * src_stride) + col_cnt;
                    current_dst_addr <= dst_addr + (row_cnt * dst_stride) + col_cnt;
                end
                MODE_TRANSPOSE: begin
                    // 转置：源按行读，目标按列写
                    current_src_addr <= src_addr + (row_cnt * src_stride) + col_cnt;
                    current_dst_addr <= dst_addr + (col_cnt * dst_stride) + row_cnt * (DATA_WIDTH/8);
                end
                MODE_INTERLEAVE: begin
                    // 交织模式：用于通道重排
                    // 实现NCHW -> NHWC转换等
                    current_src_addr <= src_addr + calculate_interleave_src(row_cnt, col_cnt);
                    current_dst_addr <= dst_addr + calculate_interleave_dst(row_cnt, col_cnt);
                end
            endcase
        end
    end
    
    // 状态机控制
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n)
            state <= IDLE;
        else
            state <= next_state;
    end
    
    always @(*) begin
        next_state = state;
        case (state)
            IDLE: begin
                if (start)
                    next_state = CALC_ADDR;
            end
            
            CALC_ADDR: begin
                next_state = READ_REQ;
            end
            
            READ_REQ: begin
                if (src_arready)
                    next_state = READ_DATA;
            end
            
            READ_DATA: begin
                if (src_rvalid && burst_cnt == calculate_burst_len() - 1)
                    next_state = WRITE_REQ;
            end
            
            WRITE_REQ: begin
                if (dst_awready)
                    next_state = WRITE_DATA;
            end
            
            WRITE_DATA: begin
                if (dst_wready && buffer_rd_ptr == buffer_wr_ptr - 1)
                    next_state = WRITE_RESP;
            end
            
            WRITE_RESP: begin
                if (dst_bvalid)
                    next_state = NEXT_LINE;
            end
            
            NEXT_LINE: begin
                if (row_cnt == height - 1 && col_cnt >= width - (DATA_WIDTH/8))
                    next_state = IDLE;
                else
                    next_state = CALC_ADDR;
            end
        endcase
    end
    
    // 数据路径控制
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            row_cnt <= 0;
            col_cnt <= 0;
            burst_cnt <= 0;
            buffer_wr_ptr <= 0;
            buffer_rd_ptr <= 0;
            done <= 0;
            busy <= 0;
        end else begin
            case (state)
                IDLE: begin
                    done <= 0;
                    if (start) begin
                        row_cnt <= 0;
                        col_cnt <= 0;
                        busy <= 1;
                    end
                end
                
                READ_DATA: begin
                    if (src_rvalid) begin
                        data_buffer[buffer_wr_ptr] <= apply_transform(src_rdata);
                        buffer_wr_ptr <= buffer_wr_ptr + 1;
                        burst_cnt <= burst_cnt + 1;
                    end
                end
                
                WRITE_DATA: begin
                    if (dst_wready) begin
                        buffer_rd_ptr <= buffer_rd_ptr + 1;
                    end
                end
                
                NEXT_LINE: begin
                    col_cnt <= col_cnt + (DATA_WIDTH/8) * calculate_burst_len();
                    if (col_cnt >= width - (DATA_WIDTH/8)) begin
                        col_cnt <= 0;
                        row_cnt <= row_cnt + 1;
                        if (row_cnt == height - 1) begin
                            done <= 1;
                            busy <= 0;
                        end
                    end
                    burst_cnt <= 0;
                    buffer_wr_ptr <= 0;
                    buffer_rd_ptr <= 0;
                end
            endcase
        end
    end
    
    // AXI接口信号
    always @(*) begin
        // 默认值
        src_arvalid = 0;
        src_rready = 0;
        dst_awvalid = 0;
        dst_wvalid = 0;
        dst_bready = 0;
        
        case (state)
            READ_REQ: begin
                src_araddr = current_src_addr;
                src_arvalid = 1;
            end
            
            READ_DATA: begin
                src_rready = 1;
            end
            
            WRITE_REQ: begin
                dst_awaddr = current_dst_addr;
                dst_awvalid = 1;
            end
            
            WRITE_DATA: begin
                dst_wdata = data_buffer[buffer_rd_ptr];
                dst_wvalid = 1;
            end
            
            WRITE_RESP: begin
                dst_bready = 1;
            end
        endcase
    end
    
    // 辅助函数
    function [4:0] calculate_burst_len;
        begin
            // 根据剩余数据量计算突发长度
            if (width - col_cnt >= BURST_LEN * (DATA_WIDTH/8))
                calculate_burst_len = BURST_LEN;
            else
                calculate_burst_len = (width - col_cnt) / (DATA_WIDTH/8);
        end
    endfunction
    
    function [DATA_WIDTH-1:0] apply_transform;
        input [DATA_WIDTH-1:0] data;
        begin
            // 根据模式应用数据变换（如字节序转换等）
            case (transfer_mode)
                MODE_LINEAR, MODE_2D_BLOCK: 
                    apply_transform = data;
                MODE_TRANSPOSE:
                    apply_transform = transpose_bytes(data);
                MODE_INTERLEAVE:
                    apply_transform = interleave_channels(data);
                default:
                    apply_transform = data;
            endcase
        end
    endfunction

endmodule
                        </div>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目3.6：</strong>分析Tensor Core架构相比传统MAC阵列的优势，并计算其理论性能提升。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：Tensor Core是以矩阵为基本计算单位，而不是标量。比较一次操作完成的计算量、数据复用率、带宽需求。考虑不同精度（FP16、INT8）的影响。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p><strong>1. 架构对比：</strong></p>
                        <table>
                            <tr>
                                <th>特性</th>
                                <th>传统MAC阵列</th>
                                <th>Tensor Core</th>
                            </tr>
                            <tr>
                                <td>基本运算</td>
                                <td>标量MAC: c += a × b</td>
                                <td>矩阵MAC: D = A×B + C</td>
                            </tr>
                            <tr>
                                <td>运算粒度</td>
                                <td>1×1</td>
                                <td>4×4×4 (或更大)</td>
                            </tr>
                            <tr>
                                <td>每周期运算量</td>
                                <td>2 ops (乘+加)</td>
                                <td>128 ops (4×4×4×2)</td>
                            </tr>
                            <tr>
                                <td>数据复用</td>
                                <td>有限</td>
                                <td>矩阵级复用</td>
                            </tr>
                        </table>
                        
                        <p><strong>2. Tensor Core工作原理：</strong></p>
                        <div class="code-block">
// Tensor Core执行的运算
D[4×4] = A[4×4] × B[4×4] + C[4×4]

// 分解为标量运算：
for i in 0..3:
    for j in 0..3:
        sum = 0
        for k in 0..3:
            sum += A[i][k] * B[k][j]
        D[i][j] = sum + C[i][j]

// 总运算数：4×4×4 = 64次乘法，48次加法，16次加法
// 共128 ops
                        </div>
                        
                        <p><strong>3. 性能提升计算：</strong></p>
                        <p>假设：</p>
                        <ul>
                            <li>传统MAC阵列：16×16 = 256个MAC单元</li>
                            <li>Tensor Core阵列：4×4 = 16个Tensor Core</li>
                            <li>相同的总硬件面积</li>
                        </ul>
                        
                        <p>性能对比：</p>
                        <ul>
                            <li>传统MAC：256 × 2 = 512 ops/cycle</li>
                            <li>Tensor Core：16 × 128 = 2048 ops/cycle</li>
                            <li><strong>理论加速比：4×</strong></li>
                        </ul>
                        
                        <p><strong>4. 优势分析：</strong></p>
                        <ol>
                            <li><strong>更高的计算密度：</strong>相同面积下提供更多运算</li>
                            <li><strong>更好的数据复用：</strong>矩阵运算天然具有数据复用</li>
                            <li><strong>减少控制开销：</strong>一条指令完成更多运算</li>
                            <li><strong>更适合深度学习：</strong>直接匹配GEMM运算模式</li>
                        </ol>
                        
                        <p><strong>5. 限制条件：</strong></p>
                        <ul>
                            <li>需要对齐到4×4块大小</li>
                            <li>不适合稀疏或不规则运算</li>
                            <li>精度限制（通常是混合精度）</li>
                            <li>编程模型相对复杂</li>
                        </ul>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目3.7：</strong>设计一个简单的NPU指令集架构(ISA)，包含计算、数据传输和控制指令。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：NPU ISA需要支持矩阵运算、卷积、激活函数等。设计指令格式、寻址模式、寄存器文件。考虑VLIW或SIMD指令集的特点。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p><strong>NPU ISA设计：</strong></p>
                        
                        <p><strong>1. 指令格式（32-bit）：</strong></p>
                        <div class="code-block">
[31:28] | [27:24] | [23:16] | [15:8] | [7:0]
OPCODE  | FLAGS   | DEST    | SRC1   | SRC2/IMM

OPCODE: 4-bit 操作码
FLAGS:  4-bit 标志位（精度、饱和模式等）
DEST:   8-bit 目标寄存器/地址
SRC1:   8-bit 源操作数1
SRC2:   8-bit 源操作数2或立即数
                        </div>
                        
                        <p><strong>2. 指令集分类：</strong></p>
                        
                        <p><strong>A. 计算指令：</strong></p>
                        <table>
                            <tr>
                                <th>助记符</th>
                                <th>操作码</th>
                                <th>功能</th>
                                <th>示例</th>
                            </tr>
                            <tr>
                                <td>MMUL</td>
                                <td>0x0</td>
                                <td>矩阵乘法</td>
                                <td>MMUL R0, M1, M2</td>
                            </tr>
                            <tr>
                                <td>CONV</td>
                                <td>0x1</td>
                                <td>卷积运算</td>
                                <td>CONV R0, I1, W1</td>
                            </tr>
                            <tr>
                                <td>MADD</td>
                                <td>0x2</td>
                                <td>矩阵加法</td>
                                <td>MADD R0, M1, M2</td>
                            </tr>
                            <tr>
                                <td>ACTV</td>
                                <td>0x3</td>
                                <td>激活函数</td>
                                <td>ACTV.RELU R0, R1</td>
                            </tr>
                            <tr>
                                <td>POOL</td>
                                <td>0x4</td>
                                <td>池化操作</td>
                                <td>POOL.MAX R0, I1</td>
                            </tr>
                        </table>
                        
                        <p><strong>B. 数据传输指令：</strong></p>
                        <table>
                            <tr>
                                <th>助记符</th>
                                <th>操作码</th>
                                <th>功能</th>
                                <th>示例</th>
                            </tr>
                            <tr>
                                <td>LOAD</td>
                                <td>0x8</td>
                                <td>从内存加载</td>
                                <td>LOAD R0, [ADDR]</td>
                            </tr>
                            <tr>
                                <td>STORE</td>
                                <td>0x9</td>
                                <td>存储到内存</td>
                                <td>STORE [ADDR], R0</td>
                            </tr>
                            <tr>
                                <td>DMA</td>
                                <td>0xA</td>
                                <td>DMA传输</td>
                                <td>DMA DST, SRC, LEN</td>
                            </tr>
                            <tr>
                                <td>BCAST</td>
                                <td>0xB</td>
                                <td>广播数据</td>
                                <td>BCAST R0, VAL</td>
                            </tr>
                        </table>
                        
                        <p><strong>C. 控制指令：</strong></p>
                        <table>
                            <tr>
                                <th>助记符</th>
                                <th>操作码</th>
                                <th>功能</th>
                                <th>示例</th>
                            </tr>
                            <tr>
                                <td>SYNC</td>
                                <td>0xC</td>
                                <td>同步屏障</td>
                                <td>SYNC</td>
                            </tr>
                            <tr>
                                <td>LOOP</td>
                                <td>0xD</td>
                                <td>循环控制</td>
                                <td>LOOP CNT, LABEL</td>
                            </tr>
                            <tr>
                                <td>JUMP</td>
                                <td>0xE</td>
                                <td>跳转</td>
                                <td>JUMP LABEL</td>
                            </tr>
                            <tr>
                                <td>HALT</td>
                                <td>0xF</td>
                                <td>停止执行</td>
                                <td>HALT</td>
                            </tr>
                        </table>
                        
                        <p><strong>3. 寄存器组织：</strong></p>
                        <div class="code-block">
// 通用寄存器
R0-R31: 32个通用寄存器（标量）
M0-M15: 16个矩阵寄存器（每个可存储32×32矩阵）
V0-V15: 16个向量寄存器（每个256元素）

// 特殊寄存器
PC:     程序计数器
SP:     栈指针
STATUS: 状态寄存器
CONFIG: 配置寄存器（精度模式等）
                        </div>
                        
                        <p><strong>4. 示例程序（卷积层）：</strong></p>
                        <div class="code-block">
// 执行一个3×3卷积层
// 输入: I0, 权重: W0, 输出: O0

    // 配置卷积参数
    LOAD  R0, #3        // 卷积核大小
    LOAD  R1, #1        // stride
    LOAD  R2, #1        // padding
    
    // 加载数据
    DMA   M0, [input_addr], #input_size
    DMA   M1, [weight_addr], #weight_size
    
    // 执行卷积
    CONV  M2, M0, M1    // 使用配置的参数
    
    // 应用激活函数
    ACTV.RELU M3, M2
    
    // 存储结果
    DMA   [output_addr], M3, #output_size
    
    // 同步确保完成
    SYNC
    HALT
                        </div>
                        
                        <p><strong>5. ISA特点：</strong></p>
                        <ul>
                            <li><strong>CISC风格：</strong>单条指令完成复杂操作</li>
                            <li><strong>数据并行：</strong>原生支持矩阵/向量操作</li>
                            <li><strong>内存层次感知：</strong>显式DMA管理</li>
                            <li><strong>灵活精度：</strong>通过FLAGS支持多精度</li>
                            <li><strong>硬件加速：</strong>直接映射到硬件单元</li>
                        </ul>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目3.8：</strong>评估不同的功耗优化技术对NPU的影响。给定一个100 TOPS的NPU，分析各种技术的节能潜力。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：从动态功耗（开关活动）和静态功耗（漏电流）两方面分析。考虑时钟门控、电压频率调节（DVFS）、数据精度优化、稀疏性利用等技术。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p><strong>基准NPU规格：</strong></p>
                        <ul>
                            <li>峰值性能：100 TOPS (INT8)</li>
                            <li>功耗：50W (2 TOPS/W)</li>
                            <li>工艺：7nm</li>
                            <li>频率：1GHz</li>
                        </ul>
                        
                        <p><strong>功耗优化技术分析：</strong></p>
                        <table>
                            <tr>
                                <th>优化技术</th>
                                <th>原理</th>
                                <th>节能潜力</th>
                                <th>性能影响</th>
                                <th>实现复杂度</th>
                            </tr>
                            <tr>
                                <td>时钟门控</td>
                                <td>关闭空闲单元时钟</td>
                                <td>10-20%</td>
                                <td>无</td>
                                <td>低</td>
                            </tr>
                            <tr>
                                <td>电源门控</td>
                                <td>关闭空闲单元电源</td>
                                <td>20-30%</td>
                                <td>唤醒延迟</td>
                                <td>中</td>
                            </tr>
                            <tr>
                                <td>DVFS</td>
                                <td>动态调节电压频率</td>
                                <td>30-40%</td>
                                <td>性能下降</td>
                                <td>中</td>
                            </tr>
                            <tr>
                                <td>近阈值计算</td>
                                <td>降低工作电压</td>
                                <td>50-70%</td>
                                <td>频率降低</td>
                                <td>高</td>
                            </tr>
                            <tr>
                                <td>数据压缩</td>
                                <td>减少数据传输</td>
                                <td>15-25%</td>
                                <td>轻微</td>
                                <td>中</td>
                            </tr>
                            <tr>
                                <td>稀疏计算</td>
                                <td>跳过零值运算</td>
                                <td>20-60%</td>
                                <td>依赖稀疏度</td>
                                <td>高</td>
                            </tr>
                            <tr>
                                <td>精度缩放</td>
                                <td>动态调整精度</td>
                                <td>25-40%</td>
                                <td>精度损失</td>
                                <td>中</td>
                            </tr>
                        </table>
                        
                        <p><strong>功耗分解（50W总功耗）：</strong></p>
                        <div class="code-block">
计算单元：    20W (40%)
├── MAC阵列： 15W
└── 向量单元： 5W

存储系统：    15W (30%)
├── SRAM：    10W
└── 接口：     5W

互连网络：     8W (16%)

控制逻辑：     4W (8%)

IO接口：       3W (6%)
                        </div>
                        
                        <p><strong>组合优化方案：</strong></p>
                        <ol>
                            <li><strong>方案A（保守型）：</strong>
                                <ul>
                                    <li>时钟门控 + 基础DVFS</li>
                                    <li>预期节能：25%</li>
                                    <li>功耗降至：37.5W</li>
                                    <li>能效提升至：2.67 TOPS/W</li>
                                </ul>
                            </li>
                            <li><strong>方案B（平衡型）：</strong>
                                <ul>
                                    <li>时钟/电源门控 + DVFS + 数据压缩</li>
                                    <li>预期节能：45%</li>
                                    <li>功耗降至：27.5W</li>
                                    <li>能效提升至：3.64 TOPS/W</li>
                                </ul>
                            </li>
                            <li><strong>方案C（激进型）：</strong>
                                <ul>
                                    <li>全部技术组合 + 近阈值计算</li>
                                    <li>预期节能：70%</li>
                                    <li>功耗降至：15W（但性能降至70 TOPS）</li>
                                    <li>能效提升至：4.67 TOPS/W</li>
                                </ul>
                            </li>
                        </ol>
                        
                        <p><strong>实施建议：</strong></p>
                        <ul>
                            <li>优先实施低复杂度高收益技术（时钟门控）</li>
                            <li>根据应用场景选择DVFS策略</li>
                            <li>稀疏计算需要软硬件协同优化</li>
                            <li>考虑功耗-性能-面积(PPA)平衡</li>
                        </ul>
                    </div>
                </div>
            </div>
            
            <h3>3.5 Transformer专用架构设计</h3>
            
            <p>Transformer模型的独特计算模式需要专门的架构优化。与CNN主要依赖卷积运算不同，Transformer的自注意力机制带来了新的架构设计挑战。</p>
            
            <h4>3.5.1 注意力计算的架构挑战</h4>
            <p>自注意力计算的特点对NPU架构设计提出了独特要求：</p>
            
            <div class="info-box">
                <p><strong>Transformer vs CNN计算特征对比：</strong></p>
                <table>
                    <thead>
                        <tr>
                            <th>特征</th>
                            <th>CNN</th>
                            <th>Transformer</th>
                            <th>架构影响</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>计算模式</td>
                            <td>局部连接，权重共享</td>
                            <td>全局连接，动态权重</td>
                            <td>需要更大的片上存储</td>
                        </tr>
                        <tr>
                            <td>内存访问</td>
                            <td>规律的滑窗模式</td>
                            <td>不规则的全局访问</td>
                            <td>需要灵活的内存系统</td>
                        </tr>
                        <tr>
                            <td>计算复杂度</td>
                            <td>O(N)</td>
                            <td>O(N²)</td>
                            <td>需要更强的计算能力</td>
                        </tr>
                        <tr>
                            <td>数据复用</td>
                            <td>高（权重复用）</td>
                            <td>低（动态注意力）</td>
                            <td>需要新的数据流设计</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            
            <h4>3.5.2 Transformer加速器架构</h4>
            <p>针对Transformer的特点，现代NPU采用了多种架构创新：</p>
            
            <div class="code-block">
// Transformer专用NPU架构
┌─────────────────────────────────────────┐
│          控制单元 (Controller)           │
│  - 注意力调度器                         │
│  - 动态分块控制                         │
│  - 多头并行管理                         │
├─────────────────────────────────────────┤
│     专用计算引擎 (Compute Engines)      │
│ ┌─────────────┐ ┌──────────────┐       │
│ │  GEMM引擎   │ │ Softmax引擎 │       │
│ │ - QK计算    │ │ - 指数单元  │       │
│ │ - PV计算    │ │ - 归一化器  │       │
│ └─────────────┘ └──────────────┘       │
│ ┌─────────────┐ ┌──────────────┐       │
│ │ 层归一化    │ │  特殊函数   │       │
│ │   引擎      │ │    单元     │       │
│ └─────────────┘ └──────────────┘       │
├─────────────────────────────────────────┤
│      层次化存储系统 (Memory)            │
│ ┌─────────────────────────────┐         │
│ │     注意力缓存 (Att Cache)  │         │
│ │   - KV Cache: 512KB         │         │
│ │   - Score Buffer: 256KB     │         │
│ └─────────────────────────────┘         │
│ ┌─────────────────────────────┐         │
│ │    全局缓冲区 (L2 Buffer)   │         │
│ │   - 统一地址空间: 2MB       │         │
│ └─────────────────────────────┘         │
└─────────────────────────────────────────┘
            </div>
            
            <h4>3.5.3 KV Cache优化架构</h4>
            <p>在Transformer推理中，KV Cache是关键的性能瓶颈。专用的缓存架构可以显著提升性能：</p>
            
            <div class="code-block">
// KV Cache管理单元
module KVCacheManager #(
    parameter MAX_SEQ_LEN = 8192,
    parameter D_MODEL = 1024,
    parameter NUM_HEADS = 16,
    parameter CACHE_WAYS = 4
)(
    input wire clk,
    input wire rst_n,
    
    // 请求接口
    input wire cache_req,
    input wire cache_write,
    input wire [12:0] seq_pos,      // 序列位置
    input wire [3:0] head_idx,       // 注意力头索引
    input wire [9:0] dim_idx,        // 维度索引
    
    // 数据接口
    input wire [15:0] write_data,    // FP16
    output reg [15:0] read_data,
    output reg cache_hit,
    
    // 预取接口
    input wire prefetch_enable,
    input wire [12:0] prefetch_pos
);
    
    // 分组关联缓存结构
    localparam CACHE_SETS = MAX_SEQ_LEN / CACHE_WAYS;
    localparam D_HEAD = D_MODEL / NUM_HEADS;
    
    // 缓存存储
    reg [15:0] k_cache [CACHE_SETS-1:0][CACHE_WAYS-1:0][D_HEAD-1:0];
    reg [15:0] v_cache [CACHE_SETS-1:0][CACHE_WAYS-1:0][D_HEAD-1:0];
    
    // 标签和有效位
    reg [12:0] cache_tags [CACHE_SETS-1:0][CACHE_WAYS-1:0];
    reg cache_valid [CACHE_SETS-1:0][CACHE_WAYS-1:0];
    
    // LRU替换策略
    reg [1:0] lru_counter [CACHE_SETS-1:0][CACHE_WAYS-1:0];
    
    // 地址解码
    wire [9:0] set_idx = seq_pos[9:0];
    wire [2:0] tag = seq_pos[12:10];
    
    // 命中检测
    integer way;
    reg [1:0] hit_way;
    always @(*) begin
        cache_hit = 1'b0;
        hit_way = 2'b00;
        for (way = 0; way < CACHE_WAYS; way = way + 1) begin
            if (cache_valid[set_idx][way] && 
                cache_tags[set_idx][way] == tag) begin
                cache_hit = 1'b1;
                hit_way = way;
            end
        end
    end
    
    // 缓存访问
    always @(posedge clk) begin
        if (!rst_n) begin
            // 初始化
            for (int i = 0; i < CACHE_SETS; i++) begin
                for (int j = 0; j < CACHE_WAYS; j++) begin
                    cache_valid[i][j] <= 1'b0;
                    lru_counter[i][j] <= 2'b00;
                end
            end
        end else if (cache_req) begin
            if (cache_write) begin
                if (cache_hit) begin
                    // 写命中：更新数据
                    k_cache[set_idx][hit_way][dim_idx] <= write_data;
                    // 更新LRU
                    lru_counter[set_idx][hit_way] <= 2'b11;
                end else begin
                    // 写缺失：分配新行
                    // 找LRU way
                    reg [1:0] lru_way = 0;
                    reg [1:0] min_lru = 2'b11;
                    for (way = 0; way < CACHE_WAYS; way = way + 1) begin
                        if (lru_counter[set_idx][way] < min_lru) begin
                            min_lru = lru_counter[set_idx][way];
                            lru_way = way;
                        end
                    end
                    
                    // 写入新数据
                    k_cache[set_idx][lru_way][dim_idx] <= write_data;
                    cache_tags[set_idx][lru_way] <= tag;
                    cache_valid[set_idx][lru_way] <= 1'b1;
                    lru_counter[set_idx][lru_way] <= 2'b11;
                end
            end else begin
                // 读操作
                if (cache_hit) begin
                    read_data <= k_cache[set_idx][hit_way][dim_idx];
                    // 更新LRU
                    lru_counter[set_idx][hit_way] <= 2'b11;
                end
            end
            
            // 老化LRU计数器
            for (way = 0; way < CACHE_WAYS; way = way + 1) begin
                if (way != hit_way && lru_counter[set_idx][way] > 0) begin
                    lru_counter[set_idx][way] <= lru_counter[set_idx][way] - 1;
                end
            end
        end
    end
    
    // 预取逻辑
    reg [12:0] prefetch_addr;
    reg prefetch_active;
    
    always @(posedge clk) begin
        if (!rst_n) begin
            prefetch_active <= 1'b0;
        end else if (prefetch_enable && !cache_req) begin
            // 在空闲时执行预取
            prefetch_active <= 1'b1;
            prefetch_addr <= prefetch_pos;
            // 实际预取逻辑需要连接到内存系统
        end
    end
endmodule
            </div>
            
            <h4>3.5.4 动态序列长度支持</h4>
            <p>Transformer的序列长度可变特性需要灵活的架构支持：</p>
            
            <div class="info-box">
                <p><strong>序列长度自适应策略：</strong></p>
                <ul>
                    <li><strong>分段处理：</strong>将长序列分成固定大小的段，每段独立处理</li>
                    <li><strong>动态分块：</strong>根据序列长度动态调整块大小，平衡内存和计算</li>
                    <li><strong>稀疏注意力：</strong>只计算重要的注意力连接，减少计算量</li>
                    <li><strong>滑窗注意力：</strong>限制注意力范围在局部窗口内</li>
                </ul>
            </div>
            
            <h4>3.5.5 多模态融合架构</h4>
            <p>现代Transformer需要处理多种模态（文本、图像、音频），这需要统一的架构设计：</p>
            
            <div class="code-block">
// 多模态Transformer处理单元
module MultiModalProcessor #(
    parameter MAX_TEXT_LEN = 2048,
    parameter MAX_IMAGE_PATCHES = 1024,
    parameter D_MODEL = 768
)(
    input wire clk,
    input wire rst_n,
    
    // 模态选择
    input wire [1:0] modality,  // 0:文本 1:图像 2:音频 3:融合
    
    // 文本输入
    input wire [15:0] text_embeddings [MAX_TEXT_LEN-1:0][D_MODEL-1:0],
    input wire [10:0] text_len,
    
    // 图像输入（patch embeddings）
    input wire [15:0] image_patches [MAX_IMAGE_PATCHES-1:0][D_MODEL-1:0],
    input wire [9:0] num_patches,
    
    // 位置编码生成器
    output reg [15:0] position_encoding [2047:0][D_MODEL-1:0]
);
    
    // 统一的embedding投影
    reg [15:0] unified_embeddings [4095:0][D_MODEL-1:0];
    reg [11:0] total_len;
    
    // 模态特定的位置编码
    always @(posedge clk) begin
        case (modality)
            2'b00: begin  // 文本：1D位置编码
                for (int i = 0; i < text_len; i++) begin
                    for (int j = 0; j < D_MODEL; j++) begin
                        if (j[0] == 0) begin
                            // 偶数维度：sin(pos/10000^(2i/d_model))
                            position_encoding[i][j] <= $sin(i / (10000.0 ** (j/D_MODEL)));
                        end else begin
                            // 奇数维度：cos(pos/10000^(2i/d_model))
                            position_encoding[i][j] <= $cos(i / (10000.0 ** ((j-1)/D_MODEL)));
                        end
                    end
                end
                total_len <= text_len;
            end
            
            2'b01: begin  // 图像：2D位置编码
                for (int p = 0; p < num_patches; p++) begin
                    int row = p / 32;  // 假设32x32 patches
                    int col = p % 32;
                    for (int j = 0; j < D_MODEL/2; j++) begin
                        // 行编码
                        position_encoding[p][j*2] <= $sin(row / (10000.0 ** (j/(D_MODEL/2))));
                        // 列编码
                        position_encoding[p][j*2+1] <= $sin(col / (10000.0 ** (j/(D_MODEL/2))));
                    end
                end
                total_len <= num_patches;
            end
            
            2'b11: begin  // 多模态融合
                // 文本部分
                for (int i = 0; i < text_len; i++) begin
                    unified_embeddings[i] <= text_embeddings[i];
                end
                // 图像部分（追加）
                for (int i = 0; i < num_patches; i++) begin
                    unified_embeddings[text_len + i] <= image_patches[i];
                end
                total_len <= text_len + num_patches;
                
                // 生成融合的位置编码
                // 可以使用不同的策略，如相对位置编码
            end
        endcase
    end
    
    // 跨模态注意力掩码生成
    reg attention_mask [4095:0][4095:0];
    
    always @(posedge clk) begin
        if (modality == 2'b11) begin  // 融合模式
            // 允许跨模态注意力
            for (int i = 0; i < total_len; i++) begin
                for (int j = 0; j < total_len; j++) begin
                    if (i < text_len && j >= text_len) begin
                        // 文本可以关注图像
                        attention_mask[i][j] <= 1'b1;
                    end else if (i >= text_len && j < text_len) begin
                        // 图像可以关注文本
                        attention_mask[i][j] <= 1'b1;
                    end else begin
                        // 模态内注意力始终允许
                        attention_mask[i][j] <= 1'b1;
                    end
                end
            end
        end
    end
endmodule
            </div>
            
            <div class="exercise">
                <h4>练习 3.5</h4>
                <div class="question">
                    <p><strong>题目：</strong>设计一个支持动态批处理的Transformer加速器架构，要求：
                    1) 支持可变的批大小（1-32）
                    2) 支持不同序列长度的padding和mask
                    3) 实现高效的批内并行和批间流水
                    4) 考虑内存带宽优化</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module DynamicBatchTransformer #(
    parameter MAX_BATCH_SIZE = 32,
    parameter MAX_SEQ_LEN = 512,
    parameter D_MODEL = 768,
    parameter NUM_HEADS = 12,
    parameter NUM_PE = 256  // 处理单元数量
)(
    input wire clk,
    input wire rst_n,
    
    // 批处理配置
    input wire [4:0] batch_size,          // 1-32
    input wire [8:0] seq_lengths [MAX_BATCH_SIZE-1:0],  // 每个样本的长度
    input wire batch_start,
    
    // 输入数据接口
    input wire [15:0] input_data,
    input wire input_valid,
    input wire [4:0] sample_idx,
    input wire [8:0] token_idx,
    
    // 输出接口
    output reg [15:0] output_data,
    output reg output_valid,
    output reg [4:0] output_sample_idx,
    output reg [8:0] output_token_idx,
    output reg batch_done
);
    
    // 批处理调度器
    reg [2:0] batch_state;
    localparam IDLE = 3'b000;
    localparam SCHEDULE = 3'b001;
    localparam PROCESS = 3'b010;
    localparam COLLECT = 3'b011;
    
    // 工作分配表
    reg [4:0] pe_assignment [NUM_PE-1:0];  // PE到样本的映射
    reg [8:0] pe_token_start [NUM_PE-1:0]; // 每个PE处理的起始token
    reg [8:0] pe_token_end [NUM_PE-1:0];   // 每个PE处理的结束token
    reg pe_active [NUM_PE-1:0];
    
    // Padding掩码生成
    reg padding_mask [MAX_BATCH_SIZE-1:0][MAX_SEQ_LEN-1:0];
    
    always @(posedge clk) begin
        if (!rst_n) begin
            batch_state <= IDLE;
            batch_done <= 1'b0;
        end else begin
            case (batch_state)
                IDLE: begin
                    if (batch_start) begin
                        batch_state <= SCHEDULE;
                        batch_done <= 1'b0;
                        
                        // 生成padding掩码
                        for (int b = 0; b < MAX_BATCH_SIZE; b++) begin
                            for (int s = 0; s < MAX_SEQ_LEN; s++) begin
                                if (b < batch_size && s < seq_lengths[b]) begin
                                    padding_mask[b][s] <= 1'b1;  // 有效位置
                                end else begin
                                    padding_mask[b][s] <= 1'b0;  // Padding位置
                                end
                            end
                        end
                    end
                end
                
                SCHEDULE: begin
                    // 动态工作分配算法
                    schedule_work();
                    batch_state <= PROCESS;
                end
                
                PROCESS: begin
                    // 等待所有PE完成
                    if (all_pe_done()) begin
                        batch_state <= COLLECT;
                    end
                end
                
                COLLECT: begin
                    batch_done <= 1'b1;
                    batch_state <= IDLE;
                end
            endcase
        end
    end
    
    // 工作调度函数
    task schedule_work;
        integer total_tokens;
        integer tokens_per_pe;
        integer current_pe;
        integer assigned_tokens;
        begin
            // 计算总token数
            total_tokens = 0;
            for (int b = 0; b < batch_size; b++) begin
                total_tokens = total_tokens + seq_lengths[b];
            end
            
            // 平均分配策略
            tokens_per_pe = (total_tokens + NUM_PE - 1) / NUM_PE;
            
            current_pe = 0;
            assigned_tokens = 0;
            
            // 分配样本和token范围到PE
            for (int b = 0; b < batch_size; b++) begin
                integer sample_start = 0;
                integer remaining = seq_lengths[b];
                
                while (remaining > 0 && current_pe < NUM_PE) begin
                    integer chunk_size;
                    
                    // 确定当前PE处理的token数
                    if (assigned_tokens + remaining <= tokens_per_pe) begin
                        chunk_size = remaining;
                    end else begin
                        chunk_size = tokens_per_pe - assigned_tokens;
                    end
                    
                    // 分配工作
                    pe_assignment[current_pe] = b;
                    pe_token_start[current_pe] = sample_start;
                    pe_token_end[current_pe] = sample_start + chunk_size;
                    pe_active[current_pe] = 1'b1;
                    
                    sample_start = sample_start + chunk_size;
                    remaining = remaining - chunk_size;
                    assigned_tokens = assigned_tokens + chunk_size;
                    
                    // 切换到下一个PE
                    if (assigned_tokens >= tokens_per_pe) begin
                        current_pe = current_pe + 1;
                        assigned_tokens = 0;
                    end
                end
            end
            
            // 标记未使用的PE
            for (int p = current_pe; p < NUM_PE; p++) begin
                pe_active[p] = 1'b0;
            end
        end
    endtask
    
    // 检查所有PE是否完成
    function all_pe_done;
        begin
            all_pe_done = 1'b1;
            for (int p = 0; p < NUM_PE; p++) begin
                if (pe_active[p] && !pe_done[p]) begin
                    all_pe_done = 1'b0;
                end
            end
        end
    endfunction
    
    // PE阵列实例化
    wire pe_done [NUM_PE-1:0];
    
    genvar pe_idx;
    generate
        for (pe_idx = 0; pe_idx < NUM_PE; pe_idx = pe_idx + 1) begin : pe_array
            TransformerPE #(
                .D_MODEL(D_MODEL),
                .NUM_HEADS(NUM_HEADS)
            ) pe_inst (
                .clk(clk),
                .rst_n(rst_n),
                .enable(pe_active[pe_idx]),
                .sample_idx(pe_assignment[pe_idx]),
                .token_start(pe_token_start[pe_idx]),
                .token_end(pe_token_end[pe_idx]),
                .padding_mask(padding_mask[pe_assignment[pe_idx]]),
                .done(pe_done[pe_idx])
            );
        end
    endgenerate
    
    // 内存带宽优化：批内数据预取
    reg [15:0] prefetch_buffer [MAX_BATCH_SIZE-1:0][63:0][D_MODEL-1:0];
    reg [5:0] prefetch_ptr [MAX_BATCH_SIZE-1:0];
    
    always @(posedge clk) begin
        if (batch_state == PROCESS) begin
            // 预取下一个窗口的数据
            for (int b = 0; b < batch_size; b++) begin
                if (prefetch_ptr[b] < seq_lengths[b]) begin
                    // 发起预取请求
                    // 实际实现需要连接到内存控制器
                end
            end
        end
    end
    
    // 结果收集和重排序
    reg [15:0] output_buffer [MAX_BATCH_SIZE-1:0][MAX_SEQ_LEN-1:0][D_MODEL-1:0];
    reg output_ready [MAX_BATCH_SIZE-1:0][MAX_SEQ_LEN-1:0];
    
    // 输出生成状态机
    reg [4:0] out_sample;
    reg [8:0] out_token;
    
    always @(posedge clk) begin
        if (!rst_n) begin
            output_valid <= 1'b0;
            out_sample <= 0;
            out_token <= 0;
        end else if (batch_state == COLLECT) begin
            // 按顺序输出结果
            if (out_sample < batch_size) begin
                if (out_token < seq_lengths[out_sample] && 
                    output_ready[out_sample][out_token]) begin
                    output_data <= output_buffer[out_sample][out_token][0]; // 简化：只输出第一维
                    output_valid <= 1'b1;
                    output_sample_idx <= out_sample;
                    output_token_idx <= out_token;
                    
                    // 移动到下一个token
                    if (out_token == seq_lengths[out_sample] - 1) begin
                        out_token <= 0;
                        out_sample <= out_sample + 1;
                    end else begin
                        out_token <= out_token + 1;
                    end
                end else begin
                    output_valid <= 1'b0;
                end
            end
        end else begin
            output_valid <= 1'b0;
        end
    end
endmodule
                        </div>
                        <p><strong>设计要点：</strong></p>
                        <ul>
                            <li>动态工作分配实现负载均衡</li>
                            <li>Padding掩码避免无效计算</li>
                            <li>预取机制优化内存带宽利用</li>
                            <li>PE级并行和流水线提高吞吐量</li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>

        <div id="chapter4" class="chapter">
            <h2>第4章：计算核心设计</h2>
            
            <h3>4.1 MAC阵列设计</h3>
            
            <h4>4.1.1 基础MAC单元</h4>
            <p>MAC (Multiply-Accumulate) 是NPU的基本计算单元，执行 <code>C = C + A × B</code> 运算。</p>
            
            <div class="code-block">
// 优化的流水线MAC单元 - Verilog版本
module MAC_Unit #(
    parameter DATA_WIDTH = 8,      // 输入数据位宽(INT8)
    parameter ACC_WIDTH = 32,      // 累加器位宽(防止溢出)
    parameter PIPELINE_STAGES = 3  // 流水线级数
)(
    input wire clk,
    input wire rst_n,
    input wire enable,
    
    // 输入接口
    input wire signed [DATA_WIDTH-1:0] a_in,      // 激活值
    input wire signed [DATA_WIDTH-1:0] b_in,      // 权重
    input wire signed [ACC_WIDTH-1:0] c_in,       // 部分和输入
    
    // 输出接口
    output reg signed [ACC_WIDTH-1:0] c_out,      // 累加结果
    output reg valid_out
);

    // 流水线寄存器 - 第一级
    reg signed [DATA_WIDTH-1:0] a_reg1, b_reg1;
    reg signed [ACC_WIDTH-1:0] c_reg1;
    reg enable_reg1;
    
    // 流水线寄存器 - 第二级
    reg signed [2*DATA_WIDTH-1:0] mult_reg2;
    reg signed [ACC_WIDTH-1:0] c_reg2;
    reg enable_reg2;
    
    // 乘法结果（第二级计算）
    wire signed [2*DATA_WIDTH-1:0] mult_result;
    assign mult_result = a_reg1 * b_reg1;
    
    // 加法结果（第三级计算）
    wire signed [ACC_WIDTH-1:0] add_result;
    assign add_result = c_reg2 + {{(ACC_WIDTH-2*DATA_WIDTH){mult_reg2[2*DATA_WIDTH-1]}}, mult_reg2};
    
    // 第一级流水线：输入寄存
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            a_reg1 <= 0;
            b_reg1 <= 0;
            c_reg1 <= 0;
            enable_reg1 <= 0;
        end else begin
            if (enable) begin
                a_reg1 <= a_in;
                b_reg1 <= b_in;
                c_reg1 <= c_in;
            end
            enable_reg1 <= enable;
        end
    end
    
    // 第二级流水线：乘法结果寄存
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            mult_reg2 <= 0;
            c_reg2 <= 0;
            enable_reg2 <= 0;
        end else begin
            if (enable_reg1) begin
                mult_reg2 <= mult_result;
                c_reg2 <= c_reg1;
            end
            enable_reg2 <= enable_reg1;
        end
    end
    
    // 第三级流水线：累加结果输出
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            c_out <= 0;
            valid_out <= 0;
        end else begin
            if (enable_reg2) begin
                c_out <= add_result;
            end
            valid_out <= enable_reg2;
        end
    end
endmodule
            </div>
            
            <p>Chisel版本的MAC单元：</p>
            <div class="code-block">
import chisel3._
import chisel3.util._

class MACUnit(val dataWidth: Int = 8, val accWidth: Int = 32) extends Module {
    val io = IO(new Bundle {
        val enable = Input(Bool())
        val a_in = Input(SInt(dataWidth.W))
        val b_in = Input(SInt(dataWidth.W))
        val c_in = Input(SInt(accWidth.W))
        val c_out = Output(SInt(accWidth.W))
        val valid_out = Output(Bool())
    })
    
    // 第一级流水线：输入寄存器
    val a_reg1 = RegEnable(io.a_in, 0.S(dataWidth.W), io.enable)
    val b_reg1 = RegEnable(io.b_in, 0.S(dataWidth.W), io.enable)
    val c_reg1 = RegEnable(io.c_in, 0.S(accWidth.W), io.enable)
    val enable_reg1 = RegNext(io.enable, false.B)
    
    // 第二级流水线：乘法
    val mult_result = a_reg1 * b_reg1
    val mult_reg2 = RegEnable(mult_result, 0.S((2*dataWidth).W), enable_reg1)
    val c_reg2 = RegEnable(c_reg1, 0.S(accWidth.W), enable_reg1)
    val enable_reg2 = RegNext(enable_reg1, false.B)
    
    // 第三级流水线：累加
    val mult_extended = Wire(SInt(accWidth.W))
    mult_extended := mult_reg2.asSInt
    val add_result = c_reg2 + mult_extended
    
    io.c_out := RegEnable(add_result, 0.S(accWidth.W), enable_reg2)
    io.valid_out := RegNext(enable_reg2, false.B)
}

// 生成Verilog
object MACUnitGen extends App {
    (new chisel3.stage.ChiselStage).emitVerilog(
        new MACUnit(),
        Array("--target-dir", "generated")
    )
}
            </div>

            <h4>4.1.2 多精度MAC设计</h4>
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>数据类型</th>
                            <th>乘法器面积</th>
                            <th>功耗</th>
                            <th>延迟</th>
                            <th>应用场景</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>INT4</td>
                            <td>16 gates</td>
                            <td>0.1x</td>
                            <td>1 cycle</td>
                            <td>极低功耗推理</td>
                        </tr>
                        <tr>
                            <td>INT8</td>
                            <td>64 gates</td>
                            <td>0.25x</td>
                            <td>1 cycle</td>
                            <td>主流推理</td>
                        </tr>
                        <tr>
                            <td>FP16</td>
                            <td>~400 gates</td>
                            <td>0.4x</td>
                            <td>2 cycles</td>
                            <td>训练/高精度推理</td>
                        </tr>
                        <tr>
                            <td>FP32</td>
                            <td>~1600 gates</td>
                            <td>1.0x</td>
                            <td>3 cycles</td>
                            <td>科学计算/训练</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h4>4.1.3 MAC阵列组织</h4>
            <div class="code-block">
// 二维MAC阵列组织示例 (8x8)
module MAC_Array_8x8 #(
    parameter DATA_WIDTH = 8,
    parameter ACC_WIDTH = 32,
    parameter ARRAY_SIZE = 8
)(
    input wire clk,
    input wire rst_n,
    input wire enable,
    
    // 输入数据广播
    input wire [DATA_WIDTH-1:0] act_broadcast [0:ARRAY_SIZE-1],  // 激活值广播
    input wire [DATA_WIDTH-1:0] weight_array [0:ARRAY_SIZE-1][0:ARRAY_SIZE-1],  // 权重
    
    // 部分和累加
    output wire [ACC_WIDTH-1:0] psum_out [0:ARRAY_SIZE-1][0:ARRAY_SIZE-1]
);

    // MAC单元阵列
    genvar i, j;
    generate
        for (i = 0; i < ARRAY_SIZE; i = i + 1) begin : row
            for (j = 0; j < ARRAY_SIZE; j = j + 1) begin : col
                MAC_Unit #(
                    .DATA_WIDTH(DATA_WIDTH),
                    .ACC_WIDTH(ACC_WIDTH)
                ) mac_inst (
                    .clk(clk),
                    .rst_n(rst_n),
                    .enable(enable),
                    .a_in(act_broadcast[i]),              // 行广播
                    .b_in(weight_array[i][j]),            // 本地权重
                    .c_in(/* 根据数据流选择 */),
                    .c_out(psum_out[i][j])
                );
            end
        end
    endgenerate
endmodule
            </div>

            <h3>4.2 脉动阵列架构</h3>
            
            <h4>4.2.1 脉动阵列原理</h4>
            <p>脉动阵列通过数据在PE间的有节奏流动，实现高效的数据复用和规则的计算模式。</p>
            
            <div class="info-box">
                <p><strong>核心优势：</strong></p>
                <ul>
                    <li>数据复用率高：每个数据被多个PE使用</li>
                    <li>通信局部化：只需要邻近PE间通信</li>
                    <li>控制简单：规则的数据流动模式</li>
                    <li>易于扩展：模块化设计便于增加阵列规模</li>
                </ul>
            </div>

            <h4>4.2.2 Weight Stationary脉动阵列实现</h4>
            <div class="code-block">
// 权重固定型脉动阵列PE
module SystolicPE_WS #(
    parameter DATA_WIDTH = 8,
    parameter ACC_WIDTH = 32
)(
    input wire clk,
    input wire rst_n,
    
    // 控制信号
    input wire weight_load,      // 权重加载使能
    input wire compute_en,       // 计算使能
    
    // 数据输入
    input wire [DATA_WIDTH-1:0] act_in,      // 激活值输入（从上方）
    input wire [DATA_WIDTH-1:0] weight_in,   // 权重输入（加载时）
    input wire [ACC_WIDTH-1:0] psum_in,      // 部分和输入（从左侧）
    
    // 数据输出
    output reg [DATA_WIDTH-1:0] act_out,     // 激活值输出（向下方）
    output reg [ACC_WIDTH-1:0] psum_out      // 部分和输出（向右侧）
);

    // 内部寄存器
    reg [DATA_WIDTH-1:0] weight_reg;         // 存储的权重
    reg [DATA_WIDTH-1:0] act_reg;            // 激活值寄存器
    
    // MAC运算
    wire [2*DATA_WIDTH-1:0] mult_result;
    wire [ACC_WIDTH-1:0] mac_result;
    
    assign mult_result = act_reg * weight_reg;
    assign mac_result = psum_in + {{(ACC_WIDTH-2*DATA_WIDTH){mult_result[2*DATA_WIDTH-1]}}, mult_result};
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            weight_reg <= 0;
            act_reg <= 0;
            act_out <= 0;
            psum_out <= 0;
        end else begin
            // 权重加载
            if (weight_load) begin
                weight_reg <= weight_in;
            end
            
            // 计算模式
            if (compute_en) begin
                // 激活值向下传递
                act_reg <= act_in;
                act_out <= act_reg;
                
                // MAC结果向右传递
                psum_out <= mac_result;
            end
        end
    end
endmodule

// 优化的流水线脉动阵列 - Verilog版本
module SystolicArray_4x4_WS #(
    parameter DATA_WIDTH = 8,
    parameter ACC_WIDTH = 32,
    parameter ARRAY_DIM = 4
)(
    input wire clk,
    input wire rst_n,
    input wire weight_load,
    input wire compute_en,
    
    // 激活值输入（从顶部进入，已寄存）
    input wire [DATA_WIDTH-1:0] act_in [0:ARRAY_DIM-1],
    
    // 权重加载接口
    input wire [DATA_WIDTH-1:0] weight_in [0:ARRAY_DIM-1][0:ARRAY_DIM-1],
    
    // 结果输出（从右侧输出，已寄存）
    output wire [ACC_WIDTH-1:0] result_out [0:ARRAY_DIM-1]
);

    // PE间的寄存连接
    reg [DATA_WIDTH-1:0] act_reg [0:ARRAY_DIM][0:ARRAY_DIM-1];  // 激活值寄存器
    reg [ACC_WIDTH-1:0] psum_reg [0:ARRAY_DIM-1][0:ARRAY_DIM];  // 部分和寄存器
    reg valid_reg [0:ARRAY_DIM][0:ARRAY_DIM-1];                 // 有效信号寄存器
    
    // 初始化边界条件
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            for (int i = 0; i < ARRAY_DIM; i++) begin
                psum_reg[i][0] <= 0;  // 左边界部分和为0
                valid_reg[0][i] <= 0;  // 顶部有效信号初始化
            end
        end else begin
            // 左边界保持为0
            for (int i = 0; i < ARRAY_DIM; i++) begin
                psum_reg[i][0] <= 0;
            end
            // 顶部输入寄存
            for (int j = 0; j < ARRAY_DIM; j++) begin
                act_reg[0][j] <= act_in[j];
                valid_reg[0][j] <= compute_en;
            end
        end
    end
    
    // PE阵列实例化（优化版本）
    genvar i, j;
    generate
        for (i = 0; i < ARRAY_DIM; i = i + 1) begin : pe_row
            for (j = 0; j < ARRAY_DIM; j = j + 1) begin : pe_col
                SystolicPE_WS_Pipelined #(
                    .DATA_WIDTH(DATA_WIDTH),
                    .ACC_WIDTH(ACC_WIDTH)
                ) pe_inst (
                    .clk(clk),
                    .rst_n(rst_n),
                    .weight_load(weight_load),
                    .valid_in(valid_reg[i][j]),
                    .act_in(act_reg[i][j]),
                    .weight_in(weight_in[i][j]),
                    .psum_in(psum_reg[i][j]),
                    .act_out(act_reg[i+1][j]),
                    .psum_out(psum_reg[i][j+1]),
                    .valid_out(valid_reg[i+1][j])
                );
            end
        end
    endgenerate
    
    // 输出连接（已寄存）
    generate
        for (i = 0; i < ARRAY_DIM; i = i + 1) begin
            assign result_out[i] = psum_reg[i][ARRAY_DIM];
        end
    endgenerate
endmodule

// 优化的流水线PE单元
module SystolicPE_WS_Pipelined #(
    parameter DATA_WIDTH = 8,
    parameter ACC_WIDTH = 32
)(
    input wire clk,
    input wire rst_n,
    input wire weight_load,
    input wire valid_in,
    input wire [DATA_WIDTH-1:0] act_in,
    input wire [DATA_WIDTH-1:0] weight_in,
    input wire [ACC_WIDTH-1:0] psum_in,
    output reg [DATA_WIDTH-1:0] act_out,
    output reg [ACC_WIDTH-1:0] psum_out,
    output reg valid_out
);
    // 权重寄存器（保持不变）
    reg [DATA_WIDTH-1:0] weight_reg;
    
    // 流水线寄存器
    reg [DATA_WIDTH-1:0] act_reg;
    reg [ACC_WIDTH-1:0] psum_reg;
    reg valid_reg;
    
    // MAC计算（组合逻辑）
    wire [2*DATA_WIDTH-1:0] mult_result;
    wire [ACC_WIDTH-1:0] mac_result;
    
    assign mult_result = $signed(act_reg) * $signed(weight_reg);
    assign mac_result = psum_reg + {{(ACC_WIDTH-2*DATA_WIDTH){mult_result[2*DATA_WIDTH-1]}}, mult_result};
    
    // 权重加载
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            weight_reg <= 0;
        end else if (weight_load) begin
            weight_reg <= weight_in;
        end
    end
    
    // 流水线第一级：输入寄存
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            act_reg <= 0;
            psum_reg <= 0;
            valid_reg <= 0;
        end else begin
            act_reg <= act_in;
            psum_reg <= psum_in;
            valid_reg <= valid_in;
        end
    end
    
    // 流水线第二级：输出寄存
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            act_out <= 0;
            psum_out <= 0;
            valid_out <= 0;
        end else begin
            act_out <= act_reg;  // 激活值向下传递
            psum_out <= valid_reg ? mac_result : psum_reg;  // MAC结果向右传递
            valid_out <= valid_reg;
        end
    end
endmodule
            </div>
            
            <p>Chisel版本的脉动阵列：</p>
            <div class="code-block">
import chisel3._
import chisel3.util._

// 脉动PE单元
class SystolicPE(val dataWidth: Int = 8, val accWidth: Int = 32) extends Module {
    val io = IO(new Bundle {
        val weight_load = Input(Bool())
        val valid_in = Input(Bool())
        val act_in = Input(SInt(dataWidth.W))
        val weight_in = Input(SInt(dataWidth.W))
        val psum_in = Input(SInt(accWidth.W))
        val act_out = Output(SInt(dataWidth.W))
        val psum_out = Output(SInt(accWidth.W))
        val valid_out = Output(Bool())
    })
    
    // 权重寄存器
    val weight_reg = RegInit(0.S(dataWidth.W))
    when(io.weight_load) {
        weight_reg := io.weight_in
    }
    
    // 流水线寄存器
    val act_reg = RegNext(io.act_in)
    val psum_reg = RegNext(io.psum_in)
    val valid_reg = RegNext(io.valid_in)
    
    // MAC计算
    val mult_result = act_reg * weight_reg
    val mac_result = psum_reg + mult_result
    
    // 输出寄存器
    io.act_out := RegNext(act_reg)
    io.psum_out := RegNext(Mux(valid_reg, mac_result, psum_reg))
    io.valid_out := RegNext(valid_reg)
}

// 4x4脉动阵列
class SystolicArray4x4(val dataWidth: Int = 8, val accWidth: Int = 32) extends Module {
    val arrayDim = 4
    val io = IO(new Bundle {
        val weight_load = Input(Bool())
        val compute_en = Input(Bool())
        val act_in = Input(Vec(arrayDim, SInt(dataWidth.W)))
        val weight_in = Input(Vec(arrayDim, Vec(arrayDim, SInt(dataWidth.W))))
        val result_out = Output(Vec(arrayDim, SInt(accWidth.W)))
    })
    
    // 创建PE阵列
    val peArray = Array.fill(arrayDim, arrayDim)(Module(new SystolicPE(dataWidth, accWidth)))
    
    // 连接PE阵列
    for (i <- 0 until arrayDim) {
        for (j <- 0 until arrayDim) {
            val pe = peArray(i)(j)
            
            // 权重加载
            pe.io.weight_load := io.weight_load
            pe.io.weight_in := io.weight_in(i)(j)
            
            // 激活值连接（从上到下）
            if (i == 0) {
                pe.io.act_in := RegNext(io.act_in(j))
                pe.io.valid_in := RegNext(io.compute_en)
            } else {
                pe.io.act_in := peArray(i-1)(j).io.act_out
                pe.io.valid_in := peArray(i-1)(j).io.valid_out
            }
            
            // 部分和连接（从左到右）
            if (j == 0) {
                pe.io.psum_in := 0.S
            } else {
                pe.io.psum_in := peArray(i)(j-1).io.psum_out
            }
        }
    }
    
    // 输出连接
    for (i <- 0 until arrayDim) {
        io.result_out(i) := peArray(i)(arrayDim-1).io.psum_out
    }
}
            </div>

            <h4>4.2.3 脉动阵列数据流动示例</h4>
            <p>以2×2矩阵乘法为例，展示数据在脉动阵列中的流动过程：</p>
            <div class="code-block">
矩阵A = [a00 a01]    矩阵B = [b00 b01]    结果C = A×B
        [a10 a11]            [b10 b11]

时刻0: 权重加载
PE[0][0] <- b00    PE[0][1] <- b01
PE[1][0] <- b10    PE[1][1] <- b11

时刻1: 
输入: a00, a10 (错开一个周期)
      ↓
    [b00]--[b01]    a00×b00 → PE[0][0]
      ↓
    [b10]--[b11]    

时刻2:
输入: a01, a11
    a00  ↓
    [b00]--[b01]    a00×b01 → PE[0][1], a10×b00 → PE[1][0]
    a10  ↓
    [b10]--[b11]

时刻3:
    a01  a00
    [b00]--[b01]→c00   a01×b10 → PE[0][0], a10×b01 → PE[1][1]
    a11  a10
    [b10]--[b11]

时刻4:
         a01
    [b00]--[b01]→c01   a01×b11 → PE[0][1], a11×b10 → PE[1][0]
         a11
    [b10]--[b11]→c10

时刻5:
    [b00]--[b01]       a11×b11 → PE[1][1]
    [b10]--[b11]→c11
            </div>

            <h4>4.2.4 Output Stationary 脉动阵列实现</h4>
            <p>Output Stationary（输出固定）是另一种重要的脉动阵列架构，特别适合深度卷积和批处理场景。在这种架构中，每个PE负责计算输出矩阵的一个固定元素，输入数据和权重在PE阵列中流动。</p>
            
            <div class="code-block">
// 优化的Output Stationary脉动阵列 - Verilog版本
module OutputStationarySystolicArray #(
    parameter ARRAY_SIZE = 4,
    parameter DATA_WIDTH = 8,
    parameter ACC_WIDTH = 32,
    parameter PIPELINE_STAGES = 3
)(
    input wire clk,
    input wire rst_n,
    input wire enable,
    input wire clear_acc,
    
    // 数据输入 - A矩阵从左侧输入，每行错开一个周期
    input wire signed [DATA_WIDTH-1:0] a_data_in [0:ARRAY_SIZE-1],
    input wire a_valid_in [0:ARRAY_SIZE-1],
    
    // 权重输入 - B矩阵从顶部输入，每列错开一个周期
    input wire signed [DATA_WIDTH-1:0] b_data_in [0:ARRAY_SIZE-1],
    input wire b_valid_in [0:ARRAY_SIZE-1],
    
    // 结果输出 - C矩阵
    output reg signed [ACC_WIDTH-1:0] c_data_out [0:ARRAY_SIZE-1][0:ARRAY_SIZE-1],
    output reg c_valid_out [0:ARRAY_SIZE-1][0:ARRAY_SIZE-1]
);

    // 内部信号
    wire signed [DATA_WIDTH-1:0] a_flow [0:ARRAY_SIZE-1][0:ARRAY_SIZE];
    wire signed [DATA_WIDTH-1:0] b_flow [0:ARRAY_SIZE][0:ARRAY_SIZE-1];
    wire a_valid_flow [0:ARRAY_SIZE-1][0:ARRAY_SIZE];
    wire b_valid_flow [0:ARRAY_SIZE][0:ARRAY_SIZE-1];
    wire signed [ACC_WIDTH-1:0] pe_results [0:ARRAY_SIZE-1][0:ARRAY_SIZE-1];
    wire pe_valid [0:ARRAY_SIZE-1][0:ARRAY_SIZE-1];
    
    // 输入延迟寄存器（创建数据错位）
    reg signed [DATA_WIDTH-1:0] a_delay_reg [0:ARRAY_SIZE-1][0:ARRAY_SIZE-1];
    reg signed [DATA_WIDTH-1:0] b_delay_reg [0:ARRAY_SIZE-1][0:ARRAY_SIZE-1];
    reg a_valid_delay [0:ARRAY_SIZE-1][0:ARRAY_SIZE-1];
    reg b_valid_delay [0:ARRAY_SIZE-1][0:ARRAY_SIZE-1];
    
    // 生成输入延迟链
    genvar d, r, c;
    generate
        // A矩阵输入延迟（每行延迟递增）
        for (r = 0; r < ARRAY_SIZE; r = r + 1) begin : a_delay_gen
            always @(posedge clk or negedge rst_n) begin
                if (!rst_n) begin
                    for (int i = 0; i < r; i = i + 1) begin
                        a_delay_reg[r][i] <= 0;
                        a_valid_delay[r][i] <= 0;
                    end
                end else if (enable) begin
                    if (r == 0) begin
                        // 第一行无延迟
                        a_flow[0][0] <= a_data_in[0];
                        a_valid_flow[0][0] <= a_valid_in[0];
                    end else begin
                        // 延迟链
                        a_delay_reg[r][0] <= a_data_in[r];
                        a_valid_delay[r][0] <= a_valid_in[r];
                        for (int i = 1; i < r; i = i + 1) begin
                            a_delay_reg[r][i] <= a_delay_reg[r][i-1];
                            a_valid_delay[r][i] <= a_valid_delay[r][i-1];
                        end
                        a_flow[r][0] <= a_delay_reg[r][r-1];
                        a_valid_flow[r][0] <= a_valid_delay[r][r-1];
                    end
                end
            end
        end
        
        // B矩阵输入延迟（每列延迟递增）
        for (c = 0; c < ARRAY_SIZE; c = c + 1) begin : b_delay_gen
            always @(posedge clk or negedge rst_n) begin
                if (!rst_n) begin
                    for (int i = 0; i < c; i = i + 1) begin
                        b_delay_reg[c][i] <= 0;
                        b_valid_delay[c][i] <= 0;
                    end
                end else if (enable) begin
                    if (c == 0) begin
                        // 第一列无延迟
                        b_flow[0][0] <= b_data_in[0];
                        b_valid_flow[0][0] <= b_valid_in[0];
                    end else begin
                        // 延迟链
                        b_delay_reg[c][0] <= b_data_in[c];
                        b_valid_delay[c][0] <= b_valid_in[c];
                        for (int i = 1; i < c; i = i + 1) begin
                            b_delay_reg[c][i] <= b_delay_reg[c][i-1];
                            b_valid_delay[c][i] <= b_valid_delay[c][i-1];
                        end
                        b_flow[0][c] <= b_delay_reg[c][c-1];
                        b_valid_flow[0][c] <= b_valid_delay[c][c-1];
                    end
                end
            end
        end
    endgenerate
    
    // PE阵列实例化
    generate
        for (r = 0; r < ARRAY_SIZE; r = r + 1) begin : pe_row
            for (c = 0; c < ARRAY_SIZE; c = c + 1) begin : pe_col
                OutputStationaryPE #(
                    .DATA_WIDTH(DATA_WIDTH),
                    .ACC_WIDTH(ACC_WIDTH)
                ) pe_inst (
                    .clk(clk),
                    .rst_n(rst_n),
                    .enable(enable),
                    .clear_acc(clear_acc),
                    
                    // A数据从左向右流动
                    .a_data_in(a_flow[r][c]),
                    .a_valid_in(a_valid_flow[r][c]),
                    .a_data_out(a_flow[r][c+1]),
                    .a_valid_out(a_valid_flow[r][c+1]),
                    
                    // B数据从上向下流动
                    .b_data_in(b_flow[r][c]),
                    .b_valid_in(b_valid_flow[r][c]),
                    .b_data_out(b_flow[r+1][c]),
                    .b_valid_out(b_valid_flow[r+1][c]),
                    
                    // 累加结果
                    .acc_out(pe_results[r][c]),
                    .acc_valid(pe_valid[r][c])
                );
            end
        end
    endgenerate
    
    // 输出寄存
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            for (int i = 0; i < ARRAY_SIZE; i = i + 1) begin
                for (int j = 0; j < ARRAY_SIZE; j = j + 1) begin
                    c_data_out[i][j] <= 0;
                    c_valid_out[i][j] <= 0;
                end
            end
        end else begin
            for (int i = 0; i < ARRAY_SIZE; i = i + 1) begin
                for (int j = 0; j < ARRAY_SIZE; j = j + 1) begin
                    c_data_out[i][j] <= pe_results[i][j];
                    c_valid_out[i][j] <= pe_valid[i][j];
                end
            end
        end
    end

endmodule

// Output Stationary PE单元
module OutputStationaryPE #(
    parameter DATA_WIDTH = 8,
    parameter ACC_WIDTH = 32
)(
    input wire clk,
    input wire rst_n,
    input wire enable,
    input wire clear_acc,
    
    // A数据接口（水平流动）
    input wire signed [DATA_WIDTH-1:0] a_data_in,
    input wire a_valid_in,
    output reg signed [DATA_WIDTH-1:0] a_data_out,
    output reg a_valid_out,
    
    // B数据接口（垂直流动）
    input wire signed [DATA_WIDTH-1:0] b_data_in,
    input wire b_valid_in,
    output reg signed [DATA_WIDTH-1:0] b_data_out,
    output reg b_valid_out,
    
    // 累加结果（固定在PE中）
    output reg signed [ACC_WIDTH-1:0] acc_out,
    output reg acc_valid
);

    // 内部寄存器
    reg signed [2*DATA_WIDTH-1:0] mult_result;
    reg mult_valid;
    reg signed [ACC_WIDTH-1:0] acc_reg;
    
    // 数据传递流水线
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            a_data_out <= 0;
            a_valid_out <= 0;
            b_data_out <= 0;
            b_valid_out <= 0;
        end else if (enable) begin
            // 数据向右和向下传递
            a_data_out <= a_data_in;
            a_valid_out <= a_valid_in;
            b_data_out <= b_data_in;
            b_valid_out <= b_valid_in;
        end
    end
    
    // 乘法流水线
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            mult_result <= 0;
            mult_valid <= 0;
        end else if (enable) begin
            if (a_valid_in && b_valid_in) begin
                mult_result <= a_data_in * b_data_in;
                mult_valid <= 1;
            end else begin
                mult_result <= 0;
                mult_valid <= 0;
            end
        end
    end
    
    // 累加流水线
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            acc_reg <= 0;
            acc_valid <= 0;
        end else if (clear_acc) begin
            acc_reg <= 0;
            acc_valid <= 0;
        end else if (enable && mult_valid) begin
            acc_reg <= acc_reg + mult_result;
            acc_valid <= 1;
        end
    end
    
    // 输出
    assign acc_out = acc_reg;

endmodule
            </div>
            
            <div class="code-block">
// Chisel版本的Output Stationary脉动阵列
import chisel3._
import chisel3.util._

class OutputStationaryPE(dataWidth: Int = 8, accWidth: Int = 32) extends Module {
  val io = IO(new Bundle {
    val enable = Input(Bool())
    val clearAcc = Input(Bool())
    
    // A数据接口（水平流动）
    val aDataIn = Input(SInt(dataWidth.W))
    val aValidIn = Input(Bool())
    val aDataOut = Output(SInt(dataWidth.W))
    val aValidOut = Output(Bool())
    
    // B数据接口（垂直流动）
    val bDataIn = Input(SInt(dataWidth.W))
    val bValidIn = Input(Bool())
    val bDataOut = Output(SInt(dataWidth.W))
    val bValidOut = Output(Bool())
    
    // 累加结果
    val accOut = Output(SInt(accWidth.W))
    val accValid = Output(Bool())
  })
  
  // 数据传递寄存器
  val aDataReg = RegNext(io.aDataIn)
  val aValidReg = RegNext(io.aValidIn)
  val bDataReg = RegNext(io.bDataIn)
  val bValidReg = RegNext(io.bValidIn)
  
  // 乘法流水线
  val multResult = RegNext(io.aDataIn * io.bDataIn)
  val multValid = RegNext(io.aValidIn && io.bValidIn)
  
  // 累加器
  val accReg = RegInit(0.S(accWidth.W))
  val accValidReg = RegInit(false.B)
  
  when (io.clearAcc) {
    accReg := 0.S
    accValidReg := false.B
  }.elsewhen (io.enable && multValid) {
    accReg := accReg + multResult
    accValidReg := true.B
  }
  
  // 输出连接
  io.aDataOut := aDataReg
  io.aValidOut := aValidReg
  io.bDataOut := bDataReg
  io.bValidOut := bValidReg
  io.accOut := accReg
  io.accValid := accValidReg
}

class OutputStationarySystolicArray(arraySize: Int = 4, dataWidth: Int = 8, accWidth: Int = 32) extends Module {
  val io = IO(new Bundle {
    val enable = Input(Bool())
    val clearAcc = Input(Bool())
    
    // A矩阵输入
    val aDataIn = Input(Vec(arraySize, SInt(dataWidth.W)))
    val aValidIn = Input(Vec(arraySize, Bool()))
    
    // B矩阵输入
    val bDataIn = Input(Vec(arraySize, SInt(dataWidth.W)))
    val bValidIn = Input(Vec(arraySize, Bool()))
    
    // C矩阵输出
    val cDataOut = Output(Vec(arraySize, Vec(arraySize, SInt(accWidth.W))))
    val cValidOut = Output(Vec(arraySize, Vec(arraySize, Bool())))
  })
  
  // PE阵列
  val peArray = Seq.fill(arraySize, arraySize)(Module(new OutputStationaryPE(dataWidth, accWidth)))
  
  // 输入延迟链 - 创建数据错位
  val aDelayChain = Seq.tabulate(arraySize) { r =>
    if (r == 0) {
      (io.aDataIn(0), io.aValidIn(0))
    } else {
      val delayRegs = Seq.fill(r)(Module(new Queue(new Bundle {
        val data = SInt(dataWidth.W)
        val valid = Bool()
      }, 1)))
      
      // 连接延迟链
      delayRegs(0).io.enq.valid := io.enable
      delayRegs(0).io.enq.bits.data := io.aDataIn(r)
      delayRegs(0).io.enq.bits.valid := io.aValidIn(r)
      delayRegs(0).io.deq.ready := io.enable
      
      for (i <- 1 until r) {
        delayRegs(i).io.enq <> delayRegs(i-1).io.deq
        delayRegs(i).io.deq.ready := io.enable
      }
      
      (delayRegs(r-1).io.deq.bits.data, delayRegs(r-1).io.deq.bits.valid)
    }
  }
  
  val bDelayChain = Seq.tabulate(arraySize) { c =>
    if (c == 0) {
      (io.bDataIn(0), io.bValidIn(0))
    } else {
      val delayRegs = Seq.fill(c)(Module(new Queue(new Bundle {
        val data = SInt(dataWidth.W)
        val valid = Bool()
      }, 1)))
      
      // 连接延迟链
      delayRegs(0).io.enq.valid := io.enable
      delayRegs(0).io.enq.bits.data := io.bDataIn(c)
      delayRegs(0).io.enq.bits.valid := io.bValidIn(c)
      delayRegs(0).io.deq.ready := io.enable
      
      for (i <- 1 until c) {
        delayRegs(i).io.enq <> delayRegs(i-1).io.deq
        delayRegs(i).io.deq.ready := io.enable
      }
      
      (delayRegs(c-1).io.deq.bits.data, delayRegs(c-1).io.deq.bits.valid)
    }
  }
  
  // 连接PE阵列
  for (r <- 0 until arraySize) {
    for (c <- 0 until arraySize) {
      val pe = peArray(r)(c)
      pe.io.enable := io.enable
      pe.io.clearAcc := io.clearAcc
      
      // A数据连接（水平）
      if (c == 0) {
        pe.io.aDataIn := aDelayChain(r)._1
        pe.io.aValidIn := aDelayChain(r)._2
      } else {
        pe.io.aDataIn := peArray(r)(c-1).io.aDataOut
        pe.io.aValidIn := peArray(r)(c-1).io.aValidOut
      }
      
      // B数据连接（垂直）
      if (r == 0) {
        pe.io.bDataIn := bDelayChain(c)._1
        pe.io.bValidIn := bDelayChain(c)._2
      } else {
        pe.io.bDataIn := peArray(r-1)(c).io.bDataOut
        pe.io.bValidIn := peArray(r-1)(c).io.bValidOut
      }
      
      // 输出连接
      io.cDataOut(r)(c) := pe.io.accOut
      io.cValidOut(r)(c) := pe.io.accValid
    }
  }
}
            </div>
            
            <h4>4.2.5 Output Stationary vs Weight Stationary 对比</h4>
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>特性</th>
                            <th>Weight Stationary</th>
                            <th>Output Stationary</th>
                            <th>适用场景</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>数据复用</td>
                            <td>权重驻留在PE中</td>
                            <td>部分和驻留在PE中</td>
                            <td>WS: 批量小<br>OS: 批量大</td>
                        </tr>
                        <tr>
                            <td>内存带宽</td>
                            <td>输入/输出带宽高</td>
                            <td>权重/输入带宽高</td>
                            <td>WS: 权重复用多<br>OS: 输出通道多</td>
                        </tr>
                        <tr>
                            <td>控制复杂度</td>
                            <td>简单</td>
                            <td>中等</td>
                            <td>WS: 资源受限<br>OS: 性能优先</td>
                        </tr>
                        <tr>
                            <td>延迟</td>
                            <td>较低</td>
                            <td>较高（需要数据对齐）</td>
                            <td>WS: 实时推理<br>OS: 批处理训练</td>
                        </tr>
                        <tr>
                            <td>能效</td>
                            <td>权重读取能耗低</td>
                            <td>部分和读写能耗低</td>
                            <td>WS: 边缘设备<br>OS: 数据中心</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h3>4.3 向量处理单元</h3>
            
            <h4>4.3.1 SIMD架构设计</h4>
            <p>向量处理单元采用SIMD架构，支持非线性激活、池化等操作。</p>
            
            <div class="code-block">
module VectorProcessingUnit #(
    parameter VECTOR_WIDTH = 16,    // 向量宽度（并行度）
    parameter DATA_WIDTH = 8,       // 数据位宽
    parameter OPCODE_WIDTH = 5      // 操作码宽度
)(
    input wire clk,
    input wire rst_n,
    
    // 指令接口
    input wire [OPCODE_WIDTH-1:0] opcode,
    input wire execute,
    
    // 向量输入
    input wire [DATA_WIDTH-1:0] vec_a [0:VECTOR_WIDTH-1],
    input wire [DATA_WIDTH-1:0] vec_b [0:VECTOR_WIDTH-1],
    
    // 向量输出
    output reg [DATA_WIDTH-1:0] vec_result [0:VECTOR_WIDTH-1],
    output reg done
);

    // 操作码定义
    localparam OP_ADD  = 5'b00001;
    localparam OP_SUB  = 5'b00010;
    localparam OP_MUL  = 5'b00011;
    localparam OP_MAX  = 5'b00100;
    localparam OP_MIN  = 5'b00101;
    localparam OP_RELU = 5'b00110;
    localparam OP_SIGM = 5'b00111;
    localparam OP_TANH = 5'b01000;
    
    // 功能单元输出
    wire [DATA_WIDTH-1:0] alu_out [0:VECTOR_WIDTH-1];
    wire [DATA_WIDTH-1:0] act_out [0:VECTOR_WIDTH-1];
    
    // SIMD ALU阵列
    genvar i;
    generate
        for (i = 0; i < VECTOR_WIDTH; i = i + 1) begin : simd_lane
            // 算术逻辑单元
            VectorALU #(.DATA_WIDTH(DATA_WIDTH)) alu_inst (
                .a(vec_a[i]),
                .b(vec_b[i]),
                .op(opcode[2:0]),
                .result(alu_out[i])
            );
            
            // 激活函数单元
            ActivationUnit #(.DATA_WIDTH(DATA_WIDTH)) act_inst (
                .data_in(vec_a[i]),
                .func_sel(opcode[4:3]),
                .data_out(act_out[i])
            );
        end
    endgenerate
    
    // 结果选择和流水线控制
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            done <= 0;
        end else if (execute) begin
            case (opcode)
                OP_ADD, OP_SUB, OP_MUL, OP_MAX, OP_MIN: begin
                    for (int j = 0; j < VECTOR_WIDTH; j = j + 1) begin
                        vec_result[j] <= alu_out[j];
                    end
                end
                OP_RELU, OP_SIGM, OP_TANH: begin
                    for (int j = 0; j < VECTOR_WIDTH; j = j + 1) begin
                        vec_result[j] <= act_out[j];
                    end
                end
            endcase
            done <= 1;
        end else begin
            done <= 0;
        end
    end
endmodule
            </div>

            <h4>4.3.2 特殊功能单元</h4>
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>功能单元</th>
                            <th>操作</th>
                            <th>实现方式</th>
                            <th>硬件成本</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>ReLU单元</td>
                            <td>max(0, x)</td>
                            <td>比较器+选择器</td>
                            <td>极低</td>
                        </tr>
                        <tr>
                            <td>池化单元</td>
                            <td>max/avg pooling</td>
                            <td>比较树/加法树</td>
                            <td>低</td>
                        </tr>
                        <tr>
                            <td>LUT单元</td>
                            <td>sigmoid/tanh</td>
                            <td>查找表+插值</td>
                            <td>中等</td>
                        </tr>
                        <tr>
                            <td>归一化单元</td>
                            <td>batch/layer norm</td>
                            <td>乘法器+移位器</td>
                            <td>高</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h3>4.4 特殊计算单元</h3>
            
            <h4>4.4.1 Tensor Core设计</h4>
            <p>Tensor Core是一种执行小矩阵乘法的专用单元，提供更高的计算密度。</p>
            
            <div class="code-block">
// 4x4x4 Tensor Core实现
// 计算 D = A×B + C，其中A、B、C、D都是4×4矩阵
module TensorCore_4x4x4 #(
    parameter DATA_WIDTH = 8,
    parameter ACC_WIDTH = 32
)(
    input wire clk,
    input wire rst_n,
    input wire enable,
    
    // 输入矩阵（扁平化表示）
    input wire [DATA_WIDTH-1:0] mat_a [0:15],  // 4x4矩阵A
    input wire [DATA_WIDTH-1:0] mat_b [0:15],  // 4x4矩阵B
    input wire [ACC_WIDTH-1:0] mat_c [0:15],   // 4x4矩阵C（累加）
    
    // 输出矩阵
    output reg [ACC_WIDTH-1:0] mat_d [0:15],   // 4x4结果矩阵D
    output reg valid
);

    // 内部信号
    wire [ACC_WIDTH-1:0] dot_products [0:15];
    
    // 生成16个点积计算单元
    genvar i, j, k;
    generate
        for (i = 0; i < 4; i = i + 1) begin : row
            for (j = 0; j < 4; j = j + 1) begin : col
                // 计算D[i][j] = sum(A[i][k] * B[k][j]) + C[i][j]
                wire [2*DATA_WIDTH-1:0] products [0:3];
                wire [ACC_WIDTH-1:0] sum;
                
                // 4个并行乘法器
                for (k = 0; k < 4; k = k + 1) begin : mult
                    assign products[k] = mat_a[i*4+k] * mat_b[k*4+j];
                end
                
                // 加法树
                assign sum = mat_c[i*4+j] + 
                           {{(ACC_WIDTH-2*DATA_WIDTH){products[0][2*DATA_WIDTH-1]}}, products[0]} +
                           {{(ACC_WIDTH-2*DATA_WIDTH){products[1][2*DATA_WIDTH-1]}}, products[1]} +
                           {{(ACC_WIDTH-2*DATA_WIDTH){products[2][2*DATA_WIDTH-1]}}, products[2]} +
                           {{(ACC_WIDTH-2*DATA_WIDTH){products[3][2*DATA_WIDTH-1]}}, products[3]};
                
                assign dot_products[i*4+j] = sum;
            end
        end
    endgenerate
    
    // 寄存输出
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            valid <= 0;
        end else if (enable) begin
            for (int idx = 0; idx < 16; idx = idx + 1) begin
                mat_d[idx] <= dot_products[idx];
            end
            valid <= 1;
        end else begin
            valid <= 0;
        end
    end
endmodule
            </div>

            <h4>4.4.2 稀疏计算支持</h4>
            <p>支持结构化稀疏（如2:4稀疏）可以显著提升有效计算吞吐量。</p>
            
            <div class="code-block">
// 2:4结构化稀疏MAC单元
// 每4个权重中有2个非零值
module SparseMACUnit_2in4 #(
    parameter DATA_WIDTH = 8,
    parameter ACC_WIDTH = 32
)(
    input wire clk,
    input wire rst_n,
    input wire enable,
    
    // 稀疏权重输入（2个非零值）
    input wire [DATA_WIDTH-1:0] weight_values [0:1],  // 非零权重值
    input wire [1:0] weight_indices [0:1],            // 权重位置索引(0-3)
    
    // 4个激活值输入
    input wire [DATA_WIDTH-1:0] activations [0:3],
    
    // 累加输入输出
    input wire [ACC_WIDTH-1:0] psum_in,
    output reg [ACC_WIDTH-1:0] psum_out,
    output reg valid
);

    // 选择对应的激活值并计算
    wire [DATA_WIDTH-1:0] selected_acts [0:1];
    wire [2*DATA_WIDTH-1:0] products [0:1];
    wire [ACC_WIDTH-1:0] sum;
    
    // 根据索引选择激活值
    assign selected_acts[0] = activations[weight_indices[0]];
    assign selected_acts[1] = activations[weight_indices[1]];
    
    // 计算两个乘积
    assign products[0] = selected_acts[0] * weight_values[0];
    assign products[1] = selected_acts[1] * weight_values[1];
    
    // 累加
    assign sum = psum_in + 
                {{(ACC_WIDTH-2*DATA_WIDTH){products[0][2*DATA_WIDTH-1]}}, products[0]} +
                {{(ACC_WIDTH-2*DATA_WIDTH){products[1][2*DATA_WIDTH-1]}}, products[1]};
    
    // 寄存输出
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            psum_out <= 0;
            valid <= 0;
        end else if (enable) begin
            psum_out <= sum;
            valid <= 1;
        end else begin
            valid <= 0;
        end
    end
endmodule
            </div>

            <div class="exercise">
                <h4>练习题集 4</h4>
                
                <div class="question">
                    <p><strong>题目4.1：</strong>设计一个支持INT8/INT16混合精度的MAC单元。要求能够处理不同精度的输入组合。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module MixedPrecisionMAC #(
    parameter MAX_WIDTH = 16,      // 最大数据宽度
    parameter ACC_WIDTH = 48       // 累加器宽度（支持INT16×INT16）
)(
    input wire clk,
    input wire rst_n,
    input wire enable,
    
    // 输入数据和精度控制
    input wire [MAX_WIDTH-1:0] a_in,
    input wire [MAX_WIDTH-1:0] b_in,
    input wire [1:0] precision_mode,  // 00: INT8×INT8, 01: INT8×INT16, 10: INT16×INT8, 11: INT16×INT16
    input wire [ACC_WIDTH-1:0] c_in,
    
    // 输出
    output reg [ACC_WIDTH-1:0] c_out,
    output reg valid_out
);

    // 内部信号
    reg signed [MAX_WIDTH-1:0] a_ext, b_ext;
    wire signed [2*MAX_WIDTH-1:0] mult_result;
    wire signed [ACC_WIDTH-1:0] add_result;
    
    // 根据精度模式进行符号扩展
    always @(*) begin
        case (precision_mode)
            2'b00: begin  // INT8 × INT8
                a_ext = {{8{a_in[7]}}, a_in[7:0]};
                b_ext = {{8{b_in[7]}}, b_in[7:0]};
            end
            2'b01: begin  // INT8 × INT16
                a_ext = {{8{a_in[7]}}, a_in[7:0]};
                b_ext = b_in;
            end
            2'b10: begin  // INT16 × INT8
                a_ext = a_in;
                b_ext = {{8{b_in[7]}}, b_in[7:0]};
            end
            2'b11: begin  // INT16 × INT16
                a_ext = a_in;
                b_ext = b_in;
            end
        endcase
    end
    
    // 乘法器（支持最大精度）
    assign mult_result = a_ext * b_ext;
    
    // 累加器
    assign add_result = c_in + {{(ACC_WIDTH-2*MAX_WIDTH){mult_result[2*MAX_WIDTH-1]}}, mult_result};
    
    // 输出寄存
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            c_out <= 0;
            valid_out <= 0;
        end else if (enable) begin
            c_out <= add_result;
            valid_out <= 1;
        end else begin
            valid_out <= 0;
        end
    end
    
    // 功耗优化：根据精度模式门控高位逻辑
    // 实际实现中可以添加时钟门控逻辑
endmodule
                        </div>
                        <p><strong>设计要点：</strong></p>
                        <ul>
                            <li>使用参数化的最大位宽支持多种精度</li>
                            <li>根据精度模式进行正确的符号扩展</li>
                            <li>累加器位宽需要足够大以防止溢出</li>
                            <li>可以通过时钟门控优化低精度模式的功耗</li>
                        </ul>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目4.2：</strong>分析脉动阵列的三种数据流（WS/OS/RS）在执行1×1卷积时的效率差异。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：1×1卷积本质上是矩阵乘法，没有空间维度的滑窗。分析每种数据流在权重复用、激活值复用、部分和累加方面的特点。WS在这种情况下为什么最优？</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p><strong>1×1卷积特点：</strong></p>
                        <ul>
                            <li>没有空间维度的滑动窗口</li>
                            <li>本质上是通道间的线性组合</li>
                            <li>可以完全转化为矩阵乘法</li>
                        </ul>
                        
                        <table>
                            <tr>
                                <th>数据流</th>
                                <th>数据复用</th>
                                <th>带宽需求</th>
                                <th>控制复杂度</th>
                                <th>1×1卷积效率</th>
                            </tr>
                            <tr>
                                <td>Weight Stationary (WS)</td>
                                <td>权重100%复用<br>激活值无复用</td>
                                <td>低（权重预加载）</td>
                                <td>简单</td>
                                <td><strong>最优</strong></td>
                            </tr>
                            <tr>
                                <td>Output Stationary (OS)</td>
                                <td>部分和本地累加<br>权重和激活都需流动</td>
                                <td>高</td>
                                <td>中等</td>
                                <td>较差</td>
                            </tr>
                            <tr>
                                <td>Row Stationary (RS)</td>
                                <td>退化为WS模式</td>
                                <td>低</td>
                                <td>复杂（但退化后简化）</td>
                                <td>等同于WS</td>
                            </tr>
                        </table>
                        
                        <p><strong>定量分析（假设计算1×1×256×256卷积）：</strong></p>
                        <ul>
                            <li><strong>WS模式：</strong>
                                <ul>
                                    <li>权重读取：256×256 = 65,536次（仅一次）</li>
                                    <li>激活值读取：取决于输入特征图大小</li>
                                    <li>部分和写回：每个输出位置一次</li>
                                </ul>
                            </li>
                            <li><strong>OS模式：</strong>
                                <ul>
                                    <li>权重读取：每个空间位置都需要读取所有权重</li>
                                    <li>带宽需求增加H×W倍</li>
                                </ul>
                            </li>
                        </ul>
                        
                        <p><strong>结论：</strong>对于1×1卷积，WS数据流最优，因为可以充分利用权重复用，而没有空间维度的复用需求。</p>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目4.3：</strong>设计一个8×8脉动阵列的控制器，支持矩阵分块计算。输入矩阵可能大于8×8。</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module SystolicArrayController #(
    parameter ARRAY_DIM = 8,
    parameter DATA_WIDTH = 8,
    parameter ADDR_WIDTH = 32,
    parameter ACC_WIDTH = 32
)(
    input wire clk,
    input wire rst_n,
    
    // 配置接口
    input wire [31:0] M, N, K,              // 矩阵维度
    input wire [ADDR_WIDTH-1:0] addr_a,    // 矩阵A基地址
    input wire [ADDR_WIDTH-1:0] addr_b,    // 矩阵B基地址
    input wire [ADDR_WIDTH-1:0] addr_c,    // 矩阵C基地址
    input wire start,
    output reg done,
    
    // 内存接口
    output reg [ADDR_WIDTH-1:0] mem_addr_a,
    output reg [ADDR_WIDTH-1:0] mem_addr_b,
    output reg [ADDR_WIDTH-1:0] mem_addr_c,
    output reg mem_rd_a, mem_rd_b,
    output reg mem_wr_c,
    input wire [DATA_WIDTH*ARRAY_DIM-1:0] mem_data_a,
    input wire [DATA_WIDTH*ARRAY_DIM-1:0] mem_data_b,
    output reg [ACC_WIDTH*ARRAY_DIM-1:0] mem_data_c,
    
    // 脉动阵列接口
    output reg sa_weight_load,
    output reg sa_compute_en,
    output reg [DATA_WIDTH-1:0] sa_act_in [0:ARRAY_DIM-1],
    output reg [DATA_WIDTH-1:0] sa_weight_in [0:ARRAY_DIM-1][0:ARRAY_DIM-1],
    input wire [ACC_WIDTH-1:0] sa_result_out [0:ARRAY_DIM-1]
);

    // 状态机定义
    typedef enum logic [3:0] {
        IDLE,
        CALC_TILES,
        LOAD_WEIGHT,
        INIT_COMPUTE,
        COMPUTE,
        DRAIN,
        STORE_RESULT,
        NEXT_TILE
    } state_t;
    
    state_t state, next_state;
    
    // 分块计算控制
    reg [31:0] tile_m, tile_n, tile_k;     // 当前分块索引
    reg [31:0] num_tiles_m, num_tiles_n, num_tiles_k;
    reg [31:0] compute_cycles;              // 计算周期计数
    reg [31:0] row_offset, col_offset;     // 数据输入偏移
    
    // 计算分块数量
    always @(posedge clk) begin
        if (start) begin
            num_tiles_m <= (M + ARRAY_DIM - 1) / ARRAY_DIM;
            num_tiles_n <= (N + ARRAY_DIM - 1) / ARRAY_DIM;
            num_tiles_k <= (K + ARRAY_DIM - 1) / ARRAY_DIM;
        end
    end
    
    // 状态转换
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n)
            state <= IDLE;
        else
            state <= next_state;
    end
    
    always @(*) begin
        next_state = state;
        case (state)
            IDLE: begin
                if (start)
                    next_state = CALC_TILES;
            end
            
            CALC_TILES: begin
                next_state = LOAD_WEIGHT;
            end
            
            LOAD_WEIGHT: begin
                if (compute_cycles == ARRAY_DIM - 1)
                    next_state = INIT_COMPUTE;
            end
            
            INIT_COMPUTE: begin
                next_state = COMPUTE;
            end
            
            COMPUTE: begin
                // 需要K个周期完成一个K维的点积
                if (compute_cycles == K - 1)
                    next_state = DRAIN;
            end
            
            DRAIN: begin
                // 等待最后的结果流出
                if (compute_cycles == ARRAY_DIM - 1)
                    next_state = STORE_RESULT;
            end
            
            STORE_RESULT: begin
                if (compute_cycles == ARRAY_DIM - 1)
                    next_state = NEXT_TILE;
            end
            
            NEXT_TILE: begin
                if (tile_k < num_tiles_k - 1) begin
                    // 同一输出块的下一个K分块
                    next_state = LOAD_WEIGHT;
                end else if (tile_n < num_tiles_n - 1 || tile_m < num_tiles_m - 1) begin
                    // 下一个输出块
                    next_state = LOAD_WEIGHT;
                end else begin
                    // 完成所有计算
                    next_state = IDLE;
                end
            end
        endcase
    end
    
    // 数据路径控制
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            tile_m <= 0;
            tile_n <= 0;
            tile_k <= 0;
            compute_cycles <= 0;
            done <= 0;
            sa_weight_load <= 0;
            sa_compute_en <= 0;
            mem_rd_a <= 0;
            mem_rd_b <= 0;
            mem_wr_c <= 0;
        end else begin
            case (state)
                IDLE: begin
                    done <= 0;
                    if (start) begin
                        tile_m <= 0;
                        tile_n <= 0;
                        tile_k <= 0;
                    end
                end
                
                LOAD_WEIGHT: begin
                    // 加载权重矩阵B的一个tile
                    sa_weight_load <= 1;
                    mem_rd_b <= 1;
                    mem_addr_b <= addr_b + 
                                 (tile_n * ARRAY_DIM * K + tile_k * ARRAY_DIM) * DATA_WIDTH/8;
                    
                    // 将权重数据分配到阵列
                    // 简化处理：假设数据已正确排列
                    for (int i = 0; i < ARRAY_DIM; i++) begin
                        for (int j = 0; j < ARRAY_DIM; j++) begin
                            sa_weight_in[i][j] <= mem_data_b[(i*ARRAY_DIM+j)*DATA_WIDTH +: DATA_WIDTH];
                        end
                    end
                    
                    compute_cycles <= compute_cycles + 1;
                    if (compute_cycles == ARRAY_DIM - 1) begin
                        compute_cycles <= 0;
                        sa_weight_load <= 0;
                        mem_rd_b <= 0;
                    end
                end
                
                COMPUTE: begin
                    // 流式输入激活值
                    sa_compute_en <= 1;
                    mem_rd_a <= 1;
                    
                    // 计算当前输入地址
                    mem_addr_a <= addr_a + 
                                 ((tile_m * ARRAY_DIM + row_offset) * K + 
                                  tile_k * ARRAY_DIM + col_offset) * DATA_WIDTH/8;
                    
                    // 错开输入时序（脉动阵列需要）
                    for (int i = 0; i < ARRAY_DIM; i++) begin
                        if (compute_cycles >= i && compute_cycles - i < K) begin
                            sa_act_in[i] <= mem_data_a[i*DATA_WIDTH +: DATA_WIDTH];
                        end else begin
                            sa_act_in[i] <= 0;
                        end
                    end
                    
                    compute_cycles <= compute_cycles + 1;
                    col_offset <= col_offset + 1;
                    
                    if (col_offset == ARRAY_DIM - 1) begin
                        col_offset <= 0;
                        row_offset <= row_offset + 1;
                    end
                    
                    if (compute_cycles == K - 1) begin
                        compute_cycles <= 0;
                        row_offset <= 0;
                        col_offset <= 0;
                        sa_compute_en <= 0;
                        mem_rd_a <= 0;
                    end
                end
                
                STORE_RESULT: begin
                    // 存储计算结果
                    mem_wr_c <= 1;
                    mem_addr_c <= addr_c + 
                                 ((tile_m * ARRAY_DIM + compute_cycles) * N + 
                                  tile_n * ARRAY_DIM) * ACC_WIDTH/8;
                    
                    // 收集结果
                    for (int i = 0; i < ARRAY_DIM; i++) begin
                        mem_data_c[i*ACC_WIDTH +: ACC_WIDTH] <= sa_result_out[i];
                    end
                    
                    compute_cycles <= compute_cycles + 1;
                    if (compute_cycles == ARRAY_DIM - 1) begin
                        compute_cycles <= 0;
                        mem_wr_c <= 0;
                    end
                end
                
                NEXT_TILE: begin
                    if (tile_k < num_tiles_k - 1) begin
                        tile_k <= tile_k + 1;
                    end else begin
                        tile_k <= 0;
                        if (tile_n < num_tiles_n - 1) begin
                            tile_n <= tile_n + 1;
                        end else begin
                            tile_n <= 0;
                            tile_m <= tile_m + 1;
                        end
                    end
                    
                    if (tile_m == num_tiles_m - 1 && 
                        tile_n == num_tiles_n - 1 && 
                        tile_k == num_tiles_k - 1) begin
                        done <= 1;
                    end
                end
            endcase
        end
    end
endmodule
                        </div>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目4.4：</strong>设计一个高效的激活函数单元，支持ReLU、Leaky ReLU和Swish。考虑面积和延迟的权衡。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：ReLU只需要符号位判断，Leaky ReLU需要分支选择，Swish需要Sigmoid和乘法。考虑使用查找表（LUT）或分段线性逼近来实现复杂函数。通过多路选择器复用硬件资源。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module EfficientActivationUnit #(
    parameter DATA_WIDTH = 16,
    parameter FRAC_WIDTH = 8    // 小数位宽（定点数）
)(
    input wire clk,
    input wire rst_n,
    input wire enable,
    
    // 输入数据
    input wire signed [DATA_WIDTH-1:0] data_in,
    
    // 功能选择和参数
    input wire [1:0] func_sel,  // 00: ReLU, 01: LeakyReLU, 10: Swish
    input wire [DATA_WIDTH-1:0] alpha,  // LeakyReLU的斜率（定点表示）
    
    // 输出
    output reg signed [DATA_WIDTH-1:0] data_out,
    output reg valid
);

    // 内部信号
    wire is_negative;
    wire signed [DATA_WIDTH-1:0] relu_out;
    wire signed [DATA_WIDTH-1:0] leaky_relu_out;
    wire signed [DATA_WIDTH-1:0] swish_out;
    
    // 负数检测
    assign is_negative = data_in[DATA_WIDTH-1];
    
    // ReLU: max(0, x)
    assign relu_out = is_negative ? {DATA_WIDTH{1'b0}} : data_in;
    
    // Leaky ReLU: x if x > 0, else alpha * x
    wire signed [2*DATA_WIDTH-1:0] alpha_mult;
    assign alpha_mult = data_in * alpha;
    assign leaky_relu_out = is_negative ? 
                           alpha_mult[DATA_WIDTH+FRAC_WIDTH-1:FRAC_WIDTH] : 
                           data_in;
    
    // Swish: x * sigmoid(x)
    // 使用分段线性逼近sigmoid
    wire signed [DATA_WIDTH-1:0] sigmoid_approx;
    SwishLUT #(
        .DATA_WIDTH(DATA_WIDTH),
        .FRAC_WIDTH(FRAC_WIDTH)
    ) swish_lut (
        .x(data_in),
        .sigmoid_x(sigmoid_approx)
    );
    
    wire signed [2*DATA_WIDTH-1:0] swish_mult;
    assign swish_mult = data_in * sigmoid_approx;
    assign swish_out = swish_mult[DATA_WIDTH+FRAC_WIDTH-1:FRAC_WIDTH];
    
    // 输出选择（组合逻辑，最小化延迟）
    always @(*) begin
        case (func_sel)
            2'b00: data_out = relu_out;
            2'b01: data_out = leaky_relu_out;
            2'b10: data_out = swish_out;
            default: data_out = data_in;  // 直通
        endcase
    end
    
    // 有效信号生成
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            valid <= 0;
        end else begin
            valid <= enable;
        end
    end
endmodule

// Swish激活函数的LUT实现
module SwishLUT #(
    parameter DATA_WIDTH = 16,
    parameter FRAC_WIDTH = 8,
    parameter LUT_DEPTH = 256  // LUT条目数
)(
    input wire signed [DATA_WIDTH-1:0] x,
    output reg signed [DATA_WIDTH-1:0] sigmoid_x
);

    // 定义查找表（实际中由工具生成）
    reg signed [DATA_WIDTH-1:0] lut_table [0:LUT_DEPTH-1];
    
    // LUT初始化（sigmoid函数的采样点）
    initial begin
        // 覆盖范围 [-8, 8]，均匀采样
        for (int i = 0; i < LUT_DEPTH; i++) begin
            real x_real = -8.0 + 16.0 * i / (LUT_DEPTH - 1);
            real sigmoid_real = 1.0 / (1.0 + $exp(-x_real));
            lut_table[i] = sigmoid_real * (1 << FRAC_WIDTH);
        end
    end
    
    // 地址计算和查表
    wire [7:0] lut_addr;
    wire signed [DATA_WIDTH-1:0] x_saturated;
    
    // 饱和到[-8, 8]范围
    assign x_saturated = (x > (8 << FRAC_WIDTH)) ? (8 << FRAC_WIDTH) :
                        (x < (-8 << FRAC_WIDTH)) ? (-8 << FRAC_WIDTH) : x;
    
    // 映射到LUT地址
    assign lut_addr = ((x_saturated + (8 << FRAC_WIDTH)) * LUT_DEPTH) >> (FRAC_WIDTH + 4);
    
    // 查表（可以添加线性插值以提高精度）
    always @(*) begin
        sigmoid_x = lut_table[lut_addr];
    end
endmodule
                        </div>
                        <p><strong>设计权衡分析：</strong></p>
                        <table>
                            <tr>
                                <th>激活函数</th>
                                <th>硬件成本</th>
                                <th>延迟</th>
                                <th>精度</th>
                            </tr>
                            <tr>
                                <td>ReLU</td>
                                <td>极低（1个比较器）</td>
                                <td>0延迟</td>
                                <td>精确</td>
                            </tr>
                            <tr>
                                <td>Leaky ReLU</td>
                                <td>低（1个乘法器）</td>
                                <td>1个乘法延迟</td>
                                <td>取决于alpha精度</td>
                            </tr>
                            <tr>
                                <td>Swish</td>
                                <td>中等（LUT+乘法器）</td>
                                <td>查表+乘法延迟</td>
                                <td>取决于LUT大小</td>
                            </tr>
                        </table>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目4.5：</strong>分析Tensor Core相比传统脉动阵列在执行批量矩阵乘法(Batched GEMM)时的优势。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：Tensor Core以4×4×4或更大的矩阵块为计算单位。分析批处理时的数据复用率、带宽需求、调度开销。考虑不同batch size对性能的影响。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p><strong>批量矩阵乘法场景：</strong>计算C[i] = A[i] × B[i]，其中i = 0...batch_size-1</p>
                        
                        <p><strong>1. 传统脉动阵列处理方式：</strong></p>
                        <ul>
                            <li>串行处理：依次计算每个矩阵乘法</li>
                            <li>时间复杂度：O(batch_size × 矩阵乘法时间)</li>
                            <li>无法利用batch维度的并行性</li>
                        </ul>
                        
                        <p><strong>2. Tensor Core优势：</strong></p>
                        <table>
                            <tr>
                                <th>方面</th>
                                <th>传统脉动阵列</th>
                                <th>Tensor Core</th>
                                <th>优势倍数</th>
                            </tr>
                            <tr>
                                <td>基本运算粒度</td>
                                <td>标量MAC</td>
                                <td>4×4×4矩阵乘法</td>
                                <td>64×</td>
                            </tr>
                            <tr>
                                <td>批处理能力</td>
                                <td>串行</td>
                                <td>可并行多个小矩阵</td>
                                <td>与batch size相关</td>
                            </tr>
                            <tr>
                                <td>数据重排开销</td>
                                <td>需要外部重排</td>
                                <td>硬件原生支持</td>
                                <td>-</td>
                            </tr>
                            <tr>
                                <td>寄存器利用率</td>
                                <td>~50%</td>
                                <td>~90%</td>
                                <td>1.8×</td>
                            </tr>
                        </table>
                        
                        <p><strong>3. 具体示例（Transformer注意力计算）：</strong></p>
                        <div class="code-block">
// Transformer中的批量矩阵乘法
// Q, K, V: [batch_size, seq_len, d_model]
// 需要计算：Attention = softmax(Q × K^T) × V

// 传统脉动阵列：
for (batch = 0; batch < batch_size; batch++) {
    // 计算 Q[batch] × K[batch]^T
    systolic_array_compute(Q[batch], K[batch].T);
    // 等待完成...
}
// 总时间：batch_size × (seq_len × seq_len × d_model)

// Tensor Core：
// 可以将多个batch的小块同时映射到不同的Tensor Core
for (batch_group = 0; batch_group < batch_size; batch_group += 4) {
    // 4个batch并行计算
    tensor_core_batch_compute(Q[batch_group:batch_group+4], 
                            K[batch_group:batch_group+4].T);
}
// 总时间：(batch_size/4) × (seq_len × seq_len × d_model) / 64
                        </div>
                        
                        <p><strong>4. 性能提升分析：</strong></p>
                        <ul>
                            <li>理论加速比：最高可达 4× (batch并行) × 64× (Tensor Core加速) = 256×</li>
                            <li>实际加速比：考虑内存带宽限制，通常为10-50×</li>
                            <li>功耗效率提升：3-5×（更少的数据移动）</li>
                        </ul>
                        
                        <p><strong>5. 适用条件：</strong></p>
                        <ul>
                            <li>矩阵尺寸是4的倍数</li>
                            <li>Batch size较大（≥4）</li>
                            <li>支持的数据精度（通常是FP16/INT8混合）</li>
                        </ul>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目4.6：</strong>设计一个支持动态稀疏的MAC阵列。要求能够跳过零权重和零激活值的计算。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：零检测电路、非零元素索引存储、动态调度器将非零数据分配给MAC单元。考虑使用压缩稀疏表示（CSR/CSC）。注意调度开销可能抵消稀疏性带来的好处。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module DynamicSparseMACArray #(
    parameter DATA_WIDTH = 8,
    parameter ACC_WIDTH = 32,
    parameter PE_NUM = 16,        // PE数量
    parameter FIFO_DEPTH = 8      // 输入FIFO深度
)(
    input wire clk,
    input wire rst_n,
    input wire enable,
    
    // 稀疏数据输入（压缩格式）
    input wire [DATA_WIDTH-1:0] act_values [0:PE_NUM-1],      // 非零激活值
    input wire [4:0] act_indices [0:PE_NUM-1],                // 激活值索引
    input wire [PE_NUM-1:0] act_valid,                        // 激活值有效标志
    
    input wire [DATA_WIDTH-1:0] weight_values [0:PE_NUM-1],   // 非零权重
    input wire [4:0] weight_indices [0:PE_NUM-1],             // 权重索引
    input wire [PE_NUM-1:0] weight_valid,                     // 权重有效标志
    
    // 输出接口
    output reg [ACC_WIDTH-1:0] results [0:PE_NUM-1],
    output reg [PE_NUM-1:0] result_valid,
    output reg done
);

    // PE阵列
    genvar i;
    generate
        for (i = 0; i < PE_NUM; i = i + 1) begin : sparse_pe
            SparsePE #(
                .DATA_WIDTH(DATA_WIDTH),
                .ACC_WIDTH(ACC_WIDTH),
                .FIFO_DEPTH(FIFO_DEPTH)
            ) pe_inst (
                .clk(clk),
                .rst_n(rst_n),
                .enable(enable),
                .act_value(act_values[i]),
                .act_index(act_indices[i]),
                .act_valid(act_valid[i]),
                .weight_value(weight_values[i]),
                .weight_index(weight_indices[i]),
                .weight_valid(weight_valid[i]),
                .result(results[i]),
                .result_valid(result_valid[i])
            );
        end
    endgenerate
    
    // 完成信号生成
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            done <= 0;
        end else begin
            done <= &result_valid;  // 所有PE完成
        end
    end
endmodule

// 稀疏PE单元
module SparsePE #(
    parameter DATA_WIDTH = 8,
    parameter ACC_WIDTH = 32,
    parameter FIFO_DEPTH = 8
)(
    input wire clk,
    input wire rst_n,
    input wire enable,
    
    // 稀疏输入
    input wire [DATA_WIDTH-1:0] act_value,
    input wire [4:0] act_index,
    input wire act_valid,
    
    input wire [DATA_WIDTH-1:0] weight_value,
    input wire [4:0] weight_index,
    input wire weight_valid,
    
    // 输出
    output reg [ACC_WIDTH-1:0] result,
    output reg result_valid
);

    // 输入FIFO
    reg [DATA_WIDTH-1:0] act_fifo_data [0:FIFO_DEPTH-1];
    reg [4:0] act_fifo_index [0:FIFO_DEPTH-1];
    reg [DATA_WIDTH-1:0] weight_fifo_data [0:FIFO_DEPTH-1];
    reg [4:0] weight_fifo_index [0:FIFO_DEPTH-1];
    
    reg [2:0] act_wr_ptr, act_rd_ptr;
    reg [2:0] weight_wr_ptr, weight_rd_ptr;
    reg [3:0] act_count, weight_count;
    
    // 匹配逻辑
    wire index_match;
    wire compute_valid;
    
    assign index_match = (act_fifo_index[act_rd_ptr] == weight_fifo_index[weight_rd_ptr]);
    assign compute_valid = (act_count > 0) && (weight_count > 0) && index_match;
    
    // MAC计算
    wire signed [2*DATA_WIDTH-1:0] mult_result;
    wire signed [ACC_WIDTH-1:0] acc_result;
    
    assign mult_result = act_fifo_data[act_rd_ptr] * weight_fifo_data[weight_rd_ptr];
    assign acc_result = result + {{(ACC_WIDTH-2*DATA_WIDTH){mult_result[2*DATA_WIDTH-1]}}, mult_result};
    
    // FIFO写入逻辑
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            act_wr_ptr <= 0;
            weight_wr_ptr <= 0;
            act_count <= 0;
            weight_count <= 0;
        end else if (enable) begin
            // 激活值FIFO写入
            if (act_valid && act_count < FIFO_DEPTH) begin
                act_fifo_data[act_wr_ptr] <= act_value;
                act_fifo_index[act_wr_ptr] <= act_index;
                act_wr_ptr <= act_wr_ptr + 1;
                act_count <= act_count + 1;
            end
            
            // 权重FIFO写入
            if (weight_valid && weight_count < FIFO_DEPTH) begin
                weight_fifo_data[weight_wr_ptr] <= weight_value;
                weight_fifo_index[weight_wr_ptr] <= weight_index;
                weight_wr_ptr <= weight_wr_ptr + 1;
                weight_count <= weight_count + 1;
            end
        end
    end
    
    // 计算和FIFO读取逻辑
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            result <= 0;
            result_valid <= 0;
            act_rd_ptr <= 0;
            weight_rd_ptr <= 0;
        end else if (enable) begin
            if (compute_valid) begin
                // 执行MAC运算
                result <= acc_result;
                
                // 更新读指针
                act_rd_ptr <= act_rd_ptr + 1;
                weight_rd_ptr <= weight_rd_ptr + 1;
                act_count <= act_count - 1;
                weight_count <= weight_count - 1;
            end else if (act_count > 0 && weight_count > 0) begin
                // 索引不匹配，跳过较小的索引
                if (act_fifo_index[act_rd_ptr] < weight_fifo_index[weight_rd_ptr]) begin
                    act_rd_ptr <= act_rd_ptr + 1;
                    act_count <= act_count - 1;
                end else begin
                    weight_rd_ptr <= weight_rd_ptr + 1;
                    weight_count <= weight_count - 1;
                end
            end
            
            // 生成完成信号
            result_valid <= (act_count == 0) || (weight_count == 0);
        end
    end
endmodule
                        </div>
                        <p><strong>设计特点：</strong></p>
                        <ul>
                            <li>使用FIFO缓存稀疏数据，解耦输入和计算</li>
                            <li>索引匹配逻辑，只计算索引相同的元素</li>
                            <li>支持不同稀疏度的激活值和权重</li>
                            <li>自动跳过不匹配的索引，提高效率</li>
                        </ul>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目4.7：</strong>优化一个16×16脉动阵列的时钟分配网络，考虑时钟偏斜和功耗。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：脉动阵列中数据流动方向要求特定的时钟关系。考虑H树、fishbone等时钟网络拓扑。使用时钟门控降低动态功耗。平衡skew和useful skew的关系。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p><strong>1. 时钟网络挑战：</strong></p>
                        <ul>
                            <li>16×16 = 256个PE，每个PE需要同步时钟</li>
                            <li>时钟偏斜影响最高工作频率</li>
                            <li>时钟网络功耗占总功耗的20-30%</li>
                        </ul>
                        
                        <p><strong>2. H-Tree时钟分配设计：</strong></p>
                        <div class="code-block">
module ClockTreeOptimized_16x16 (
    input wire clk_in,
    input wire [255:0] clock_enable,  // 每个PE的时钟使能
    output wire clk_out [0:15][0:15]  // 分配到每个PE的时钟
);

    // H-Tree层次结构
    // Level 0: 根节点
    wire clk_l0;
    ClockBuffer #(.DRIVE_STRENGTH(16)) buf_l0 (
        .clk_in(clk_in),
        .clk_out(clk_l0)
    );
    
    // Level 1: 4个象限
    wire clk_l1 [0:3];
    genvar q;
    generate
        for (q = 0; q < 4; q = q + 1) begin : quadrant
            ClockBuffer #(.DRIVE_STRENGTH(8)) buf_l1 (
                .clk_in(clk_l0),
                .clk_out(clk_l1[q])
            );
        end
    endgenerate
    
    // Level 2: 16个区域（4×4）
    wire clk_l2 [0:3][0:3];
    genvar i, j;
    generate
        for (i = 0; i < 2; i = i + 1) begin
            for (j = 0; j < 2; j = j + 1) begin
                ClockBuffer #(.DRIVE_STRENGTH(4)) buf_l2_q0 (
                    .clk_in(clk_l1[0]),
                    .clk_out(clk_l2[i][j])
                );
                // 类似处理其他象限...
            end
        end
    endgenerate
    
    // Level 3: 叶节点（带时钟门控）
    generate
        for (i = 0; i < 16; i = i + 1) begin : row
            for (j = 0; j < 16; j = j + 1) begin : col
                ClockGatingCell cgc (
                    .clk_in(clk_l2[i/4][j/4]),
                    .enable(clock_enable[i*16+j]),
                    .clk_out(clk_out[i][j])
                );
            end
        end
    endgenerate
endmodule

// 低偏斜时钟缓冲器
module ClockBuffer #(
    parameter DRIVE_STRENGTH = 1
) (
    input wire clk_in,
    output wire clk_out
);
    // 使用对称的缓冲器链
    wire [DRIVE_STRENGTH-1:0] buf_chain;
    
    assign buf_chain[0] = clk_in;
    genvar k;
    generate
        for (k = 1; k < DRIVE_STRENGTH; k = k + 1) begin
            // 渐进式增大驱动能力
            buf #(.size(2**k)) buffer_inst (
                .in(buf_chain[k-1]),
                .out(buf_chain[k])
            );
        end
    endgenerate
    
    assign clk_out = buf_chain[DRIVE_STRENGTH-1];
endmodule

// 集成时钟门控单元
module ClockGatingCell (
    input wire clk_in,
    input wire enable,
    output wire clk_out
);
    reg enable_latch;
    
    // 锁存使能信号（避免毛刺）
    always @(clk_in or enable) begin
        if (!clk_in)
            enable_latch <= enable;
    end
    
    // AND门输出门控时钟
    assign clk_out = clk_in & enable_latch;
endmodule
                        </div>
                        
                        <p><strong>3. 优化技术：</strong></p>
                        <table>
                            <tr>
                                <th>技术</th>
                                <th>原理</th>
                                <th>效果</th>
                                <th>成本</th>
                            </tr>
                            <tr>
                                <td>H-Tree拓扑</td>
                                <td>对称分支，等长路径</td>
                                <td>偏斜<10ps</td>
                                <td>布线资源多</td>
                            </tr>
                            <tr>
                                <td>细粒度时钟门控</td>
                                <td>PE级别关断</td>
                                <td>功耗降低40%</td>
                                <td>控制复杂</td>
                            </tr>
                            <tr>
                                <td>多级缓冲</td>
                                <td>逐级放大驱动</td>
                                <td>转换时间优化</td>
                                <td>面积增加</td>
                            </tr>
                            <tr>
                                <td>局部时钟域</td>
                                <td>分区异步</td>
                                <td>降低全局偏斜</td>
                                <td>同步开销</td>
                            </tr>
                        </table>
                        
                        <p><strong>4. 实施建议：</strong></p>
                        <ul>
                            <li>使用专用时钟布线层，减少干扰</li>
                            <li>在每个分支点放置去耦电容</li>
                            <li>考虑工艺偏差，预留时序裕量</li>
                            <li>支持动态频率调节（DVFS）</li>
                        </ul>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目4.8：</strong>比较不同MAC阵列规模（8×8、16×16、32×32）的设计权衡，给出选择建议。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：从面积、功耗、利用率、布线复杂度、内存带宽需求等多个维度分析。考虑不同应用场景（云端/边缘）和工作负载特征对阵列规模的要求。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <table>
                            <tr>
                                <th>指标</th>
                                <th>8×8阵列</th>
                                <th>16×16阵列</th>
                                <th>32×32阵列</th>
                            </tr>
                            <tr>
                                <td>MAC单元数</td>
                                <td>64</td>
                                <td>256</td>
                                <td>1024</td>
                            </tr>
                            <tr>
                                <td>峰值算力(相对)</td>
                                <td>1×</td>
                                <td>4×</td>
                                <td>16×</td>
                            </tr>
                            <tr>
                                <td>面积(相对)</td>
                                <td>1×</td>
                                <td>~4.5×</td>
                                <td>~20×</td>
                            </tr>
                            <tr>
                                <td>功耗(相对)</td>
                                <td>1×</td>
                                <td>~4.2×</td>
                                <td>~18×</td>
                            </tr>
                            <tr>
                                <td>片上SRAM需求</td>
                                <td>64KB</td>
                                <td>256KB</td>
                                <td>1MB+</td>
                            </tr>
                            <tr>
                                <td>带宽需求</td>
                                <td>64GB/s</td>
                                <td>256GB/s</td>
                                <td>1TB/s</td>
                            </tr>
                            <tr>
                                <td>控制复杂度</td>
                                <td>低</td>
                                <td>中</td>
                                <td>高</td>
                            </tr>
                            <tr>
                                <td>时钟分配难度</td>
                                <td>简单</td>
                                <td>适中</td>
                                <td>困难</td>
                            </tr>
                            <tr>
                                <td>利用率(典型)</td>
                                <td>85%</td>
                                <td>75%</td>
                                <td>60%</td>
                            </tr>
                        </table>
                        
                        <p><strong>设计权衡分析：</strong></p>
                        
                        <p><strong>1. 8×8阵列：</strong></p>
                        <ul>
                            <li><strong>优势：</strong>
                                <ul>
                                    <li>控制简单，易于实现</li>
                                    <li>利用率高，适合小矩阵</li>
                                    <li>功耗密度低，散热容易</li>
                                </ul>
                            </li>
                            <li><strong>劣势：</strong>
                                <ul>
                                    <li>绝对性能有限</li>
                                    <li>大矩阵需要多次分块</li>
                                </ul>
                            </li>
                            <li><strong>适用场景：</strong>边缘设备、低功耗应用</li>
                        </ul>
                        
                        <p><strong>2. 16×16阵列：</strong></p>
                        <ul>
                            <li><strong>优势：</strong>
                                <ul>
                                    <li>性能功耗比最优</li>
                                    <li>适配主流网络的层大小</li>
                                    <li>设计复杂度可控</li>
                                </ul>
                            </li>
                            <li><strong>劣势：</strong>
                                <ul>
                                    <li>需要更复杂的数据调度</li>
                                </ul>
                            </li>
                            <li><strong>适用场景：</strong>主流推理加速器</li>
                        </ul>
                        
                        <p><strong>3. 32×32阵列：</strong></p>
                        <ul>
                            <li><strong>优势：</strong>
                                <ul>
                                    <li>峰值性能高</li>
                                    <li>大矩阵效率好</li>
                                </ul>
                            </li>
                            <li><strong>劣势：</strong>
                                <ul>
                                    <li>面积开销呈超线性增长</li>
                                    <li>带宽墙问题严重</li>
                                    <li>小矩阵利用率低</li>
                                    <li>时序收敛困难</li>
                                </ul>
                            </li>
                            <li><strong>适用场景：</strong>高端服务器、特定大模型</li>
                        </ul>
                        
                        <p><strong>选择建议：</strong></p>
                        <ol>
                            <li><strong>边缘推理：</strong>8×8，功耗优先</li>
                            <li><strong>移动端NPU：</strong>8×8或16×16，平衡性能功耗</li>
                            <li><strong>数据中心推理：</strong>16×16多核，可扩展性好</li>
                            <li><strong>训练加速器：</strong>32×32或更大，性能优先</li>
                        </ol>
                        
                        <p><strong>未来趋势：</strong>多个中等规模阵列（16×16）+ 灵活互联 > 单个超大阵列</p>
                    </div>
                </div>
            </div>
            
            <h3>4.5 Transformer专用计算核心</h3>
            
            <p>Transformer模型的计算特征与CNN显著不同，需要专门优化的计算核心设计。本节探讨针对Transformer优化的硬件计算单元。</p>
            
            <h4>4.5.1 注意力计算引擎</h4>
            <p>自注意力机制是Transformer的核心，其计算包含矩阵乘法、Softmax和缩放等操作：</p>
            
            <div class="code-block">
// 统一的注意力计算引擎
module AttentionEngine #(
    parameter SEQ_LEN = 512,
    parameter D_MODEL = 768,
    parameter NUM_HEADS = 12,
    parameter PE_ARRAY_SIZE = 16
)(
    input wire clk,
    input wire rst_n,
    
    // 控制接口
    input wire [2:0] compute_phase,  // 0:QK 1:Softmax 2:PV
    input wire start,
    
    // 数据输入
    input wire [15:0] q_input [PE_ARRAY_SIZE-1:0],
    input wire [15:0] k_input [PE_ARRAY_SIZE-1:0],
    input wire [15:0] v_input [PE_ARRAY_SIZE-1:0],
    input wire input_valid,
    
    // 输出
    output reg [15:0] attention_output [PE_ARRAY_SIZE-1:0],
    output reg output_valid,
    output reg done
);
    
    localparam D_HEAD = D_MODEL / NUM_HEADS;
    
    // 内部PE阵列（可重构）
    wire [15:0] pe_outputs [PE_ARRAY_SIZE-1:0][PE_ARRAY_SIZE-1:0];
    reg [2:0] pe_mode;
    
    // 可重构PE阵列
    genvar i, j;
    generate
        for (i = 0; i < PE_ARRAY_SIZE; i = i + 1) begin : row
            for (j = 0; j < PE_ARRAY_SIZE; j = j + 1) begin : col
                FlexiblePE #(
                    .DATA_WIDTH(16)
                ) pe_inst (
                    .clk(clk),
                    .rst_n(rst_n),
                    .mode(pe_mode),
                    .a_in(q_input[i]),
                    .b_in(k_input[j]),
                    .c_in(v_input[j]),
                    .result(pe_outputs[i][j])
                );
            end
        end
    endgenerate
    
    // Softmax专用单元
    reg [15:0] softmax_input [PE_ARRAY_SIZE-1:0];
    wire [15:0] softmax_output [PE_ARRAY_SIZE-1:0];
    wire softmax_done;
    
    StreamingSoftmax #(
        .VECTOR_SIZE(PE_ARRAY_SIZE),
        .DATA_WIDTH(16)
    ) softmax_unit (
        .clk(clk),
        .rst_n(rst_n),
        .enable(compute_phase == 3'b001),
        .input_vector(softmax_input),
        .output_vector(softmax_output),
        .done(softmax_done)
    );
    
    // 缩放因子计算
    reg [15:0] scale_factor;
    always @(posedge clk) begin
        // scale = 1/sqrt(d_k)
        scale_factor <= 16'h0200;  // 示例值，实际需要根据D_HEAD计算
    end
    
    // 计算状态机
    reg [3:0] state;
    localparam IDLE = 4'd0;
    localparam QK_COMPUTE = 4'd1;
    localparam QK_SCALE = 4'd2;
    localparam SOFTMAX = 4'd3;
    localparam PV_COMPUTE = 4'd4;
    localparam OUTPUT = 4'd5;
    
    always @(posedge clk) begin
        if (!rst_n) begin
            state <= IDLE;
            done <= 1'b0;
        end else begin
            case (state)
                IDLE: begin
                    if (start) begin
                        case (compute_phase)
                            3'b000: state <= QK_COMPUTE;
                            3'b001: state <= SOFTMAX;
                            3'b010: state <= PV_COMPUTE;
                        endcase
                        done <= 1'b0;
                    end
                end
                
                QK_COMPUTE: begin
                    pe_mode <= 3'b000;  // 矩阵乘法模式
                    if (/* QK计算完成 */) begin
                        state <= QK_SCALE;
                    end
                end
                
                QK_SCALE: begin
                    // 应用缩放因子
                    for (int i = 0; i < PE_ARRAY_SIZE; i++) begin
                        for (int j = 0; j < PE_ARRAY_SIZE; j++) begin
                            softmax_input[j] <= pe_outputs[i][j] >> 3; // 简化的缩放
                        end
                    end
                    state <= SOFTMAX;
                end
                
                SOFTMAX: begin
                    if (softmax_done) begin
                        state <= PV_COMPUTE;
                    end
                end
                
                PV_COMPUTE: begin
                    pe_mode <= 3'b001;  // 加权求和模式
                    if (/* PV计算完成 */) begin
                        state <= OUTPUT;
                    end
                end
                
                OUTPUT: begin
                    done <= 1'b1;
                    state <= IDLE;
                end
            endcase
        end
    end
endmodule

// 流式Softmax实现
module StreamingSoftmax #(
    parameter VECTOR_SIZE = 16,
    parameter DATA_WIDTH = 16
)(
    input wire clk,
    input wire rst_n,
    input wire enable,
    
    input wire [DATA_WIDTH-1:0] input_vector [VECTOR_SIZE-1:0],
    output reg [DATA_WIDTH-1:0] output_vector [VECTOR_SIZE-1:0],
    output reg done
);
    
    // 两遍扫描实现
    reg [2:0] state;
    localparam FIND_MAX = 3'd0;
    localparam COMPUTE_EXP = 3'd1;
    localparam SUM_EXP = 3'd2;
    localparam NORMALIZE = 3'd3;
    localparam DONE = 3'd4;
    
    reg [DATA_WIDTH-1:0] max_value;
    reg [DATA_WIDTH+7:0] exp_sum;  // 扩展位宽防止溢出
    reg [DATA_WIDTH-1:0] exp_values [VECTOR_SIZE-1:0];
    
    // 指数函数近似（查找表）
    wire [DATA_WIDTH-1:0] exp_result [VECTOR_SIZE-1:0];
    genvar i;
    generate
        for (i = 0; i < VECTOR_SIZE; i = i + 1) begin : exp_units
            ExpApprox #(
                .DATA_WIDTH(DATA_WIDTH)
            ) exp_inst (
                .x(input_vector[i] - max_value),
                .exp_x(exp_result[i])
            );
        end
    endgenerate
    
    integer idx;
    always @(posedge clk) begin
        if (!rst_n) begin
            state <= FIND_MAX;
            done <= 1'b0;
        end else if (enable) begin
            case (state)
                FIND_MAX: begin
                    // 找最大值
                    max_value = input_vector[0];
                    for (idx = 1; idx < VECTOR_SIZE; idx = idx + 1) begin
                        if (input_vector[idx] > max_value) begin
                            max_value = input_vector[idx];
                        end
                    end
                    state <= COMPUTE_EXP;
                end
                
                COMPUTE_EXP: begin
                    // 计算exp(x - max)
                    for (idx = 0; idx < VECTOR_SIZE; idx = idx + 1) begin
                        exp_values[idx] <= exp_result[idx];
                    end
                    state <= SUM_EXP;
                end
                
                SUM_EXP: begin
                    // 求和
                    exp_sum = 0;
                    for (idx = 0; idx < VECTOR_SIZE; idx = idx + 1) begin
                        exp_sum = exp_sum + exp_values[idx];
                    end
                    state <= NORMALIZE;
                end
                
                NORMALIZE: begin
                    // 归一化
                    for (idx = 0; idx < VECTOR_SIZE; idx = idx + 1) begin
                        output_vector[idx] <= (exp_values[idx] << 8) / exp_sum[DATA_WIDTH+7:8];
                    end
                    state <= DONE;
                end
                
                DONE: begin
                    done <= 1'b1;
                    state <= FIND_MAX;
                end
            endcase
        end
    end
endmodule
            </div>
            
            <h4>4.5.2 多头并行处理单元</h4>
            <p>多头注意力的并行性为硬件加速提供了机会：</p>
            
            <div class="info-box">
                <p><strong>多头并行策略：</strong></p>
                <ul>
                    <li><strong>头间并行：</strong>不同注意力头完全独立计算</li>
                    <li><strong>头内并行：</strong>每个头内的矩阵运算并行化</li>
                    <li><strong>批间并行：</strong>不同批次样本的并行处理</li>
                    <li><strong>序列并行：</strong>长序列分段并行计算</li>
                </ul>
            </div>
            
            <div class="code-block">
// 多头注意力并行处理器
module MultiHeadProcessor #(
    parameter NUM_HEADS = 12,
    parameter D_MODEL = 768,
    parameter SEQ_LEN = 512,
    parameter HEAD_PE_SIZE = 8  // 每个头的PE阵列大小
)(
    input wire clk,
    input wire rst_n,
    
    // 输入数据
    input wire [15:0] q_matrix [SEQ_LEN-1:0][D_MODEL-1:0],
    input wire [15:0] k_matrix [SEQ_LEN-1:0][D_MODEL-1:0],
    input wire [15:0] v_matrix [SEQ_LEN-1:0][D_MODEL-1:0],
    input wire start,
    
    // 输出
    output reg [15:0] output_matrix [SEQ_LEN-1:0][D_MODEL-1:0],
    output reg done
);
    
    localparam D_HEAD = D_MODEL / NUM_HEADS;
    
    // 投影权重（实际应从外部加载）
    reg [15:0] w_q [NUM_HEADS-1:0][D_MODEL-1:0][D_HEAD-1:0];
    reg [15:0] w_k [NUM_HEADS-1:0][D_MODEL-1:0][D_HEAD-1:0];
    reg [15:0] w_v [NUM_HEADS-1:0][D_MODEL-1:0][D_HEAD-1:0];
    reg [15:0] w_o [D_MODEL-1:0][D_MODEL-1:0];
    
    // 每个头的计算状态
    wire head_done [NUM_HEADS-1:0];
    wire [15:0] head_output [NUM_HEADS-1:0][SEQ_LEN-1:0][D_HEAD-1:0];
    
    // 并行实例化注意力头
    genvar h;
    generate
        for (h = 0; h < NUM_HEADS; h = h + 1) begin : heads
            AttentionHead #(
                .SEQ_LEN(SEQ_LEN),
                .D_HEAD(D_HEAD),
                .PE_SIZE(HEAD_PE_SIZE)
            ) head_inst (
                .clk(clk),
                .rst_n(rst_n),
                .start(start),
                
                // 投影后的输入
                .q_head(/* 投影后的Q */),
                .k_head(/* 投影后的K */),
                .v_head(/* 投影后的V */),
                
                .output(head_output[h]),
                .done(head_done[h])
            );
        end
    endgenerate
    
    // 输出投影和拼接
    reg [2:0] output_state;
    reg [NUM_HEADS-1:0] heads_complete;
    
    always @(posedge clk) begin
        if (!rst_n) begin
            output_state <= 3'b000;
            done <= 1'b0;
        end else begin
            case (output_state)
                3'b000: begin  // 等待所有头完成
                    heads_complete <= {head_done[NUM_HEADS-1:0]};
                    if (&heads_complete) begin
                        output_state <= 3'b001;
                    end
                end
                
                3'b001: begin  // 拼接各头输出
                    for (int s = 0; s < SEQ_LEN; s++) begin
                        for (int h = 0; h < NUM_HEADS; h++) begin
                            for (int d = 0; d < D_HEAD; d++) begin
                                output_matrix[s][h*D_HEAD + d] <= head_output[h][s][d];
                            end
                        end
                    end
                    output_state <= 3'b010;
                end
                
                3'b010: begin  // 输出投影
                    // 实际需要矩阵乘法，这里简化
                    done <= 1'b1;
                    output_state <= 3'b000;
                end
            endcase
        end
    end
endmodule
            </div>
            
            <h4>4.5.3 位置编码处理单元</h4>
            <p>高效的位置编码计算对Transformer性能至关重要：</p>
            
            <div class="code-block">
// 旋转位置编码（RoPE）处理单元
module RoPEUnit #(
    parameter MAX_SEQ_LEN = 2048,
    parameter D_MODEL = 768,
    parameter DATA_WIDTH = 16
)(
    input wire clk,
    input wire rst_n,
    
    // 输入
    input wire [DATA_WIDTH-1:0] q_in [D_MODEL-1:0],
    input wire [DATA_WIDTH-1:0] k_in [D_MODEL-1:0],
    input wire [10:0] position,  // 当前位置
    input wire enable,
    
    // 输出
    output reg [DATA_WIDTH-1:0] q_out [D_MODEL-1:0],
    output reg [DATA_WIDTH-1:0] k_out [D_MODEL-1:0],
    output reg done
);
    
    // 预计算的sin/cos表（实际应使用ROM）
    reg [DATA_WIDTH-1:0] sin_table [MAX_SEQ_LEN-1:0][D_MODEL/2-1:0];
    reg [DATA_WIDTH-1:0] cos_table [MAX_SEQ_LEN-1:0][D_MODEL/2-1:0];
    
    // 复数乘法单元
    reg [DATA_WIDTH-1:0] real_part, imag_part;
    reg [DATA_WIDTH-1:0] cos_theta, sin_theta;
    
    // 2D旋转计算
    // [cos θ  -sin θ] [x]   [x cos θ - y sin θ]
    // [sin θ   cos θ] [y] = [x sin θ + y cos θ]
    
    integer i;
    always @(posedge clk) begin
        if (!rst_n) begin
            done <= 1'b0;
        end else if (enable) begin
            // 并行处理所有维度对
            for (i = 0; i < D_MODEL/2; i = i + 1) begin
                // 获取旋转角度
                cos_theta = cos_table[position][i];
                sin_theta = sin_table[position][i];
                
                // Q的旋转
                real_part = q_in[2*i];
                imag_part = q_in[2*i + 1];
                q_out[2*i]     <= (real_part * cos_theta - imag_part * sin_theta) >> 8;
                q_out[2*i + 1] <= (real_part * sin_theta + imag_part * cos_theta) >> 8;
                
                // K的旋转
                real_part = k_in[2*i];
                imag_part = k_in[2*i + 1];
                k_out[2*i]     <= (real_part * cos_theta - imag_part * sin_theta) >> 8;
                k_out[2*i + 1] <= (real_part * sin_theta + imag_part * cos_theta) >> 8;
            end
            
            done <= 1'b1;
        end else begin
            done <= 1'b0;
        end
    end
    
    // 初始化sin/cos表
    initial begin
        for (int pos = 0; pos < MAX_SEQ_LEN; pos++) begin
            for (int dim = 0; dim < D_MODEL/2; dim++) begin
                real theta = pos / (10000.0 ** (2.0 * dim / D_MODEL));
                sin_table[pos][dim] = $sin(theta) * (1 << 8);  // Q8格式
                cos_table[pos][dim] = $cos(theta) * (1 << 8);
            end
        end
    end
endmodule
            </div>
            
            <h4>4.5.4 层归一化加速单元</h4>
            <p>层归一化是Transformer中的关键操作，需要专门的硬件支持：</p>
            
            <div class="code-block">
// 高效层归一化单元
module LayerNormUnit #(
    parameter VECTOR_DIM = 768,
    parameter DATA_WIDTH = 16,
    parameter PRECISION = 8  // 小数位数
)(
    input wire clk,
    input wire rst_n,
    
    // 输入
    input wire [DATA_WIDTH-1:0] input_vector [VECTOR_DIM-1:0],
    input wire input_valid,
    
    // 可学习参数
    input wire [DATA_WIDTH-1:0] gamma [VECTOR_DIM-1:0],
    input wire [DATA_WIDTH-1:0] beta [VECTOR_DIM-1:0],
    
    // 输出
    output reg [DATA_WIDTH-1:0] output_vector [VECTOR_DIM-1:0],
    output reg output_valid
);
    
    // 流水线寄存器
    reg [DATA_WIDTH+9:0] sum_stage1;  // 扩展位宽防止溢出
    reg [DATA_WIDTH+9:0] sum_sq_stage1;
    reg [DATA_WIDTH-1:0] mean_stage2;
    reg [DATA_WIDTH-1:0] var_stage2;
    reg [DATA_WIDTH-1:0] std_stage3;
    
    // 第一级：计算和与平方和
    integer i;
    always @(posedge clk) begin
        if (!rst_n) begin
            sum_stage1 <= 0;
            sum_sq_stage1 <= 0;
        end else if (input_valid) begin
            sum_stage1 = 0;
            sum_sq_stage1 = 0;
            for (i = 0; i < VECTOR_DIM; i = i + 1) begin
                sum_stage1 = sum_stage1 + input_vector[i];
                sum_sq_stage1 = sum_sq_stage1 + input_vector[i] * input_vector[i];
            end
        end
    end
    
    // 第二级：计算均值和方差
    always @(posedge clk) begin
        if (!rst_n) begin
            mean_stage2 <= 0;
            var_stage2 <= 0;
        end else begin
            mean_stage2 <= sum_stage1 / VECTOR_DIM;
            var_stage2 <= (sum_sq_stage1 / VECTOR_DIM) - 
                         (mean_stage2 * mean_stage2);
        end
    end
    
    // 第三级：计算标准差（使用近似）
    wire [DATA_WIDTH-1:0] sqrt_result;
    SqrtApprox #(
        .DATA_WIDTH(DATA_WIDTH)
    ) sqrt_inst (
        .x(var_stage2 + (1 << 4)),  // 加小量避免除零
        .sqrt_x(sqrt_result)
    );
    
    always @(posedge clk) begin
        if (!rst_n) begin
            std_stage3 <= 0;
        end else begin
            std_stage3 <= sqrt_result;
        end
    end
    
    // 第四级：归一化和仿射变换
    reg [3:0] output_counter;
    always @(posedge clk) begin
        if (!rst_n) begin
            output_valid <= 0;
            output_counter <= 0;
        end else if (output_counter < VECTOR_DIM) begin
            // 分批处理以减少硬件资源
            for (i = 0; i < 16 && output_counter + i < VECTOR_DIM; i = i + 1) begin
                reg [DATA_WIDTH+7:0] normalized;
                normalized = ((input_vector[output_counter + i] - mean_stage2) << PRECISION) 
                           / std_stage3;
                output_vector[output_counter + i] <= 
                    (normalized * gamma[output_counter + i] >> PRECISION) + 
                    beta[output_counter + i];
            end
            output_counter <= output_counter + 16;
            
            if (output_counter + 16 >= VECTOR_DIM) begin
                output_valid <= 1'b1;
                output_counter <= 0;
            end
        end else begin
            output_valid <= 1'b0;
        end
    end
endmodule

// 平方根近似单元
module SqrtApprox #(
    parameter DATA_WIDTH = 16
)(
    input wire [DATA_WIDTH-1:0] x,
    output reg [DATA_WIDTH-1:0] sqrt_x
);
    // 使用Newton-Raphson迭代或查找表
    // 这里简化实现
    always @(*) begin
        sqrt_x = x >> 1;  // 极简近似，实际需要更精确的实现
    end
endmodule
            </div>
            
            <h4>4.5.5 融合计算优化</h4>
            <p>Transformer中多个操作可以融合以提高效率：</p>
            
            <div class="info-box">
                <p><strong>常见的融合模式：</strong></p>
                <ul>
                    <li><strong>QKV投影融合：</strong>将Q、K、V的线性投影合并为一次矩阵乘法</li>
                    <li><strong>注意力+Dropout融合：</strong>在Softmax后直接应用Dropout掩码</li>
                    <li><strong>LayerNorm+线性层融合：</strong>减少中间结果的存储</li>
                    <li><strong>激活函数融合：</strong>将GELU/SiLU等激活函数与前面的线性层融合</li>
                </ul>
            </div>
            
            <div class="exercise">
                <h4>练习 4.5</h4>
                <div class="question">
                    <p><strong>题目：</strong>设计一个支持混合精度计算的Transformer加速器，要求：
                    1) 支持FP16/INT8混合精度
                    2) 关键层（注意力）使用FP16，其他层使用INT8
                    3) 实现动态精度切换
                    4) 优化不同精度间的数据转换开销</p>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module MixedPrecisionTransformer #(
    parameter SEQ_LEN = 512,
    parameter D_MODEL = 768,
    parameter NUM_HEADS = 12,
    parameter NUM_LAYERS = 12
)(
    input wire clk,
    input wire rst_n,
    
    // 精度配置（每层）
    input wire [NUM_LAYERS-1:0] layer_precision,  // 0:INT8, 1:FP16
    
    // 输入
    input wire [7:0] input_int8 [SEQ_LEN-1:0][D_MODEL-1:0],
    input wire start,
    
    // 输出
    output reg [7:0] output_int8 [SEQ_LEN-1:0][D_MODEL-1:0],
    output reg done
);
    
    // 精度转换单元
    reg [15:0] fp16_buffer [SEQ_LEN-1:0][D_MODEL-1:0];
    reg [7:0] int8_buffer [SEQ_LEN-1:0][D_MODEL-1:0];
    
    // INT8到FP16转换
    task int8_to_fp16;
        input [7:0] int8_val;
        input [7:0] scale;
        input [7:0] zero_point;
        output [15:0] fp16_val;
        begin
            // 反量化：fp_val = (int_val - zero_point) * scale
            reg signed [15:0] dequant;
            dequant = $signed(int8_val) - $signed(zero_point);
            fp16_val = dequant * scale;  // 简化，实际需要浮点运算
        end
    endtask
    
    // FP16到INT8转换
    task fp16_to_int8;
        input [15:0] fp16_val;
        input [7:0] scale;
        input [7:0] zero_point;
        output [7:0] int8_val;
        begin
            // 量化：int_val = round(fp_val / scale) + zero_point
            reg signed [15:0] quant;
            quant = fp16_val / scale;  // 简化
            
            // 饱和处理
            if (quant + zero_point > 127)
                int8_val = 8'd127;
            else if (quant + zero_point < -128)
                int8_val = 8'd128;  // -128
            else
                int8_val = quant + zero_point;
        end
    endtask
    
    // 层处理状态机
    reg [3:0] current_layer;
    reg [2:0] layer_state;
    
    // 双精度计算单元
    wire attention_done, ffn_done;
    wire [15:0] attention_output_fp16 [SEQ_LEN-1:0][D_MODEL-1:0];
    wire [7:0] ffn_output_int8 [SEQ_LEN-1:0][D_MODEL-1:0];
    
    // FP16注意力单元
    AttentionLayerFP16 #(
        .SEQ_LEN(SEQ_LEN),
        .D_MODEL(D_MODEL),
        .NUM_HEADS(NUM_HEADS)
    ) attention_fp16 (
        .clk(clk),
        .rst_n(rst_n),
        .enable(layer_state == 3'b001 && layer_precision[current_layer]),
        .input_data(fp16_buffer),
        .output_data(attention_output_fp16),
        .done(attention_done)
    );
    
    // INT8 FFN单元
    FFNLayerINT8 #(
        .SEQ_LEN(SEQ_LEN),
        .D_MODEL(D_MODEL)
    ) ffn_int8 (
        .clk(clk),
        .rst_n(rst_n),
        .enable(layer_state == 3'b010 && !layer_precision[current_layer]),
        .input_data(int8_buffer),
        .output_data(ffn_output_int8),
        .done(ffn_done)
    );
    
    // 量化参数存储（每层）
    reg [7:0] quant_scale [NUM_LAYERS-1:0];
    reg [7:0] quant_zero_point [NUM_LAYERS-1:0];
    
    // 主控制逻辑
    always @(posedge clk) begin
        if (!rst_n) begin
            current_layer <= 0;
            layer_state <= 3'b000;
            done <= 1'b0;
        end else begin
            case (layer_state)
                3'b000: begin  // 准备阶段
                    if (start) begin
                        current_layer <= 0;
                        int8_buffer <= input_int8;
                        layer_state <= 3'b001;
                    end
                end
                
                3'b001: begin  // 精度转换（如需要）
                    if (layer_precision[current_layer]) begin
                        // INT8 -> FP16
                        for (int s = 0; s < SEQ_LEN; s++) begin
                            for (int d = 0; d < D_MODEL; d++) begin
                                int8_to_fp16(
                                    int8_buffer[s][d],
                                    quant_scale[current_layer],
                                    quant_zero_point[current_layer],
                                    fp16_buffer[s][d]
                                );
                            end
                        end
                    end
                    layer_state <= 3'b010;
                end
                
                3'b010: begin  // 计算阶段
                    if (layer_precision[current_layer]) begin
                        // FP16注意力计算
                        if (attention_done) begin
                            // FP16 -> INT8
                            for (int s = 0; s < SEQ_LEN; s++) begin
                                for (int d = 0; d < D_MODEL; d++) begin
                                    fp16_to_int8(
                                        attention_output_fp16[s][d],
                                        quant_scale[current_layer],
                                        quant_zero_point[current_layer],
                                        int8_buffer[s][d]
                                    );
                                end
                            end
                            layer_state <= 3'b011;
                        end
                    end else begin
                        // INT8 FFN计算
                        if (ffn_done) begin
                            int8_buffer <= ffn_output_int8;
                            layer_state <= 3'b011;
                        end
                    end
                end
                
                3'b011: begin  // 层完成
                    if (current_layer == NUM_LAYERS - 1) begin
                        output_int8 <= int8_buffer;
                        done <= 1'b1;
                        layer_state <= 3'b000;
                    end else begin
                        current_layer <= current_layer + 1;
                        layer_state <= 3'b001;
                    end
                end
            endcase
        end
    end
    
    // 性能监控
    reg [31:0] fp16_cycles;
    reg [31:0] int8_cycles;
    reg [31:0] conversion_cycles;
    
    always @(posedge clk) begin
        if (!rst_n) begin
            fp16_cycles <= 0;
            int8_cycles <= 0;
            conversion_cycles <= 0;
        end else begin
            case (layer_state)
                3'b001: conversion_cycles <= conversion_cycles + 1;
                3'b010: begin
                    if (layer_precision[current_layer])
                        fp16_cycles <= fp16_cycles + 1;
                    else
                        int8_cycles <= int8_cycles + 1;
                end
            endcase
        end
    end
endmodule
                        </div>
                        <p><strong>设计要点：</strong></p>
                        <ul>
                            <li>关键层使用高精度保证准确性</li>
                            <li>非关键层使用低精度提高效率</li>
                            <li>精度转换单元优化减少开销</li>
                            <li>动态配置支持不同模型需求</li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>

        <!-- Chapter 5: 存储系统设计 -->
        <section id="chapter5" class="chapter">
            <h2>第5章：存储系统设计</h2>
            
            <p>存储系统是NPU性能的关键瓶颈之一。本章深入探讨NPU片上存储系统的架构与设计要点，包括SRAM设计、Memory Banking策略、数据预取机制、缓存一致性、DMA设计以及内存压缩技术。</p>

            <h3>5.1 片上SRAM设计</h3>
            
            <p>片上SRAM是NPU存储层次结构的核心，为计算单元提供超低延迟、超高带宽的数据访问。</p>

            <h4>5.1.1 SRAM设计权衡</h4>
            <div class="code-block">
SRAM设计的关键权衡：

1. 容量 vs. 面积/功耗
   - SRAM面积密度：~0.2 MB/mm² (7nm工艺)
   - 静态功耗：~1mW/MB
   - 动态功耗：与访问频率成正比

2. 端口设计
   - 单端口：面积最小，但限制并行访问
   - 真双端口(1R1W)：面积增加~70%，支持一个读操作和一个写操作同时进行
   - 多端口(nRmW)：面积随端口数超线性增长

3. 访问延迟
   - 容量增大 → 延迟增加（解码器、字线、位线延迟）
   - 典型延迟：32KB ~1 cycle, 256KB ~2-3 cycles
            </div>

            <h4>5.1.2 多级存储层次</h4>
            <div class="code-block">
// 典型的三级存储层次设计
module MemoryHierarchy (
    input wire clk,
    input wire rst_n,
    // L0: PE本地寄存器文件
    // L1: PE集群共享缓存
    // L2: 全局共享缓存
);

// 优化的L0寄存器文件 - SystemVerilog版本（带流水线和旁路）
module L0_RegisterFile #(
    parameter DEPTH = 16,       // 16个寄存器
    parameter WIDTH = 256       // 256-bit宽度
)(
    input wire clk,
    input wire rst_n,
    input wire [3:0] rd_addr,
    input wire [3:0] wr_addr,
    input wire wr_en,
    input wire [WIDTH-1:0] wr_data,
    output reg [WIDTH-1:0] rd_data
);
    reg [WIDTH-1:0] regs [0:DEPTH-1];
    
    // 写数据流水线寄存器
    reg wr_en_r;
    reg [3:0] wr_addr_r;
    reg [WIDTH-1:0] wr_data_r;
    
    // 旁路逻辑（处理读写同地址情况）
    wire bypass_enable;
    assign bypass_enable = wr_en && (rd_addr == wr_addr);
    
    // 写操作流水线
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            wr_en_r <= 0;
            wr_addr_r <= 0;
            wr_data_r <= 0;
        end else begin
            wr_en_r <= wr_en;
            wr_addr_r <= wr_addr;
            wr_data_r <= wr_data;
        end
    end
    
    // 寄存器写入
    always @(posedge clk) begin
        if (wr_en_r)
            regs[wr_addr_r] <= wr_data_r;
    end
    
    // 读操作（带旁路）
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            rd_data <= 0;
        end else begin
            if (bypass_enable)
                rd_data <= wr_data;  // 旁路当前写入数据
            else
                rd_data <= regs[rd_addr];  // 正常读取
        end
    end
endmodule
            </div>
            
            <p>Chisel版本的L0寄存器文件：</p>
            <div class="code-block">
import chisel3._
import chisel3.util._

class L0RegisterFile(depth: Int = 16, width: Int = 256) extends Module {
    val io = IO(new Bundle {
        val rdAddr = Input(UInt(log2Ceil(depth).W))
        val wrAddr = Input(UInt(log2Ceil(depth).W))
        val wrEn = Input(Bool())
        val wrData = Input(UInt(width.W))
        val rdData = Output(UInt(width.W))
    })
    
    // 寄存器文件
    val regs = RegInit(VecInit(Seq.fill(depth)(0.U(width.W))))
    
    // 写操作流水线
    val wrEnR = RegNext(io.wrEn, false.B)
    val wrAddrR = RegNext(io.wrAddr)
    val wrDataR = RegNext(io.wrData)
    
    // 写入寄存器
    when(wrEnR) {
        regs(wrAddrR) := wrDataR
    }
    
    // 旁路检测
    val bypassEnable = wrEnR && (io.rdAddr === wrAddrR)
    
    // 读操作（带旁路）
    io.rdData := RegNext(Mux(bypassEnable, wrDataR, regs(io.rdAddr)))
}

// L1 Cluster Buffer (PE集群共享)
module L1_ClusterBuffer #(
    parameter SIZE = 64 * 1024,     // 64KB
    parameter PORTS = 4,            // 4个访问端口
    parameter WIDTH = 256
)(
    input wire clk,
    input wire [PORTS-1:0] rd_en,
    input wire [PORTS-1:0] wr_en,
    input wire [15:0] rd_addr [PORTS-1:0],
    input wire [15:0] wr_addr [PORTS-1:0],
    input wire [WIDTH-1:0] wr_data [PORTS-1:0],
    output wire [WIDTH-1:0] rd_data [PORTS-1:0]
);
    // 多端口SRAM实现
endmodule
            </div>

            <h4>5.1.3 特殊SRAM结构</h4>
            <div class="code-block">
// 转置SRAM：支持行列双向访问
module TransposeSRAM #(
    parameter ROWS = 64,
    parameter COLS = 64,
    parameter DATA_WIDTH = 8
)(
    input wire clk,
    input wire row_mode,    // 1: 行访问, 0: 列访问
    input wire [5:0] addr_major,
    input wire [5:0] addr_minor,
    input wire wr_en,
    input wire [DATA_WIDTH*COLS-1:0] wr_data,
    output wire [DATA_WIDTH*COLS-1:0] rd_data
);
    // 实现支持行列转置访问的SRAM
    reg [DATA_WIDTH-1:0] mem [0:ROWS-1][0:COLS-1];
    
    genvar i;
    generate
        for (i = 0; i < COLS; i = i + 1) begin
            always @(posedge clk) begin
                if (wr_en) begin
                    if (row_mode)
                        mem[addr_major][i] <= wr_data[i*DATA_WIDTH +: DATA_WIDTH];
                    else
                        mem[i][addr_major] <= wr_data[i*DATA_WIDTH +: DATA_WIDTH];
                end
            end
            
            assign rd_data[i*DATA_WIDTH +: DATA_WIDTH] = 
                row_mode ? mem[addr_major][i] : mem[i][addr_major];
        end
    endgenerate
endmodule
            </div>

            <h3>5.2 Memory Banking策略</h3>
            
            <p>Memory Banking通过将SRAM划分为多个独立的Bank，实现并行访问，成倍提升有效带宽。</p>

            <h4>5.2.1 Bank冲突分析</h4>
            <div class="code-block">
Bank冲突的主要场景：

1. 卷积中的步长访问
   - 3×3卷积，stride=2时的访问模式
   - Bank数量需要考虑GCD(stride, bank_num)

2. 矩阵转置访问
   - 行访问：连续地址
   - 列访问：地址间隔为矩阵宽度

3. 稀疏访问模式
   - 不规则的访问地址
   - 需要动态仲裁机制
            </div>

            <h4>5.2.2 地址映射策略</h4>
            <div class="code-block">
// 优化的多Bank SRAM控制器 - SystemVerilog版本（带流水线和仲裁）
module MultiBank_SRAM #(
    parameter NUM_BANKS = 8,
    parameter BANK_SIZE = 8192,     // 每个Bank 8KB
    parameter DATA_WIDTH = 256,
    parameter ADDR_WIDTH = 16
)(
    input wire clk,
    input wire rst_n,
    
    // 请求接口（支持多个并行请求）
    input wire [3:0] req_valid,
    input wire [ADDR_WIDTH-1:0] req_addr [3:0],
    input wire [3:0] req_wr,
    input wire [DATA_WIDTH-1:0] req_wdata [3:0],
    output reg [3:0] req_ready,
    output reg [DATA_WIDTH-1:0] resp_data [3:0],
    output reg [3:0] resp_valid
);

    // 第一级流水线：地址解码
    reg [3:0] req_valid_r1;
    reg [2:0] bank_id_r1 [3:0];
    reg [12:0] bank_addr_r1 [3:0];
    reg [3:0] req_wr_r1;
    reg [DATA_WIDTH-1:0] req_wdata_r1 [3:0];
    reg [3:0] req_id_r1;  // 请求者ID
    
    // 地址解码逻辑
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            req_valid_r1 <= 0;
            for (int i = 0; i < 4; i++) begin
                bank_id_r1[i] <= 0;
                bank_addr_r1[i] <= 0;
                req_wr_r1[i] <= 0;
                req_wdata_r1[i] <= 0;
                req_id_r1[i] <= i;
            end
        end else begin
            req_valid_r1 <= req_valid;
            for (int i = 0; i < 4; i++) begin
                // 交织映射：低位作为bank索引
                bank_id_r1[i] <= req_addr[i][2:0];
                bank_addr_r1[i] <= req_addr[i][ADDR_WIDTH-1:3];
                req_wr_r1[i] <= req_wr[i];
                req_wdata_r1[i] <= req_wdata[i];
            end
        end
    end
    
    // 第二级流水线：Bank仲裁
    reg [3:0] bank_grant_r2 [NUM_BANKS-1:0];
    reg [3:0] grant_id_r2 [NUM_BANKS-1:0];  // 被授权的请求者ID
    
    // 改进的仲裁逻辑（轮询优先级）
    reg [1:0] priority_ptr [NUM_BANKS-1:0];  // 每个Bank的优先级指针
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            for (int j = 0; j < NUM_BANKS; j++) begin
                bank_grant_r2[j] <= 0;
                grant_id_r2[j] <= 0;
                priority_ptr[j] <= 0;
            end
        end else begin
            // 对每个Bank进行仲裁
            for (int j = 0; j < NUM_BANKS; j++) begin
                bank_grant_r2[j] <= 0;
                
                // 从优先级指针开始轮询
                for (int k = 0; k < 4; k++) begin
                    int req_idx = (priority_ptr[j] + k) % 4;
                    if (req_valid_r1[req_idx] && bank_id_r1[req_idx] == j && |bank_grant_r2[j] == 0) begin
                        bank_grant_r2[j][req_idx] <= 1;
                        grant_id_r2[j] <= req_idx;
                        priority_ptr[j] <= (req_idx + 1) % 4;  // 更新优先级
                    end
                end
            end
        end
    end
    
    // Bank SRAM实例和第三级流水线
    wire [DATA_WIDTH-1:0] bank_rdata [NUM_BANKS-1:0];
    reg [3:0] resp_valid_r3;
    reg [3:0] resp_id_r3 [NUM_BANKS-1:0];
    
    genvar i;
    generate
        for (i = 0; i < NUM_BANKS; i = i + 1) begin : bank_gen
            // 选择授权的请求
            wire bank_en = |bank_grant_r2[i];
            wire [3:0] grant_onehot = bank_grant_r2[i];
            wire [1:0] grant_idx = grant_id_r2[i];
            
            // Mux选择授权请求的信号
            wire bank_wr = req_wr_r1[grant_idx] & bank_en;
            wire [12:0] bank_addr = bank_addr_r1[grant_idx];
            wire [DATA_WIDTH-1:0] bank_wdata = req_wdata_r1[grant_idx];
            
            // Bank SRAM实例
            BankSRAM #(
                .SIZE(BANK_SIZE),
                .WIDTH(DATA_WIDTH)
            ) bank_inst (
                .clk(clk),
                .en(bank_en),
                .wr(bank_wr),
                .addr(bank_addr),
                .wdata(bank_wdata),
                .rdata(bank_rdata[i])
            );
            
            // 响应ID寄存
            always @(posedge clk) begin
                resp_id_r3[i] <= grant_id_r2[i];
            end
        end
    endgenerate
    
    // 第四级流水线：响应汇集
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            resp_valid <= 0;
            for (int i = 0; i < 4; i++)
                resp_data[i] <= 0;
        end else begin
            resp_valid <= 0;
            
            // 将Bank响应路由回请求者
            for (int j = 0; j < NUM_BANKS; j++) begin
                if (|bank_grant_r2[j]) begin
                    int resp_idx = resp_id_r3[j];
                    resp_data[resp_idx] <= bank_rdata[j];
                    resp_valid[resp_idx] <= 1;
                end
            end
        end
    end
    
    // Ready信号（考虑仲裁结果）
    always @(*) begin
        req_ready = 4'b1111;  // 默认都ready，实际使用时可根据Bank忙碌状态调整
    end
endmodule

// Bank SRAM模块
module BankSRAM #(
    parameter SIZE = 8192,
    parameter WIDTH = 256,
    parameter ADDR_WIDTH = 13
)(
    input wire clk,
    input wire en,
    input wire wr,
    input wire [ADDR_WIDTH-1:0] addr,
    input wire [WIDTH-1:0] wdata,
    output reg [WIDTH-1:0] rdata
);
    reg [WIDTH-1:0] mem [0:SIZE-1];
    
    always @(posedge clk) begin
        if (en) begin
            if (wr)
                mem[addr] <= wdata;
            else
                rdata <= mem[addr];
        end
    end
endmodule

// Chisel版本的多Bank SRAM
            </div>
            
            <p>Chisel版本的多Bank SRAM控制器：</p>
            <div class="code-block">
import chisel3._
import chisel3.util._

class MultiBankSRAM(numBanks: Int = 8, bankSize: Int = 8192, 
                    dataWidth: Int = 256, numPorts: Int = 4) extends Module {
    val addrWidth = log2Ceil(numBanks * bankSize)
    val bankAddrWidth = log2Ceil(bankSize)
    
    val io = IO(new Bundle {
        val req = Vec(numPorts, new Bundle {
            val valid = Input(Bool())
            val addr = Input(UInt(addrWidth.W))
            val wr = Input(Bool())
            val wdata = Input(UInt(dataWidth.W))
            val ready = Output(Bool())
        })
        val resp = Vec(numPorts, new Bundle {
            val data = Output(UInt(dataWidth.W))
            val valid = Output(Bool())
        })
    })
    
    // 第一级流水线：地址解码
    val reqValidR1 = RegNext(VecInit(io.req.map(_.valid)))
    val bankIdR1 = io.req.map(r => RegNext(r.addr(log2Ceil(numBanks)-1, 0)))
    val bankAddrR1 = io.req.map(r => RegNext(r.addr >> log2Ceil(numBanks)))
    val reqWrR1 = RegNext(VecInit(io.req.map(_.wr)))
    val reqWdataR1 = RegNext(VecInit(io.req.map(_.wdata)))
    
    // 仲裁器（每个Bank一个）
    val arbiters = Seq.fill(numBanks)(Module(new RRArbiter(numPorts)))
    val banks = Seq.fill(numBanks)(Module(new BankSRAM(bankSize, dataWidth)))
    
    // 连接请求到仲裁器
    for (i <- 0 until numPorts) {
        for (j <- 0 until numBanks) {
            arbiters(j).io.req(i).valid := reqValidR1(i) && (bankIdR1(i) === j.U)
            arbiters(j).io.req(i).bits := Cat(reqWdataR1(i), bankAddrR1(i), reqWrR1(i))
        }
    }
    
    // 连接仲裁器到Bank
    for (j <- 0 until numBanks) {
        banks(j).io.en := arbiters(j).io.chosen.valid
        banks(j).io.wr := arbiters(j).io.chosen.bits(0)
        banks(j).io.addr := arbiters(j).io.chosen.bits(bankAddrWidth, 1)
        banks(j).io.wdata := arbiters(j).io.chosen.bits >> (bankAddrWidth + 1)
    }
    
    // 响应路由
    for (i <- 0 until numPorts) {
        io.resp(i).valid := RegNext(arbiters.map(a => a.io.grant(i)).reduce(_ || _))
        io.resp(i).data := RegNext(MuxCase(0.U, 
            banks.zipWithIndex.map { case (bank, j) => 
                (arbiters(j).io.grant(i) -> bank.io.rdata)
            }
        ))
        io.req(i).ready := true.B  // 简化：始终ready
    }
}

// 轮询仲裁器
class RRArbiter(n: Int) extends Module {
    val io = IO(new Bundle {
        val req = Vec(n, Flipped(Valid(UInt())))
        val chosen = Valid(UInt())
        val grant = Vec(n, Output(Bool()))
    })
    
    val priority = RegInit(0.U(log2Ceil(n).W))
    
    // 轮询逻辑
    val reqVec = VecInit(io.req.map(_.valid))
    val shiftReq = VecInit((0 until n).map(i => reqVec((i + priority) % n)))
    val shiftGrant = PriorityEncoderOH(shiftReq)
    
    // 输出
    io.grant := VecInit((0 until n).map(i => shiftGrant((i - priority + n) % n)))
    io.chosen.valid := reqVec.reduce(_ || _)
    io.chosen.bits := Mux1H(io.grant, io.req.map(_.bits))
    
    // 更新优先级
    when(io.chosen.valid) {
        priority := (priority + PriorityEncoder(io.grant) + 1.U) % n.U
    }
}
                .rdata(/* 连接到响应数据 */)
            );
        end
    endgenerate
endmodule

// 专用于卷积的Bank映射
module ConvBankMapping #(
    parameter BANK_BITS = 3,        // 8个Bank
    parameter CHANNEL_BITS = 6      // 64个通道
)(
    input wire [15:0] h_idx,        // Height坐标
    input wire [15:0] w_idx,        // Width坐标
    input wire [CHANNEL_BITS-1:0] c_idx,  // Channel坐标
    output wire [BANK_BITS-1:0] bank_id,
    output wire [15:0] bank_offset
);
    // 斜对角映射，避免3×3卷积的Bank冲突
    wire [BANK_BITS-1:0] skew;
    assign skew = (h_idx + w_idx) & ((1 << BANK_BITS) - 1);
    assign bank_id = (c_idx[BANK_BITS-1:0] + skew) & ((1 << BANK_BITS) - 1);
    
    // Bank内偏移地址
    assign bank_offset = {c_idx[CHANNEL_BITS-1:BANK_BITS], h_idx[7:0], w_idx[7:0]};
endmodule
            </div>

            <h4>5.2.3 Bank冲突解决</h4>
            <div class="code-block">
// 带冲突缓冲的Bank访问调度器
module BankScheduler #(
    parameter NUM_BANKS = 8,
    parameter NUM_REQUESTORS = 16,
    parameter QUEUE_DEPTH = 4
)(
    input wire clk,
    input wire rst_n,
    
    // 请求端口
    input wire [NUM_REQUESTORS-1:0] req_valid,
    input wire [2:0] req_bank [NUM_REQUESTORS-1:0],
    input wire [15:0] req_addr [NUM_REQUESTORS-1:0],
    output reg [NUM_REQUESTORS-1:0] req_ready,
    
    // Bank接口
    output reg [NUM_BANKS-1:0] bank_valid,
    output reg [15:0] bank_addr [NUM_BANKS-1:0],
    input wire [NUM_BANKS-1:0] bank_ready
);

    // 每个请求者的请求队列
    reg [2:0] req_queue_bank [NUM_REQUESTORS-1:0][QUEUE_DEPTH-1:0];
    reg [15:0] req_queue_addr [NUM_REQUESTORS-1:0][QUEUE_DEPTH-1:0];
    reg [1:0] req_queue_head [NUM_REQUESTORS-1:0];
    reg [1:0] req_queue_tail [NUM_REQUESTORS-1:0];
    
    // 冲突检测与调度
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            // 复位逻辑
        end else begin
            // 1. 将新请求加入队列
            // 2. 从每个队列头部选择无冲突的请求
            // 3. 发送到对应的Bank
        end
    end
endmodule
            </div>

            <h3>5.3 数据预取机制</h3>
            
            <p>数据预取通过提前将数据从DRAM加载到片上SRAM，隐藏内存访问延迟，是提升NPU性能的关键技术。</p>

            <h4>5.3.1 预取策略</h4>
            <div class="code-block">
预取机制的核心要素：

1. 预取时机
   - 基于计算进度的预取
   - 基于地址模式的预取
   - 软件控制的显式预取

2. 预取粒度
   - 细粒度：单个Tile (如16×16)
   - 粗粒度：整个Feature Map
   - 自适应粒度：根据可用空间动态调整

3. 预取深度
   - Double Buffering: 计算当前数据时预取下一批
   - Triple Buffering: 更深的流水线，容忍更大延迟
            </div>

            <h4>5.3.2 硬件预取引擎</h4>
            <div class="code-block">
// 智能预取引擎
module PrefetchEngine #(
    parameter ADDR_WIDTH = 32,
    parameter DATA_WIDTH = 256,
    parameter PREFETCH_DEPTH = 4
)(
    input wire clk,
    input wire rst_n,
    
    // 控制接口
    input wire prefetch_enable,
    input wire [ADDR_WIDTH-1:0] base_addr,
    input wire [15:0] stride,
    input wire [15:0] count,
    
    // 计算进度监控
    input wire [15:0] compute_progress,
    
    // DRAM接口
    output reg dram_req_valid,
    output reg [ADDR_WIDTH-1:0] dram_req_addr,
    output reg [7:0] dram_req_len,
    input wire dram_req_ready,
    
    // SRAM写接口
    output reg sram_wr_valid,
    output reg [15:0] sram_wr_addr,
    output reg [DATA_WIDTH-1:0] sram_wr_data,
    input wire sram_wr_ready
);

    // 预取状态机
    localparam IDLE = 0, MONITOR = 1, ISSUE_REQ = 2, WAIT_RESP = 3;
    reg [1:0] state, next_state;
    
    // 预取队列
    reg [ADDR_WIDTH-1:0] prefetch_queue [PREFETCH_DEPTH-1:0];
    reg [2:0] queue_head, queue_tail;
    reg [3:0] queue_count;
    
    // 地址生成器
    reg [ADDR_WIDTH-1:0] next_addr;
    reg [15:0] fetch_count;
    
    // 预取距离计算
    wire [15:0] prefetch_distance;
    assign prefetch_distance = queue_count * 16; // 假设每次预取16个元素
    
    // 状态机逻辑
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            state <= IDLE;
            queue_head <= 0;
            queue_tail <= 0;
            queue_count <= 0;
        end else begin
            state <= next_state;
            
            case (state)
                IDLE: begin
                    if (prefetch_enable) begin
                        next_addr <= base_addr;
                        fetch_count <= 0;
                    end
                end
                
                MONITOR: begin
                    // 监控计算进度，决定是否发起预取
                    if (compute_progress + prefetch_distance < count && 
                        queue_count < PREFETCH_DEPTH - 1) begin
                        // 需要预取更多数据
                        prefetch_queue[queue_tail] <= next_addr;
                        queue_tail <= queue_tail + 1;
                        queue_count <= queue_count + 1;
                        next_addr <= next_addr + stride;
                        fetch_count <= fetch_count + 1;
                    end
                end
                
                ISSUE_REQ: begin
                    if (dram_req_ready && queue_count > 0) begin
                        dram_req_valid <= 1'b1;
                        dram_req_addr <= prefetch_queue[queue_head];
                        dram_req_len <= 8'd16; // 预取16个元素
                        queue_head <= queue_head + 1;
                        queue_count <= queue_count - 1;
                    end
                end
            endcase
        end
    end
    
    // 下一状态逻辑
    always @(*) begin
        next_state = state;
        case (state)
            IDLE: 
                if (prefetch_enable) next_state = MONITOR;
            MONITOR:
                if (queue_count > 0) next_state = ISSUE_REQ;
            ISSUE_REQ:
                if (dram_req_ready) next_state = WAIT_RESP;
            WAIT_RESP:
                if (/* DRAM响应完成 */) next_state = MONITOR;
        endcase
    end
endmodule

// 双缓冲预取控制器
module DoubleBufferPrefetch #(
    parameter BUFFER_SIZE = 16384,  // 16KB per buffer
    parameter DATA_WIDTH = 256
)(
    input wire clk,
    input wire rst_n,
    
    // 计算单元接口
    input wire compute_req,
    input wire [13:0] compute_addr,
    output wire [DATA_WIDTH-1:0] compute_data,
    output wire compute_ready,
    
    // 预取控制
    input wire [31:0] prefetch_base_addr,
    input wire [15:0] prefetch_length,
    input wire prefetch_start,
    
    // DRAM接口
    output wire dram_req_valid,
    output wire [31:0] dram_req_addr,
    input wire dram_resp_valid,
    input wire [DATA_WIDTH-1:0] dram_resp_data
);
    
    // 双缓冲控制
    reg buffer_sel;  // 0: Buffer A用于计算, 1: Buffer B用于计算
    reg [13:0] buffer_write_addr [1:0];
    reg buffer_ready [1:0];
    
    // 缓冲区实例
    wire [DATA_WIDTH-1:0] buffer_rdata [1:0];
    
    genvar i;
    generate
        for (i = 0; i < 2; i = i + 1) begin
            SimpleDualPortRAM #(
                .DEPTH(BUFFER_SIZE/32),
                .WIDTH(DATA_WIDTH)
            ) buffer (
                .clk(clk),
                .wr_en(dram_resp_valid && (buffer_sel != i)),
                .wr_addr(buffer_write_addr[i]),
                .wr_data(dram_resp_data),
                .rd_addr(compute_addr),
                .rd_data(buffer_rdata[i])
            );
        end
    endgenerate
    
    // 计算接口
    assign compute_data = buffer_rdata[buffer_sel];
    assign compute_ready = buffer_ready[buffer_sel];
    
    // 缓冲切换逻辑
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            buffer_sel <= 0;
        end else if (/* 当前buffer计算完成 && 另一个buffer预取完成 */) begin
            buffer_sel <= ~buffer_sel;
        end
    end
endmodule
            </div>

            <h4>5.3.3 软件控制预取</h4>
            <div class="code-block">
// 预取指令格式
typedef struct {
    uint32_t opcode : 8;      // PREFETCH指令码
    uint32_t buffer_id : 4;   // 目标缓冲区ID
    uint32_t pattern : 4;     // 访问模式（线性/2D/3D）
    uint32_t priority : 2;    // 预取优先级
    uint32_t reserved : 14;
} prefetch_inst_t;

// 预取描述符
typedef struct {
    uint32_t src_addr;        // 源地址（DRAM）
    uint32_t dst_addr;        // 目标地址（SRAM）
    uint16_t dim0_size;       // 第一维大小
    uint16_t dim0_stride;     // 第一维步长
    uint16_t dim1_size;       // 第二维大小
    uint16_t dim1_stride;     // 第二维步长
    uint16_t dim2_size;       // 第三维大小
    uint16_t dim2_stride;     // 第三维步长
} prefetch_desc_t;

// 软件预取示例（卷积层）
void conv_layer_with_prefetch(
    float* input,     // [N, H, W, C_in]
    float* weights,   // [K, K, C_in, C_out]
    float* output,    // [N, H_out, W_out, C_out]
    conv_params_t params
) {
    // 设置权重预取（权重复用率高，优先预取）
    prefetch_desc_t weight_pf = {
        .src_addr = (uint32_t)weights,
        .dst_addr = WEIGHT_BUFFER_BASE,
        .dim0_size = params.kernel_size,
        .dim0_stride = params.kernel_size * params.c_in * sizeof(float),
        .dim1_size = params.kernel_size,
        .dim1_stride = params.c_in * sizeof(float),
        .dim2_size = params.c_in,
        .dim2_stride = sizeof(float)
    };
    
    // 发起权重预取
    issue_prefetch(WEIGHT_PREFETCH_ENGINE, &weight_pf);
    
    // 双缓冲处理输入特征图
    for (int tile_y = 0; tile_y < params.h_out; tile_y += TILE_SIZE) {
        // 预取下一个tile的输入数据
        if (tile_y + TILE_SIZE < params.h_out) {
            prefetch_desc_t input_pf = {
                .src_addr = (uint32_t)&input[tile_y + TILE_SIZE][0][0],
                .dst_addr = INPUT_BUFFER_B,
                .dim0_size = TILE_SIZE + params.kernel_size - 1,
                .dim0_stride = params.w * params.c_in * sizeof(float),
                .dim1_size = params.w,
                .dim1_stride = params.c_in * sizeof(float),
                .dim2_size = params.c_in,
                .dim2_stride = sizeof(float)
            };
            issue_prefetch(INPUT_PREFETCH_ENGINE, &input_pf);
        }
        
        // 等待当前tile数据就绪
        wait_prefetch_complete(current_buffer);
        
        // 执行计算
        compute_conv_tile(current_buffer, WEIGHT_BUFFER_BASE, 
                         OUTPUT_BUFFER + tile_y * params.w_out * params.c_out);
        
        // 切换缓冲区
        current_buffer = (current_buffer == INPUT_BUFFER_A) ? 
                        INPUT_BUFFER_B : INPUT_BUFFER_A;
    }
}
            </div>

            <h3>5.4 缓存一致性</h3>
            
            <p>在多核NPU系统中，缓存一致性确保不同核心看到的数据是一致的，这对正确性至关重要。</p>

            <h4>5.4.1 NPU缓存一致性挑战</h4>
            <div class="code-block">
NPU缓存一致性的特点：

1. 软件管理为主
   - 神经网络计算流程确定
   - 编译器可以精确分析数据依赖
   - 显式同步点插入

2. 简化的硬件支持
   - 基本的Cache刷新/失效指令
   - DMA与Cache的协同
   - 全局同步屏障

3. 常见场景
   - 多核协同计算大矩阵乘法
   - Pipeline并行中的数据传递
   - 模型参数的广播更新
            </div>

            <h4>5.4.2 软件管理的缓存一致性</h4>
            <div class="code-block">
// 缓存控制单元
module CacheController #(
    parameter CACHE_SIZE = 32768,   // 32KB
    parameter LINE_SIZE = 64,       // 64B cache line
    parameter NUM_WAYS = 4
)(
    input wire clk,
    input wire rst_n,
    
    // 处理器接口
    input wire [31:0] cpu_addr,
    input wire cpu_req,
    input wire cpu_wr,
    input wire [255:0] cpu_wdata,
    output wire [255:0] cpu_rdata,
    output wire cpu_ready,
    
    // 缓存控制指令
    input wire cache_flush,         // 写回所有脏数据
    input wire cache_invalidate,    // 失效所有缓存行
    input wire [31:0] inv_addr,     // 特定地址失效
    input wire inv_addr_valid,
    
    // 内存接口
    output reg mem_req,
    output reg [31:0] mem_addr,
    output reg mem_wr,
    output reg [255:0] mem_wdata,
    input wire [255:0] mem_rdata,
    input wire mem_ready
);

    // Cache标签和数据存储
    reg [19:0] tag_array [NUM_WAYS-1:0][CACHE_SIZE/LINE_SIZE/NUM_WAYS-1:0];
    reg valid_array [NUM_WAYS-1:0][CACHE_SIZE/LINE_SIZE/NUM_WAYS-1:0];
    reg dirty_array [NUM_WAYS-1:0][CACHE_SIZE/LINE_SIZE/NUM_WAYS-1:0];
    reg [255:0] data_array [NUM_WAYS-1:0][CACHE_SIZE/LINE_SIZE/NUM_WAYS-1:0];
    
    // 地址解析
    wire [19:0] tag = cpu_addr[31:12];
    wire [7:0] index = cpu_addr[11:6];
    wire [5:0] offset = cpu_addr[5:0];
    
    // 缓存刷新状态机
    reg [2:0] flush_state;
    reg [7:0] flush_index;
    reg [1:0] flush_way;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            flush_state <= 0;
            flush_index <= 0;
            flush_way <= 0;
        end else if (cache_flush && flush_state == 0) begin
            flush_state <= 1;
            flush_index <= 0;
            flush_way <= 0;
        end else if (flush_state != 0) begin
            case (flush_state)
                1: begin // 检查脏位
                    if (dirty_array[flush_way][flush_index]) begin
                        // 发起写回请求
                        mem_req <= 1'b1;
                        mem_wr <= 1'b1;
                        mem_addr <= {tag_array[flush_way][flush_index], 
                                   flush_index, 6'b0};
                        mem_wdata <= data_array[flush_way][flush_index];
                        flush_state <= 2;
                    end else begin
                        // 继续下一个
                        if (flush_way == NUM_WAYS-1) begin
                            flush_way <= 0;
                            if (flush_index == (CACHE_SIZE/LINE_SIZE/NUM_WAYS-1))
                                flush_state <= 0; // 完成
                            else
                                flush_index <= flush_index + 1;
                        end else begin
                            flush_way <= flush_way + 1;
                        end
                    end
                end
                
                2: begin // 等待写回完成
                    if (mem_ready) begin
                        mem_req <= 1'b0;
                        dirty_array[flush_way][flush_index] <= 1'b0;
                        flush_state <= 1;
                        // 继续下一个
                        if (flush_way == NUM_WAYS-1) begin
                            flush_way <= 0;
                            if (flush_index == (CACHE_SIZE/LINE_SIZE/NUM_WAYS-1))
                                flush_state <= 0;
                            else
                                flush_index <= flush_index + 1;
                        end else begin
                            flush_way <= flush_way + 1;
                        end
                    end
                end
            endcase
        end
    end
    
    // 缓存失效逻辑
    always @(posedge clk) begin
        if (cache_invalidate) begin
            // 全部失效
            integer i, j;
            for (i = 0; i < NUM_WAYS; i = i + 1) begin
                for (j = 0; j < CACHE_SIZE/LINE_SIZE/NUM_WAYS; j = j + 1) begin
                    valid_array[i][j] <= 1'b0;
                end
            end
        end else if (inv_addr_valid) begin
            // 特定地址失效
            wire [7:0] inv_index = inv_addr[11:6];
            wire [19:0] inv_tag = inv_addr[31:12];
            
            integer k;
            for (k = 0; k < NUM_WAYS; k = k + 1) begin
                if (valid_array[k][inv_index] && 
                    tag_array[k][inv_index] == inv_tag) begin
                    valid_array[k][inv_index] <= 1'b0;
                end
            end
        end
    end
endmodule

// 多核同步屏障
module GlobalSyncBarrier #(
    parameter NUM_CORES = 16
)(
    input wire clk,
    input wire rst_n,
    
    // 每个核心的同步请求
    input wire [NUM_CORES-1:0] sync_req,
    output reg [NUM_CORES-1:0] sync_ack,
    
    // 同步ID（支持多个屏障）
    input wire [3:0] sync_id [NUM_CORES-1:0],
    
    // 缓存控制输出
    output reg cache_flush_all,
    output reg cache_inv_all
);

    // 同步状态跟踪
    reg [NUM_CORES-1:0] sync_pending [15:0]; // 16个同步ID
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            sync_ack <= 0;
            cache_flush_all <= 0;
            cache_inv_all <= 0;
        end else begin
            // 收集同步请求
            integer i, j;
            for (i = 0; i < NUM_CORES; i = i + 1) begin
                if (sync_req[i] && !sync_ack[i]) begin
                    sync_pending[sync_id[i]][i] <= 1'b1;
                end
            end
            
            // 检查是否所有核心都到达屏障
            for (j = 0; j < 16; j = j + 1) begin
                if (sync_pending[j] == {NUM_CORES{1'b1}}) begin
                    // 触发全局缓存刷新
                    cache_flush_all <= 1'b1;
                    cache_inv_all <= 1'b1;
                    
                    // 释放所有等待的核心
                    for (i = 0; i < NUM_CORES; i = i + 1) begin
                        if (sync_pending[j][i]) begin
                            sync_ack[i] <= 1'b1;
                            sync_pending[j][i] <= 1'b0;
                        end
                    end
                end
            end
            
            // 清除控制信号
            if (cache_flush_all) cache_flush_all <= 1'b0;
            if (cache_inv_all) cache_inv_all <= 1'b0;
            
            // 清除应答信号
            sync_ack <= sync_ack & ~sync_req;
        end
    end
endmodule
            </div>

            <h4>5.4.3 DMA与缓存协同</h4>
            <div class="code-block">
// DMA与缓存协同示例
// 确保DMA传输的数据一致性

// 场景1：DMA写入内存前，刷新相关缓存
void dma_write_with_cache_sync(
    void* src_sram_addr,
    void* dst_dram_addr,
    size_t size
) {
    // 1. 刷新可能缓存了目标地址的所有缓存行
    cache_flush_range(dst_dram_addr, size);
    
    // 2. 等待刷新完成
    wait_cache_flush_complete();
    
    // 3. 启动DMA传输
    dma_desc_t desc = {
        .src = src_sram_addr,
        .dst = dst_dram_addr,
        .len = size,
        .flags = DMA_FLAG_WRITE_BACK
    };
    dma_start_transfer(&desc);
    
    // 4. 等待DMA完成
    dma_wait_complete();
    
    // 5. 失效相关缓存，确保后续读取获得最新数据
    cache_invalidate_range(dst_dram_addr, size);
}

// 场景2：DMA读取内存前，确保数据已写回
void dma_read_with_cache_sync(
    void* src_dram_addr,
    void* dst_sram_addr,
    size_t size
) {
    // 1. 刷新源地址范围的所有脏数据
    cache_flush_range(src_dram_addr, size);
    
    // 2. 等待刷新完成
    wait_cache_flush_complete();
    
    // 3. 启动DMA传输
    dma_desc_t desc = {
        .src = src_dram_addr,
        .dst = dst_sram_addr,
        .len = size,
        .flags = DMA_FLAG_READ
    };
    dma_start_transfer(&desc);
}

// 硬件实现：DMA控制器与缓存的接口
module DMA_CacheInterface (
    input wire clk,
    input wire rst_n,
    
    // DMA请求
    input wire dma_start,
    input wire [31:0] dma_src_addr,
    input wire [31:0] dma_dst_addr,
    input wire [15:0] dma_length,
    input wire dma_direction, // 0: read, 1: write
    
    // 缓存控制接口
    output reg cache_flush_req,
    output reg [31:0] cache_flush_addr,
    output reg [15:0] cache_flush_len,
    input wire cache_flush_done,
    
    output reg cache_inv_req,
    output reg [31:0] cache_inv_addr,
    output reg [15:0] cache_inv_len,
    input wire cache_inv_done,
    
    // DMA引擎接口
    output reg dma_go,
    input wire dma_done
);

    reg [2:0] state;
    localparam IDLE = 0, FLUSH = 1, WAIT_FLUSH = 2, 
               DMA_TRANS = 3, INVALIDATE = 4;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            state <= IDLE;
        end else begin
            case (state)
                IDLE: begin
                    if (dma_start) begin
                        if (dma_direction) begin
                            // DMA写：先刷新目标地址
                            cache_flush_req <= 1'b1;
                            cache_flush_addr <= dma_dst_addr;
                            cache_flush_len <= dma_length;
                            state <= WAIT_FLUSH;
                        end else begin
                            // DMA读：先刷新源地址
                            cache_flush_req <= 1'b1;
                            cache_flush_addr <= dma_src_addr;
                            cache_flush_len <= dma_length;
                            state <= WAIT_FLUSH;
                        end
                    end
                end
                
                WAIT_FLUSH: begin
                    cache_flush_req <= 1'b0;
                    if (cache_flush_done) begin
                        dma_go <= 1'b1;
                        state <= DMA_TRANS;
                    end
                end
                
                DMA_TRANS: begin
                    dma_go <= 1'b0;
                    if (dma_done) begin
                        if (dma_direction) begin
                            // DMA写完成后，失效目标缓存
                            cache_inv_req <= 1'b1;
                            cache_inv_addr <= dma_dst_addr;
                            cache_inv_len <= dma_length;
                            state <= INVALIDATE;
                        end else begin
                            state <= IDLE;
                        end
                    end
                end
                
                INVALIDATE: begin
                    cache_inv_req <= 1'b0;
                    if (cache_inv_done) begin
                        state <= IDLE;
                    end
                end
            endcase
        end
    end
endmodule
            </div>

            <h3>5.5 DMA设计</h3>
            
            <p>DMA（直接内存访问）控制器是NPU中的数据搬运引擎，负责在片外DRAM和片上SRAM之间高效传输数据。</p>

            <h4>5.5.1 NPU DMA特性</h4>
            <div class="code-block">
NPU DMA的特殊需求：

1. 多维寻址能力
   - 支持2D/3D/4D张量传输
   - 灵活的步长（stride）和填充（padding）
   - 数据重排（如NHWC→NCHW）

2. 高带宽利用率
   - 多通道并行传输
   - 突发传输优化
   - 带宽聚合

3. 与计算的协同
   - 描述符链接
   - 事件触发机制
   - 双缓冲/多缓冲支持
            </div>

            <h4>5.5.2 多维DMA引擎</h4>
            <div class="code-block">
// 支持多维张量传输的DMA引擎
module TensorDMA #(
    parameter ADDR_WIDTH = 32,
    parameter DATA_WIDTH = 256,
    parameter MAX_DIM = 4,
    parameter DESC_DEPTH = 16
)(
    input wire clk,
    input wire rst_n,
    
    // 描述符编程接口
    input wire desc_valid,
    input wire [ADDR_WIDTH-1:0] src_base_addr,
    input wire [ADDR_WIDTH-1:0] dst_base_addr,
    input wire [15:0] dim_size [MAX_DIM-1:0],    // 各维度大小
    input wire [15:0] src_stride [MAX_DIM-1:0],  // 源步长
    input wire [15:0] dst_stride [MAX_DIM-1:0],  // 目标步长
    input wire [2:0] active_dims,                 // 活跃维度数
    output wire desc_ready,
    
    // 内存接口
    output reg mem_rd_req,
    output reg [ADDR_WIDTH-1:0] mem_rd_addr,
    output reg [7:0] mem_rd_len,
    input wire mem_rd_valid,
    input wire [DATA_WIDTH-1:0] mem_rd_data,
    
    output reg mem_wr_req,
    output reg [ADDR_WIDTH-1:0] mem_wr_addr,
    output reg [DATA_WIDTH-1:0] mem_wr_data,
    output reg [7:0] mem_wr_len,
    input wire mem_wr_ready,
    
    // 状态输出
    output reg dma_busy,
    output reg dma_done
);

    // 描述符FIFO
    reg [ADDR_WIDTH-1:0] desc_src_base [DESC_DEPTH-1:0];
    reg [ADDR_WIDTH-1:0] desc_dst_base [DESC_DEPTH-1:0];
    reg [15:0] desc_dim_size [DESC_DEPTH-1:0][MAX_DIM-1:0];
    reg [15:0] desc_src_stride [DESC_DEPTH-1:0][MAX_DIM-1:0];
    reg [15:0] desc_dst_stride [DESC_DEPTH-1:0][MAX_DIM-1:0];
    reg [2:0] desc_active_dims [DESC_DEPTH-1:0];
    reg [3:0] desc_head, desc_tail;
    reg [4:0] desc_count;
    
    // 地址生成器状态
    reg [15:0] dim_counter [MAX_DIM-1:0];
    reg [ADDR_WIDTH-1:0] current_src_addr;
    reg [ADDR_WIDTH-1:0] current_dst_addr;
    reg [2:0] state;
    
    // 描述符入队
    assign desc_ready = (desc_count < DESC_DEPTH);
    
    always @(posedge clk) begin
        if (desc_valid && desc_ready) begin
            desc_src_base[desc_tail] <= src_base_addr;
            desc_dst_base[desc_tail] <= dst_base_addr;
            desc_active_dims[desc_tail] <= active_dims;
            
            integer i;
            for (i = 0; i < MAX_DIM; i = i + 1) begin
                desc_dim_size[desc_tail][i] <= dim_size[i];
                desc_src_stride[desc_tail][i] <= src_stride[i];
                desc_dst_stride[desc_tail][i] <= dst_stride[i];
            end
            
            desc_tail <= desc_tail + 1;
            desc_count <= desc_count + 1;
        end
    end
    
    // 多维地址生成状态机
    localparam IDLE = 0, CALC_ADDR = 1, ISSUE_READ = 2, 
               WAIT_DATA = 3, ISSUE_WRITE = 4, UPDATE_DIM = 5;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            state <= IDLE;
            dma_busy <= 0;
            desc_head <= 0;
            desc_count <= 0;
        end else begin
            case (state)
                IDLE: begin
                    if (desc_count > 0) begin
                        dma_busy <= 1;
                        // 初始化维度计数器
                        integer j;
                        for (j = 0; j < MAX_DIM; j = j + 1) begin
                            dim_counter[j] <= 0;
                        end
                        current_src_addr <= desc_src_base[desc_head];
                        current_dst_addr <= desc_dst_base[desc_head];
                        state <= CALC_ADDR;
                    end
                end
                
                CALC_ADDR: begin
                    // 计算当前传输的地址
                    mem_rd_addr <= current_src_addr;
                    mem_rd_len <= 1; // 简化：每次传输一个元素
                    state <= ISSUE_READ;
                end
                
                ISSUE_READ: begin
                    mem_rd_req <= 1'b1;
                    state <= WAIT_DATA;
                end
                
                WAIT_DATA: begin
                    mem_rd_req <= 1'b0;
                    if (mem_rd_valid) begin
                        mem_wr_data <= mem_rd_data;
                        mem_wr_addr <= current_dst_addr;
                        mem_wr_len <= 1;
                        state <= ISSUE_WRITE;
                    end
                end
                
                ISSUE_WRITE: begin
                    if (mem_wr_ready) begin
                        mem_wr_req <= 1'b1;
                        state <= UPDATE_DIM;
                    end
                end
                
                UPDATE_DIM: begin
                    mem_wr_req <= 1'b0;
                    // 更新多维计数器和地址
                    reg done;
                    done = 1'b1;
                    
                    integer k;
                    for (k = 0; k < MAX_DIM; k = k + 1) begin
                        if (k < desc_active_dims[desc_head]) begin
                            if (dim_counter[k] < desc_dim_size[desc_head][k] - 1) begin
                                dim_counter[k] <= dim_counter[k] + 1;
                                current_src_addr <= current_src_addr + 
                                    desc_src_stride[desc_head][k];
                                current_dst_addr <= current_dst_addr + 
                                    desc_dst_stride[desc_head][k];
                                done = 1'b0;
                                break;
                            end else begin
                                dim_counter[k] <= 0;
                                // 回退到该维度的起始位置
                                current_src_addr <= current_src_addr - 
                                    (desc_dim_size[desc_head][k] - 1) * 
                                    desc_src_stride[desc_head][k];
                                current_dst_addr <= current_dst_addr - 
                                    (desc_dim_size[desc_head][k] - 1) * 
                                    desc_dst_stride[desc_head][k];
                            end
                        end
                    end
                    
                    if (done) begin
                        // 当前描述符完成
                        desc_head <= desc_head + 1;
                        desc_count <= desc_count - 1;
                        dma_done <= 1'b1;
                        state <= IDLE;
                    end else begin
                        state <= CALC_ADDR;
                    end
                end
            endcase
        end
    end
endmodule

// 数据布局转换DMA
module LayoutTransformDMA #(
    parameter DATA_WIDTH = 8,
    parameter MAX_CHANNEL = 1024,
    parameter MAX_HEIGHT = 1024,
    parameter MAX_WIDTH = 1024
)(
    input wire clk,
    input wire rst_n,
    
    // 配置接口
    input wire start,
    input wire [1:0] transform_type, // 0: NHWC->NCHW, 1: NCHW->NHWC
    input wire [9:0] height,
    input wire [9:0] width,
    input wire [9:0] channels,
    input wire [31:0] src_addr,
    input wire [31:0] dst_addr,
    
    // 内存接口
    output reg [31:0] rd_addr,
    output reg rd_req,
    input wire [DATA_WIDTH-1:0] rd_data,
    input wire rd_valid,
    
    output reg [31:0] wr_addr,
    output reg [DATA_WIDTH-1:0] wr_data,
    output reg wr_req,
    input wire wr_ready,
    
    // 状态
    output reg busy,
    output reg done
);

    // 坐标计数器
    reg [9:0] h_cnt, w_cnt, c_cnt;
    
    // 地址计算
    always @(*) begin
        case (transform_type)
            2'b00: begin // NHWC -> NCHW
                // 源地址: base + h*W*C + w*C + c
                rd_addr = src_addr + (h_cnt * width * channels) + 
                         (w_cnt * channels) + c_cnt;
                // 目标地址: base + c*H*W + h*W + w
                wr_addr = dst_addr + (c_cnt * height * width) + 
                         (h_cnt * width) + w_cnt;
            end
            2'b01: begin // NCHW -> NHWC
                // 源地址: base + c*H*W + h*W + w
                rd_addr = src_addr + (c_cnt * height * width) + 
                         (h_cnt * width) + w_cnt;
                // 目标地址: base + h*W*C + w*C + c
                wr_addr = dst_addr + (h_cnt * width * channels) + 
                         (w_cnt * channels) + c_cnt;
            end
            default: begin
                rd_addr = 0;
                wr_addr = 0;
            end
        endcase
    end
    
    // 控制状态机
    reg [2:0] state;
    localparam IDLE = 0, READ = 1, WRITE = 2, NEXT = 3;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            state <= IDLE;
            busy <= 0;
            done <= 0;
        end else begin
            case (state)
                IDLE: begin
                    if (start) begin
                        h_cnt <= 0;
                        w_cnt <= 0;
                        c_cnt <= 0;
                        busy <= 1;
                        done <= 0;
                        state <= READ;
                    end
                end
                
                READ: begin
                    rd_req <= 1;
                    if (rd_valid) begin
                        wr_data <= rd_data;
                        rd_req <= 0;
                        state <= WRITE;
                    end
                end
                
                WRITE: begin
                    if (wr_ready) begin
                        wr_req <= 1;
                        state <= NEXT;
                    end
                end
                
                NEXT: begin
                    wr_req <= 0;
                    // 更新坐标
                    if (c_cnt < channels - 1) begin
                        c_cnt <= c_cnt + 1;
                    end else begin
                        c_cnt <= 0;
                        if (w_cnt < width - 1) begin
                            w_cnt <= w_cnt + 1;
                        end else begin
                            w_cnt <= 0;
                            if (h_cnt < height - 1) begin
                                h_cnt <= h_cnt + 1;
                            end else begin
                                // 完成
                                busy <= 0;
                                done <= 1;
                                state <= IDLE;
                            end
                        end
                    end
                    
                    if (state != IDLE) begin
                        state <= READ;
                    end
                end
            endcase
        end
    end
endmodule
            </div>

            <h4>5.5.3 分散-聚集DMA</h4>
            <div class="code-block">
// 支持分散-聚集操作的DMA控制器
module ScatterGatherDMA #(
    parameter ADDR_WIDTH = 32,
    parameter DATA_WIDTH = 256,
    parameter MAX_SEGMENTS = 64
)(
    input wire clk,
    input wire rst_n,
    
    // 控制接口
    input wire sg_start,
    input wire sg_mode,  // 0: Gather, 1: Scatter
    input wire [5:0] num_segments,
    
    // 段描述符接口
    input wire seg_desc_wr,
    input wire [5:0] seg_desc_addr,
    input wire [ADDR_WIDTH-1:0] seg_src_addr,
    input wire [ADDR_WIDTH-1:0] seg_dst_addr,
    input wire [15:0] seg_length,
    
    // 内存接口
    output reg mem_req,
    output reg mem_wr,
    output reg [ADDR_WIDTH-1:0] mem_addr,
    output reg [DATA_WIDTH-1:0] mem_wdata,
    input wire [DATA_WIDTH-1:0] mem_rdata,
    input wire mem_ready,
    
    // 状态
    output reg sg_busy,
    output reg sg_done
);

    // 段描述符存储
    reg [ADDR_WIDTH-1:0] segment_src [MAX_SEGMENTS-1:0];
    reg [ADDR_WIDTH-1:0] segment_dst [MAX_SEGMENTS-1:0];
    reg [15:0] segment_len [MAX_SEGMENTS-1:0];
    
    // 描述符写入
    always @(posedge clk) begin
        if (seg_desc_wr) begin
            segment_src[seg_desc_addr] <= seg_src_addr;
            segment_dst[seg_desc_addr] <= seg_dst_addr;
            segment_len[seg_desc_addr] <= seg_length;
        end
    end
    
    // 状态机变量
    reg [5:0] current_segment;
    reg [15:0] segment_offset;
    reg [ADDR_WIDTH-1:0] gather_buffer_addr;
    reg [DATA_WIDTH-1:0] data_buffer;
    reg [2:0] state;
    
    localparam IDLE = 0, FETCH_DESC = 1, READ_DATA = 2, 
               WRITE_DATA = 3, NEXT_WORD = 4, NEXT_SEG = 5;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            state <= IDLE;
            sg_busy <= 0;
            sg_done <= 0;
        end else begin
            case (state)
                IDLE: begin
                    if (sg_start) begin
                        sg_busy <= 1;
                        sg_done <= 0;
                        current_segment <= 0;
                        segment_offset <= 0;
                        if (sg_mode == 0) begin
                            // Gather模式：初始化目标地址
                            gather_buffer_addr <= segment_dst[0];
                        end
                        state <= FETCH_DESC;
                    end
                end
                
                FETCH_DESC: begin
                    if (current_segment < num_segments) begin
                        state <= READ_DATA;
                    end else begin
                        // 所有段完成
                        sg_done <= 1;
                        sg_busy <= 0;
                        state <= IDLE;
                    end
                end
                
                READ_DATA: begin
                    mem_req <= 1;
                    mem_wr <= 0;
                    if (sg_mode == 0) begin
                        // Gather: 从分散的源地址读取
                        mem_addr <= segment_src[current_segment] + segment_offset;
                    end else begin
                        // Scatter: 从连续的源地址读取
                        mem_addr <= segment_src[0] + 
                                   (current_segment * segment_len[0]) + segment_offset;
                    end
                    
                    if (mem_ready) begin
                        data_buffer <= mem_rdata;
                        mem_req <= 0;
                        state <= WRITE_DATA;
                    end
                end
                
                WRITE_DATA: begin
                    mem_req <= 1;
                    mem_wr <= 1;
                    mem_wdata <= data_buffer;
                    
                    if (sg_mode == 0) begin
                        // Gather: 写入连续的目标地址
                        mem_addr <= gather_buffer_addr;
                    end else begin
                        // Scatter: 写入分散的目标地址
                        mem_addr <= segment_dst[current_segment] + segment_offset;
                    end
                    
                    if (mem_ready) begin
                        mem_req <= 0;
                        state <= NEXT_WORD;
                    end
                end
                
                NEXT_WORD: begin
                    segment_offset <= segment_offset + (DATA_WIDTH / 8);
                    if (sg_mode == 0) begin
                        gather_buffer_addr <= gather_buffer_addr + (DATA_WIDTH / 8);
                    end
                    
                    if (segment_offset >= segment_len[current_segment]) begin
                        state <= NEXT_SEG;
                    end else begin
                        state <= READ_DATA;
                    end
                end
                
                NEXT_SEG: begin
                    current_segment <= current_segment + 1;
                    segment_offset <= 0;
                    state <= FETCH_DESC;
                end
            endcase
        end
    end
endmodule
            </div>

            <h3>5.6 内存压缩技术</h3>
            
            <p>内存压缩通过减少数据存储和传输的大小，有效提升存储容量和带宽利用率，是优化NPU性能的重要技术。</p>

            <h4>5.6.1 压缩策略概述</h4>
            <div class="code-block">
NPU内存压缩的层次：

1. 权重压缩
   - 量化：FP32→INT8/INT4
   - 剪枝：移除小权重
   - 哈夫曼编码：频率编码
   - 共享权重：权重聚类

2. 激活值压缩
   - 稀疏性压缩：ReLU后大量零值
   - 动态范围压缩：激活值量化
   - 差分编码：相邻值相似

3. 压缩时机
   - 离线压缩：部署前压缩权重
   - 在线压缩：运行时压缩激活值
   - 传输压缩：DRAM↔SRAM传输时压缩
            </div>

            <h4>5.6.2 稀疏性压缩实现</h4>
            <div class="code-block">
// 游程编码（RLE）压缩器
module RLECompressor #(
    parameter DATA_WIDTH = 8,
    parameter MAX_RUN_LENGTH = 255
)(
    input wire clk,
    input wire rst_n,
    
    // 输入接口
    input wire in_valid,
    input wire [DATA_WIDTH-1:0] in_data,
    input wire in_last,
    output wire in_ready,
    
    // 输出接口
    output reg out_valid,
    output reg [DATA_WIDTH-1:0] out_data,
    output reg [7:0] out_count,     // 游程长度
    output reg out_is_zero,         // 标识是否为零游程
    input wire out_ready
);

    // 状态机
    reg [1:0] state;
    localparam IDLE = 0, COLLECT = 1, OUTPUT = 2;
    
    // 游程计数器
    reg [7:0] run_count;
    reg current_is_zero;
    reg [DATA_WIDTH-1:0] current_value;
    
    assign in_ready = (state != OUTPUT);
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            state <= IDLE;
            run_count <= 0;
            out_valid <= 0;
        end else begin
            case (state)
                IDLE: begin
                    if (in_valid) begin
                        current_value <= in_data;
                        current_is_zero <= (in_data == 0);
                        run_count <= 1;
                        state <= COLLECT;
                    end
                end
                
                COLLECT: begin
                    if (in_valid) begin
                        if ((in_data == 0) == current_is_zero && 
                            (!current_is_zero || in_data == current_value) &&
                            run_count < MAX_RUN_LENGTH) begin
                            // 继续当前游程
                            run_count <= run_count + 1;
                            if (!current_is_zero) 
                                current_value <= in_data;
                        end else begin
                            // 游程结束，输出当前游程
                            state <= OUTPUT;
                        end
                        
                        if (in_last && state != OUTPUT) begin
                            state <= OUTPUT;
                        end
                    end
                end
                
                OUTPUT: begin
                    out_valid <= 1;
                    out_data <= current_value;
                    out_count <= run_count;
                    out_is_zero <= current_is_zero;
                    
                    if (out_ready) begin
                        out_valid <= 0;
                        if (in_valid) begin
                            // 开始新的游程
                            current_value <= in_data;
                            current_is_zero <= (in_data == 0);
                            run_count <= 1;
                            state <= COLLECT;
                        end else begin
                            state <= IDLE;
                        end
                    end
                end
            endcase
        end
    end
endmodule

// RLE解压器
module RLEDecompressor #(
    parameter DATA_WIDTH = 8
)(
    input wire clk,
    input wire rst_n,
    
    // 输入接口
    input wire in_valid,
    input wire [DATA_WIDTH-1:0] in_data,
    input wire [7:0] in_count,
    input wire in_is_zero,
    output wire in_ready,
    
    // 输出接口
    output reg out_valid,
    output reg [DATA_WIDTH-1:0] out_data,
    input wire out_ready
);

    reg [7:0] counter;
    reg [DATA_WIDTH-1:0] stored_value;
    reg active;
    
    assign in_ready = !active || (counter == 1 && out_ready);
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            counter <= 0;
            active <= 0;
            out_valid <= 0;
        end else begin
            if (!active && in_valid) begin
                // 接收新的压缩数据
                stored_value <= in_is_zero ? 0 : in_data;
                counter <= in_count;
                active <= 1;
            end
            
            if (active) begin
                out_valid <= 1;
                out_data <= stored_value;
                
                if (out_ready) begin
                    counter <= counter - 1;
                    if (counter == 1) begin
                        active <= 0;
                        out_valid <= 0;
                    end
                end
            end
        end
    end
endmodule

// 位图压缩器（用于2:4稀疏）
module BitmapCompressor #(
    parameter DATA_WIDTH = 8,
    parameter BLOCK_SIZE = 4
)(
    input wire clk,
    input wire rst_n,
    
    // 输入接口
    input wire in_valid,
    input wire [DATA_WIDTH*BLOCK_SIZE-1:0] in_data,
    output wire in_ready,
    
    // 输出接口
    output reg out_valid,
    output reg [BLOCK_SIZE-1:0] out_bitmap,      // 非零位置的位图
    output reg [DATA_WIDTH-1:0] out_values [1:0], // 2个非零值
    input wire out_ready
);

    wire [DATA_WIDTH-1:0] values [BLOCK_SIZE-1:0];
    wire [BLOCK_SIZE-1:0] is_nonzero;
    
    // 解包输入数据
    genvar i;
    generate
        for (i = 0; i < BLOCK_SIZE; i = i + 1) begin
            assign values[i] = in_data[i*DATA_WIDTH +: DATA_WIDTH];
            assign is_nonzero[i] = (values[i] != 0);
        end
    endgenerate
    
    // 计算非零值数量
    wire [2:0] nonzero_count;
    assign nonzero_count = is_nonzero[0] + is_nonzero[1] + 
                          is_nonzero[2] + is_nonzero[3];
    
    assign in_ready = !out_valid || out_ready;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            out_valid <= 0;
        end else begin
            if (in_valid && in_ready) begin
                out_valid <= 1;
                out_bitmap <= is_nonzero;
                
                // 提取非零值（假设正好2个）
                integer j, k;
                k = 0;
                for (j = 0; j < BLOCK_SIZE && k < 2; j = j + 1) begin
                    if (is_nonzero[j]) begin
                        out_values[k] <= values[j];
                        k = k + 1;
                    end
                end
            end else if (out_valid && out_ready) begin
                out_valid <= 0;
            end
        end
    end
endmodule
            </div>

            <h4>5.6.3 压缩系统集成</h4>
            <div class="code-block">
// 带压缩功能的内存控制器
module CompressedMemoryController #(
    parameter ADDR_WIDTH = 32,
    parameter DATA_WIDTH = 256,
    parameter COMPRESSION_RATIO = 4  // 最大压缩比
)(
    input wire clk,
    input wire rst_n,
    
    // CPU/DMA接口
    input wire req_valid,
    input wire req_write,
    input wire [ADDR_WIDTH-1:0] req_addr,
    input wire [DATA_WIDTH-1:0] req_wdata,
    output reg [DATA_WIDTH-1:0] req_rdata,
    output reg req_ready,
    
    // 压缩控制
    input wire compression_enable,
    input wire [1:0] compression_mode, // 0: None, 1: RLE, 2: Bitmap
    
    // DRAM接口
    output reg dram_req,
    output reg dram_write,
    output reg [ADDR_WIDTH-1:0] dram_addr,
    output reg [DATA_WIDTH-1:0] dram_wdata,
    input wire [DATA_WIDTH-1:0] dram_rdata,
    input wire dram_ready,
    
    // 统计信息
    output reg [31:0] compressed_bytes,
    output reg [31:0] uncompressed_bytes
);

    // 元数据表（记录压缩信息）
    reg [15:0] metadata_table [4095:0]; // 4K entries
    // [15:14] - 压缩类型
    // [13:8]  - 压缩块数
    // [7:0]   - 原始块数
    
    // 地址映射
    wire [11:0] block_index = req_addr[23:12];
    wire [15:0] metadata = metadata_table[block_index];
    
    // 压缩/解压缓冲区
    reg [DATA_WIDTH-1:0] compress_buffer;
    reg [DATA_WIDTH/2-1:0] compressed_data;
    reg [7:0] compressed_size;
    
    // 状态机
    reg [2:0] state;
    localparam IDLE = 0, COMPRESS = 1, DECOMPRESS = 2, 
               DRAM_ACCESS = 3, UPDATE_META = 4;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            state <= IDLE;
            req_ready <= 0;
            compressed_bytes <= 0;
            uncompressed_bytes <= 0;
        end else begin
            case (state)
                IDLE: begin
                    if (req_valid) begin
                        if (req_write && compression_enable) begin
                            // 写入时压缩
                            compress_buffer <= req_wdata;
                            state <= COMPRESS;
                        end else if (!req_write && metadata[15:14] != 2'b00) begin
                            // 读取压缩数据需要解压
                            state <= DRAM_ACCESS;
                        end else begin
                            // 直接访问DRAM
                            dram_req <= 1;
                            dram_write <= req_write;
                            dram_addr <= req_addr;
                            dram_wdata <= req_wdata;
                            state <= DRAM_ACCESS;
                        end
                    end
                end
                
                COMPRESS: begin
                    // 简化的压缩逻辑
                    case (compression_mode)
                        2'b01: begin // RLE
                            // 检测零值比例
                            integer zero_count;
                            zero_count = 0;
                            integer i;
                            for (i = 0; i < DATA_WIDTH/8; i = i + 1) begin
                                if (compress_buffer[i*8 +: 8] == 0)
                                    zero_count = zero_count + 1;
                            end
                            
                            if (zero_count > DATA_WIDTH/16) begin
                                // 值得压缩
                                compressed_size <= DATA_WIDTH/8 - zero_count;
                                compressed_bytes <= compressed_bytes + compressed_size;
                                uncompressed_bytes <= uncompressed_bytes + DATA_WIDTH/8;
                            end
                        end
                        
                        2'b10: begin // Bitmap
                            // 2:4稀疏压缩
                            compressed_size <= DATA_WIDTH/16; // 50%压缩
                        end
                        
                        default: begin
                            compressed_size <= DATA_WIDTH/8;
                        end
                    endcase
                    
                    state <= DRAM_ACCESS;
                end
                
                DRAM_ACCESS: begin
                    if (dram_ready) begin
                        dram_req <= 0;
                        if (!req_write) begin
                            req_rdata <= dram_rdata;
                            if (metadata[15:14] != 2'b00) begin
                                state <= DECOMPRESS;
                            end else begin
                                req_ready <= 1;
                                state <= IDLE;
                            end
                        end else begin
                            state <= UPDATE_META;
                        end
                    end
                end
                
                DECOMPRESS: begin
                    // 解压逻辑
                    case (metadata[15:14])
                        2'b01: begin // RLE解压
                            // 恢复零值
                        end
                        2'b10: begin // Bitmap解压
                            // 恢复稀疏数据
                        end
                    endcase
                    
                    req_ready <= 1;
                    state <= IDLE;
                end
                
                UPDATE_META: begin
                    // 更新元数据表
                    metadata_table[block_index] <= {
                        compression_mode,
                        compressed_size[7:2],
                        8'd32  // 原始大小
                    };
                    
                    req_ready <= 1;
                    state <= IDLE;
                end
            endcase
        end
    end
endmodule

// 压缩性能监控
module CompressionMonitor #(
    parameter NUM_ENGINES = 4
)(
    input wire clk,
    input wire rst_n,
    
    // 各压缩引擎的统计输入
    input wire [31:0] compressed_bytes [NUM_ENGINES-1:0],
    input wire [31:0] uncompressed_bytes [NUM_ENGINES-1:0],
    input wire [15:0] compression_cycles [NUM_ENGINES-1:0],
    
    // 性能指标输出
    output reg [15:0] avg_compression_ratio,  // 定点数 8.8
    output reg [31:0] total_saved_bytes,
    output reg [15:0] avg_latency_cycles
);

    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            avg_compression_ratio <= 16'h0100; // 1.0
            total_saved_bytes <= 0;
            avg_latency_cycles <= 0;
        end else begin
            // 计算总压缩比
            reg [63:0] total_compressed, total_uncompressed;
            reg [31:0] total_cycles;
            integer i;
            
            total_compressed = 0;
            total_uncompressed = 0;
            total_cycles = 0;
            
            for (i = 0; i < NUM_ENGINES; i = i + 1) begin
                total_compressed = total_compressed + compressed_bytes[i];
                total_uncompressed = total_uncompressed + uncompressed_bytes[i];
                total_cycles = total_cycles + compression_cycles[i];
            end
            
            // 计算平均压缩比
            if (total_compressed > 0) begin
                avg_compression_ratio <= (total_uncompressed << 8) / total_compressed;
            end
            
            // 计算节省的字节数
            total_saved_bytes <= total_uncompressed - total_compressed;
            
            // 计算平均延迟
            if (total_uncompressed > 0) begin
                avg_latency_cycles <= total_cycles / (total_uncompressed >> 10); // per KB
            end
        end
    end
endmodule
            </div>

            <h3>5.7 习题</h3>
            
            <div class="exercise">
                <h4>习题1：多Bank SRAM地址映射</h4>
                <p>设计一个8-Bank SRAM的地址映射方案，支持3×3卷积的无冲突访问。假设特征图大小为64×64×32（H×W×C），数据类型为INT8。</p>
                <details class="hint">
                    <summary>💡 提示</summary>
                    <p>思考方向：3×3卷积窗口中的9个元素需要同时访问，因此要确保它们映射到不同的Bank。考虑使用斜对角映射或基于坐标和的哈希函数。通道维度也可以参与Bank选择以增加随机性。</p>
                </details>
                <button class="toggle-answer">显示答案</button>
                <div class="answer">
                    <p><strong>解答：</strong></p>
                    <p>为了支持3×3卷积的无冲突访问，需要设计特殊的地址映射函数：</p>
                    
                    <div class="code-block">
// 斜对角Bank映射方案
module Conv3x3BankMapping #(
    parameter BANK_BITS = 3,     // 8 Banks
    parameter HEIGHT = 64,
    parameter WIDTH = 64,
    parameter CHANNELS = 32
)(
    input wire [5:0] h,          // 高度坐标
    input wire [5:0] w,          // 宽度坐标
    input wire [4:0] c,          // 通道坐标
    output wire [2:0] bank_id,
    output wire [13:0] bank_offset
);
    // 斜对角映射函数
    // bank_id = (h + w + c/4) mod 8
    wire [8:0] sum = h + w + (c >> 2);
    assign bank_id = sum[2:0];
    
    // Bank内地址计算
    // offset = (h * WIDTH + w) * (CHANNELS/8) + (c/8)
    wire [11:0] spatial_offset = (h << 6) + w;  // h*64 + w
    wire [13:0] channel_offset = c >> 3;        // c/8
    assign bank_offset = (spatial_offset << 2) + channel_offset;
endmodule

// 验证无冲突访问
module VerifyNoConflict;
    reg conflict_found;
    initial begin
        conflict_found = 0;
        // 测试3×3窗口内的9个位置
        for (int h_base = 0; h_base < 62; h_base++) begin
            for (int w_base = 0; w_base < 62; w_base++) begin
                reg [2:0] banks_used [8:0];
                
                // 计算3×3窗口内每个位置的bank
                for (int dh = 0; dh < 3; dh++) begin
                    for (int dw = 0; dw < 3; dw++) begin
                        int h = h_base + dh;
                        int w = w_base + dw;
                        int idx = dh * 3 + dw;
                        banks_used[idx] = ((h + w) & 7);
                    end
                end
                
                // 检查是否有bank冲突
                for (int i = 0; i < 9; i++) begin
                    for (int j = i+1; j < 9; j++) begin
                        if (banks_used[i] == banks_used[j]) begin
                            conflict_found = 1;
                            $display("Conflict at window (%d,%d)", h_base, w_base);
                        end
                    end
                end
            end
        end
        
        if (!conflict_found) begin
            $display("No conflicts found!");
        end
    end
endmodule
                    </div>
                    
                    <p><strong>关键设计要点：</strong></p>
                    <ol>
                        <li>使用斜对角映射：(h+w+c/4) mod 8，确保3×3窗口内的像素分布到不同Bank</li>
                        <li>通道维度也参与映射，避免不同通道的相同位置冲突</li>
                        <li>每个Bank存储4个通道的数据，提高空间局部性</li>
                        <li>Bank内地址连续存储，便于突发传输</li>
                    </ol>
                </div>
            </div>

            <div class="exercise">
                <h4>习题2：双缓冲预取控制器</h4>
                <p>实现一个支持计算和预取完全重叠的双缓冲控制器，要求计算延迟和预取延迟可以不同。</p>
                <details class="hint">
                    <summary>💡 提示</summary>
                    <p>思考方向：乒乓缓冲的核心是一个缓冲用于计算，另一个用于预取。需要状态机管理两个缓冲的交换。考虑当计算和预取速度不匹配时的处理策略。</p>
                </details>
                <button class="toggle-answer">显示答案</button>
                <div class="answer">
                    <div class="code-block">
module AdaptiveDoubleBuffer #(
    parameter BUFFER_SIZE = 16384,
    parameter DATA_WIDTH = 256
)(
    input wire clk,
    input wire rst_n,
    
    // 计算接口
    input wire compute_start,
    input wire [31:0] compute_cycles,  // 预期计算周期数
    output reg compute_buffer_ready,
    output reg compute_buffer_id,      // 当前计算使用的buffer
    
    // 预取接口
    input wire [31:0] prefetch_addr,
    input wire [15:0] prefetch_size,
    input wire [31:0] prefetch_cycles, // 预期预取周期数
    output reg prefetch_buffer_ready,
    output reg prefetch_buffer_id,     // 当前预取使用的buffer
    
    // 性能监控
    output reg [31:0] idle_cycles,
    output reg [31:0] overlap_cycles
);

    // 状态跟踪
    reg buffer_status [1:0]; // 0: 空闲, 1: 计算中, 2: 预取中, 3: 就绪
    reg [31:0] compute_timer, prefetch_timer;
    reg [31:0] cycle_counter;
    
    // 状态机
    reg [2:0] state;
    localparam INIT = 0, PREFETCH_0 = 1, COMPUTE_0_PREFETCH_1 = 2,
               SWITCH = 3, COMPUTE_1_PREFETCH_0 = 4;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            state <= INIT;
            compute_buffer_id <= 0;
            prefetch_buffer_id <= 0;
            buffer_status[0] <= 0;
            buffer_status[1] <= 0;
            idle_cycles <= 0;
            overlap_cycles <= 0;
            cycle_counter <= 0;
        end else begin
            cycle_counter <= cycle_counter + 1;
            
            // 更新定时器
            if (compute_timer > 0) compute_timer <= compute_timer - 1;
            if (prefetch_timer > 0) prefetch_timer <= prefetch_timer - 1;
            
            case (state)
                INIT: begin
                    // 初始预取到Buffer 0
                    if (prefetch_size > 0) begin
                        prefetch_buffer_id <= 0;
                        prefetch_buffer_ready <= 1;
                        prefetch_timer <= prefetch_cycles;
                        buffer_status[0] <= 2; // 预取中
                        state <= PREFETCH_0;
                    end
                end
                
                PREFETCH_0: begin
                    idle_cycles <= idle_cycles + 1;
                    if (prefetch_timer == 0) begin
                        buffer_status[0] <= 3; // 就绪
                        compute_buffer_ready <= 1;
                        compute_buffer_id <= 0;
                        state <= COMPUTE_0_PREFETCH_1;
                    end
                end
                
                COMPUTE_0_PREFETCH_1: begin
                    overlap_cycles <= overlap_cycles + 1;
                    
                    // 开始在Buffer 0上计算
                    if (compute_start && compute_timer == 0) begin
                        compute_timer <= compute_cycles;
                        buffer_status[0] <= 1; // 计算中
                        compute_buffer_ready <= 0;
                    end
                    
                    // 同时预取到Buffer 1
                    if (prefetch_timer == 0 && buffer_status[1] != 2) begin
                        prefetch_buffer_id <= 1;
                        prefetch_buffer_ready <= 1;
                        prefetch_timer <= prefetch_cycles;
                        buffer_status[1] <= 2; // 预取中
                    end
                    
                    // 检查是否可以切换
                    if (compute_timer == 0 && buffer_status[0] == 1) begin
                        buffer_status[0] <= 0; // 空闲
                    end
                    
                    if (prefetch_timer == 0 && buffer_status[1] == 2) begin
                        buffer_status[1] <= 3; // 就绪
                    end
                    
                    // 两个都完成，切换buffer
                    if (buffer_status[0] == 0 && buffer_status[1] == 3) begin
                        state <= SWITCH;
                    end
                end
                
                SWITCH: begin
                    // 切换计算和预取buffer
                    compute_buffer_id <= 1;
                    prefetch_buffer_id <= 0;
                    compute_buffer_ready <= 1;
                    prefetch_buffer_ready <= 1;
                    state <= COMPUTE_1_PREFETCH_0;
                end
                
                COMPUTE_1_PREFETCH_0: begin
                    overlap_cycles <= overlap_cycles + 1;
                    
                    // 在Buffer 1上计算
                    if (compute_start && compute_timer == 0) begin
                        compute_timer <= compute_cycles;
                        buffer_status[1] <= 1;
                        compute_buffer_ready <= 0;
                    end
                    
                    // 预取到Buffer 0
                    if (prefetch_timer == 0 && buffer_status[0] != 2) begin
                        prefetch_timer <= prefetch_cycles;
                        buffer_status[0] <= 2;
                    end
                    
                    // 完成检查和状态更新
                    if (compute_timer == 0 && buffer_status[1] == 1) begin
                        buffer_status[1] <= 0;
                    end
                    
                    if (prefetch_timer == 0 && buffer_status[0] == 2) begin
                        buffer_status[0] <= 3;
                    end
                    
                    if (buffer_status[1] == 0 && buffer_status[0] == 3) begin
                        state <= SWITCH;
                    end
                end
            endcase
        end
    end
    
    // 性能分析
    wire is_idle = (buffer_status[0] == 0 || buffer_status[0] == 3) && 
                   (buffer_status[1] == 0 || buffer_status[1] == 3) &&
                   (compute_timer == 0) && (prefetch_timer == 0);
    
    always @(posedge clk) begin
        if (is_idle) idle_cycles <= idle_cycles + 1;
    end
endmodule
                    </div>
                    
                    <p><strong>设计特点：</strong></p>
                    <ol>
                        <li>自适应时序：根据实际计算和预取时间动态调整</li>
                        <li>完全重叠：计算和预取可以同时进行</li>
                        <li>性能监控：统计空闲周期和重叠周期</li>
                        <li>灵活切换：自动在两个buffer间切换</li>
                    </ol>
                </div>
            </div>

            <div class="exercise">
                <h4>习题3：缓存一致性协议</h4>
                <p>设计一个简化的缓存一致性协议，支持4个NPU核心共享数据。要求支持独占读、共享读和写操作。</p>
                <details class="hint">
                    <summary>💡 提示</summary>
                    <p>思考方向：参考MESI协议，但可以简化。每个缓存行需要状态位（无效/共享/独占）。设计目录或广播机制来维护一致性。注意处理写回和写无效策略。</p>
                </details>
                <button class="toggle-answer">显示答案</button>
                <div class="answer">
                    <div class="code-block">
// 简化的MSI协议实现
module SimpleMSIProtocol #(
    parameter NUM_CORES = 4,
    parameter ADDR_WIDTH = 32,
    parameter CACHE_LINE_SIZE = 64
)(
    input wire clk,
    input wire rst_n,
    
    // 各核心的请求
    input wire [NUM_CORES-1:0] core_req_valid,
    input wire [1:0] core_req_type [NUM_CORES-1:0], // 0:Read, 1:Write, 2:Upgrade
    input wire [ADDR_WIDTH-1:0] core_req_addr [NUM_CORES-1:0],
    output reg [NUM_CORES-1:0] core_req_grant,
    output reg [1:0] core_resp_type [NUM_CORES-1:0], // 0:Data, 1:Ack, 2:Inv
    
    // 目录接口
    output reg dir_req_valid,
    output reg [ADDR_WIDTH-1:0] dir_req_addr,
    input wire [NUM_CORES-1:0] dir_sharers,  // 共享者位图
    input wire dir_modified,                  // 是否被修改
    input wire [1:0] dir_owner                // 独占所有者
);

    // 状态定义
    localparam INVALID = 0, SHARED = 1, MODIFIED = 2;
    
    // 缓存行状态表
    reg [1:0] cache_state [NUM_CORES-1:0][1023:0]; // 1K条目
    
    // 仲裁逻辑
    reg [1:0] current_requester;
    reg [2:0] protocol_state;
    localparam IDLE = 0, CHECK_DIR = 1, SEND_INV = 2, 
               WAIT_ACK = 3, GRANT_ACCESS = 4;
    
    // 失效确认计数
    reg [NUM_CORES-1:0] inv_ack_pending;
    
    // 获取缓存行索引
    function [9:0] get_index(input [ADDR_WIDTH-1:0] addr);
        get_index = addr[15:6]; // 64B行，1K条目
    endfunction
    
    // 仲裁器：轮询选择请求者
    reg [1:0] rr_pointer;
    always @(posedge clk) begin
        if (protocol_state == IDLE) begin
            reg found;
            found = 0;
            for (int i = 0; i < NUM_CORES && !found; i++) begin
                int idx = (rr_pointer + i) % NUM_CORES;
                if (core_req_valid[idx]) begin
                    current_requester <= idx;
                    rr_pointer <= (idx + 1) % NUM_CORES;
                    found = 1;
                end
            end
        end
    end
    
    // 协议状态机
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            protocol_state <= IDLE;
            core_req_grant <= 0;
            inv_ack_pending <= 0;
        end else begin
            case (protocol_state)
                IDLE: begin
                    if (|core_req_valid) begin
                        // 查询目录
                        dir_req_valid <= 1;
                        dir_req_addr <= core_req_addr[current_requester];
                        protocol_state <= CHECK_DIR;
                    end
                end
                
                CHECK_DIR: begin
                    dir_req_valid <= 0;
                    
                    case (core_req_type[current_requester])
                        2'b00: begin // 读请求
                            if (dir_modified && dir_owner != current_requester) begin
                                // 需要从修改者获取数据
                                core_resp_type[dir_owner] <= 2'b10; // 发送失效
                                inv_ack_pending[dir_owner] <= 1;
                                protocol_state <= WAIT_ACK;
                            end else begin
                                // 可以直接授权
                                protocol_state <= GRANT_ACCESS;
                            end
                        end
                        
                        2'b01: begin // 写请求
                            // 失效所有共享者
                            for (int i = 0; i < NUM_CORES; i++) begin
                                if (i != current_requester && 
                                    (dir_sharers[i] || (dir_modified && dir_owner == i))) begin
                                    core_resp_type[i] <= 2'b10; // 失效
                                    inv_ack_pending[i] <= 1;
                                end
                            end
                            
                            if (|inv_ack_pending) begin
                                protocol_state <= WAIT_ACK;
                            end else begin
                                protocol_state <= GRANT_ACCESS;
                            end
                        end
                        
                        2'b10: begin // 升级请求（S->M）
                            // 失效其他共享者
                            for (int i = 0; i < NUM_CORES; i++) begin
                                if (i != current_requester && dir_sharers[i]) begin
                                    core_resp_type[i] <= 2'b10;
                                    inv_ack_pending[i] <= 1;
                                end
                            end
                            
                            if (|inv_ack_pending) begin
                                protocol_state <= WAIT_ACK;
                            end else begin
                                protocol_state <= GRANT_ACCESS;
                            end
                        end
                    endcase
                end
                
                WAIT_ACK: begin
                    // 等待所有失效确认
                    // 简化：假设立即收到确认
                    inv_ack_pending <= 0;
                    protocol_state <= GRANT_ACCESS;
                end
                
                GRANT_ACCESS: begin
                    // 授权访问
                    core_req_grant[current_requester] <= 1;
                    
                    // 更新本地状态
                    wire [9:0] idx = get_index(core_req_addr[current_requester]);
                    
                    case (core_req_type[current_requester])
                        2'b00: // 读
                            cache_state[current_requester][idx] <= SHARED;
                        2'b01, 2'b10: // 写或升级
                            cache_state[current_requester][idx] <= MODIFIED;
                    endcase
                    
                    protocol_state <= IDLE;
                end
            endcase
            
            // 清除授权信号
            if (protocol_state != GRANT_ACCESS) begin
                core_req_grant <= 0;
            end
        end
    end
endmodule
                    </div>
                    
                    <p><strong>协议特点：</strong></p>
                    <ol>
                        <li><strong>三状态MSI：</strong>Invalid、Shared、Modified</li>
                        <li><strong>目录式管理：</strong>跟踪每个缓存行的共享者</li>
                        <li><strong>失效广播：</strong>写操作前失效所有副本</li>
                        <li><strong>轮询仲裁：</strong>公平处理多个请求</li>
                    </ol>
                </div>
            </div>

            <div class="exercise">
                <h4>习题4：张量DMA传输优化</h4>
                <p>优化一个4D张量（N×C×H×W）的DMA传输，支持padding和stride操作。目标是最小化传输次数。</p>
                <details class="hint">
                    <summary>💡 提示</summary>
                    <p>思考方向：4D张量可以看作多层嵌套的循环。尽量合并连续的内存区域为一次传输。Padding操作可以通过地址计算和零填充实现。Stride操作需要调整地址步进。</p>
                </details>
                <button class="toggle-answer">显示答案</button>
                <div class="answer">
                    <div class="code-block">
module OptimizedTensorDMA #(
    parameter ADDR_WIDTH = 32,
    parameter DATA_WIDTH = 256,
    parameter BURST_LEN = 16
)(
    input wire clk,
    input wire rst_n,
    
    // 张量描述
    input wire [15:0] dim_n, dim_c, dim_h, dim_w,
    input wire [3:0] pad_top, pad_bottom, pad_left, pad_right,
    input wire [3:0] stride_h, stride_w,
    input wire [ADDR_WIDTH-1:0] src_addr, dst_addr,
    
    // DMA接口
    output reg dma_req,
    output reg [ADDR_WIDTH-1:0] dma_src,
    output reg [ADDR_WIDTH-1:0] dma_dst,
    output reg [15:0] dma_len,
    output reg dma_2d_mode,
    output reg [15:0] dma_2d_stride,
    input wire dma_done
);

    // 传输优化分析
    reg [2:0] transfer_mode;
    localparam LINEAR = 0, STRIPE_2D = 1, TILE_3D = 2, BLOCK_4D = 3;
    
    // 计算最优传输模式
    always @(*) begin
        // 分析数据布局
        reg is_contiguous_w = (stride_w == 1 && pad_left == 0 && pad_right == 0);
        reg is_contiguous_h = (stride_h == 1 && pad_top == 0 && pad_bottom == 0);
        
        if (is_contiguous_w && is_contiguous_h) begin
            // 可以使用大块传输
            if (dim_w * dim_h <= BURST_LEN * 8) begin
                transfer_mode = STRIPE_2D; // 2D条带传输
            end else begin
                transfer_mode = TILE_3D;   // 3D块传输
            end
        end else if (is_contiguous_w) begin
            transfer_mode = STRIPE_2D;     // 逐行传输
        end else begin
            transfer_mode = LINEAR;        // 逐元素传输
        end
    end
    
    // 传输状态机
    reg [3:0] state;
    reg [15:0] n_idx, c_idx, h_idx, w_idx;
    reg [15:0] h_out, w_out;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            state <= 0;
            dma_req <= 0;
        end else begin
            case (state)
                0: begin // 初始化
                    n_idx <= 0;
                    c_idx <= 0;
                    h_idx <= 0;
                    w_idx <= 0;
                    h_out <= 0;
                    w_out <= 0;
                    state <= 1;
                end
                
                1: begin // 计算传输参数
                    case (transfer_mode)
                        STRIPE_2D: begin
                            // 计算2D传输的源地址
                            reg [31:0] src_offset;
                            src_offset = n_idx * dim_c * dim_h * dim_w +
                                       c_idx * dim_h * dim_w +
                                       h_idx * dim_w;
                            
                            // 处理padding
                            if (h_out < pad_top || h_out >= dim_h + pad_top) begin
                                // Padding区域，跳过
                                state <= 4;
                            end else begin
                                dma_req <= 1;
                                dma_src <= src_addr + src_offset * (DATA_WIDTH/8);
                                dma_dst <= dst_addr + 
                                         (n_idx * dim_c * (dim_h + pad_top + pad_bottom) * 
                                          (dim_w + pad_left + pad_right) +
                                          c_idx * (dim_h + pad_top + pad_bottom) * 
                                          (dim_w + pad_left + pad_right) +
                                          h_out * (dim_w + pad_left + pad_right) + 
                                          pad_left) * (DATA_WIDTH/8);
                                
                                dma_len <= dim_w;
                                dma_2d_mode <= 0;
                                state <= 2;
                            end
                        end
                        
                        TILE_3D: begin
                            // 3D块传输，一次传输多行
                            reg [15:0] rows_to_transfer;
                            rows_to_transfer = (dim_h - h_idx > 16) ? 16 : (dim_h - h_idx);
                            
                            dma_req <= 1;
                            dma_src <= src_addr + 
                                     (n_idx * dim_c * dim_h * dim_w +
                                      c_idx * dim_h * dim_w +
                                      h_idx * dim_w) * (DATA_WIDTH/8);
                            dma_dst <= dst_addr + 
                                     (n_idx * dim_c * (dim_h + pad_top + pad_bottom) * 
                                      (dim_w + pad_left + pad_right) +
                                      c_idx * (dim_h + pad_top + pad_bottom) * 
                                      (dim_w + pad_left + pad_right) +
                                      (h_idx + pad_top) * (dim_w + pad_left + pad_right) + 
                                      pad_left) * (DATA_WIDTH/8);
                            
                            dma_len <= dim_w * rows_to_transfer;
                            dma_2d_mode <= 1;
                            dma_2d_stride <= dim_w + pad_left + pad_right;
                            state <= 2;
                        end
                    endcase
                end
                
                2: begin // 等待DMA完成
                    dma_req <= 0;
                    if (dma_done) begin
                        state <= 3;
                    end
                end
                
                3: begin // 更新索引
                    case (transfer_mode)
                        STRIPE_2D: begin
                            h_idx <= h_idx + stride_h;
                            h_out <= h_out + 1;
                            
                            if (h_idx >= dim_h) begin
                                h_idx <= 0;
                                h_out <= 0;
                                c_idx <= c_idx + 1;
                                
                                if (c_idx >= dim_c) begin
                                    c_idx <= 0;
                                    n_idx <= n_idx + 1;
                                    
                                    if (n_idx >= dim_n) begin
                                        state <= 5; // 完成
                                    end
                                end
                            end
                        end
                        
                        TILE_3D: begin
                            h_idx <= h_idx + 16;
                            
                            if (h_idx >= dim_h) begin
                                h_idx <= 0;
                                c_idx <= c_idx + 1;
                                
                                if (c_idx >= dim_c) begin
                                    c_idx <= 0;
                                    n_idx <= n_idx + 1;
                                    
                                    if (n_idx >= dim_n) begin
                                        state <= 5;
                                    end
                                end
                            end
                        end
                    endcase
                    
                    if (state != 5) state <= 1;
                end
                
                4: begin // 处理padding（填充0）
                    // 简化：假设硬件自动填充0
                    h_out <= h_out + 1;
                    if (h_out >= dim_h + pad_top + pad_bottom) begin
                        h_out <= 0;
                        c_idx <= c_idx + 1;
                        // ... 更新其他索引
                    end
                    state <= 1;
                end
                
                5: begin // 完成
                    // 传输完成
                end
            endcase
        end
    end
endmodule
                    </div>
                    
                    <p><strong>优化策略：</strong></p>
                    <ol>
                        <li><strong>传输模式选择：</strong>根据数据连续性选择最优传输模式</li>
                        <li><strong>2D/3D块传输：</strong>减少DMA请求次数</li>
                        <li><strong>Padding处理：</strong>硬件自动填充，避免传输padding数据</li>
                        <li><strong>Stride优化：</strong>使用2D DMA模式处理stride</li>
                    </ol>
                </div>
            </div>

            <div class="exercise">
                <h4>习题5：压缩算法选择</h4>
                <p>为不同类型的神经网络数据选择合适的压缩算法。考虑权重、激活值和梯度的特点。</p>
                <details class="hint">
                    <summary>💡 提示</summary>
                    <p>思考方向：权重通常有较好的稀疏性和可预测性；激活值在ReLU后有大量零值；梯度可能有较小的动态范围。不同数据类型适合不同的压缩算法（游程编码、位图、哈夫曼编码等）。</p>
                </details>
                <button class="toggle-answer">显示答案</button>
                <div class="answer">
                    <div class="code-block">
// 自适应压缩算法选择器
module AdaptiveCompressionSelector #(
    parameter DATA_WIDTH = 256,
    parameter SAMPLE_SIZE = 1024
)(
    input wire clk,
    input wire rst_n,
    
    // 数据类型
    input wire [1:0] data_type, // 0: Weight, 1: Activation, 2: Gradient
    input wire [2:0] layer_type, // 0: Conv, 1: FC, 2: BN, 3: Attention
    
    // 数据采样输入
    input wire sample_valid,
    input wire [DATA_WIDTH-1:0] sample_data,
    
    // 压缩算法选择输出
    output reg [2:0] selected_algorithm,
    output reg [7:0] algorithm_params,
    output reg selection_done
);

    // 算法定义
    localparam NONE = 0, QUANTIZE = 1, RLE = 2, 
               SPARSE = 3, HUFFMAN = 4, DELTA = 5;
    
    // 统计信息
    reg [31:0] zero_count;
    reg [31:0] unique_values;
    reg [31:0] max_run_length;
    reg [31:0] value_range;
    reg signed [31:0] min_value, max_value;
    reg [31:0] sample_count;
    
    // 统计收集
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            zero_count <= 0;
            sample_count <= 0;
            min_value <= 32'h7FFFFFFF;
            max_value <= 32'h80000000;
        end else if (sample_valid && sample_count < SAMPLE_SIZE) begin
            sample_count <= sample_count + 1;
            
            // 统计零值
            for (int i = 0; i < DATA_WIDTH/32; i++) begin
                if (sample_data[i*32 +: 32] == 0) begin
                    zero_count <= zero_count + 1;
                end
                
                // 更新最大最小值
                signed [31:0] val = sample_data[i*32 +: 32];
                if (val < min_value) min_value <= val;
                if (val > max_value) max_value <= val;
            end
        end
    end
    
    // 算法选择逻辑
    always @(posedge clk) begin
        if (sample_count >= SAMPLE_SIZE && !selection_done) begin
            // 计算统计指标
            reg [15:0] sparsity = (zero_count * 100) / (sample_count * DATA_WIDTH/32);
            value_range = max_value - min_value;
            
            case (data_type)
                2'b00: begin // 权重
                    case (layer_type)
                        3'b000: begin // Conv层权重
                            if (sparsity > 60) begin
                                selected_algorithm <= SPARSE;
                                algorithm_params <= 8'h24; // 2:4稀疏
                            end else begin
                                selected_algorithm <= QUANTIZE;
                                algorithm_params <= 8'h08; // INT8量化
                            end
                        end
                        
                        3'b001: begin // FC层权重
                            // FC层通常稀疏性更高
                            if (sparsity > 70) begin
                                selected_algorithm <= SPARSE;
                                algorithm_params <= 8'h48; // 4:8稀疏
                            end else if (unique_values < 256) begin
                                selected_algorithm <= HUFFMAN;
                                algorithm_params <= 8'h00;
                            end else begin
                                selected_algorithm <= QUANTIZE;
                                algorithm_params <= 8'h04; // INT4量化
                            end
                        end
                        
                        3'b011: begin // Attention层权重
                            // Attention通常需要更高精度
                            selected_algorithm <= QUANTIZE;
                            algorithm_params <= 8'h10; // INT16量化
                        end
                    endcase
                end
                
                2'b01: begin // 激活值
                    if (layer_type == 3'b000 || layer_type == 3'b001) begin
                        // ReLU后激活值有大量零
                        if (sparsity > 50) begin
                            selected_algorithm <= RLE;
                            algorithm_params <= 8'hFF; // 最大游程255
                        end else begin
                            // 动态量化
                            selected_algorithm <= QUANTIZE;
                            algorithm_params <= 8'h88; // 动态INT8
                        end
                    end else if (layer_type == 3'b010) begin // BN层
                        // BN后数据分布较均匀
                        selected_algorithm <= DELTA;
                        algorithm_params <= 8'h01; // 一阶差分
                    end
                end
                
                2'b10: begin // 梯度
                    // 梯度通常很小且稀疏
                    if (sparsity > 80) begin
                        selected_algorithm <= SPARSE;
                        algorithm_params <= 8'h11; // 1:1稀疏（只传非零）
                    end else if (value_range < 65536) begin
                        // 小范围梯度用差分编码
                        selected_algorithm <= DELTA;
                        algorithm_params <= 8'h02; // 二阶差分
                    end else begin
                        selected_algorithm <= QUANTIZE;
                        algorithm_params <= 8'h10; // FP16量化
                    end
                end
            endcase
            
            selection_done <= 1;
        end
    end
    
    // 压缩比预测
    reg [15:0] predicted_ratio;
    always @(*) begin
        case (selected_algorithm)
            QUANTIZE: begin
                case (algorithm_params[3:0])
                    4'h4: predicted_ratio = 16'h0800;  // 8x (INT4)
                    4'h8: predicted_ratio = 16'h0400;  // 4x (INT8)
                    default: predicted_ratio = 16'h0200; // 2x
                endcase
            end
            
            RLE: begin
                // 基于稀疏性预测
                if (sparsity > 75) predicted_ratio = 16'h0600; // 6x
                else if (sparsity > 50) predicted_ratio = 16'h0300; // 3x
                else predicted_ratio = 16'h0150; // 1.5x
            end
            
            SPARSE: begin
                // 基于稀疏模式
                case (algorithm_params)
                    8'h24: predicted_ratio = 16'h0200; // 2x (2:4)
                    8'h48: predicted_ratio = 16'h0200; // 2x (4:8)
                    8'h11: predicted_ratio = sparsity * 16'h0010; // 可变
                endcase
            end
            
            default: predicted_ratio = 16'h0100; // 1x
        endcase
    end
endmodule
                    </div>
                    
                    <p><strong>压缩策略总结：</strong></p>
                    <table>
                        <tr>
                            <th>数据类型</th>
                            <th>特征</th>
                            <th>推荐算法</th>
                            <th>预期压缩比</th>
                        </tr>
                        <tr>
                            <td>Conv权重</td>
                            <td>中等稀疏性，分布集中</td>
                            <td>INT8量化/2:4稀疏</td>
                            <td>2-4x</td>
                        </tr>
                        <tr>
                            <td>FC权重</td>
                            <td>高稀疏性，可剪枝</td>
                            <td>4:8稀疏/INT4量化</td>
                            <td>4-8x</td>
                        </tr>
                        <tr>
                            <td>激活值(ReLU后)</td>
                            <td>大量零值，正值分布</td>
                            <td>RLE/动态量化</td>
                            <td>3-6x</td>
                        </tr>
                        <tr>
                            <td>梯度</td>
                            <td>极稀疏，小值</td>
                            <td>Top-K稀疏/差分编码</td>
                            <td>10-100x</td>
                        </tr>
                    </table>
                </div>
            </div>

            <div class="exercise">
                <h4>习题6：存储带宽优化</h4>
                <p>设计一个存储带宽监控和优化系统，动态调整各个模块的带宽分配。</p>
                <details class="hint">
                    <summary>💡 提示</summary>
                    <p>思考方向：监控各个模块的带宽使用率和队列长度。实现QoS（服务质量）策略，为关键路径分配更多带宽。考虑使用令牌桶或加权轮询算法。</p>
                </details>
                <button class="toggle-answer">显示答案</button>
                <div class="answer">
                    <div class="code-block">
module BandwidthOptimizer #(
    parameter NUM_CLIENTS = 8,
    parameter TOTAL_BANDWIDTH = 1000, // GB/s
    parameter MONITOR_WINDOW = 1024
)(
    input wire clk,
    input wire rst_n,
    
    // 客户端请求
    input wire [NUM_CLIENTS-1:0] client_req,
    input wire [31:0] client_addr [NUM_CLIENTS-1:0],
    input wire [15:0] client_len [NUM_CLIENTS-1:0],
    input wire [2:0] client_priority [NUM_CLIENTS-1:0],
    
    // 带宽分配输出
    output reg [NUM_CLIENTS-1:0] client_grant,
    output reg [9:0] client_bandwidth [NUM_CLIENTS-1:0], // MB/s
    
    // 性能监控
    output reg [31:0] total_throughput,
    output reg [15:0] bandwidth_efficiency // 0-100%
);

    // 带宽使用统计
    reg [31:0] bytes_transferred [NUM_CLIENTS-1:0];
    reg [31:0] request_count [NUM_CLIENTS-1:0];
    reg [31:0] stall_cycles [NUM_CLIENTS-1:0];
    reg [15:0] monitor_cycles;
    
    // QoS参数
    reg [9:0] min_bandwidth [NUM_CLIENTS-1:0];
    reg [9:0] max_bandwidth [NUM_CLIENTS-1:0];
    reg [15:0] burst_allowance [NUM_CLIENTS-1:0];
    
    // 初始化QoS参数
    initial begin
        for (int i = 0; i < NUM_CLIENTS; i++) begin
            min_bandwidth[i] = 50;  // 50 MB/s minimum
            max_bandwidth[i] = 300; // 300 MB/s maximum
            burst_allowance[i] = 100; // 100 MB burst
        end
    end
    
    // 带宽令牌桶
    reg [15:0] tokens [NUM_CLIENTS-1:0];
    reg [3:0] refill_counter;
    
    // 令牌补充
    always @(posedge clk) begin
        refill_counter <= refill_counter + 1;
        if (refill_counter == 0) begin // 每16周期补充一次
            for (int i = 0; i < NUM_CLIENTS; i++) begin
                if (tokens[i] < client_bandwidth[i]) begin
                    tokens[i] <= tokens[i] + (client_bandwidth[i] >> 4);
                end
            end
        end
    end
    
    // 动态带宽分配算法
    reg [2:0] allocation_state;
    reg [31:0] total_demand;
    reg [31:0] allocated_bandwidth;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            allocation_state <= 0;
            monitor_cycles <= 0;
            // 初始均分带宽
            for (int i = 0; i < NUM_CLIENTS; i++) begin
                client_bandwidth[i] <= TOTAL_BANDWIDTH / NUM_CLIENTS;
            end
        end else begin
            monitor_cycles <= monitor_cycles + 1;
            
            // 收集统计信息
            for (int i = 0; i < NUM_CLIENTS; i++) begin
                if (client_req[i]) begin
                    request_count[i] <= request_count[i] + 1;
                    if (!client_grant[i]) begin
                        stall_cycles[i] <= stall_cycles[i] + 1;
                    end
                end
                
                if (client_grant[i]) begin
                    bytes_transferred[i] <= bytes_transferred[i] + client_len[i];
                end
            end
            
            // 周期性重新分配
            if (monitor_cycles >= MONITOR_WINDOW) begin
                monitor_cycles <= 0;
                allocation_state <= 1;
            end
            
            case (allocation_state)
                1: begin // 计算需求
                    total_demand = 0;
                    for (int i = 0; i < NUM_CLIENTS; i++) begin
                        // 基于历史使用计算需求
                        reg [31:0] demand;
                        demand = (bytes_transferred[i] * 1000) / MONITOR_WINDOW;
                        
                        // 考虑停顿率
                        if (stall_cycles[i] > MONITOR_WINDOW/10) begin
                            demand = demand * 15 / 10; // 增加50%
                        end
                        
                        total_demand = total_demand + demand;
                    end
                    allocation_state <= 2;
                end
                
                2: begin // 分配带宽
                    allocated_bandwidth = 0;
                    
                    // 第一轮：保证最小带宽
                    for (int i = 0; i < NUM_CLIENTS; i++) begin
                        client_bandwidth[i] <= min_bandwidth[i];
                        allocated_bandwidth = allocated_bandwidth + min_bandwidth[i];
                    end
                    
                    allocation_state <= 3;
                end
                
                3: begin // 分配剩余带宽
                    reg [31:0] remaining = TOTAL_BANDWIDTH - allocated_bandwidth;
                    
                    // 按优先级和需求比例分配
                    for (int i = 0; i < NUM_CLIENTS; i++) begin
                        reg [31:0] extra;
                        if (total_demand > 0) begin
                            extra = (remaining * bytes_transferred[i]) / total_demand;
                            
                            // 优先级加权
                            extra = extra * (client_priority[i] + 1) / 4;
                            
                            // 限制在最大带宽内
                            if (client_bandwidth[i] + extra > max_bandwidth[i]) begin
                                extra = max_bandwidth[i] - client_bandwidth[i];
                            end
                            
                            client_bandwidth[i] <= client_bandwidth[i] + extra;
                        end
                    end
                    
                    // 清除统计
                    for (int i = 0; i < NUM_CLIENTS; i++) begin
                        bytes_transferred[i] <= 0;
                        request_count[i] <= 0;
                        stall_cycles[i] <= 0;
                    end
                    
                    allocation_state <= 0;
                end
            endcase
        end
    end
    
    // 授权仲裁器
    reg [2:0] rr_pointer;
    always @(posedge clk) begin
        client_grant <= 0;
        
        // 轮询检查有令牌的请求者
        for (int i = 0; i < NUM_CLIENTS; i++) begin
            int idx = (rr_pointer + i) % NUM_CLIENTS;
            if (client_req[idx] && tokens[idx] >= client_len[idx]) begin
                client_grant[idx] <= 1;
                tokens[idx] <= tokens[idx] - client_len[idx];
                rr_pointer <= (idx + 1) % NUM_CLIENTS;
                break;
            end
        end
    end
    
    // 性能计算
    always @(posedge clk) begin
        reg [31:0] total_bytes = 0;
        reg [31:0] total_allocated = 0;
        
        for (int i = 0; i < NUM_CLIENTS; i++) begin
            total_bytes = total_bytes + bytes_transferred[i];
            total_allocated = total_allocated + client_bandwidth[i];
        end
        
        total_throughput <= (total_bytes * 1000) / monitor_cycles;
        bandwidth_efficiency <= (total_throughput * 100) / TOTAL_BANDWIDTH;
    end
endmodule
                    </div>
                    
                    <p><strong>优化策略：</strong></p>
                    <ol>
                        <li><strong>动态带宽分配：</strong>基于历史使用和停顿率</li>
                        <li><strong>QoS保证：</strong>最小/最大带宽限制</li>
                        <li><strong>令牌桶限流：</strong>平滑突发流量</li>
                        <li><strong>优先级支持：</strong>关键路径获得更多带宽</li>
                        <li><strong>效率监控：</strong>实时跟踪带宽利用率</li>
                    </ol>
                </div>
            </div>

            <div class="exercise">
                <h4>习题7：存储层次优化</h4>
                <p>为CNN推理设计一个三级存储层次（L0/L1/L2），优化数据复用。</p>
                <button class="toggle-answer">显示答案</button>
                <div class="answer">
                    <div class="code-block">
// CNN优化的三级存储层次
module CNNMemoryHierarchy #(
    parameter PE_ARRAY_DIM = 16,
    parameter L0_SIZE = 256,      // 每个PE 256B
    parameter L1_SIZE = 16384,    // 每个PE组 16KB
    parameter L2_SIZE = 2097152,  // 全局 2MB
    parameter DATA_WIDTH = 8
)(
    input wire clk,
    input wire rst_n,
    
    // CNN层配置
    input wire [15:0] layer_h, layer_w, layer_c_in, layer_c_out,
    input wire [3:0] kernel_size,
    input wire [3:0] stride,
    
    // 数据流控制
    input wire start_layer,
    output reg layer_done,
    
    // 性能统计
    output reg [31:0] l0_hits, l0_misses,
    output reg [31:0] l1_hits, l1_misses,
    output reg [31:0] l2_hits, l2_misses,
    output reg [31:0] dram_accesses
);

    // 数据复用分析
    reg [2:0] dataflow_mode;
    localparam WEIGHT_STATIONARY = 0, OUTPUT_STATIONARY = 1, 
               ROW_STATIONARY = 2, NO_LOCAL_REUSE = 3;
    
    // 复用距离计算
    function [31:0] calc_reuse_distance(
        input [2:0] data_type, // 0: weight, 1: input, 2: output
        input [2:0] df_mode
    );
        case (df_mode)
            WEIGHT_STATIONARY: begin
                case (data_type)
                    0: calc_reuse_distance = layer_h * layer_w; // 权重复用整个特征图
                    1: calc_reuse_distance = kernel_size * kernel_size; // 输入复用卷积窗口
                    2: calc_reuse_distance = 1; // 输出无复用
                endcase
            end
            
            OUTPUT_STATIONARY: begin
                case (data_type)
                    0: calc_reuse_distance = 1; // 权重无复用
                    1: calc_reuse_distance = layer_c_out; // 输入复用所有输出通道
                    2: calc_reuse_distance = layer_c_in * kernel_size * kernel_size; // 输出累加
                endcase
            end
            
            ROW_STATIONARY: begin
                // 行固定：平衡三种数据的复用
                case (data_type)
                    0: calc_reuse_distance = layer_w / stride; // 权重复用一行
                    1: calc_reuse_distance = kernel_size; // 输入复用卷积行
                    2: calc_reuse_distance = kernel_size * layer_c_in / PE_ARRAY_DIM; // 部分累加
                endcase
            end
        endcase
    endfunction
    
    // 选择最优数据流
    always @(*) begin
        reg [31:0] weight_size = kernel_size * kernel_size * layer_c_in * layer_c_out;
        reg [31:0] input_size = layer_h * layer_w * layer_c_in;
        reg [31:0] output_size = (layer_h/stride) * (layer_w/stride) * layer_c_out;
        
        // 基于层参数选择数据流
        if (kernel_size == 1) begin
            // 1x1卷积，输出固定最优
            dataflow_mode = OUTPUT_STATIONARY;
        end else if (weight_size < L1_SIZE) begin
            // 权重能放入L1，权重固定
            dataflow_mode = WEIGHT_STATIONARY;
        end else if (layer_c_in < 16 && layer_c_out > 256) begin
            // 深度可分离卷积，行固定
            dataflow_mode = ROW_STATIONARY;
        end else begin
            // 默认行固定
            dataflow_mode = ROW_STATIONARY;
        end
    end
    
    // L0缓存管理（每个PE私有）
    reg [DATA_WIDTH-1:0] l0_weight_reg [PE_ARRAY_DIM-1:0];
    reg [DATA_WIDTH-1:0] l0_input_reg [PE_ARRAY_DIM-1:0];
    reg [31:0] l0_partial_sum [PE_ARRAY_DIM-1:0];
    
    // L1缓存管理（PE组共享）
    reg [2:0] l1_allocation_mode;
    reg [15:0] l1_weight_lines;
    reg [15:0] l1_input_lines; 
    reg [15:0] l1_output_lines;
    
    always @(posedge clk) begin
        if (start_layer) begin
            // 根据数据流模式分配L1空间
            case (dataflow_mode)
                WEIGHT_STATIONARY: begin
                    l1_weight_lines <= L1_SIZE * 7 / 10; // 70%给权重
                    l1_input_lines <= L1_SIZE * 2 / 10;  // 20%给输入
                    l1_output_lines <= L1_SIZE * 1 / 10; // 10%给输出
                end
                
                OUTPUT_STATIONARY: begin
                    l1_weight_lines <= L1_SIZE * 2 / 10; // 20%给权重
                    l1_input_lines <= L1_SIZE * 3 / 10;  // 30%给输入
                    l1_output_lines <= L1_SIZE * 5 / 10; // 50%给输出
                end
                
                ROW_STATIONARY: begin
                    l1_weight_lines <= L1_SIZE * 4 / 10; // 40%给权重
                    l1_input_lines <= L1_SIZE * 4 / 10;  // 40%给输入
                    l1_output_lines <= L1_SIZE * 2 / 10; // 20%给输出
                end
            endcase
        end
    end
    
    // L2缓存管理（全局共享）
    reg [2:0] l2_partition_mode;
    reg [20:0] l2_weight_base, l2_input_base, l2_output_base;
    
    // Tile大小计算
    reg [15:0] tile_h, tile_w, tile_c;
    
    always @(posedge clk) begin
        if (start_layer) begin
            // 计算能装入L2的最大tile
            reg [31:0] weight_per_tile, input_per_tile, output_per_tile;
            
            // 尝试不同的tile大小
            for (tile_h = layer_h; tile_h > 0; tile_h = tile_h >> 1) begin
                for (tile_w = layer_w; tile_w > 0; tile_w = tile_w >> 1) begin
                    for (tile_c = layer_c_in; tile_c > 0; tile_c = tile_c >> 1) begin
                        weight_per_tile = kernel_size * kernel_size * tile_c * layer_c_out;
                        input_per_tile = (tile_h + kernel_size - 1) * 
                                       (tile_w + kernel_size - 1) * tile_c;
                        output_per_tile = (tile_h/stride) * (tile_w/stride) * layer_c_out;
                        
                        if (weight_per_tile + input_per_tile + output_per_tile <= L2_SIZE) begin
                            // 找到合适的tile大小
                            break;
                        end
                    end
                    if (weight_per_tile + input_per_tile + output_per_tile <= L2_SIZE) break;
                end
                if (weight_per_tile + input_per_tile + output_per_tile <= L2_SIZE) break;
            end
            
            // 设置L2分区
            l2_weight_base = 0;
            l2_input_base = weight_per_tile;
            l2_output_base = weight_per_tile + input_per_tile;
        end
    end
    
    // 预取调度器
    reg [3:0] prefetch_state;
    reg [15:0] current_tile_h, current_tile_w, current_tile_c;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            prefetch_state <= 0;
            layer_done <= 0;
        end else begin
            case (prefetch_state)
                0: begin // 空闲
                    if (start_layer) begin
                        current_tile_h <= 0;
                        current_tile_w <= 0;
                        current_tile_c <= 0;
                        prefetch_state <= 1;
                    end
                end
                
                1: begin // 预取权重到L2
                    // 预取当前tile的权重
                    dram_accesses <= dram_accesses + 
                        (kernel_size * kernel_size * tile_c * layer_c_out) / 64;
                    prefetch_state <= 2;
                end
                
                2: begin // 预取输入到L2
                    // 预取当前tile的输入（考虑halo）
                    dram_accesses <= dram_accesses + 
                        ((tile_h + kernel_size - 1) * (tile_w + kernel_size - 1) * tile_c) / 64;
                    prefetch_state <= 3;
                end
                
                3: begin // L2到L1传输
                    // 根据数据流模式，将数据从L2搬到L1
                    case (dataflow_mode)
                        WEIGHT_STATIONARY: begin
                            // 权重常驻L1
                            l2_hits <= l2_hits + kernel_size * kernel_size;
                            l1_misses <= l1_misses + kernel_size * kernel_size;
                        end
                        
                        OUTPUT_STATIONARY: begin
                            // 输出块常驻L1
                            l2_hits <= l2_hits + tile_h * tile_w / (stride * stride);
                            l1_misses <= l1_misses + tile_h * tile_w / (stride * stride);
                        end
                    endcase
                    prefetch_state <= 4;
                end
                
                4: begin // L1到L0传输并计算
                    // 模拟PE阵列计算
                    // 统计L0/L1命中率
                    case (dataflow_mode)
                        WEIGHT_STATIONARY: begin
                            l0_hits <= l0_hits + tile_h * tile_w; // 权重复用
                            l1_hits <= l1_hits + tile_h * tile_w * kernel_size * kernel_size;
                        end
                        
                        OUTPUT_STATIONARY: begin
                            l0_hits <= l0_hits + layer_c_in * kernel_size * kernel_size; // 输出复用
                            l1_hits <= l1_hits + layer_c_in;
                        end
                    endcase
                    
                    // 检查是否完成当前tile
                    prefetch_state <= 5;
                end
                
                5: begin // 下一个tile
                    current_tile_w <= current_tile_w + tile_w;
                    if (current_tile_w >= layer_w) begin
                        current_tile_w <= 0;
                        current_tile_h <= current_tile_h + tile_h;
                        
                        if (current_tile_h >= layer_h) begin
                            current_tile_h <= 0;
                            current_tile_c <= current_tile_c + tile_c;
                            
                            if (current_tile_c >= layer_c_in) begin
                                // 层计算完成
                                layer_done <= 1;
                                prefetch_state <= 0;
                            end else begin
                                prefetch_state <= 1;
                            end
                        end else begin
                            prefetch_state <= 2; // 只需预取新的输入
                        end
                    end else begin
                        prefetch_state <= 2; // 只需预取新的输入
                    end
                end
            endcase
        end
    end
endmodule
                    </div>
                    
                    <p><strong>优化要点：</strong></p>
                    <ol>
                        <li><strong>自适应数据流：</strong>根据层类型选择最优数据流模式</li>
                        <li><strong>动态空间分配：</strong>L1/L2空间根据复用模式动态分配</li>
                        <li><strong>Tile优化：</strong>计算最大可容纳的tile尺寸</li>
                        <li><strong>预取流水：</strong>L2预取与L1计算重叠</li>
                        <li><strong>层次化复用：</strong>L0复用最频繁数据，L1复用中等，L2缓存tile</li>
                    </ol>
                </div>
            </div>

            <div class="exercise">
                <h4>习题8：综合设计题</h4>
                <p>设计一个完整的NPU存储子系统，支持8×8 MAC阵列，目标是在7nm工艺下达到1TOPS@1GHz。要求：
                1) 设计存储层次结构
                2) 实现高效的数据搬运
                3) 支持INT8/INT16混合精度
                4) 功耗预算2W</p>
                <button class="toggle-answer">显示答案</button>
                <div class="answer">
                    <div class="code-block">
// NPU存储子系统顶层设计
module NPUMemorySubsystem (
    input wire clk,              // 1GHz
    input wire rst_n,
    
    // 配置接口
    input wire [1:0] precision_mode, // 0: INT8, 1: INT16, 2: Mixed
    input wire [2:0] dataflow_mode,
    
    // 性能监控
    output wire [31:0] actual_tops,
    output wire [15:0] power_estimate_mw
);

    // ===== 1. 存储层次设计 =====
    // L0: 64 × 256b = 2KB (寄存器文件，每个PE)
    // L1: 8 × 8KB = 64KB (PE组本地缓存)
    // L2: 512KB (全局缓存)
    // 带宽需求：1TOPS × 3操作数 × 1B = 3TB/s
    
    // MAC阵列：8×8 = 64 MACs
    // 峰值性能：64 MACs × 2 ops/MAC × 1GHz = 128 GOPS (INT8)
    //           64 MACs × 2 ops/MAC × 0.5GHz = 64 GOPS (INT16)
    
    // ===== 2. 多级SRAM设计 =====
    // L0 Register File (每个PE)
    genvar i, j;
    generate
        for (i = 0; i < 8; i = i + 1) begin
            for (j = 0; j < 8; j = j + 1) begin
                L0_RegFile #(
                    .NUM_REGS(8),
                    .REG_WIDTH(256)
                ) pe_rf (
                    .clk(clk),
                    .rd_en(pe_rf_rd_en[i][j]),
                    .rd_addr(pe_rf_rd_addr[i][j]),
                    .rd_data(pe_rf_rd_data[i][j]),
                    .wr_en(pe_rf_wr_en[i][j]),
                    .wr_addr(pe_rf_wr_addr[i][j]),
                    .wr_data(pe_rf_wr_data[i][j])
                );
            end
        end
    endgenerate
    
    // L1 SRAM (PE行共享，8个8KB banks)
    generate
        for (i = 0; i < 8; i = i + 1) begin
            MultiPortSRAM #(
                .DEPTH(1024),      // 1K × 64B = 64KB
                .WIDTH(512),       // 64B宽
                .NUM_PORTS(8),     // 8个PE访问
                .BANK_COUNT(4)     // 4-way banked
            ) l1_sram (
                .clk(clk),
                .en(l1_en[i]),
                .wr(l1_wr[i]),
                .addr(l1_addr[i]),
                .wdata(l1_wdata[i]),
                .rdata(l1_rdata[i])
            );
        end
    endgenerate
    
    // L2 Global Buffer (512KB, 16-way banked)
    GlobalBuffer #(
        .SIZE(524288),      // 512KB
        .WIDTH(512),        // 64B接口
        .NUM_BANKS(16),
        .NUM_PORTS(8)       // 8个L1可同时访问
    ) l2_buffer (
        .clk(clk),
        .req_valid(l2_req_valid),
        .req_addr(l2_req_addr),
        .req_wr(l2_req_wr),
        .req_data(l2_req_data),
        .resp_valid(l2_resp_valid),
        .resp_data(l2_resp_data)
    );
    
    // ===== 3. 高带宽互连网络 =====
    // L0-L1互连：64个256b端口，聚合带宽 = 64×256b×1GHz = 2TB/s
    // L1-L2互连：8个512b端口，聚合带宽 = 8×512b×1GHz = 512GB/s
    
    CrossbarNetwork #(
        .NUM_MASTERS(64),   // 64个PE
        .NUM_SLAVES(8),     // 8个L1
        .DATA_WIDTH(256)
    ) l0_l1_xbar (
        .clk(clk),
        .master_req(pe_to_l1_req),
        .master_addr(pe_to_l1_addr),
        .master_data(pe_to_l1_data),
        .slave_ack(l1_to_pe_ack),
        .slave_data(l1_to_pe_data)
    );
    
    // ===== 4. 智能DMA引擎 =====
    IntelligentDMA #(
        .NUM_CHANNELS(4),
        .ADDR_WIDTH(32),
        .MAX_2D_SIZE(256)
    ) dma_engine (
        .clk(clk),
        .rst_n(rst_n),
        
        // 描述符接口
        .desc_valid(dma_desc_valid),
        .desc_2d_mode(dma_2d_mode),
        .desc_src_addr(dma_src_addr),
        .desc_dst_addr(dma_dst_addr),
        .desc_x_size(dma_x_size),
        .desc_y_size(dma_y_size),
        .desc_src_stride(dma_src_stride),
        .desc_dst_stride(dma_dst_stride),
        
        // L2接口
        .l2_req(dma_l2_req),
        .l2_addr(dma_l2_addr),
        .l2_wdata(dma_l2_wdata),
        .l2_rdata(l2_dma_rdata),
        
        // DRAM接口
        .dram_req(dma_dram_req),
        .dram_addr(dma_dram_addr),
        .dram_wdata(dma_dram_wdata),
        .dram_rdata(dram_dma_rdata)
    );
    
    // ===== 5. 混合精度支持 =====
    MixedPrecisionController #(
        .MAC_ARRAY_DIM(8)
    ) prec_ctrl (
        .clk(clk),
        .precision_mode(precision_mode),
        .weight_precision(weight_prec),
        .activation_precision(act_prec),
        
        // PE配置输出
        .pe_mode(pe_precision_mode),
        .pe_grouping(pe_group_config)
    );
    
    // ===== 6. 功耗优化控制 =====
    PowerController #(
        .NUM_DOMAINS(4)     // L0, L1, L2, DMA
    ) pwr_ctrl (
        .clk(clk),
        .rst_n(rst_n),
        
        // 活动监控
        .l0_active(|pe_rf_rd_en),
        .l1_active(|l1_en),
        .l2_active(|l2_req_valid),
        .dma_active(dma_busy),
        
        // 功耗控制
        .clock_gate_en(clk_gate_en),
        .voltage_scale(vdd_scale),
        .power_gate_en(pwr_gate_en),
        
        // 功耗估计
        .power_estimate(power_estimate_mw)
    );
    
    // ===== 7. 数据流协调器 =====
    DataflowOrchestrator orch (
        .clk(clk),
        .rst_n(rst_n),
        .dataflow_mode(dataflow_mode),
        
        // 层参数
        .layer_params(layer_params),
        
        // PE控制
        .pe_config(pe_config),
        .pe_enable(pe_enable),
        
        // 存储控制
        .l1_alloc_map(l1_allocation),
        .l2_alloc_map(l2_allocation),
        
        // DMA控制
        .dma_schedule(dma_schedule)
    );
    
    // ===== 8. 性能计数器 =====
    PerformanceCounters perf_cnt (
        .clk(clk),
        .rst_n(rst_n),
        
        // 输入事件
        .mac_active(mac_active),
        .l0_hit(l0_cache_hit),
        .l1_hit(l1_cache_hit),
        .l2_hit(l2_cache_hit),
        .dram_access(dram_access),
        
        // 输出统计
        .total_ops(total_operations),
        .actual_tops(actual_tops),
        .bandwidth_utilization(bw_util),
        .cache_hit_rate(cache_hit_rate)
    );
    
    // ===== 功耗分解（2W预算）=====
    // MAC阵列：~800mW (40%)
    // L0 (RegFile)：~200mW (10%)
    // L1 SRAM：~400mW (20%)
    // L2 SRAM：~300mW (15%)
    // 互连网络：~200mW (10%)
    // 控制逻辑：~100mW (5%)
    
endmodule

// 关键子模块：智能预取器
module SmartPrefetcher #(
    parameter ADDR_WIDTH = 32,
    parameter PATTERN_DEPTH = 8
)(
    input wire clk,
    input wire rst_n,
    
    // 访问监控
    input wire access_valid,
    input wire [ADDR_WIDTH-1:0] access_addr,
    
    // 预取输出
    output reg prefetch_req,
    output reg [ADDR_WIDTH-1:0] prefetch_addr,
    output reg [7:0] prefetch_len,
    
    // 模式识别
    output reg [2:0] detected_pattern // 0:Sequential, 1:Strided, 2:2D
);

    // 访问历史
    reg [ADDR_WIDTH-1:0] addr_history [PATTERN_DEPTH-1:0];
    reg [31:0] stride_history [PATTERN_DEPTH-2:0];
    reg [3:0] history_ptr;
    
    // 模式检测
    always @(posedge clk) begin
        if (access_valid) begin
            // 更新历史
            addr_history[history_ptr] <= access_addr;
            history_ptr <= (history_ptr + 1) % PATTERN_DEPTH;
            
            // 计算步长
            if (history_ptr > 0) begin
                stride_history[history_ptr-1] <= 
                    access_addr - addr_history[history_ptr-1];
            end
            
            // 检测模式
            if (history_ptr >= 3) begin
                if (stride_history[history_ptr-1] == stride_history[history_ptr-2] &&
                    stride_history[history_ptr-2] == stride_history[history_ptr-3]) begin
                    // 固定步长模式
                    detected_pattern <= 1;
                    prefetch_req <= 1;
                    prefetch_addr <= access_addr + stride_history[history_ptr-1];
                    prefetch_len <= 8; // 预取8个元素
                end
            end
        end
    end
endmodule
                    </div>
                    
                    <p><strong>设计总结：</strong></p>
                    <table>
                        <tr>
                            <th>组件</th>
                            <th>规格</th>
                            <th>带宽</th>
                            <th>功耗</th>
                        </tr>
                        <tr>
                            <td>MAC阵列</td>
                            <td>8×8 INT8/INT16</td>
                            <td>-</td>
                            <td>800mW</td>
                        </tr>
                        <tr>
                            <td>L0 RegFile</td>
                            <td>64×2KB</td>
                            <td>2TB/s</td>
                            <td>200mW</td>
                        </tr>
                        <tr>
                            <td>L1 SRAM</td>
                            <td>8×8KB</td>
                            <td>512GB/s</td>
                            <td>400mW</td>
                        </tr>
                        <tr>
                            <td>L2 Buffer</td>
                            <td>512KB</td>
                            <td>128GB/s</td>
                            <td>300mW</td>
                        </tr>
                        <tr>
                            <td>NoC+DMA</td>
                            <td>-</td>
                            <td>-</td>
                            <td>300mW</td>
                        </tr>
                        <tr>
                            <td><strong>总计</strong></td>
                            <td>-</td>
                            <td>-</td>
                            <td><strong>2000mW</strong></td>
                        </tr>
                    </table>
                    
                    <p><strong>关键设计决策：</strong></p>
                    <ol>
                        <li><strong>存储层次：</strong>三级结构平衡容量、带宽和功耗</li>
                        <li><strong>Banking策略：</strong>L1/L2多体设计减少冲突</li>
                        <li><strong>预取机制：</strong>模式识别的智能预取</li>
                        <li><strong>功耗优化：</strong>细粒度时钟门控和电源门控</li>
                        <li><strong>混合精度：</strong>动态配置支持INT8/INT16</li>
                    </ol>
                </div>
            </div>

            <h3>5.7 Cache与Scratchpad对比</h3>
            
            <p>NPU设计中的一个关键决策是选择Cache还是Scratchpad存储器。两者各有优势，理解其特点对优化NPU存储系统至关重要。</p>

            <h4>5.7.1 架构对比</h4>
            <div class="code-block">
Cache与Scratchpad的根本区别：

1. Cache（硬件管理）
   - 自动的数据加载/替换
   - 透明的地址映射
   - 需要标签存储和比较逻辑
   - 访问延迟不确定（命中/未命中）

2. Scratchpad（软件管理）
   - 显式的数据搬移（DMA）
   - 直接的地址映射
   - 无需标签，面积效率高
   - 访问延迟固定且低

3. NPU的典型选择
   - 主流NPU多采用Scratchpad
   - 原因：可预测的访问模式
   - 软件可精确控制数据布局
            </div>

            <h4>5.7.2 性能与成本分析</h4>
            <div class="code-block">
// Cache实现示例
module SimpleCache #(
    parameter CACHE_SIZE = 32768,    // 32KB
    parameter LINE_SIZE = 64,        // 64字节缓存行
    parameter WAYS = 4               // 4路组相联
)(
    input wire clk,
    input wire rst_n,
    input wire [31:0] addr,
    input wire req_valid,
    output reg [511:0] data_out,
    output reg hit,
    output reg miss
);
    localparam SETS = CACHE_SIZE / (LINE_SIZE * WAYS);
    localparam SET_BITS = $clog2(SETS);
    localparam TAG_BITS = 32 - SET_BITS - $clog2(LINE_SIZE);
    
    // 标签存储（开销：~10-15%容量）
    reg [TAG_BITS-1:0] tags [WAYS-1:0][SETS-1:0];
    reg valid [WAYS-1:0][SETS-1:0];
    reg [1:0] lru [SETS-1:0]; // LRU替换
    
    // 数据存储
    reg [LINE_SIZE*8-1:0] data [WAYS-1:0][SETS-1:0];
    
    // 地址解码
    wire [TAG_BITS-1:0] tag = addr[31:32-TAG_BITS];
    wire [SET_BITS-1:0] set = addr[32-TAG_BITS-1:6];
    
    // 标签比较（关键路径）
    always @(posedge clk) begin
        hit <= 0;
        miss <= 0;
        
        if (req_valid) begin
            for (int i = 0; i < WAYS; i++) begin
                if (valid[i][set] && tags[i][set] == tag) begin
                    hit <= 1;
                    data_out <= data[i][set];
                    // 更新LRU
                end
            end
            
            if (!hit) begin
                miss <= 1;
                // 触发缺失处理
            end
        end
    end
endmodule

// Scratchpad实现示例
module Scratchpad #(
    parameter SIZE = 32768,          // 32KB
    parameter WIDTH = 512            // 512位宽
)(
    input wire clk,
    input wire en,
    input wire wr,
    input wire [13:0] addr,          // 直接地址
    input wire [WIDTH-1:0] wdata,
    output reg [WIDTH-1:0] rdata
);
    // 简单的SRAM阵列
    reg [WIDTH-1:0] mem [0:SIZE/(WIDTH/8)-1];
    
    always @(posedge clk) begin
        if (en) begin
            if (wr)
                mem[addr] <= wdata;
            else
                rdata <= mem[addr];  // 固定1周期延迟
        end
    end
endmodule
            </div>

            <h4>5.7.3 NPU优化的混合方案</h4>
            <div class="code-block">
// 混合存储架构：Scratchpad + 小型Cache
module HybridMemorySystem #(
    parameter SCRATCHPAD_SIZE = 256*1024,  // 256KB Scratchpad
    parameter CACHE_SIZE = 8*1024,         // 8KB Cache（用于不规则访问）
    parameter DATA_WIDTH = 256
)(
    input wire clk,
    input wire rst_n,
    
    // Scratchpad接口（主要数据路径）
    input wire sp_en,
    input wire sp_wr,
    input wire [16:0] sp_addr,
    input wire [DATA_WIDTH-1:0] sp_wdata,
    output wire [DATA_WIDTH-1:0] sp_rdata,
    
    // Cache接口（辅助路径）
    input wire cache_req,
    input wire [31:0] cache_addr,
    output wire cache_hit,
    output wire [DATA_WIDTH-1:0] cache_data
);
    
    // Scratchpad实例（用于规则的张量数据）
    Scratchpad #(
        .SIZE(SCRATCHPAD_SIZE),
        .WIDTH(DATA_WIDTH)
    ) sp_inst (
        .clk(clk),
        .en(sp_en),
        .wr(sp_wr),
        .addr(sp_addr),
        .wdata(sp_wdata),
        .rdata(sp_rdata)
    );
    
    // 小型Cache（用于索引、表格查找等）
    SimpleCache #(
        .CACHE_SIZE(CACHE_SIZE),
        .LINE_SIZE(32),
        .WAYS(2)
    ) cache_inst (
        .clk(clk),
        .rst_n(rst_n),
        .addr(cache_addr),
        .req_valid(cache_req),
        .data_out(cache_data),
        .hit(cache_hit)
    );
endmodule

// 性能对比表
/*
┌─────────────────┬────────────────┬────────────────┬────────────────┐
│     指标        │     Cache      │   Scratchpad   │   混合方案     │
├─────────────────┼────────────────┼────────────────┼────────────────┤
│ 面积效率        │      低        │      高        │      中        │
│ (数据/总面积)   │   (~85%)       │   (~95%)       │   (~92%)       │
├─────────────────┼────────────────┼────────────────┼────────────────┤
│ 访问延迟        │   1-3周期      │    1周期       │   1周期(SP)    │
│                 │   (变化)       │    (固定)      │   1-3周期(Cache)│
├─────────────────┼────────────────┼────────────────┼────────────────┤
│ 功耗            │      高        │      低        │      中        │
│                 │  (标签比较)    │   (直接访问)   │                │
├─────────────────┼────────────────┼────────────────┼────────────────┤
│ 编程复杂度      │      低        │      高        │      中        │
│                 │   (自动)       │   (手动DMA)    │   (混合)       │
├─────────────────┼────────────────┼────────────────┼────────────────┤
│ 适用场景        │  不规则访问    │   规则访问     │   通用NPU      │
│                 │  通用处理器    │   专用加速器   │   灵活性+效率  │
└─────────────────┴────────────────┴────────────────┴────────────────┘
*/
            </div>

            <p>Chisel版本的混合存储系统：</p>
            <div class="code-block">
import chisel3._
import chisel3.util._

class HybridMemorySystem(
    scratchpadSize: Int = 256 * 1024,
    cacheSize: Int = 8 * 1024,
    dataWidth: Int = 256
) extends Module {
    val io = IO(new Bundle {
        // Scratchpad接口
        val sp = new Bundle {
            val en = Input(Bool())
            val wr = Input(Bool())
            val addr = Input(UInt(log2Ceil(scratchpadSize/(dataWidth/8)).W))
            val wdata = Input(UInt(dataWidth.W))
            val rdata = Output(UInt(dataWidth.W))
        }
        
        // Cache接口
        val cache = new Bundle {
            val req = Input(Bool())
            val addr = Input(UInt(32.W))
            val hit = Output(Bool())
            val data = Output(UInt(dataWidth.W))
        }
    })
    
    // Scratchpad模块
    val scratchpad = Module(new Scratchpad(scratchpadSize, dataWidth))
    scratchpad.io <> io.sp
    
    // Cache模块
    val cache = Module(new SimpleCache(cacheSize, dataWidth))
    cache.io.req := io.cache.req
    cache.io.addr := io.cache.addr
    io.cache.hit := cache.io.hit
    io.cache.data := cache.io.data
}

// 优化建议实现
class OptimizedNPUMemory extends Module {
    val io = IO(new Bundle {
        val cmd = Input(new MemoryCommand)
        val status = Output(new MemoryStatus)
    })
    
    // 根据访问模式自动选择存储类型
    val accessPatternDetector = Module(new AccessPatternDetector)
    val memoryAllocator = Module(new DynamicMemoryAllocator)
    
    // 自适应分配策略
    when(accessPatternDetector.io.isRegular) {
        // 规则访问 -> Scratchpad
        memoryAllocator.io.allocType := MemType.Scratchpad
    }.elsewhen(accessPatternDetector.io.isRandom) {
        // 随机访问 -> Cache
        memoryAllocator.io.allocType := MemType.Cache
    }.otherwise {
        // 混合访问 -> 智能分配
        memoryAllocator.io.allocType := MemType.Hybrid
    }
}
            </div>

            <div class="exercise">
                <h4>习题6：Cache vs Scratchpad权衡</h4>
                <p>为一个处理稀疏矩阵乘法的NPU设计存储系统。稀疏数据访问不规则，但计算密集部分访问规则。如何设计？</p>
                <details class="hint">
                    <summary>💡 提示</summary>
                    <p>思考方向：稀疏矩阵的索引访问不规则（适合Cache），但非零元素的值访问可能是连续的（适合Scratchpad）。考虑混合方案：索引用Cache，数据值用Scratchpad。</p>
                </details>
                <button class="toggle-answer">显示答案</button>
                <div class="answer">
                    <div class="code-block">
module SparseMatrixMemorySystem #(
    parameter INDEX_CACHE_SIZE = 16384,     // 16KB索引Cache
    parameter VALUE_SCRATCHPAD_SIZE = 262144, // 256KB值Scratchpad
    parameter DATA_WIDTH = 16
)(
    input wire clk,
    input wire rst_n,
    
    // 稀疏矩阵参数
    input wire [15:0] nnz,  // 非零元素数量
    
    // 索引访问（通过Cache）
    input wire idx_req,
    input wire [31:0] idx_addr,
    output wire idx_hit,
    output wire [31:0] idx_data,
    
    // 值访问（通过Scratchpad）
    input wire val_en,
    input wire [16:0] val_addr,
    output wire [DATA_WIDTH-1:0] val_data
);
    
    // 索引Cache（CSR格式的行指针和列索引）
    IndexCache #(
        .SIZE(INDEX_CACHE_SIZE),
        .LINE_SIZE(64)  // 一次加载多个索引
    ) idx_cache (
        .clk(clk),
        .rst_n(rst_n),
        .req(idx_req),
        .addr(idx_addr),
        .hit(idx_hit),
        .data(idx_data)
    );
    
    // 值Scratchpad（连续存储非零值）
    ValueScratchpad #(
        .SIZE(VALUE_SCRATCHPAD_SIZE),
        .WIDTH(DATA_WIDTH)
    ) val_sp (
        .clk(clk),
        .en(val_en),
        .addr(val_addr),
        .rdata(val_data)
    );
    
    // 预取控制器（基于访问模式）
    SparsePrefetcher prefetcher (
        .clk(clk),
        .rst_n(rst_n),
        .idx_access(idx_req),
        .idx_addr(idx_addr),
        .prefetch_trigger(prefetch_en),
        .prefetch_addr(prefetch_addr)
    );
endmodule
                    </div>
                    
                    <p><strong>设计要点：</strong></p>
                    <ol>
                        <li><strong>混合存储：</strong>索引用Cache处理不规则访问，值用Scratchpad保证带宽</li>
                        <li><strong>预取优化：</strong>基于CSR访问模式的智能预取</li>
                        <li><strong>分离路径：</strong>索引和数据值独立访问，避免冲突</li>
                        <li><strong>带宽匹配：</strong>Scratchpad宽接口匹配计算吞吐率</li>
                    </ol>
                </div>
            </div>
        </section>

        <!-- Chapter 6: RTL设计实现 -->
        <section id="chapter6" class="chapter">
            <h2>第6章：RTL设计实现</h2>
            
            <p>本章详细介绍NPU从架构设计到RTL实现的完整流程，涵盖编码规范、时钟域设计、复位策略、低功耗设计、面积优化和时序收敛等关键技术。</p>

            <h3>6.1 设计流程</h3>
            
            <p>NPU的RTL设计是连接算法架构与物理实现的关键环节，需要遵循严格的设计流程。</p>

            <h4>6.1.1 设计流程概览</h4>
            <div class="code-block">
NPU RTL设计流程：

1. 系统级设计
   └── 定义性能指标：TOPS、精度、功耗
   └── 算法映射：支持的算子、数据流

2. 微架构设计
   └── 计算阵列规模：8×8、16×16等
   └── 存储层次：L0/L1/L2容量和带宽
   └── 数据通路：位宽、流水线级数
   └── 控制架构：指令集、调度器

3. RTL编码
   └── 模块划分和接口定义
   └── 功能实现和时序设计
   └── 参数化和可配置设计

4. 验证与仿真
   └── 功能验证：UVM测试平台
   └── 性能验证：周期精确模型
   └── 形式验证：等价性检查

5. 逻辑综合
   └── 约束定义：时序、面积、功耗
   └── 工艺映射：标准单元库
   └── 优化策略：时序/面积/功耗权衡

6. 物理实现
   └── 布局规划：模块摆放
   └── 时钟树综合：时钟偏斜控制
   └── 布线优化：拥塞和串扰

7. 签核验证
   └── STA：静态时序分析
   └── 功耗分析：IR Drop
   └── DRC/LVS：物理验证
            </div>

            <h4>6.1.2 设计迭代与优化</h4>
            <div class="code-block">
// 设计质量评估框架
module DesignQualityMonitor #(
    parameter DESIGN_NAME = "NPU_TOP"
)(
    // 综合报告输入
    input real target_freq_mhz,
    input real actual_freq_mhz,
    input real target_area_mm2,
    input real actual_area_mm2,
    input real target_power_mw,
    input real actual_power_mw,
    
    // 质量指标输出
    output reg timing_met,
    output reg area_met,
    output reg power_met,
    output reg [7:0] overall_score
);

    // 评估逻辑
    always @(*) begin
        timing_met = (actual_freq_mhz >= target_freq_mhz);
        area_met = (actual_area_mm2 <= target_area_mm2);
        power_met = (actual_power_mw <= target_power_mw);
        
        // 计算综合得分
        real timing_score = (actual_freq_mhz / target_freq_mhz) * 100;
        real area_score = (target_area_mm2 / actual_area_mm2) * 100;
        real power_score = (target_power_mw / actual_power_mw) * 100;
        
        overall_score = (timing_score * 0.4 + 
                        area_score * 0.3 + 
                        power_score * 0.3) / 100 * 255;
    end
    
    // 生成优化建议
    always @(*) begin
        if (!timing_met) begin
            $display("[%s] Timing not met. Suggestions:", DESIGN_NAME);
            $display("  - Increase pipeline stages");
            $display("  - Reduce logic levels");
            $display("  - Optimize critical paths");
        end
        
        if (!area_met) begin
            $display("[%s] Area exceeded. Suggestions:", DESIGN_NAME);
            $display("  - Enable resource sharing");
            $display("  - Reduce data width where possible");
            $display("  - Use memory instead of registers");
        end
        
        if (!power_met) begin
            $display("[%s] Power exceeded. Suggestions:", DESIGN_NAME);
            $display("  - Add more clock gating");
            $display("  - Reduce switching activity");
            $display("  - Consider voltage scaling");
        end
    end
endmodule
            </div>

            <h3>6.2 编码规范</h3>
            
            <p>统一的编码规范是保证代码质量、可读性和可维护性的基础。</p>

            <h4>6.2.1 命名规则</h4>
            <div class="code-block">
// ========== NPU RTL编码规范示例 ==========

// 1. 模块命名：使用大驼峰命名法
module NpuTopModule #(
    parameter ARRAY_SIZE = 16,
    parameter DATA_WIDTH = 8
)(
    // 2. 端口命名规则
    // 时钟信号：clk_前缀
    input  wire                     clk_sys,        // 系统时钟
    input  wire                     clk_noc,        // NoC时钟
    
    // 复位信号：rst_前缀，_n表示低有效
    input  wire                     rst_sys_n,      // 系统复位
    input  wire                     rst_noc_n,      // NoC复位
    
    // 输入信号：_i后缀
    input  wire [DATA_WIDTH-1:0]    weight_data_i,
    input  wire                     weight_valid_i,
    output wire                     weight_ready_o,
    
    // 输出信号：_o后缀
    output wire [31:0]              result_data_o,
    output wire                     result_valid_o,
    input  wire                     result_ready_i,
    
    // 配置寄存器：cfg_前缀
    input  wire [31:0]              cfg_layer_param,
    input  wire [15:0]              cfg_tile_size
);

    // 3. 内部信号命名
    // 寄存器输出：_q后缀
    reg  [DATA_WIDTH-1:0]           weight_buffer_q;
    
    // 寄存器输入：_d后缀
    wire [DATA_WIDTH-1:0]           weight_buffer_d;
    
    // 组合逻辑中间信号：_comb后缀
    wire [DATA_WIDTH-1:0]           partial_sum_comb;
    
    // 控制信号：描述性命名
    wire                            compute_enable;
    wire                            accumulate_start;
    
    // 4. 参数命名：全大写，下划线分隔
    localparam BUFFER_DEPTH = 1024;
    localparam FSM_IDLE = 3'b000;
    localparam FSM_COMPUTE = 3'b001;
    
    // 5. Generate变量：gen_前缀
    genvar gen_i, gen_j;
    
    // 6. 函数命名：小驼峰命名法
    function [7:0] calculateChecksum;
        input [31:0] data;
        begin
            calculateChecksum = data[7:0] ^ data[15:8] ^ 
                               data[23:16] ^ data[31:24];
        end
    endfunction

endmodule
            </div>

            <h4>6.2.2 模块化设计原则</h4>
            <div class="code-block">
// 良好的模块划分示例
module NpuComputeCluster #(
    parameter CLUSTER_ID = 0,
    parameter PE_ROWS = 4,
    parameter PE_COLS = 4
)(
    input  wire         clk,
    input  wire         rst_n,
    
    // 标准化接口
    NpuDataInterface.slave      data_if,
    NpuControlInterface.slave   ctrl_if,
    NpuConfigInterface.slave    cfg_if
);

    // ===== 模块化原则 =====
    // 1. 单一职责：每个模块只负责一个功能
    // 2. 接口清晰：使用SystemVerilog interface
    // 3. 参数化设计：便于复用和配置
    // 4. 层次化组织：自顶向下分解
    
    // 子模块实例化
    genvar row, col;
    generate
        for (row = 0; row < PE_ROWS; row = row + 1) begin : gen_pe_row
            for (col = 0; col < PE_COLS; col = col + 1) begin : gen_pe_col
                ProcessingElement #(
                    .PE_ID(row * PE_COLS + col),
                    .DATA_WIDTH(data_if.DATA_WIDTH)
                ) u_pe (
                    .clk        (clk),
                    .rst_n      (rst_n),
                    .north_i    (pe_north_conn[row][col]),
                    .south_o    (pe_south_conn[row][col]),
                    .west_i     (pe_west_conn[row][col]),
                    .east_o     (pe_east_conn[row][col]),
                    .config_i   (pe_config[row][col])
                );
            end
        end
    endgenerate
    
    // 本地控制器
    ClusterController #(
        .CLUSTER_ID(CLUSTER_ID)
    ) u_controller (
        .clk        (clk),
        .rst_n      (rst_n),
        .ctrl_if    (ctrl_if),
        .pe_enable  (pe_enable),
        .pe_mode    (pe_mode)
    );
    
    // 数据分发网络
    DataDistributionNetwork #(
        .NUM_PE(PE_ROWS * PE_COLS)
    ) u_data_network (
        .clk        (clk),
        .rst_n      (rst_n),
        .data_if    (data_if),
        .pe_data    (pe_data_conn)
    );

endmodule

// SystemVerilog Interface定义
interface NpuDataInterface #(
    parameter DATA_WIDTH = 256,
    parameter ADDR_WIDTH = 32
);
    logic [DATA_WIDTH-1:0]  data;
    logic [ADDR_WIDTH-1:0]  addr;
    logic                   valid;
    logic                   ready;
    
    modport master (
        output data, addr, valid,
        input  ready
    );
    
    modport slave (
        input  data, addr, valid,
        output ready
    );
endinterface
            </div>

            <h4>6.2.3 可综合RTL编码准则</h4>
            <div class="code-block">
// ===== 可综合RTL编码示例 =====

module SynthesizableDesign (
    input  wire         clk,
    input  wire         rst_n,
    input  wire [7:0]   data_in,
    input  wire         data_valid,
    output reg  [15:0]  data_out,
    output reg          data_ready
);

    // 1. 时序逻辑：统一使用非阻塞赋值
    reg [7:0] data_reg_q;
    reg [2:0] state_q;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            data_reg_q <= 8'h00;
            state_q <= 3'b000;
        end else begin
            data_reg_q <= data_in;    // 非阻塞赋值
            state_q <= next_state;     // 非阻塞赋值
        end
    end
    
    // 2. 组合逻辑：使用阻塞赋值，完整的条件覆盖
    reg [2:0] next_state;
    reg [15:0] compute_result;
    
    always @(*) begin
        // 默认赋值，避免锁存器
        next_state = state_q;
        compute_result = 16'h0000;
        data_ready = 1'b0;
        
        case (state_q)
            3'b000: begin  // IDLE
                if (data_valid) begin
                    next_state = 3'b001;
                end
            end
            
            3'b001: begin  // COMPUTE
                compute_result = {data_reg_q, data_in};  // 阻塞赋值
                next_state = 3'b010;
            end
            
            3'b010: begin  // OUTPUT
                data_ready = 1'b1;
                if (data_valid) begin
                    next_state = 3'b001;
                end else begin
                    next_state = 3'b000;
                end
            end
            
            default: begin  // 必须有default分支
                next_state = 3'b000;
            end
        endcase
    end
    
    // 3. 输出寄存器化，改善时序
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            data_out <= 16'h0000;
        end else begin
            data_out <= compute_result;
        end
    end
    
    // 4. 避免的写法示例（注释形式）
    // initial begin              // 不可综合
    //     data_out = 0;
    // end
    
    // always @(data_in) begin    // 不完整的敏感列表
    //     result = data_in + offset;
    // end
    
    // #10 data_out = result;     // 延时语句不可综合

endmodule

// 5. 推荐的参数化移位器实现
module ParametricShifter #(
    parameter WIDTH = 32,
    parameter SHIFT_WIDTH = 5
)(
    input  wire [WIDTH-1:0]         data_in,
    input  wire [SHIFT_WIDTH-1:0]   shift_amount,
    input  wire                     shift_dir,  // 0: left, 1: right
    output wire [WIDTH-1:0]         data_out
);

    // 使用generate实现可配置的移位器
    wire [WIDTH-1:0] shift_stages [SHIFT_WIDTH:0];
    assign shift_stages[0] = data_in;
    
    genvar i;
    generate
        for (i = 0; i < SHIFT_WIDTH; i = i + 1) begin : gen_shift
            assign shift_stages[i+1] = shift_amount[i] ? 
                (shift_dir ? 
                    (shift_stages[i] >> (1 << i)) : 
                    (shift_stages[i] << (1 << i))) : 
                shift_stages[i];
        end
    endgenerate
    
    assign data_out = shift_stages[SHIFT_WIDTH];

endmodule
            </div>

            <h4>6.2.4 RTL编码反例（Anti-patterns）</h4>
            <div class="warning-box">
                <p><strong>⚠️ 常见的RTL编码错误示例：</strong></p>
            </div>
            
            <div class="code-block">
// ❌ 错误示例1：产生锁存器的组合逻辑
module bad_latch_example (
    input wire [1:0] sel,
    input wire [7:0] a, b, c,
    output reg [7:0] out
);
    // 错误：不完整的条件覆盖会产生锁存器
    always @(*) begin
        case (sel)
            2'b00: out = a;
            2'b01: out = b;
            2'b10: out = c;
            // 缺少default或2'b11的情况！
        endcase
    end
endmodule

// ✅ 正确做法：完整的条件覆盖
module good_comb_example (
    input wire [1:0] sel,
    input wire [7:0] a, b, c,
    output reg [7:0] out
);
    always @(*) begin
        case (sel)
            2'b00: out = a;
            2'b01: out = b;
            2'b10: out = c;
            default: out = 8'h00;  // 必须有default
        endcase
    end
endmodule

// ❌ 错误示例2：阻塞与非阻塞赋值混用
module bad_assignment_mix (
    input wire clk, rst_n,
    input wire [7:0] d,
    output reg [7:0] q
);
    reg [7:0] temp;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            temp = 8'h00;    // 错误：时序逻辑中使用阻塞赋值
            q <= 8'h00;
        end else begin
            temp = d;        // 错误：混用赋值类型
            q <= temp;       // 会导致仿真与综合不一致
        end
    end
endmodule

// ✅ 正确做法：时序逻辑统一使用非阻塞赋值
module good_sequential (
    input wire clk, rst_n,
    input wire [7:0] d,
    output reg [7:0] q
);
    reg [7:0] temp;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            temp <= 8'h00;
            q <= 8'h00;
        end else begin
            temp <= d;
            q <= temp;
        end
    end
endmodule

// ❌ 错误示例3：组合逻辑环路
module bad_comb_loop (
    input wire enable,
    input wire [7:0] data_in,
    output wire [7:0] data_out
);
    wire [7:0] internal;
    
    // 错误：创建了组合逻辑环路
    assign internal = enable ? data_in : data_out;
    assign data_out = internal + 1;
    // 这会导致仿真时出现X态传播，综合时出现timing loop
endmodule

// ✅ 正确做法：打破组合环路
module good_registered (
    input wire clk, rst_n,
    input wire enable,
    input wire [7:0] data_in,
    output reg [7:0] data_out
);
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n)
            data_out <= 8'h00;
        else if (enable)
            data_out <= data_in + 1;
    end
endmodule
            </div>

            <div class="info-box">
                <p><strong>这些错误的危害：</strong></p>
                <ul>
                    <li><strong>锁存器：</strong>对毛刺敏感，时序分析困难，功耗高，测试覆盖率低</li>
                    <li><strong>赋值混用：</strong>仿真行为与综合结果不一致，导致硅前验证失效</li>
                    <li><strong>组合环路：</strong>产生振荡，时序无法收敛，芯片功能失效</li>
                    <li><strong>预防措施：</strong>使用lint工具（如Spyglass）在早期发现这些问题</li>
                </ul>
            </div>

            <h3>6.3 时钟域设计</h3>
            
            <p>NPU通常包含多个时钟域，正确的跨时钟域(CDC)设计对系统稳定性至关重要。</p>

            <h4>6.3.1 时钟域划分</h4>
            <div class="code-block">
// NPU典型时钟域划分
module NpuClockDomains (
    // 多时钟输入
    input wire clk_sys,          // 系统时钟 (1GHz)
    input wire clk_noc,          // NoC时钟 (800MHz)
    input wire clk_ddr,          // DDR时钟 (2.4GHz)
    input wire clk_cfg,          // 配置时钟 (100MHz)
    input wire clk_dbg,          // 调试时钟 (50MHz)
    
    input wire rst_n
);

    // ===== 时钟域功能划分 =====
    // 1. 计算域 (clk_sys)
    //    - MAC阵列
    //    - 向量处理单元
    //    - 本地SRAM
    
    // 2. 互连域 (clk_noc)
    //    - 片上网络
    //    - DMA控制器
    //    - 全局缓冲区
    
    // 3. 存储域 (clk_ddr)
    //    - DDR控制器
    //    - PHY接口
    
    // 4. 低速域 (clk_cfg)
    //    - 配置寄存器
    //    - 中断控制器
    //    - 电源管理
    
    // 5. 调试域 (clk_dbg)
    //    - 调试接口
    //    - 性能计数器
    //    - Trace缓冲区

endmodule
            </div>

            <h4>6.3.2 CDC同步器设计</h4>
            <div class="code-block">
// 1. 单比特信号同步器（2级触发器）
module SyncBit #(
    parameter SYNC_STAGES = 2  // 可配置同步级数
)(
    input  wire clk_dst,
    input  wire rst_dst_n,
    input  wire data_in,
    output wire data_out
);

    reg [SYNC_STAGES-1:0] sync_regs;
    
    always @(posedge clk_dst or negedge rst_dst_n) begin
        if (!rst_dst_n) begin
            sync_regs <= {SYNC_STAGES{1'b0}};
        end else begin
            sync_regs <= {sync_regs[SYNC_STAGES-2:0], data_in};
        end
    end
    
    assign data_out = sync_regs[SYNC_STAGES-1];

endmodule

// 2. 多比特数据CDC - 握手协议
module HandshakeCDC #(
    parameter DATA_WIDTH = 32
)(
    // 源时钟域
    input  wire                     clk_src,
    input  wire                     rst_src_n,
    input  wire [DATA_WIDTH-1:0]    data_src,
    input  wire                     valid_src,
    output wire                     ready_src,
    
    // 目标时钟域
    input  wire                     clk_dst,
    input  wire                     rst_dst_n,
    output wire [DATA_WIDTH-1:0]    data_dst,
    output wire                     valid_dst,
    input  wire                     ready_dst
);

    // 源域：数据寄存和请求生成
    reg [DATA_WIDTH-1:0] data_hold_q;
    reg req_q;
    wire ack_sync_src;
    
    always @(posedge clk_src or negedge rst_src_n) begin
        if (!rst_src_n) begin
            data_hold_q <= {DATA_WIDTH{1'b0}};
            req_q <= 1'b0;
        end else begin
            if (valid_src && ready_src) begin
                data_hold_q <= data_src;
                req_q <= 1'b1;
            end else if (ack_sync_src) begin
                req_q <= 1'b0;
            end
        end
    end
    
    assign ready_src = !req_q || ack_sync_src;
    
    // 请求信号同步到目标域
    wire req_sync_dst;
    SyncBit u_req_sync (
        .clk_dst    (clk_dst),
        .rst_dst_n  (rst_dst_n),
        .data_in    (req_q),
        .data_out   (req_sync_dst)
    );
    
    // 目标域：接收数据和应答生成
    reg ack_q;
    reg req_sync_d1;
    
    always @(posedge clk_dst or negedge rst_dst_n) begin
        if (!rst_dst_n) begin
            ack_q <= 1'b0;
            req_sync_d1 <= 1'b0;
        end else begin
            req_sync_d1 <= req_sync_dst;
            
            if (req_sync_dst && !req_sync_d1) begin  // 上升沿检测
                ack_q <= 1'b1;
            end else if (!req_sync_dst) begin
                ack_q <= 1'b0;
            end
        end
    end
    
    assign data_dst = data_hold_q;  // 数据保持稳定
    assign valid_dst = req_sync_dst && !ack_q;
    
    // 应答信号同步回源域
    SyncBit u_ack_sync (
        .clk_dst    (clk_src),
        .rst_dst_n  (rst_src_n),
        .data_in    (ack_q),
        .data_out   (ack_sync_src)
    );

endmodule

// 3. 异步FIFO实现
module AsyncFIFO #(
    parameter DATA_WIDTH = 32,
    parameter ADDR_WIDTH = 4,
    parameter DEPTH = 16
)(
    // 写时钟域
    input  wire                     wr_clk,
    input  wire                     wr_rst_n,
    input  wire                     wr_en,
    input  wire [DATA_WIDTH-1:0]    wr_data,
    output wire                     wr_full,
    
    // 读时钟域
    input  wire                     rd_clk,
    input  wire                     rd_rst_n,
    input  wire                     rd_en,
    output wire [DATA_WIDTH-1:0]    rd_data,
    output wire                     rd_empty
);

    // 双端口RAM
    reg [DATA_WIDTH-1:0] mem [DEPTH-1:0];
    
    // 写指针（二进制和格雷码）
    reg [ADDR_WIDTH:0] wr_ptr_bin_q;
    reg [ADDR_WIDTH:0] wr_ptr_gray_q;
    wire [ADDR_WIDTH:0] wr_ptr_bin_next;
    wire [ADDR_WIDTH:0] wr_ptr_gray_next;
    
    // 读指针（二进制和格雷码）
    reg [ADDR_WIDTH:0] rd_ptr_bin_q;
    reg [ADDR_WIDTH:0] rd_ptr_gray_q;
    wire [ADDR_WIDTH:0] rd_ptr_bin_next;
    wire [ADDR_WIDTH:0] rd_ptr_gray_next;
    
    // 同步后的指针
    wire [ADDR_WIDTH:0] wr_ptr_gray_sync;
    wire [ADDR_WIDTH:0] rd_ptr_gray_sync;
    
    // 二进制转格雷码
    function [ADDR_WIDTH:0] bin2gray(input [ADDR_WIDTH:0] bin);
        bin2gray = bin ^ (bin >> 1);
    endfunction
    
    // 格雷码转二进制
    function [ADDR_WIDTH:0] gray2bin(input [ADDR_WIDTH:0] gray);
        integer i;
        begin
            gray2bin[ADDR_WIDTH] = gray[ADDR_WIDTH];
            for (i = ADDR_WIDTH-1; i >= 0; i = i-1) begin
                gray2bin[i] = gray2bin[i+1] ^ gray[i];
            end
        end
    endfunction
    
    // 写逻辑
    assign wr_ptr_bin_next = wr_ptr_bin_q + (wr_en && !wr_full);
    assign wr_ptr_gray_next = bin2gray(wr_ptr_bin_next);
    
    always @(posedge wr_clk or negedge wr_rst_n) begin
        if (!wr_rst_n) begin
            wr_ptr_bin_q <= 0;
            wr_ptr_gray_q <= 0;
        end else begin
            wr_ptr_bin_q <= wr_ptr_bin_next;
            wr_ptr_gray_q <= wr_ptr_gray_next;
            
            if (wr_en && !wr_full) begin
                mem[wr_ptr_bin_q[ADDR_WIDTH-1:0]] <= wr_data;
            end
        end
    end
    
    // 读逻辑
    assign rd_ptr_bin_next = rd_ptr_bin_q + (rd_en && !rd_empty);
    assign rd_ptr_gray_next = bin2gray(rd_ptr_bin_next);
    
    always @(posedge rd_clk or negedge rd_rst_n) begin
        if (!rd_rst_n) begin
            rd_ptr_bin_q <= 0;
            rd_ptr_gray_q <= 0;
        end else begin
            rd_ptr_bin_q <= rd_ptr_bin_next;
            rd_ptr_gray_q <= rd_ptr_gray_next;
        end
    end
    
    assign rd_data = mem[rd_ptr_bin_q[ADDR_WIDTH-1:0]];
    
    // 指针同步
    SyncBus #(.WIDTH(ADDR_WIDTH+1)) u_wr2rd_sync (
        .clk_dst    (rd_clk),
        .rst_dst_n  (rd_rst_n),
        .data_in    (wr_ptr_gray_q),
        .data_out   (wr_ptr_gray_sync)
    );
    
    SyncBus #(.WIDTH(ADDR_WIDTH+1)) u_rd2wr_sync (
        .clk_dst    (wr_clk),
        .rst_dst_n  (wr_rst_n),
        .data_in    (rd_ptr_gray_q),
        .data_out   (rd_ptr_gray_sync)
    );
    
    // 空满判断
    assign wr_full = (wr_ptr_gray_next == {~rd_ptr_gray_sync[ADDR_WIDTH:ADDR_WIDTH-1], 
                                            rd_ptr_gray_sync[ADDR_WIDTH-2:0]});
    assign rd_empty = (rd_ptr_gray_q == wr_ptr_gray_sync);

endmodule
            </div>

            <h4>6.3.3 CDC方案对比与选择</h4>
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>方案</th>
                            <th>延迟</th>
                            <th>吞吐量</th>
                            <th>面积开销</th>
                            <th>设计复杂度</th>
                            <th>适用场景</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>两级同步器</td>
                            <td>固定2-3周期</td>
                            <td>低</td>
                            <td>最小</td>
                            <td>低</td>
                            <td>单比特控制信号</td>
                        </tr>
                        <tr>
                            <td>握手协议</td>
                            <td>可变(4-10周期)</td>
                            <td>中</td>
                            <td>中等</td>
                            <td>中</td>
                            <td>多比特数据、命令传输</td>
                        </tr>
                        <tr>
                            <td>异步FIFO</td>
                            <td>高(深度相关)</td>
                            <td>高</td>
                            <td>较大</td>
                            <td>高</td>
                            <td>大量连续数据流</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <div class="warning-box">
                <p><strong>⚠️ CDC设计陷阱警告：</strong></p>
                <ul>
                    <li><strong>亚稳态问题：</strong>CDC是芯片设计中最难调试的问题之一，故障现象偶发且难以复现</li>
                    <li><strong>毛刺传播：</strong>组合逻辑输出直接跨时钟域会导致毛刺传播，必须先寄存</li>
                    <li><strong>格雷码要求：</strong>多比特计数器跨时钟域必须使用格雷码，否则会产生错误</li>
                    <li><strong>验证挑战：</strong>常规仿真难以发现CDC问题，需要专门的CDC验证工具</li>
                </ul>
            </div>

            <h3>6.4 复位策略</h3>
            
            <p>合理的复位策略对NPU的可靠性和功能正确性至关重要。需要考虑复位树的分布、同步、时序和功耗。</p>

            <h4>6.4.1 复位类型选择</h4>
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>复位类型</th>
                            <th>优点</th>
                            <th>缺点</th>
                            <th>适用场景</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>同步复位</td>
                            <td>无亚稳态问题、时序容易满足</td>
                            <td>需要时钟、复位延迟大</td>
                            <td>数据通路、状态机</td>
                        </tr>
                        <tr>
                            <td>异步复位</td>
                            <td>响应快、不需要时钟</td>
                            <td>释放时可能产生亚稳态</td>
                            <td>控制寄存器、配置模块</td>
                        </tr>
                        <tr>
                            <td>异步复位同步释放</td>
                            <td>结合两者优点</td>
                            <td>设计复杂度增加</td>
                            <td>推荐的默认选择</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <div class="info-box">
                <p><strong>为什么需要"异步复位同步释放"？</strong></p>
                <p>异步复位的释放边沿如果不同步，会导致严重的时序问题：</p>
                <ul>
                    <li><strong>Recovery时间违例：</strong>复位释放信号相对于时钟的建立时间不足</li>
                    <li><strong>Removal时间违例：</strong>复位释放信号相对于时钟的保持时间不足</li>
                    <li><strong>不同步释放：</strong>不同触发器在不同时钟周期脱离复位，导致状态机进入非法状态</li>
                    <li><strong>最佳实践：</strong>复位信号可以异步置位（立即响应），但必须同步释放（受时钟控制）</li>
                </ul>
            </div>

            <h4>6.4.2 复位同步器设计</h4>
            <div class="code-block">
// 异步复位同步释放电路
module ResetSync (
    input  wire clk,
    input  wire async_rst_n,   // 异步复位输入（低有效）
    output wire sync_rst_n     // 同步复位输出（低有效）
);

    reg [1:0] rst_sync_q;
    
    always @(posedge clk or negedge async_rst_n) begin
        if (!async_rst_n) begin
            rst_sync_q <= 2'b00;   // 异步复位立即生效
        end else begin
            rst_sync_q <= {rst_sync_q[0], 1'b1};  // 同步释放
        end
    end
    
    assign sync_rst_n = rst_sync_q[1];

endmodule

// 复位域划分与管理
module ResetController #(
    parameter NUM_DOMAINS = 4
)(
    input wire clk_sys,
    input wire power_on_rst_n,      // 上电复位
    input wire soft_rst_n,          // 软件复位
    input wire wdt_rst_n,           // 看门狗复位
    
    // 各时钟域的时钟
    input wire [NUM_DOMAINS-1:0] domain_clks,
    
    // 各域的复位输出
    output wire [NUM_DOMAINS-1:0] domain_rst_n
);

    // 合并复位源
    wire global_rst_n = power_on_rst_n & soft_rst_n & wdt_rst_n;
    
    // 为每个时钟域生成同步复位
    genvar i;
    generate
        for (i = 0; i < NUM_DOMAINS; i = i + 1) begin : rst_sync_gen
            ResetSync u_rst_sync (
                .clk         (domain_clks[i]),
                .async_rst_n (global_rst_n),
                .sync_rst_n  (domain_rst_n[i])
            );
        end
    endgenerate

endmodule

// 复位顺序控制器
module ResetSequencer (
    input wire clk,
    input wire rst_n,
    
    // 模块复位输出（按顺序释放）
    output reg rst_pll_n,        // PLL复位
    output reg rst_mem_n,        // 内存控制器复位
    output reg rst_core_n,       // 计算核心复位
    output reg rst_periph_n      // 外设复位
);

    // 状态机状态
    localparam IDLE = 3'b000;
    localparam RST_PLL = 3'b001;
    localparam RST_MEM = 3'b010;
    localparam RST_CORE = 3'b011;
    localparam RST_PERIPH = 3'b100;
    localparam DONE = 3'b101;
    
    reg [2:0] state, next_state;
    reg [7:0] wait_cnt;
    
    // 状态机
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            state <= IDLE;
            wait_cnt <= 0;
        end else begin
            state <= next_state;
            if (state != next_state) begin
                wait_cnt <= 0;
            end else begin
                wait_cnt <= wait_cnt + 1;
            end
        end
    end
    
    // 下一状态逻辑
    always @(*) begin
        next_state = state;
        case (state)
            IDLE: next_state = RST_PLL;
            RST_PLL: if (wait_cnt >= 8'h10) next_state = RST_MEM;
            RST_MEM: if (wait_cnt >= 8'h20) next_state = RST_CORE;
            RST_CORE: if (wait_cnt >= 8'h10) next_state = RST_PERIPH;
            RST_PERIPH: if (wait_cnt >= 8'h08) next_state = DONE;
            DONE: next_state = DONE;
            default: next_state = IDLE;
        endcase
    end
    
    // 复位输出控制
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            rst_pll_n <= 1'b0;
            rst_mem_n <= 1'b0;
            rst_core_n <= 1'b0;
            rst_periph_n <= 1'b0;
        end else begin
            case (state)
                RST_PLL: rst_pll_n <= 1'b1;
                RST_MEM: rst_mem_n <= 1'b1;
                RST_CORE: rst_core_n <= 1'b1;
                RST_PERIPH: rst_periph_n <= 1'b1;
                default: begin
                    // 保持当前状态
                end
            endcase
        end
    end

endmodule
            </div>

            <h4>6.4.3 复位设计最佳实践</h4>
            <div class="info-box">
                <p><strong>复位设计准则：</strong></p>
                <ul>
                    <li>使用异步复位同步释放作为默认方案</li>
                    <li>复位信号要经过时序分析，满足recovery和removal时间</li>
                    <li>大规模设计需要复位树（Reset Tree）进行扇出控制</li>
                    <li>不同功能模块可以有独立的复位控制</li>
                    <li>考虑部分复位（Partial Reset）以降低功耗</li>
                    <li>关键寄存器需要显式复位，非关键路径可以不复位</li>
                </ul>
            </div>

            <div class="exercise">
                <h4>练习 6.4</h4>
                <div class="question">
                    <p><strong>题目：</strong>设计一个支持多种复位源的复位管理器，要求：
                    1) 支持上电复位、软件复位、看门狗复位
                    2) 实现复位优先级管理
                    3) 提供复位状态寄存器供软件查询</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：不同复位源有不同优先级（上电复位>看门狗>软件复位）。使用状态机管理复位序列。复位状态需要保存以供调试。考虑异步复位同步释放的最佳实践。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module ResetManager (
    input wire clk,
    input wire por_n,           // Power-on reset (highest priority)
    input wire soft_rst_req,    // Software reset request
    input wire wdt_rst_n,       // Watchdog reset
    
    // APB接口用于状态查询
    input wire psel,
    input wire penable,
    input wire pwrite,
    input wire [7:0] paddr,
    input wire [31:0] pwdata,
    output reg [31:0] prdata,
    
    // 复位输出
    output wire sys_rst_n
);

    // 复位状态寄存器
    reg [2:0] rst_source;  // 记录复位源
    reg soft_rst_pending;
    
    // 复位源编码
    localparam RST_POR = 3'b001;
    localparam RST_SOFT = 3'b010;
    localparam RST_WDT = 3'b100;
    
    // 软件复位脉冲生成
    reg soft_rst_req_d1;
    wire soft_rst_pulse = soft_rst_req && !soft_rst_req_d1;
    
    always @(posedge clk or negedge por_n) begin
        if (!por_n) begin
            soft_rst_req_d1 <= 1'b0;
            soft_rst_pending <= 1'b0;
            rst_source <= RST_POR;
        end else begin
            soft_rst_req_d1 <= soft_rst_req;
            
            // 软件复位请求锁存
            if (soft_rst_pulse) begin
                soft_rst_pending <= 1'b1;
            end else if (!sys_rst_n) begin
                soft_rst_pending <= 1'b0;
            end
            
            // 复位源记录（优先级：POR > WDT > SOFT）
            if (!por_n) begin
                rst_source <= RST_POR;
            end else if (!wdt_rst_n) begin
                rst_source <= RST_WDT;
            end else if (soft_rst_pending) begin
                rst_source <= RST_SOFT;
            end
        end
    end
    
    // 复位输出生成
    wire rst_combined = por_n & wdt_rst_n & !soft_rst_pending;
    
    // 异步复位同步释放
    ResetSync u_rst_sync (
        .clk         (clk),
        .async_rst_n (rst_combined),
        .sync_rst_n  (sys_rst_n)
    );
    
    // APB读操作
    always @(posedge clk or negedge por_n) begin
        if (!por_n) begin
            prdata <= 32'h0;
        end else if (psel && !pwrite && penable) begin
            case (paddr[7:0])
                8'h00: prdata <= {29'h0, rst_source};  // 复位源状态
                8'h04: prdata <= {31'h0, sys_rst_n};   // 当前复位状态
                default: prdata <= 32'h0;
            endcase
        end
    end

endmodule
                        </div>
                    </div>
                </div>
            </div>

            <h3>6.5 低功耗设计</h3>
            
            <p>NPU的功耗优化是关键设计目标，需要从架构到实现各个层面进行优化。</p>

            <h4>6.5.1 时钟门控（Clock Gating）</h4>
            <div class="code-block">
// 细粒度时钟门控实现
module ClockGatingCell (
    input  wire clk,
    input  wire enable,
    input  wire test_en,  // DFT测试使能
    output wire gclk      // 门控后的时钟
);

    reg enable_latch;
    
    // 低电平锁存器，防止毛刺
    always @(clk or enable or test_en) begin
        if (!clk) begin
            enable_latch <= enable | test_en;
        end
    end
    
    // AND门生成门控时钟
    assign gclk = clk & enable_latch;

endmodule

// MAC阵列的层次化时钟门控
module MACArrayClockGated #(
    parameter ARRAY_SIZE = 16,
    parameter DATA_WIDTH = 8
)(
    input wire clk,
    input wire rst_n,
    input wire array_enable,
    input wire [ARRAY_SIZE-1:0] row_enable,
    input wire [ARRAY_SIZE-1:0] col_enable,
    
    // 数据接口
    input wire [DATA_WIDTH-1:0] act_in [ARRAY_SIZE-1:0],
    input wire [DATA_WIDTH-1:0] weight_in [ARRAY_SIZE-1:0][ARRAY_SIZE-1:0],
    output wire [31:0] acc_out [ARRAY_SIZE-1:0][ARRAY_SIZE-1:0]
);

    // 层次化时钟门控
    wire array_gclk;
    wire [ARRAY_SIZE-1:0] row_gclk;
    
    // 顶层时钟门控
    ClockGatingCell u_array_cg (
        .clk     (clk),
        .enable  (array_enable),
        .test_en (1'b0),
        .gclk    (array_gclk)
    );
    
    // 行级时钟门控
    genvar i, j;
    generate
        for (i = 0; i < ARRAY_SIZE; i = i + 1) begin : row_cg_gen
            ClockGatingCell u_row_cg (
                .clk     (array_gclk),
                .enable  (row_enable[i]),
                .test_en (1'b0),
                .gclk    (row_gclk[i])
            );
            
            // MAC单元实例化
            for (j = 0; j < ARRAY_SIZE; j = j + 1) begin : mac_gen
                wire mac_enable = row_enable[i] & col_enable[j];
                wire mac_gclk;
                
                // 单元级时钟门控（可选）
                ClockGatingCell u_mac_cg (
                    .clk     (row_gclk[i]),
                    .enable  (col_enable[j]),
                    .test_en (1'b0),
                    .gclk    (mac_gclk)
                );
                
                // MAC单元
                MACUnit #(.DATA_WIDTH(DATA_WIDTH)) u_mac (
                    .clk     (mac_gclk),
                    .rst_n   (rst_n),
                    .enable  (1'b1),  // 时钟已门控
                    .a_in    (act_in[i]),
                    .b_in    (weight_in[i][j]),
                    .acc_out (acc_out[i][j])
                );
            end
        end
    endgenerate

endmodule
            </div>

            <div class="info-box">
                <p><strong>时钟门控的功耗节省量化分析：</strong></p>
                <p>以一个32位寄存器为例，假设：</p>
                <ul>
                    <li>时钟频率：1GHz</li>
                    <li>寄存器翻转功耗：0.5pJ/bit/cycle</li>
                    <li>时钟树功耗：0.2pJ/bit/cycle</li>
                    <li>数据变化率：10%（90%时间数据不变）</li>
                </ul>
                <p><strong>不使用时钟门控：</strong></p>
                <ul>
                    <li>动态功耗 = (0.5 + 0.2) × 32 × 1G = 22.4mW</li>
                </ul>
                <p><strong>使用时钟门控后：</strong></p>
                <ul>
                    <li>时钟树功耗降为10%：0.2 × 32 × 1G × 0.1 = 0.64mW</li>
                    <li>寄存器翻转功耗：0.5 × 32 × 1G × 0.1 = 1.6mW</li>
                    <li>总功耗 = 0.64 + 1.6 = 2.24mW</li>
                    <li><strong>功耗节省：90%</strong></li>
                </ul>
                <p>对于包含数千个寄存器的NPU设计，时钟门控可以节省数瓦的功耗。</p>
            </div>

            <h4>6.5.2 操作数隔离（Operand Isolation）</h4>
            <div class="code-block">
// 操作数隔离减少无效翻转
module MACWithIsolation #(
    parameter DATA_WIDTH = 8,
    parameter ACC_WIDTH = 32
)(
    input wire clk,
    input wire rst_n,
    input wire enable,
    
    input wire signed [DATA_WIDTH-1:0] a_in,
    input wire signed [DATA_WIDTH-1:0] b_in,
    output reg signed [ACC_WIDTH-1:0] acc_out
);

    // 操作数隔离
    wire signed [DATA_WIDTH-1:0] a_isolated;
    wire signed [DATA_WIDTH-1:0] b_isolated;
    
    // 当不使能时，将输入置零，减少乘法器内部翻转
    assign a_isolated = enable ? a_in : {DATA_WIDTH{1'b0}};
    assign b_isolated = enable ? b_in : {DATA_WIDTH{1'b0}};
    
    // MAC运算
    wire signed [2*DATA_WIDTH-1:0] mult_result;
    assign mult_result = a_isolated * b_isolated;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            acc_out <= {ACC_WIDTH{1'b0}};
        end else if (enable) begin
            acc_out <= acc_out + {{(ACC_WIDTH-2*DATA_WIDTH){mult_result[2*DATA_WIDTH-1]}}, mult_result};
        end
        // 不使能时保持原值，无需else分支
    end

endmodule
            </div>

            <h4>6.5.3 动态电压频率调节（DVFS）</h4>
            <div class="code-block">
// DVFS控制器
module DVFSController (
    input wire clk,
    input wire rst_n,
    
    // 性能监控输入
    input wire [31:0] workload,      // 当前负载
    input wire [31:0] deadline,      // 截止时间
    
    // 电压频率控制输出
    output reg [2:0] vdd_level,      // 电压等级
    output reg [2:0] freq_level,     // 频率等级
    output reg dvfs_change_req       // 变更请求
);

    // DVFS状态
    localparam DVFS_LOW = 3'b000;    // 0.8V, 200MHz
    localparam DVFS_MID = 3'b001;    // 0.9V, 400MHz
    localparam DVFS_HIGH = 3'b010;   // 1.0V, 600MHz
    localparam DVFS_TURBO = 3'b011;  // 1.1V, 800MHz
    
    reg [2:0] current_level;
    reg [2:0] target_level;
    reg [15:0] change_delay_cnt;
    
    // 负载评估
    wire high_load = (workload > 32'h8000_0000);
    wire mid_load = (workload > 32'h4000_0000) && !high_load;
    wire low_load = (workload <= 32'h4000_0000);
    
    // 目标等级决策
    always @(*) begin
        if (high_load && (deadline < 32'h0000_1000)) begin
            target_level = DVFS_TURBO;
        end else if (high_load) begin
            target_level = DVFS_HIGH;
        end else if (mid_load) begin
            target_level = DVFS_MID;
        end else begin
            target_level = DVFS_LOW;
        end
    end
    
    // DVFS状态机
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            current_level <= DVFS_LOW;
            vdd_level <= DVFS_LOW;
            freq_level <= DVFS_LOW;
            dvfs_change_req <= 1'b0;
            change_delay_cnt <= 16'h0;
        end else begin
            if (current_level != target_level) begin
                if (change_delay_cnt == 16'h0) begin
                    // 发起DVFS变更
                    dvfs_change_req <= 1'b1;
                    change_delay_cnt <= 16'hFFFF;
                    
                    // 电压优先于频率调整
                    if (target_level > current_level) begin
                        vdd_level <= target_level;  // 先升压
                    end else begin
                        freq_level <= target_level; // 先降频
                    end
                end else if (change_delay_cnt == 16'h8000) begin
                    // 完成第二步调整
                    if (target_level > current_level) begin
                        freq_level <= target_level; // 后升频
                    end else begin
                        vdd_level <= target_level;  // 后降压
                    end
                    current_level <= target_level;
                end else if (change_delay_cnt == 16'h0001) begin
                    dvfs_change_req <= 1'b0;
                end
                
                if (change_delay_cnt > 0) begin
                    change_delay_cnt <= change_delay_cnt - 1;
                end
            end
        end
    end

endmodule
            </div>

            <h4>6.5.4 功耗优化技术总结</h4>
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>技术</th>
                            <th>功耗节省</th>
                            <th>实现复杂度</th>
                            <th>适用场景</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>时钟门控</td>
                            <td>20-40%</td>
                            <td>低</td>
                            <td>所有模块</td>
                        </tr>
                        <tr>
                            <td>操作数隔离</td>
                            <td>5-15%</td>
                            <td>低</td>
                            <td>算术单元</td>
                        </tr>
                        <tr>
                            <td>多阈值电压</td>
                            <td>10-20%</td>
                            <td>中</td>
                            <td>关键/非关键路径</td>
                        </tr>
                        <tr>
                            <td>电源门控</td>
                            <td>50-90%</td>
                            <td>高</td>
                            <td>空闲模块</td>
                        </tr>
                        <tr>
                            <td>DVFS</td>
                            <td>30-60%</td>
                            <td>高</td>
                            <td>系统级</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <div class="exercise">
                <h4>练习 6.5</h4>
                <div class="question">
                    <p><strong>题目：</strong>设计一个支持多级电源门控的NPU计算核心，要求：
                    1) 支持核心级、簇级、单元级三级电源门控
                    2) 实现电源开关时序控制
                    3) 处理隔离和状态保持</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：电源门控需要分层次关闭和打开（先关小单元再关大单元）。使用隔离单元防止漏电流。状态保持需要特殊的保持寄存器。注意电源开关的时序控制和rush current。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module PowerGatedNPUCore #(
    parameter NUM_CLUSTERS = 4,
    parameter UNITS_PER_CLUSTER = 16
)(
    input wire clk,
    input wire rst_n,
    
    // 电源控制
    input wire core_power_req,
    input wire [NUM_CLUSTERS-1:0] cluster_power_req,
    input wire [NUM_CLUSTERS-1:0][UNITS_PER_CLUSTER-1:0] unit_power_req,
    
    // 电源状态
    output reg core_powered,
    output reg [NUM_CLUSTERS-1:0] cluster_powered,
    output reg [NUM_CLUSTERS-1:0][UNITS_PER_CLUSTER-1:0] unit_powered
);

    // 电源开关控制信号
    reg core_sleep_n;
    reg core_iso_n;
    reg core_ret_n;
    
    reg [NUM_CLUSTERS-1:0] cluster_sleep_n;
    reg [NUM_CLUSTERS-1:0] cluster_iso_n;
    reg [NUM_CLUSTERS-1:0] cluster_ret_n;
    
    // 电源时序状态机
    localparam PSM_OFF = 3'b000;
    localparam PSM_ISO_ON = 3'b001;
    localparam PSM_RET_ON = 3'b010;
    localparam PSM_PWR_ON = 3'b011;
    localparam PSM_ACTIVE = 3'b100;
    localparam PSM_PWR_OFF = 3'b101;
    localparam PSM_RET_OFF = 3'b110;
    localparam PSM_ISO_OFF = 3'b111;
    
    reg [2:0] core_psm_state;
    reg [7:0] core_psm_timer;
    
    // 核心级电源控制状态机
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            core_psm_state <= PSM_OFF;
            core_psm_timer <= 8'h0;
            core_sleep_n <= 1'b0;
            core_iso_n <= 1'b0;
            core_ret_n <= 1'b0;
            core_powered <= 1'b0;
        end else begin
            case (core_psm_state)
                PSM_OFF: begin
                    if (core_power_req) begin
                        core_psm_state <= PSM_ISO_ON;
                        core_iso_n <= 1'b1;  // 先开启隔离
                        core_psm_timer <= 8'h10;
                    end
                end
                
                PSM_ISO_ON: begin
                    if (core_psm_timer == 0) begin
                        core_psm_state <= PSM_RET_ON;
                        core_ret_n <= 1'b1;  // 开启状态保持
                        core_psm_timer <= 8'h10;
                    end else begin
                        core_psm_timer <= core_psm_timer - 1;
                    end
                end
                
                PSM_RET_ON: begin
                    if (core_psm_timer == 0) begin
                        core_psm_state <= PSM_PWR_ON;
                        core_sleep_n <= 1'b1;  // 开启电源
                        core_psm_timer <= 8'h40;  // 更长的稳定时间
                    end else begin
                        core_psm_timer <= core_psm_timer - 1;
                    end
                end
                
                PSM_PWR_ON: begin
                    if (core_psm_timer == 0) begin
                        core_psm_state <= PSM_ACTIVE;
                        core_powered <= 1'b1;
                    end else begin
                        core_psm_timer <= core_psm_timer - 1;
                    end
                end
                
                PSM_ACTIVE: begin
                    if (!core_power_req) begin
                        core_psm_state <= PSM_PWR_OFF;
                        core_sleep_n <= 1'b0;  // 关闭电源
                        core_powered <= 1'b0;
                        core_psm_timer <= 8'h10;
                    end
                end
                
                PSM_PWR_OFF: begin
                    if (core_psm_timer == 0) begin
                        core_psm_state <= PSM_RET_OFF;
                        core_ret_n <= 1'b0;  // 关闭状态保持
                        core_psm_timer <= 8'h10;
                    end else begin
                        core_psm_timer <= core_psm_timer - 1;
                    end
                end
                
                PSM_RET_OFF: begin
                    if (core_psm_timer == 0) begin
                        core_psm_state <= PSM_ISO_OFF;
                        core_iso_n <= 1'b0;  // 关闭隔离
                        core_psm_timer <= 8'h10;
                    end else begin
                        core_psm_timer <= core_psm_timer - 1;
                    end
                end
                
                PSM_ISO_OFF: begin
                    if (core_psm_timer == 0) begin
                        core_psm_state <= PSM_OFF;
                    end else begin
                        core_psm_timer <= core_psm_timer - 1;
                    end
                end
            endcase
        end
    end
    
    // 簇级电源控制（简化示例）
    genvar i;
    generate
        for (i = 0; i < NUM_CLUSTERS; i = i + 1) begin : cluster_pg_gen
            always @(posedge clk or negedge rst_n) begin
                if (!rst_n) begin
                    cluster_powered[i] <= 1'b0;
                    cluster_sleep_n[i] <= 1'b0;
                    cluster_iso_n[i] <= 1'b0;
                    cluster_ret_n[i] <= 1'b0;
                end else begin
                    // 只有核心上电时才能控制簇
                    if (core_powered) begin
                        if (cluster_power_req[i] && !cluster_powered[i]) begin
                            // 简化的上电序列
                            cluster_iso_n[i] <= 1'b1;
                            #10 cluster_ret_n[i] <= 1'b1;
                            #10 cluster_sleep_n[i] <= 1'b1;
                            #40 cluster_powered[i] <= 1'b1;
                        end else if (!cluster_power_req[i] && cluster_powered[i]) begin
                            // 简化的下电序列
                            cluster_powered[i] <= 1'b0;
                            cluster_sleep_n[i] <= 1'b0;
                            #10 cluster_ret_n[i] <= 1'b0;
                            #10 cluster_iso_n[i] <= 1'b0;
                        end
                    end else begin
                        cluster_powered[i] <= 1'b0;
                        cluster_sleep_n[i] <= 1'b0;
                        cluster_iso_n[i] <= 1'b0;
                        cluster_ret_n[i] <= 1'b0;
                    end
                end
            end
        end
    endgenerate

endmodule
                        </div>
                    </div>
                </div>
            </div>

            <h3>6.6 面积优化</h3>
            
            <p>面积优化对降低芯片成本至关重要。NPU设计需要在性能、功耗和面积之间找到最佳平衡点。</p>

            <h4>6.6.1 资源共享技术</h4>
            <div class="code-block">
// 优化的流水线共享乘法器 - Verilog版本
module SharedMultiplier #(
    parameter DATA_WIDTH = 16,
    parameter NUM_USERS = 4,
    parameter PIPE_STAGES = 3  // 流水线级数
)(
    input wire clk,
    input wire rst_n,
    
    // 请求接口
    input wire [NUM_USERS-1:0] req,
    input wire [DATA_WIDTH-1:0] a_in [NUM_USERS-1:0],
    input wire [DATA_WIDTH-1:0] b_in [NUM_USERS-1:0],
    
    // 响应接口
    output reg [NUM_USERS-1:0] ack,
    output reg [2*DATA_WIDTH-1:0] result_out [NUM_USERS-1:0]
);

    // 流水线阶段定义
    // Stage 0: 仲裁和输入选择
    // Stage 1: 乘法第一级
    // Stage 2: 乘法第二级
    // Stage 3: 输出分发
    
    // 仲裁器状态
    reg [$clog2(NUM_USERS)-1:0] grant_id;
    reg req_valid;
    
    // 轮询仲裁器
    reg [$clog2(NUM_USERS)-1:0] rr_pointer;
    
    // 流水线寄存器
    reg [DATA_WIDTH-1:0] pipe_a [PIPE_STAGES:0];
    reg [DATA_WIDTH-1:0] pipe_b [PIPE_STAGES:0];
    reg [$clog2(NUM_USERS)-1:0] pipe_id [PIPE_STAGES:0];
    reg pipe_valid [PIPE_STAGES:0];
    
    // Stage 0: 仲裁逻辑（改进的轮询仲裁）
    integer i;
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            rr_pointer <= 0;
            req_valid <= 1'b0;
            grant_id <= 0;
        end else begin
            req_valid <= 1'b0;
            
            // 轮询查找下一个请求
            for (i = 0; i < NUM_USERS; i = i + 1) begin
                integer idx = (rr_pointer + i) % NUM_USERS;
                if (req[idx] && !req_valid) begin
                    grant_id <= idx;
                    req_valid <= 1'b1;
                    rr_pointer <= (idx + 1) % NUM_USERS;
                end
            end
        end
    end
    
    // Stage 0->1: 输入寄存
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            pipe_a[0] <= 0;
            pipe_b[0] <= 0;
            pipe_id[0] <= 0;
            pipe_valid[0] <= 1'b0;
        end else begin
            if (req_valid) begin
                pipe_a[0] <= a_in[grant_id];
                pipe_b[0] <= b_in[grant_id];
                pipe_id[0] <= grant_id;
                pipe_valid[0] <= 1'b1;
            end else begin
                pipe_valid[0] <= 1'b0;
            end
        end
    end
    
    // 流水线乘法器（分为两级）
    reg [DATA_WIDTH-1:0] mult_a_reg, mult_b_reg;
    reg [DATA_WIDTH/2-1:0] partial_prod [3:0];
    reg [2*DATA_WIDTH-1:0] mult_result;
    
    // Stage 1: 部分积计算
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            mult_a_reg <= 0;
            mult_b_reg <= 0;
            pipe_id[1] <= 0;
            pipe_valid[1] <= 1'b0;
            for (i = 0; i < 4; i = i + 1) begin
                partial_prod[i] <= 0;
            end
        end else begin
            mult_a_reg <= pipe_a[0];
            mult_b_reg <= pipe_b[0];
            pipe_id[1] <= pipe_id[0];
            pipe_valid[1] <= pipe_valid[0];
            
            // 计算部分积（Booth编码优化）
            partial_prod[0] <= pipe_a[0][DATA_WIDTH/2-1:0] * pipe_b[0][DATA_WIDTH/2-1:0];
            partial_prod[1] <= pipe_a[0][DATA_WIDTH-1:DATA_WIDTH/2] * pipe_b[0][DATA_WIDTH/2-1:0];
            partial_prod[2] <= pipe_a[0][DATA_WIDTH/2-1:0] * pipe_b[0][DATA_WIDTH-1:DATA_WIDTH/2];
            partial_prod[3] <= pipe_a[0][DATA_WIDTH-1:DATA_WIDTH/2] * pipe_b[0][DATA_WIDTH-1:DATA_WIDTH/2];
        end
    end
    
    // Stage 2: 最终累加
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            mult_result <= 0;
            pipe_id[2] <= 0;
            pipe_valid[2] <= 1'b0;
        end else begin
            pipe_id[2] <= pipe_id[1];
            pipe_valid[2] <= pipe_valid[1];
            
            // Wallace树累加部分积
            mult_result <= {partial_prod[3], {(DATA_WIDTH/2){1'b0}}} +
                          ({partial_prod[2], {(DATA_WIDTH/2){1'b0}}} >> (DATA_WIDTH/2)) +
                          ({partial_prod[1], {(DATA_WIDTH/2){1'b0}}} >> (DATA_WIDTH/2)) +
                          partial_prod[0];
        end
    end
    
    // Stage 3: 输出分发
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            ack <= 0;
            for (i = 0; i < NUM_USERS; i = i + 1) begin
                result_out[i] <= 0;
            end
        end else begin
            // 清除之前的应答
            ack <= 0;
            
            // 设置新的应答
            if (pipe_valid[2]) begin
                ack[pipe_id[2]] <= 1'b1;
                result_out[pipe_id[2]] <= mult_result;
            end
        end
    end

endmodule
            </div>
            
            <div class="code-block">
// Chisel版本的流水线共享乘法器
import chisel3._
import chisel3.util._

class SharedMultiplier(dataWidth: Int = 16, numUsers: Int = 4, pipeStages: Int = 3) extends Module {
  val io = IO(new Bundle {
    // 请求接口
    val req = Input(Vec(numUsers, Bool()))
    val aIn = Input(Vec(numUsers, UInt(dataWidth.W)))
    val bIn = Input(Vec(numUsers, UInt(dataWidth.W)))
    
    // 响应接口
    val ack = Output(Vec(numUsers, Bool()))
    val resultOut = Output(Vec(numUsers, UInt((2*dataWidth).W)))
  })
  
  // 轮询仲裁器
  val rrPointer = RegInit(0.U(log2Ceil(numUsers).W))
  val grantId = Wire(UInt(log2Ceil(numUsers).W))
  val reqValid = Wire(Bool())
  
  // 仲裁逻辑
  val arbiter = Module(new RoundRobinArbiter(numUsers))
  arbiter.io.req := io.req
  grantId := arbiter.io.grant
  reqValid := arbiter.io.valid
  
  // 流水线寄存器
  val pipeA = RegInit(VecInit(Seq.fill(pipeStages+1)(0.U(dataWidth.W))))
  val pipeB = RegInit(VecInit(Seq.fill(pipeStages+1)(0.U(dataWidth.W))))
  val pipeId = RegInit(VecInit(Seq.fill(pipeStages+1)(0.U(log2Ceil(numUsers).W))))
  val pipeValid = RegInit(VecInit(Seq.fill(pipeStages+1)(false.B)))
  
  // Stage 0->1: 输入寄存
  when (reqValid) {
    pipeA(0) := io.aIn(grantId)
    pipeB(0) := io.bIn(grantId)
    pipeId(0) := grantId
    pipeValid(0) := true.B
  }.otherwise {
    pipeValid(0) := false.B
  }
  
  // 流水线传播
  for (i <- 1 to pipeStages) {
    pipeA(i) := pipeA(i-1)
    pipeB(i) := pipeB(i-1)
    pipeId(i) := pipeId(i-1)
    pipeValid(i) := pipeValid(i-1)
  }
  
  // 乘法器实例
  val mult = Module(new PipelinedMultiplier(dataWidth))
  mult.io.a := pipeA(0)
  mult.io.b := pipeB(0)
  mult.io.valid := pipeValid(0)
  
  // 输出分发
  io.ack := VecInit(Seq.fill(numUsers)(false.B))
  when (pipeValid(pipeStages)) {
    io.ack(pipeId(pipeStages)) := true.B
    io.resultOut(pipeId(pipeStages)) := mult.io.result
  }
}
            </div>
            
            <div class="code-block">
// 优化的流水线存储器资源共享 - Verilog版本
module SharedMemoryWrapper #(
    parameter ADDR_WIDTH = 10,
    parameter DATA_WIDTH = 32,
    parameter PIPELINE_READ = 1  // 读操作流水线
)(
    input wire clk,
    input wire rst_n,
    
    // 端口A（读写）
    input wire a_en,
    input wire a_we,
    input wire [ADDR_WIDTH-1:0] a_addr,
    input wire [DATA_WIDTH-1:0] a_wdata,
    output reg [DATA_WIDTH-1:0] a_rdata,
    output reg a_ready,
    
    // 端口B（只读）
    input wire b_en,
    input wire [ADDR_WIDTH-1:0] b_addr,
    output reg [DATA_WIDTH-1:0] b_rdata,
    output reg b_ready
);

    // 单端口存储器
    reg [DATA_WIDTH-1:0] mem [(1<<ADDR_WIDTH)-1:0];
    
    // 流水线寄存器
    reg [ADDR_WIDTH-1:0] addr_pipe;
    reg [1:0] port_pipe;  // 0: none, 1: port A, 2: port B
    reg we_pipe;
    reg [DATA_WIDTH-1:0] wdata_pipe;
    
    // 请求缓冲（避免请求丢失）
    reg a_pending, b_pending;
    reg [ADDR_WIDTH-1:0] a_addr_buf, b_addr_buf;
    reg a_we_buf;
    reg [DATA_WIDTH-1:0] a_wdata_buf;
    
    // 仲裁逻辑
    wire a_grant = (a_en || a_pending) && !b_pending;  // A优先，除非B在等待
    wire b_grant = (b_en || b_pending) && !(a_en || a_pending);
    
    // Stage 1: 地址和控制流水线
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            addr_pipe <= 0;
            port_pipe <= 0;
            we_pipe <= 1'b0;
            wdata_pipe <= 0;
            a_pending <= 1'b0;
            b_pending <= 1'b0;
        end else begin
            // 默认值
            port_pipe <= 0;
            
            // 处理请求
            if (a_grant) begin
                if (a_pending) begin
                    // 使用缓冲的请求
                    addr_pipe <= a_addr_buf;
                    we_pipe <= a_we_buf;
                    wdata_pipe <= a_wdata_buf;
                    a_pending <= 1'b0;
                end else begin
                    // 使用当前请求
                    addr_pipe <= a_addr;
                    we_pipe <= a_we;
                    wdata_pipe <= a_wdata;
                end
                port_pipe <= 1;
            end else if (b_grant) begin
                if (b_pending) begin
                    addr_pipe <= b_addr_buf;
                    b_pending <= 1'b0;
                end else begin
                    addr_pipe <= b_addr;
                end
                we_pipe <= 1'b0;
                port_pipe <= 2;
            end
            
            // 缓冲未服务的请求
            if (a_en && !a_grant && !a_pending) begin
                a_pending <= 1'b1;
                a_addr_buf <= a_addr;
                a_we_buf <= a_we;
                a_wdata_buf <= a_wdata;
            end
            
            if (b_en && !b_grant && !b_pending) begin
                b_pending <= 1'b1;
                b_addr_buf <= b_addr;
            end
        end
    end
    
    // Stage 2: 存储器访问
    reg [DATA_WIDTH-1:0] read_data;
    reg [1:0] port_out;
    
    always @(posedge clk) begin
        if (we_pipe) begin
            mem[addr_pipe] <= wdata_pipe;
        end
        read_data <= mem[addr_pipe];
        port_out <= port_pipe;
    end
    
    // Stage 3: 输出分发
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            a_ready <= 1'b0;
            b_ready <= 1'b0;
            a_rdata <= 0;
            b_rdata <= 0;
        end else begin
            // 清除之前的ready
            a_ready <= 1'b0;
            b_ready <= 1'b0;
            
            // 根据端口分发结果
            case (port_out)
                1: begin  // Port A
                    a_ready <= 1'b1;
                    if (!we_pipe) begin  // 只在读操作时更新
                        a_rdata <= read_data;
                    end
                end
                
                2: begin  // Port B
                    b_ready <= 1'b1;
                    b_rdata <= read_data;
                end
            endcase
        end
    end

endmodule
            </div>
            
            <div class="code-block">
// Chisel版本的流水线存储器资源共享
import chisel3._
import chisel3.util._

class SharedMemoryWrapper(addrWidth: Int = 10, dataWidth: Int = 32) extends Module {
  val io = IO(new Bundle {
    // 端口A（读写）
    val aEn = Input(Bool())
    val aWe = Input(Bool())
    val aAddr = Input(UInt(addrWidth.W))
    val aWdata = Input(UInt(dataWidth.W))
    val aRdata = Output(UInt(dataWidth.W))
    val aReady = Output(Bool())
    
    // 端口B（只读）
    val bEn = Input(Bool())
    val bAddr = Input(UInt(addrWidth.W))
    val bRdata = Output(UInt(dataWidth.W))
    val bReady = Output(Bool())
  })
  
  // 存储器
  val mem = SyncReadMem(1 << addrWidth, UInt(dataWidth.W))
  
  // 请求缓冲
  val aPending = RegInit(false.B)
  val bPending = RegInit(false.B)
  val aAddrBuf = Reg(UInt(addrWidth.W))
  val aWeBuf = Reg(Bool())
  val aWdataBuf = Reg(UInt(dataWidth.W))
  val bAddrBuf = Reg(UInt(addrWidth.W))
  
  // 仲裁
  val aGrant = (io.aEn || aPending) && !bPending
  val bGrant = (io.bEn || bPending) && !(io.aEn || aPending)
  
  // 流水线寄存器
  val addrPipe = Reg(UInt(addrWidth.W))
  val portPipe = Reg(UInt(2.W))
  val wePipe = Reg(Bool())
  val wdataPipe = Reg(UInt(dataWidth.W))
  
  // Stage 1: 仲裁和地址流水线
  when (aGrant) {
    when (aPending) {
      addrPipe := aAddrBuf
      wePipe := aWeBuf
      wdataPipe := aWdataBuf
      aPending := false.B
    }.otherwise {
      addrPipe := io.aAddr
      wePipe := io.aWe
      wdataPipe := io.aWdata
    }
    portPipe := 1.U
  }.elsewhen (bGrant) {
    addrPipe := Mux(bPending, bAddrBuf, io.bAddr)
    wePipe := false.B
    portPipe := 2.U
    bPending := false.B
  }.otherwise {
    portPipe := 0.U
  }
  
  // 缓冲未服务请求
  when (io.aEn && !aGrant && !aPending) {
    aPending := true.B
    aAddrBuf := io.aAddr
    aWeBuf := io.aWe
    aWdataBuf := io.aWdata
  }
  
  when (io.bEn && !bGrant && !bPending) {
    bPending := true.B
    bAddrBuf := io.bAddr
  }
  
  // Stage 2: 存储器访问
  val readData = mem.read(addrPipe)
  when (wePipe) {
    mem.write(addrPipe, wdataPipe)
  }
  val portOut = RegNext(portPipe)
  
  // Stage 3: 输出分发
  io.aReady := portOut === 1.U
  io.bReady := portOut === 2.U
  io.aRdata := Mux(io.aReady && !RegNext(wePipe), readData, 0.U)
  io.bRdata := Mux(io.bReady, readData, 0.U)
}
            </div>

            <h4>6.6.2 数据路径优化</h4>
            <div class="code-block">
// 优化的流水线融合操作 - Verilog版本
module FusedOperation #(
    parameter DATA_WIDTH = 16
)(
    input wire clk,
    input wire rst_n,
    input wire enable,
    input wire valid_in,
    
    // 原始操作：Y = (A * B) + (C * D) + E
    input wire signed [DATA_WIDTH-1:0] a, b, c, d, e,
    output reg signed [DATA_WIDTH*2+1:0] y,
    output reg valid_out
);

    // 优化方案：3级流水线，共享2个乘法器
    // Stage 1: 输入寄存和乘法
    // Stage 2: 部分和累加
    // Stage 3: 最终加法和输出
    
    // 流水线寄存器
    reg signed [DATA_WIDTH-1:0] a_s1, b_s1, c_s1, d_s1, e_s1;
    reg signed [DATA_WIDTH-1:0] e_s2;
    reg valid_s1, valid_s2;
    
    // 乘法器输出
    wire signed [DATA_WIDTH*2-1:0] mult1_out, mult2_out;
    
    // 累加器
    reg signed [DATA_WIDTH*2:0] partial_sum;
    
    // Stage 1: 输入寄存
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            a_s1 <= 0;
            b_s1 <= 0;
            c_s1 <= 0;
            d_s1 <= 0;
            e_s1 <= 0;
            valid_s1 <= 1'b0;
        end else if (enable) begin
            if (valid_in) begin
                a_s1 <= a;
                b_s1 <= b;
                c_s1 <= c;
                d_s1 <= d;
                e_s1 <= e;
                valid_s1 <= 1'b1;
            end else begin
                valid_s1 <= 1'b0;
            end
        end
    end
    
    // 共享乘法器（组合逻辑）
    assign mult1_out = a_s1 * b_s1;
    assign mult2_out = c_s1 * d_s1;
    
    // Stage 2: 部分和累加
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            partial_sum <= 0;
            e_s2 <= 0;
            valid_s2 <= 1'b0;
        end else if (enable) begin
            if (valid_s1) begin
                // Wallace树加法器结构
                partial_sum <= {{1{mult1_out[DATA_WIDTH*2-1]}}, mult1_out} + 
                              {{1{mult2_out[DATA_WIDTH*2-1]}}, mult2_out};
                e_s2 <= e_s1;
                valid_s2 <= 1'b1;
            end else begin
                valid_s2 <= 1'b0;
            end
        end
    end
    
    // Stage 3: 最终加法
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            y <= 0;
            valid_out <= 1'b0;
        end else if (enable) begin
            if (valid_s2) begin
                y <= partial_sum + {{(DATA_WIDTH+2){e_s2[DATA_WIDTH-1]}}, e_s2};
                valid_out <= 1'b1;
            end else begin
                valid_out <= 1'b0;
            end
        end
    end

endmodule
            </div>
            
            <div class="code-block">
// Chisel版本的流水线融合操作
import chisel3._
import chisel3.util._

class FusedOperation(dataWidth: Int = 16) extends Module {
  val io = IO(new Bundle {
    val enable = Input(Bool())
    val validIn = Input(Bool())
    val a = Input(SInt(dataWidth.W))
    val b = Input(SInt(dataWidth.W))
    val c = Input(SInt(dataWidth.W))
    val d = Input(SInt(dataWidth.W))
    val e = Input(SInt(dataWidth.W))
    val y = Output(SInt((dataWidth*2+2).W))
    val validOut = Output(Bool())
  })
  
  // 流水线寄存器
  val stage1 = RegEnable(new Bundle {
    val a = io.a
    val b = io.b
    val c = io.c
    val d = io.d
    val e = io.e
    val valid = io.validIn
  }, io.enable)
  
  // 乘法器
  val mult1 = stage1.a * stage1.b
  val mult2 = stage1.c * stage1.d
  
  // Stage 2
  val stage2 = RegEnable(new Bundle {
    val partialSum = mult1 +& mult2  // +& 保留进位
    val e = stage1.e
    val valid = stage1.valid
  }, io.enable)
  
  // Stage 3
  val stage3 = RegEnable(new Bundle {
    val y = stage2.partialSum +& stage2.e.asSInt
    val valid = stage2.valid
  }, io.enable)
  
  io.y := stage3.y
  io.validOut := stage3.valid
}

// 优化的流水线位宽优化MAC - Verilog版本
module BitwidthOptimized #(
    parameter IN_WIDTH = 8,
    parameter WEIGHT_WIDTH = 8,
    parameter OUT_WIDTH = 24  // 优化后的位宽
)(
    input wire clk,
    input wire rst_n,
    input wire enable,
    
    // 4个输入的MAC
    input wire signed [IN_WIDTH-1:0] in0, in1, in2, in3,
    input wire signed [WEIGHT_WIDTH-1:0] w0, w1, w2, w3,
    output reg signed [OUT_WIDTH-1:0] out,
    output reg valid_out
);

    // 流水线寄存器
    reg signed [IN_WIDTH-1:0] in_reg [3:0];
    reg signed [WEIGHT_WIDTH-1:0] w_reg [3:0];
    reg valid_s1;
    
    // 部分积寄存器
    reg signed [IN_WIDTH+WEIGHT_WIDTH-1:0] p_reg [3:0];
    reg valid_s2;
    
    // Wallace树级寄存器
    reg signed [IN_WIDTH+WEIGHT_WIDTH:0] sum01_reg, sum23_reg;
    reg valid_s3;
    
    // Stage 1: 输入寄存
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            in_reg[0] <= 0; in_reg[1] <= 0; in_reg[2] <= 0; in_reg[3] <= 0;
            w_reg[0] <= 0; w_reg[1] <= 0; w_reg[2] <= 0; w_reg[3] <= 0;
            valid_s1 <= 1'b0;
        end else if (enable) begin
            in_reg[0] <= in0; in_reg[1] <= in1; in_reg[2] <= in2; in_reg[3] <= in3;
            w_reg[0] <= w0; w_reg[1] <= w1; w_reg[2] <= w2; w_reg[3] <= w3;
            valid_s1 <= 1'b1;
        end else begin
            valid_s1 <= 1'b0;
        end
    end
    
    // Stage 2: 乘法器（并行）
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            p_reg[0] <= 0; p_reg[1] <= 0; p_reg[2] <= 0; p_reg[3] <= 0;
            valid_s2 <= 1'b0;
        end else begin
            p_reg[0] <= in_reg[0] * w_reg[0];
            p_reg[1] <= in_reg[1] * w_reg[1];
            p_reg[2] <= in_reg[2] * w_reg[2];
            p_reg[3] <= in_reg[3] * w_reg[3];
            valid_s2 <= valid_s1;
        end
    end
    
    // Stage 3: Wallace树第一级
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            sum01_reg <= 0;
            sum23_reg <= 0;
            valid_s3 <= 1'b0;
        end else begin
            sum01_reg <= p_reg[0] + p_reg[1];
            sum23_reg <= p_reg[2] + p_reg[3];
            valid_s3 <= valid_s2;
        end
    end
    
    // Stage 4: 最终累加和饱和
    wire signed [IN_WIDTH+WEIGHT_WIDTH+1:0] sum_all = sum01_reg + sum23_reg;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            out <= 0;
            valid_out <= 1'b0;
        end else begin
            // 饱和逻辑
            if (sum_all > $signed({1'b0, {(OUT_WIDTH-1){1'b1}}})) begin
                out <= {1'b0, {(OUT_WIDTH-1){1'b1}}};  // 最大正值
            end else if (sum_all < $signed({1'b1, {(OUT_WIDTH-1){1'b0}}})) begin
                out <= {1'b1, {(OUT_WIDTH-1){1'b0}}};  // 最小负值
            end else begin
                out <= sum_all[OUT_WIDTH-1:0];
            end
            valid_out <= valid_s3;
        end
    end

endmodule
            </div>
            
            <div class="code-block">
// Chisel版本的流水线位宽优化MAC
import chisel3._
import chisel3.util._

class BitwidthOptimized(inWidth: Int = 8, weightWidth: Int = 8, outWidth: Int = 24) extends Module {
  val io = IO(new Bundle {
    val enable = Input(Bool())
    val in = Input(Vec(4, SInt(inWidth.W)))
    val weights = Input(Vec(4, SInt(weightWidth.W)))
    val out = Output(SInt(outWidth.W))
    val validOut = Output(Bool())
  })
  
  // Stage 1: 输入寄存
  val inReg = RegEnable(io.in, io.enable)
  val wReg = RegEnable(io.weights, io.enable)
  val validS1 = RegEnable(io.enable, io.enable)
  
  // Stage 2: 乘法
  val products = Wire(Vec(4, SInt((inWidth + weightWidth).W)))
  for (i <- 0 until 4) {
    products(i) := RegNext(inReg(i) * wReg(i))
  }
  val validS2 = RegNext(validS1)
  
  // Stage 3: Wallace树第一级
  val sum01 = RegNext(products(0) +& products(1))
  val sum23 = RegNext(products(2) +& products(3))
  val validS3 = RegNext(validS2)
  
  // Stage 4: 最终累加和饱和
  val sumAll = sum01 +& sum23
  val maxVal = ((1L << (outWidth - 1)) - 1).S
  val minVal = (-(1L << (outWidth - 1))).S
  
  io.out := RegNext(MuxCase(sumAll(outWidth-1, 0).asSInt, Seq(
    (sumAll > maxVal) -> maxVal,
    (sumAll < minVal) -> minVal
  )))
  io.validOut := RegNext(validS3)
}
            </div>

            <h4>6.6.3 面积优化检查清单</h4>
            <div class="info-box">
                <p><strong>面积优化策略：</strong></p>
                <ul>
                    <li><strong>资源共享：</strong>
                        <ul>
                            <li>共享昂贵的运算单元（乘法器、除法器）</li>
                            <li>时分复用存储器端口</li>
                            <li>共享控制逻辑</li>
                        </ul>
                    </li>
                    <li><strong>数据路径优化：</strong>
                        <ul>
                            <li>操作融合减少中间寄存器</li>
                            <li>位宽优化，移除冗余位</li>
                            <li>使用移位代替乘以2的幂</li>
                        </ul>
                    </li>
                    <li><strong>存储优化：</strong>
                        <ul>
                            <li>使用单端口代替双端口RAM</li>
                            <li>寄存器文件改为分布式RAM</li>
                            <li>压缩存储格式</li>
                        </ul>
                    </li>
                    <li><strong>逻辑优化：</strong>
                        <ul>
                            <li>布尔优化和逻辑简化</li>
                            <li>常数传播和死代码消除</li>
                            <li>FSM编码优化</li>
                        </ul>
                    </li>
                </ul>
            </div>
            
            <div class="info-box">
                <p><strong>面积优化前后对比：</strong></p>
                <p>以一个16×16 MAC阵列为例：</p>
                <ul>
                    <li><strong>优化前：</strong></li>
                    <ul>
                        <li>256个独立乘法器：256 × 1000 gates = 256K gates</li>
                        <li>256个独立累加器：256 × 500 gates = 128K gates</li>
                        <li>总面积：384K gates</li>
                    </ul>
                    <li><strong>优化后（4:1资源共享）：</strong></li>
                    <ul>
                        <li>64个共享乘法器：64 × 1000 gates = 64K gates</li>
                        <li>256个累加器：256 × 500 gates = 128K gates</li>
                        <li>仲裁和控制逻辑：20K gates</li>
                        <li>总面积：212K gates</li>
                        <li><strong>面积节省：45%</strong></li>
                    </ul>
                </ul>
                <p><strong>性能影响：</strong>吞吐量降低到25%，但通过提高频率可部分补偿。适用于对延迟不敏感的应用。</p>
            </div>

            <h3>6.7 时序收敛</h3>
            
            <p>时序收敛是RTL设计到物理实现的关键挑战，需要在设计早期就考虑时序问题。</p>

            <h4>6.7.1 流水线设计</h4>
            <div class="code-block">
// 优化的深度流水线MAC阵列 - Verilog版本
module PipelinedMACArray #(
    parameter DATA_WIDTH = 8,
    parameter ARRAY_DIM = 4,
    parameter PIPE_STAGES = 3,  // 流水线级数
    parameter ACC_WIDTH = 32     // 累加器位宽
)(
    input wire clk,
    input wire rst_n,
    input wire enable,
    input wire clear_acc,        // 清除累加器
    
    input wire [DATA_WIDTH-1:0] a_in [ARRAY_DIM-1:0],
    input wire [DATA_WIDTH-1:0] b_in [ARRAY_DIM-1:0][ARRAY_DIM-1:0],
    output wire [ACC_WIDTH-1:0] c_out [ARRAY_DIM-1:0][ARRAY_DIM-1:0],
    output reg valid_out
);

    // 流水线寄存器
    reg [DATA_WIDTH-1:0] a_pipe [PIPE_STAGES:0][ARRAY_DIM-1:0];
    reg [DATA_WIDTH-1:0] b_pipe [PIPE_STAGES:0][ARRAY_DIM-1:0][ARRAY_DIM-1:0];
    reg valid_pipe [PIPE_STAGES:0];
    
    // 输入流水线（优化：使用非阻塞赋值减少延迟）
    integer s, i, j;
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            for (s = 0; s <= PIPE_STAGES; s = s + 1) begin
                valid_pipe[s] <= 1'b0;
                for (i = 0; i < ARRAY_DIM; i = i + 1) begin
                    a_pipe[s][i] <= 0;
                    for (j = 0; j < ARRAY_DIM; j = j + 1) begin
                        b_pipe[s][i][j] <= 0;
                    end
                end
            end
        end else if (enable) begin
            // 第一级
            a_pipe[0] <= a_in;
            b_pipe[0] <= b_in;
            valid_pipe[0] <= 1'b1;
            
            // 流水线传播
            for (s = 1; s <= PIPE_STAGES; s = s + 1) begin
                a_pipe[s] <= a_pipe[s-1];
                b_pipe[s] <= b_pipe[s-1];
                valid_pipe[s] <= valid_pipe[s-1];
            end
        end else begin
            // 不使能时清除valid
            for (s = 0; s <= PIPE_STAGES; s = s + 1) begin
                valid_pipe[s] <= 1'b0;
            end
        end
    end
    
    // 输出valid信号
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            valid_out <= 1'b0;
        end else begin
            valid_out <= valid_pipe[PIPE_STAGES];
        end
    end
    
    // MAC单元实例化（优化后的流水线结构）
    genvar gi, gj;
    generate
        for (gi = 0; gi < ARRAY_DIM; gi = gi + 1) begin : row_gen
            for (gj = 0; gj < ARRAY_DIM; gj = gj + 1) begin : col_gen
                OptimizedPipelinedMAC #(
                    .DATA_WIDTH(DATA_WIDTH),
                    .ACC_WIDTH(ACC_WIDTH),
                    .INTERNAL_PIPES(2)  // MAC内部流水线
                ) u_mac (
                    .clk(clk),
                    .rst_n(rst_n),
                    .enable(valid_pipe[PIPE_STAGES]),
                    .clear(clear_acc),
                    .a(a_pipe[PIPE_STAGES][gi]),
                    .b(b_pipe[PIPE_STAGES][gi][gj]),
                    .acc_out(c_out[gi][gj])
                );
            end
        end
    endgenerate

endmodule

// 优化的流水线MAC单元
module OptimizedPipelinedMAC #(
    parameter DATA_WIDTH = 8,
    parameter ACC_WIDTH = 32,
    parameter INTERNAL_PIPES = 2
)(
    input wire clk,
    input wire rst_n,
    input wire enable,
    input wire clear,
    input wire signed [DATA_WIDTH-1:0] a,
    input wire signed [DATA_WIDTH-1:0] b,
    output wire signed [ACC_WIDTH-1:0] acc_out
);

    // 乘法器流水线寄存器
    reg signed [DATA_WIDTH-1:0] a_reg, b_reg;
    reg signed [2*DATA_WIDTH-1:0] mult_pipe [INTERNAL_PIPES:0];
    reg enable_pipe [INTERNAL_PIPES+1:0];
    
    // 累加器
    reg signed [ACC_WIDTH-1:0] acc_reg;
    
    // 流水线乘法
    integer k;
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            a_reg <= 0;
            b_reg <= 0;
            for (k = 0; k <= INTERNAL_PIPES; k = k + 1) begin
                mult_pipe[k] <= 0;
            end
            for (k = 0; k <= INTERNAL_PIPES+1; k = k + 1) begin
                enable_pipe[k] <= 1'b0;
            end
        end else begin
            // 输入寄存
            a_reg <= a;
            b_reg <= b;
            enable_pipe[0] <= enable;
            
            // 乘法第一级
            mult_pipe[0] <= a_reg * b_reg;
            enable_pipe[1] <= enable_pipe[0];
            
            // 乘法流水线
            for (k = 1; k <= INTERNAL_PIPES; k = k + 1) begin
                mult_pipe[k] <= mult_pipe[k-1];
                enable_pipe[k+1] <= enable_pipe[k];
            end
        end
    end
    
    // 累加（带清零控制）
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            acc_reg <= 0;
        end else if (clear) begin
            acc_reg <= 0;
        end else if (enable_pipe[INTERNAL_PIPES+1]) begin
            acc_reg <= acc_reg + {{(ACC_WIDTH-2*DATA_WIDTH){mult_pipe[INTERNAL_PIPES][2*DATA_WIDTH-1]}}, 
                                  mult_pipe[INTERNAL_PIPES]};
        end
    end
    
    assign acc_out = acc_reg;

endmodule
            </div>
            
            <div class="code-block">
// Chisel版本的深度流水线MAC阵列
import chisel3._
import chisel3.util._

class PipelinedMACArray(dataWidth: Int = 8, arrayDim: Int = 4, pipeStages: Int = 3, accWidth: Int = 32) extends Module {
  val io = IO(new Bundle {
    val enable = Input(Bool())
    val clearAcc = Input(Bool())
    val aIn = Input(Vec(arrayDim, SInt(dataWidth.W)))
    val bIn = Input(Vec(arrayDim, Vec(arrayDim, SInt(dataWidth.W))))
    val cOut = Output(Vec(arrayDim, Vec(arrayDim, SInt(accWidth.W))))
    val validOut = Output(Bool())
  })
  
  // 流水线寄存器
  val aPipe = RegInit(VecInit(Seq.fill(pipeStages+1)(VecInit(Seq.fill(arrayDim)(0.S(dataWidth.W))))))
  val bPipe = RegInit(VecInit(Seq.fill(pipeStages+1)(VecInit(Seq.fill(arrayDim)(VecInit(Seq.fill(arrayDim)(0.S(dataWidth.W))))))))
  val validPipe = RegInit(VecInit(Seq.fill(pipeStages+1)(false.B)))
  
  // 输入流水线
  when (io.enable) {
    aPipe(0) := io.aIn
    bPipe(0) := io.bIn
    validPipe(0) := true.B
    
    for (s <- 1 to pipeStages) {
      aPipe(s) := aPipe(s-1)
      bPipe(s) := bPipe(s-1)
      validPipe(s) := validPipe(s-1)
    }
  }.otherwise {
    validPipe.foreach(_ := false.B)
  }
  
  io.validOut := validPipe(pipeStages)
  
  // MAC单元阵列
  val macUnits = Seq.fill(arrayDim, arrayDim) {
    Module(new OptimizedPipelinedMAC(dataWidth, accWidth, 2))
  }
  
  for (i <- 0 until arrayDim; j <- 0 until arrayDim) {
    macUnits(i)(j).io.enable := validPipe(pipeStages)
    macUnits(i)(j).io.clear := io.clearAcc
    macUnits(i)(j).io.a := aPipe(pipeStages)(i)
    macUnits(i)(j).io.b := bPipe(pipeStages)(i)(j)
    io.cOut(i)(j) := macUnits(i)(j).io.accOut
  }
}

// 细粒度流水线MAC
module PipelinedMAC #(
    parameter DATA_WIDTH = 8,
    parameter ACC_WIDTH = 32,
    parameter INTERNAL_PIPES = 2
)(
    input wire clk,
    input wire rst_n,
    input wire [DATA_WIDTH-1:0] a,
    input wire [DATA_WIDTH-1:0] b,
    output wire [ACC_WIDTH-1:0] acc_out
);

    // 乘法器流水线
    reg [DATA_WIDTH-1:0] a_reg, b_reg;
    reg [2*DATA_WIDTH-1:0] mult_pipe [INTERNAL_PIPES-1:0];
    
    // 累加器
    reg [ACC_WIDTH-1:0] acc_reg;
    
    // 流水线乘法
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            a_reg <= 0;
            b_reg <= 0;
            for (int i = 0; i < INTERNAL_PIPES; i++) begin
                mult_pipe[i] <= 0;
            end
        end else begin
            // 输入寄存
            a_reg <= a;
            b_reg <= b;
            
            // 第一级乘法
            mult_pipe[0] <= a_reg * b_reg;
            
            // 乘法流水线
            for (int i = 1; i < INTERNAL_PIPES; i++) begin
                mult_pipe[i] <= mult_pipe[i-1];
            end
        end
    end
    
    // 累加
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            acc_reg <= 0;
        end else begin
            acc_reg <= acc_reg + {{(ACC_WIDTH-2*DATA_WIDTH){mult_pipe[INTERNAL_PIPES-1][2*DATA_WIDTH-1]}}, 
                                  mult_pipe[INTERNAL_PIPES-1]};
        end
    end
    
    assign acc_out = acc_reg;

endmodule
            </div>

            <h4>6.7.2 时序优化技术</h4>
            <div class="info-box">
                <p><strong>流水线深度与性能权衡分析：</strong></p>
                <table class="comparison-table">
                    <tr>
                        <th>流水线深度</th>
                        <th>最大频率</th>
                        <th>延迟(cycles)</th>
                        <th>吞吐量</th>
                        <th>面积开销</th>
                        <th>功耗</th>
                    </tr>
                    <tr>
                        <td>无流水线</td>
                        <td>200 MHz</td>
                        <td>1</td>
                        <td>200 MOPS</td>
                        <td>基准</td>
                        <td>基准</td>
                    </tr>
                    <tr>
                        <td>2级流水线</td>
                        <td>400 MHz</td>
                        <td>2</td>
                        <td>400 MOPS</td>
                        <td>+5%</td>
                        <td>+10%</td>
                    </tr>
                    <tr>
                        <td>4级流水线</td>
                        <td>667 MHz</td>
                        <td>4</td>
                        <td>667 MOPS</td>
                        <td>+12%</td>
                        <td>+20%</td>
                    </tr>
                    <tr>
                        <td>8级流水线</td>
                        <td>800 MHz</td>
                        <td>8</td>
                        <td>800 MOPS</td>
                        <td>+25%</td>
                        <td>+35%</td>
                    </tr>
                </table>
                <p><strong>结论：</strong>流水线深度增加带来递减的性能收益，同时面积和功耗开销递增。最优深度需要根据具体应用场景权衡。</p>
            </div>
            
            <div class="code-block">
// 优化的重定时（Retiming）示例 - Verilog版本
module RetimingExample #(
    parameter WIDTH = 32
)(
    input wire clk,
    input wire rst_n,
    input wire [WIDTH-1:0] a, b, c, d,
    input wire valid_in,
    output reg [WIDTH-1:0] result,
    output reg valid_out
);

    // 原始设计：长组合路径
    // assign result = ((a + b) * c) + d;
    
    // 优化后：平衡的流水线，带有效信号传播
    reg [WIDTH-1:0] sum_ab;
    reg [WIDTH-1:0] c_reg1, c_reg2;
    reg [WIDTH-1:0] d_reg1, d_reg2, d_reg3;
    reg [WIDTH*2-1:0] product;
    reg valid_stage1, valid_stage2, valid_stage3;
    
    // 为了更好的时序，将乘法分解为部分积
    reg [WIDTH-1:0] partial_prod_low, partial_prod_high;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            sum_ab <= 0;
            c_reg1 <= 0;
            c_reg2 <= 0;
            d_reg1 <= 0;
            d_reg2 <= 0;
            d_reg3 <= 0;
            partial_prod_low <= 0;
            partial_prod_high <= 0;
            product <= 0;
            result <= 0;
            valid_stage1 <= 0;
            valid_stage2 <= 0;
            valid_stage3 <= 0;
            valid_out <= 0;
        end else begin
            // Stage 1: 加法和寄存器
            sum_ab <= a + b;
            c_reg1 <= c;
            d_reg1 <= d;
            valid_stage1 <= valid_in;
            
            // Stage 2: 部分积计算
            partial_prod_low <= sum_ab[WIDTH/2-1:0] * c_reg1[WIDTH/2-1:0];
            partial_prod_high <= sum_ab[WIDTH-1:WIDTH/2] * c_reg1[WIDTH-1:WIDTH/2];
            c_reg2 <= c_reg1;
            d_reg2 <= d_reg1;
            valid_stage2 <= valid_stage1;
            
            // Stage 3: 完整乘法结果
            product <= {partial_prod_high, partial_prod_low} + 
                      (sum_ab[WIDTH/2-1:0] * c_reg2[WIDTH-1:WIDTH/2]) << (WIDTH/2) +
                      (sum_ab[WIDTH-1:WIDTH/2] * c_reg2[WIDTH/2-1:0]) << (WIDTH/2);
            d_reg3 <= d_reg2;
            valid_stage3 <= valid_stage2;
            
            // Stage 4: 最终加法和饱和
            if (valid_stage3) begin
                if (product[WIDTH*2-1:WIDTH] != 0 && product[WIDTH*2-1]) begin
                    // 负数溢出
                    result <= {1'b1, {(WIDTH-1){1'b0}}};
                end else if (product[WIDTH*2-1:WIDTH] != 0 && !product[WIDTH*2-1]) begin
                    // 正数溢出
                    result <= {1'b0, {(WIDTH-1){1'b1}}};
                end else begin
                    result <= product[WIDTH-1:0] + d_reg3;
                end
            end
            valid_out <= valid_stage3;
        end
    end

endmodule
            </div>
            
            <p>Chisel版本的重定时示例：</p>
            <div class="code-block">
import chisel3._
import chisel3.util._

class RetimingExample(width: Int = 32) extends Module {
  val io = IO(new Bundle {
    val a = Input(UInt(width.W))
    val b = Input(UInt(width.W))
    val c = Input(UInt(width.W))
    val d = Input(UInt(width.W))
    val valid_in = Input(Bool())
    val result = Output(UInt(width.W))
    val valid_out = Output(Bool())
  })
  
  // Stage 1: 加法
  val sum_ab = RegNext(io.a + io.b, 0.U)
  val c_reg1 = RegNext(io.c, 0.U)
  val d_reg1 = RegNext(io.d, 0.U)
  val valid_stage1 = RegNext(io.valid_in, false.B)
  
  // Stage 2: 部分积
  val partial_prod_low = RegNext(
    sum_ab(width/2-1, 0) * c_reg1(width/2-1, 0), 0.U
  )
  val partial_prod_high = RegNext(
    sum_ab(width-1, width/2) * c_reg1(width-1, width/2), 0.U
  )
  val c_reg2 = RegNext(c_reg1, 0.U)
  val d_reg2 = RegNext(d_reg1, 0.U)
  val valid_stage2 = RegNext(valid_stage1, false.B)
  
  // Stage 3: 完整乘法
  val cross_prod1 = sum_ab(width/2-1, 0) * c_reg2(width-1, width/2)
  val cross_prod2 = sum_ab(width-1, width/2) * c_reg2(width/2-1, 0)
  val product = RegNext(
    Cat(partial_prod_high, partial_prod_low) +
    (cross_prod1 << (width/2)) +
    (cross_prod2 << (width/2)), 0.U
  )
  val d_reg3 = RegNext(d_reg2, 0.U)
  val valid_stage3 = RegNext(valid_stage2, false.B)
  
  // Stage 4: 最终结果
  val raw_result = product(width-1, 0) + d_reg3
  
  // 饱和逻辑
  val overflow = product(width*2-1, width).orR && !product(width*2-1)
  val underflow = product(width*2-1, width).orR && product(width*2-1)
  
  io.result := RegEnable(
    MuxCase(raw_result, Seq(
      overflow -> Cat(0.U(1.W), Fill(width-1, 1.U)),
      underflow -> Cat(1.U(1.W), Fill(width-1, 0.U))
    )),
    0.U,
    valid_stage3
  )
  io.valid_out := RegNext(valid_stage3, false.B)
}

// 优化的逻辑复制解决扇出问题 - Verilog版本
module FanoutOptimization #(
    parameter WIDTH = 8,
    parameter FANOUT = 64
)(
    input wire clk,
    input wire rst_n,
    input wire [WIDTH-1:0] data_in,
    input wire valid_in,
    input wire enable,
    output reg [WIDTH-1:0] data_out [FANOUT-1:0],
    output reg valid_out
);

    // 扇出树：使用多级缓冲和流水线
    localparam TREE_LEVELS = 3;  // log4(64) = 3
    localparam FANOUT_PER_LEVEL = 4;
    
    // 中间缓冲级和有效信号
    reg [WIDTH-1:0] buffer_l1 [3:0];
    reg [WIDTH-1:0] buffer_l2 [15:0];
    reg enable_l1, enable_l2, enable_l3;
    reg valid_l1, valid_l2, valid_l3;
    
    // 输入寄存器，减少输入端口的负载
    reg [WIDTH-1:0] data_in_reg;
    reg enable_reg;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            data_in_reg <= 0;
            enable_reg <= 0;
        end else begin
            data_in_reg <= data_in;
            enable_reg <= enable;
        end
    end
    
    // 第一级：1->4 带有效信号传播
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            for (int i = 0; i < 4; i++) buffer_l1[i] <= 0;
            enable_l1 <= 0;
            valid_l1 <= 0;
        end else begin
            if (enable_reg) begin
                // 使用循环展开减少逻辑延迟
                buffer_l1[0] <= data_in_reg;
                buffer_l1[1] <= data_in_reg;
                buffer_l1[2] <= data_in_reg;
                buffer_l1[3] <= data_in_reg;
            end
            enable_l1 <= enable_reg;
            valid_l1 <= valid_in && enable_reg;
        end
    end
    
    // 第二级：4->16 带缓冲器选择逻辑
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            for (int i = 0; i < 16; i++) buffer_l2[i] <= 0;
            enable_l2 <= 0;
            valid_l2 <= 0;
        end else begin
            if (enable_l1) begin
                // 手动展开以优化时序
                buffer_l2[0]  <= buffer_l1[0];
                buffer_l2[1]  <= buffer_l1[0];
                buffer_l2[2]  <= buffer_l1[0];
                buffer_l2[3]  <= buffer_l1[0];
                buffer_l2[4]  <= buffer_l1[1];
                buffer_l2[5]  <= buffer_l1[1];
                buffer_l2[6]  <= buffer_l1[1];
                buffer_l2[7]  <= buffer_l1[1];
                buffer_l2[8]  <= buffer_l1[2];
                buffer_l2[9]  <= buffer_l1[2];
                buffer_l2[10] <= buffer_l1[2];
                buffer_l2[11] <= buffer_l1[2];
                buffer_l2[12] <= buffer_l1[3];
                buffer_l2[13] <= buffer_l1[3];
                buffer_l2[14] <= buffer_l1[3];
                buffer_l2[15] <= buffer_l1[3];
            end
            enable_l2 <= enable_l1;
            valid_l2 <= valid_l1;
        end
    end
    
    // 第三级：16->64 最终输出
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            for (int i = 0; i < FANOUT; i++) data_out[i] <= 0;
            enable_l3 <= 0;
            valid_out <= 0;
        end else begin
            if (enable_l2) begin
                // 分组处理以减少每个时钟周期的负载
                for (int j = 0; j < 16; j++) begin
                    data_out[j*4]   <= buffer_l2[j];
                    data_out[j*4+1] <= buffer_l2[j];
                    data_out[j*4+2] <= buffer_l2[j];
                    data_out[j*4+3] <= buffer_l2[j];
                end
            end
            enable_l3 <= enable_l2;
            valid_out <= valid_l2;
        end
    end

endmodule
            </div>
            
            <p>Chisel版本的扇出优化：</p>
            <div class="code-block">
import chisel3._
import chisel3.util._

class FanoutOptimization(width: Int = 8, fanout: Int = 64) extends Module {
  val io = IO(new Bundle {
    val data_in = Input(UInt(width.W))
    val valid_in = Input(Bool())
    val enable = Input(Bool())
    val data_out = Output(Vec(fanout, UInt(width.W)))
    val valid_out = Output(Bool())
  })
  
  // 层级参数
  val treeLevels = 3
  val fanoutPerLevel = 4
  
  // 输入寄存器
  val dataInReg = RegNext(io.data_in, 0.U)
  val enableReg = RegNext(io.enable, false.B)
  
  // 第一级：1->4
  val bufferL1 = Reg(Vec(4, UInt(width.W)))
  val enableL1 = RegNext(enableReg, false.B)
  val validL1 = RegNext(io.valid_in && enableReg, false.B)
  
  when(enableReg) {
    bufferL1.foreach(_ := dataInReg)
  }
  
  // 第二级：4->16
  val bufferL2 = Reg(Vec(16, UInt(width.W)))
  val enableL2 = RegNext(enableL1, false.B)
  val validL2 = RegNext(validL1, false.B)
  
  when(enableL1) {
    for (i <- 0 until 16) {
      bufferL2(i) := bufferL1(i / 4)
    }
  }
  
  // 第三级：16->64
  val dataOutReg = Reg(Vec(fanout, UInt(width.W)))
  val validOutReg = RegNext(validL2, false.B)
  
  when(enableL2) {
    for (i <- 0 until fanout) {
      dataOutReg(i) := bufferL2(i / 4)
    }
  }
  
  io.data_out := dataOutReg
  io.valid_out := validOutReg
  
  // 可选：添加性能计数器
  val updateCounter = RegInit(0.U(32.W))
  when(enableL2 && validL2) {
    updateCounter := updateCounter + 1.U
  }
}
            </div>

            <h4>6.7.3 时序收敛策略</h4>
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>阶段</th>
                            <th>策略</th>
                            <th>工具/方法</th>
                            <th>影响</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>RTL设计</td>
                            <td>合理划分流水线</td>
                            <td>架构探索、性能建模</td>
                            <td>最大影响</td>
                        </tr>
                        <tr>
                            <td>综合</td>
                            <td>约束优化、逻辑重构</td>
                            <td>compile_ultra、retime</td>
                            <td>中等影响</td>
                        </tr>
                        <tr>
                            <td>布局</td>
                            <td>层次化布局、区域约束</td>
                            <td>floorplan、region</td>
                            <td>中等影响</td>
                        </tr>
                        <tr>
                            <td>时钟树</td>
                            <td>平衡时钟偏斜</td>
                            <td>CTS、useful skew</td>
                            <td>小幅改善</td>
                        </tr>
                        <tr>
                            <td>布线后</td>
                            <td>ECO修复</td>
                            <td>sizing、buffering</td>
                            <td>有限改善</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <div class="exercise">
                <h4>练习 6.6-6.7</h4>
                <div class="question">
                    <p><strong>题目：</strong>设计一个高性能矩阵乘法单元，要求：
                    1) 支持4×4矩阵乘法
                    2) 使用脉动阵列架构
                    3) 实现3级流水线
                    4) 优化面积和时序</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：脉动阵列中数据流动需要精心设计。使用数据skew来确保正确的计算时序。3级流水线可以分为：输入寄存、乘法、累加。面积优化可以考虑资源共享和位宽优化。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
// 优化的脉动矩阵乘法器 - Verilog版本
module SystolicMatrixMultiplier #(
    parameter DATA_WIDTH = 16,
    parameter MATRIX_SIZE = 4,
    parameter ACC_WIDTH = DATA_WIDTH * 2 + $clog2(MATRIX_SIZE)
)(
    input wire clk,
    input wire rst_n,
    input wire start,
    input wire valid_in,
    
    // 矩阵输入（按对角线输入）
    input wire [DATA_WIDTH-1:0] a_in [MATRIX_SIZE-1:0],
    input wire [DATA_WIDTH-1:0] b_in [MATRIX_SIZE-1:0],
    
    // 结果输出
    output reg [ACC_WIDTH-1:0] c_out [MATRIX_SIZE-1:0][MATRIX_SIZE-1:0],
    output reg done,
    output reg valid_out
);

    // PE内部流水线寄存器
    reg [DATA_WIDTH-1:0] pe_a_reg1 [MATRIX_SIZE-1:0][MATRIX_SIZE-1:0];
    reg [DATA_WIDTH-1:0] pe_a_reg2 [MATRIX_SIZE-1:0][MATRIX_SIZE-1:0];
    reg [DATA_WIDTH-1:0] pe_b_reg1 [MATRIX_SIZE-1:0][MATRIX_SIZE-1:0];
    reg [DATA_WIDTH-1:0] pe_b_reg2 [MATRIX_SIZE-1:0][MATRIX_SIZE-1:0];
    reg [DATA_WIDTH*2-1:0] pe_mult [MATRIX_SIZE-1:0][MATRIX_SIZE-1:0];
    reg [ACC_WIDTH-1:0] pe_acc [MATRIX_SIZE-1:0][MATRIX_SIZE-1:0];
    
    // 输入延迟链（实现对角线输入）
    reg [DATA_WIDTH-1:0] a_delay [MATRIX_SIZE-1:0][MATRIX_SIZE-1:0];
    reg [DATA_WIDTH-1:0] b_delay [MATRIX_SIZE-1:0][MATRIX_SIZE-1:0];
    reg valid_delay [MATRIX_SIZE-1:0][MATRIX_SIZE-1:0];
    
    // 控制计数器和状态
    reg [5:0] cycle_count;
    reg [2:0] state;
    localparam IDLE = 3'b000;
    localparam COMPUTING = 3'b001;
    localparam DRAINING = 3'b010;
    localparam OUTPUT = 3'b011;
    
    // 输入延迟链实现
    genvar i, j;
    generate
        for (i = 0; i < MATRIX_SIZE; i = i + 1) begin : input_delay
            always @(posedge clk or negedge rst_n) begin
                if (!rst_n) begin
                    for (int k = 0; k <= i; k++) begin
                        a_delay[i][k] <= 0;
                        b_delay[i][k] <= 0;
                        valid_delay[i][k] <= 0;
                    end
                end else if (state == COMPUTING || state == DRAINING) begin
                    // A矩阵行延迟
                    a_delay[i][0] <= (state == COMPUTING) ? a_in[i] : 0;
                    valid_delay[i][0] <= (state == COMPUTING) ? valid_in : 0;
                    for (int k = 1; k <= i; k++) begin
                        a_delay[i][k] <= a_delay[i][k-1];
                        valid_delay[i][k] <= valid_delay[i][k-1];
                    end
                    
                    // B矩阵列延迟
                    b_delay[i][0] <= (state == COMPUTING) ? b_in[i] : 0;
                    for (int k = 1; k <= i; k++) begin
                        b_delay[i][k] <= b_delay[i][k-1];
                    end
                end
            end
        end
    endgenerate
    
    // 脉动阵列PE - 完全流水线化
    generate
        for (i = 0; i < MATRIX_SIZE; i = i + 1) begin : pe_row
            for (j = 0; j < MATRIX_SIZE; j = j + 1) begin : pe_col
                
                // PE输入信号
                wire [DATA_WIDTH-1:0] a_input = (j == 0) ? a_delay[i][i] : pe_a_reg2[i][j-1];
                wire [DATA_WIDTH-1:0] b_input = (i == 0) ? b_delay[j][j] : pe_b_reg2[i-1][j];
                wire valid_input = (i == 0 && j == 0) ? valid_delay[0][0] :
                                  (j == 0) ? valid_delay[i][i] :
                                  (i == 0) ? valid_delay[j][j] : 1'b1;
                
                always @(posedge clk or negedge rst_n) begin
                    if (!rst_n) begin
                        pe_a_reg1[i][j] <= 0;
                        pe_a_reg2[i][j] <= 0;
                        pe_b_reg1[i][j] <= 0;
                        pe_b_reg2[i][j] <= 0;
                        pe_mult[i][j] <= 0;
                        pe_acc[i][j] <= 0;
                    end else begin
                        // Stage 1: 输入寄存
                        pe_a_reg1[i][j] <= a_input;
                        pe_b_reg1[i][j] <= b_input;
                        
                        // Stage 2: 传播和乘法准备
                        pe_a_reg2[i][j] <= pe_a_reg1[i][j];
                        pe_b_reg2[i][j] <= pe_b_reg1[i][j];
                        
                        // Stage 3: 乘法
                        pe_mult[i][j] <= pe_a_reg1[i][j] * pe_b_reg1[i][j];
                        
                        // Stage 4: 累加
                        if (start) begin
                            pe_acc[i][j] <= 0;
                        end else if (valid_input && (state == COMPUTING || state == DRAINING)) begin
                            pe_acc[i][j] <= pe_acc[i][j] + pe_mult[i][j];
                        end
                    end
                end
            end
        end
    endgenerate
    
    // 主控制状态机
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            state <= IDLE;
            cycle_count <= 0;
            done <= 1'b0;
            valid_out <= 1'b0;
            for (int i = 0; i < MATRIX_SIZE; i++) begin
                for (int j = 0; j < MATRIX_SIZE; j++) begin
                    c_out[i][j] <= 0;
                end
            end
        end else begin
            case (state)
                IDLE: begin
                    if (start) begin
                        state <= COMPUTING;
                        cycle_count <= 0;
                        done <= 1'b0;
                        valid_out <= 1'b0;
                    end
                end
                
                COMPUTING: begin
                    cycle_count <= cycle_count + 1;
                    if (cycle_count == MATRIX_SIZE - 1) begin
                        state <= DRAINING;
                        cycle_count <= 0;
                    end
                end
                
                DRAINING: begin
                    cycle_count <= cycle_count + 1;
                    if (cycle_count == 2*MATRIX_SIZE + 2) begin
                        state <= OUTPUT;
                        cycle_count <= 0;
                    end
                end
                
                OUTPUT: begin
                    // 输出结果
                    for (int i = 0; i < MATRIX_SIZE; i++) begin
                        for (int j = 0; j < MATRIX_SIZE; j++) begin
                            c_out[i][j] <= pe_acc[i][j];
                        end
                    end
                    done <= 1'b1;
                    valid_out <= 1'b1;
                    state <= IDLE;
                end
            endcase
        end
    end

endmodule
            </div>
            
            <p>Chisel版本的脉动矩阵乘法器：</p>
            <div class="code-block">
import chisel3._
import chisel3.util._

class SystolicMatrixMultiplier(dataWidth: Int = 16, matrixSize: Int = 4) extends Module {
  val accWidth = dataWidth * 2 + log2Ceil(matrixSize)
  
  val io = IO(new Bundle {
    val start = Input(Bool())
    val valid_in = Input(Bool())
    val a_in = Input(Vec(matrixSize, UInt(dataWidth.W)))
    val b_in = Input(Vec(matrixSize, UInt(dataWidth.W)))
    val c_out = Output(Vec(matrixSize, Vec(matrixSize, UInt(accWidth.W))))
    val done = Output(Bool())
    val valid_out = Output(Bool())
  })
  
  // PE内部的流水线寄存器
  val peArray = Seq.fill(matrixSize, matrixSize) {
    new Bundle {
      val aReg1 = Reg(UInt(dataWidth.W))
      val aReg2 = Reg(UInt(dataWidth.W))
      val bReg1 = Reg(UInt(dataWidth.W))
      val bReg2 = Reg(UInt(dataWidth.W))
      val mult = Reg(UInt((dataWidth * 2).W))
      val acc = Reg(UInt(accWidth.W))
    }
  }
  
  // 输入延迟链
  val aDelay = Seq.tabulate(matrixSize) { i =>
    val delayChain = Module(new ShiftRegister(UInt(dataWidth.W), i + 1))
    delayChain.io.in := io.a_in(i)
    delayChain.io.enable := (state === computing) || (state === draining)
    delayChain
  }
  
  val bDelay = Seq.tabulate(matrixSize) { i =>
    val delayChain = Module(new ShiftRegister(UInt(dataWidth.W), i + 1))
    delayChain.io.in := io.b_in(i)
    delayChain.io.enable := (state === computing) || (state === draining)
    delayChain
  }
  
  // 状态机
  val idle :: computing :: draining :: output :: Nil = Enum(4)
  val state = RegInit(idle)
  val cycleCount = RegInit(0.U(6.W))
  
  // PE阵列连接和计算
  for (i <- 0 until matrixSize) {
    for (j <- 0 until matrixSize) {
      val pe = peArray(i)(j)
      
      // 输入连接
      val aInput = if (j == 0) aDelay(i).io.out else peArray(i)(j-1).aReg2
      val bInput = if (i == 0) bDelay(j).io.out else peArray(i-1)(j).bReg2
      
      // 流水线寄存器
      pe.aReg1 := aInput
      pe.bReg1 := bInput
      pe.aReg2 := pe.aReg1
      pe.bReg2 := pe.bReg1
      
      // 乘法器
      pe.mult := pe.aReg1 * pe.bReg1
      
      // 累加器
      when(io.start) {
        pe.acc := 0.U
      }.elsewhen((state === computing || state === draining) && io.valid_in) {
        pe.acc := pe.acc + pe.mult
      }
      
      // 输出连接
      io.c_out(i)(j) := pe.acc
    }
  }
  
  // 控制逻辑
  switch(state) {
    is(idle) {
      when(io.start) {
        state := computing
        cycleCount := 0.U
      }
    }
    is(computing) {
      cycleCount := cycleCount + 1.U
      when(cycleCount === (matrixSize - 1).U) {
        state := draining
        cycleCount := 0.U
      }
    }
    is(draining) {
      cycleCount := cycleCount + 1.U
      when(cycleCount === (2 * matrixSize + 2).U) {
        state := output
      }
    }
    is(output) {
      state := idle
    }
  }
  
  io.done := state === output
  io.valid_out := state === output
}

// 辅助移位寄存器模块
class ShiftRegister[T <: Data](gen: T, depth: Int) extends Module {
  val io = IO(new Bundle {
    val in = Input(gen.cloneType)
    val out = Output(gen.cloneType)
    val enable = Input(Bool())
  })
  
  val regs = Reg(Vec(depth, gen.cloneType))
  
  when(io.enable) {
    regs(0) := io.in
    for (i <- 1 until depth) {
      regs(i) := regs(i - 1)
    }
  }
  
  io.out := regs(depth - 1)
}
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <section id="chapter7" class="chapter">
            <h2>第7章：验证与测试</h2>
            
            <p>本章深入探讨NPU芯片的验证策略、测试方法和关键技术，涵盖从RTL验证到后硅验证的完整流程。</p>

            <h3>7.0 制定NPU验证计划</h3>
            
            <p>验证计划是指导整个验证工作的纲领性文档，定义了验证的目标、范围、策略和资源分配。一个完善的验证计划能够确保验证工作的系统性和完整性。</p>
            
            <h4>7.0.1 验证目标与范围</h4>
            <div class="info-box">
                <p><strong>NPU验证计划模板</strong></p>
                <ul>
                    <li><strong>项目概述：</strong>
                        <ul>
                            <li>NPU架构描述（计算核心数量、存储层次、互连拓扑）</li>
                            <li>目标应用场景（边缘推理、数据中心训练等）</li>
                            <li>关键性能指标（TOPS、功耗、面积）</li>
                        </ul>
                    </li>
                    <li><strong>验证范围定义：</strong>
                        <ul>
                            <li>功能验证：指令集、数据流、控制逻辑</li>
                            <li>性能验证：吞吐量、延迟、带宽利用率</li>
                            <li>功耗验证：动态功耗、静态功耗、功耗管理</li>
                            <li>兼容性验证：软件栈、编译器、驱动程序</li>
                        </ul>
                    </li>
                    <li><strong>验证边界：</strong>
                        <ul>
                            <li>包含的模块：MAC阵列、DMA控制器、调度器、互连</li>
                            <li>排除的模块：外部DDR控制器、PCIe接口（假设已验证）</li>
                            <li>配置范围：支持的数据类型、批处理大小、网络层类型</li>
                        </ul>
                    </li>
                </ul>
            </div>
            
            <h4>7.0.2 验证策略与方法选择</h4>
            <div class="info-box">
                <p><strong>验证策略金字塔：</strong></p>
                <div style="text-align: center; margin: 20px 0;">
                    <pre style="display: inline-block; text-align: left;">
                    ┌─────────────────┐
                    │  系统级验证      │ ← 软硬件协同、真实应用
                    ├─────────────────┤
                    │  子系统验证      │ ← 多模块集成、数据流
                    ├─────────────────┤  
                    │   模块验证       │ ← UVM环境、功能覆盖
                    ├─────────────────┤
                    │   单元验证       │ ← 形式化验证、定向测试
                    └─────────────────┘
                    </pre>
                </div>
                <p><strong>方法选择准则：</strong></p>
                <ul>
                    <li><strong>形式化验证：</strong>适用于控制密集型模块（如仲裁器、FSM）</li>
                    <li><strong>约束随机验证：</strong>适用于数据路径和配置空间大的模块</li>
                    <li><strong>定向测试：</strong>适用于特定场景和边界条件</li>
                    <li><strong>硬件加速：</strong>适用于系统级性能验证和软件开发</li>
                </ul>
            </div>
            
            <h4>7.0.3 覆盖率驱动的验证</h4>
            <div class="code-block">
// NPU验证计划中的覆盖率定义示例
class npu_coverage_plan;
    
    // 功能覆盖率定义
    covergroup functional_coverage;
        // 指令类型覆盖
        instruction_cp: coverpoint instruction_type {
            bins conv_ops[] = {CONV_1x1, CONV_3x3, CONV_5x5, CONV_DW};
            bins pooling_ops[] = {MAX_POOL_2x2, AVG_POOL_2x2, GLOBAL_POOL};
            bins activation_ops[] = {RELU, RELU6, SIGMOID, TANH};
            bins elementwise_ops[] = {ADD, MUL, CONCAT};
        }
        
        // 数据类型覆盖
        datatype_cp: coverpoint data_type {
            bins integer_types[] = {INT8, UINT8, INT16};
            bins float_types[] = {FP16, BF16, FP32};
            bins mixed_precision = {INT8_INT32};
        }
        
        // 张量大小覆盖
        tensor_size_cp: coverpoint tensor_size {
            bins small = {[1:32]};
            bins medium = {[33:224]};
            bins large = {[225:1024]};
            bins boundary[] = {1, 32, 64, 128, 224, 256, 512, 1024};
        }
        
        // 交叉覆盖：指令×数据类型
        inst_datatype_cross: cross instruction_cp, datatype_cp {
            // 排除不支持的组合
            illegal_bins invalid = binsof(instruction_cp.conv_ops) && 
                                  binsof(datatype_cp.float_types);
        }
        
        // 配置覆盖
        config_cp: coverpoint dma_mode {
            bins normal_mode = {DMA_NORMAL};
            bins scatter_gather = {DMA_SCATTER_GATHER};
            bins circular_buffer = {DMA_CIRCULAR};
        }
        
        // 错误场景覆盖
        error_cp: coverpoint error_injection {
            bins memory_ecc_error = {MEM_ECC_SINGLE, MEM_ECC_DOUBLE};
            bins bus_error = {AXI_DECODE_ERROR, AXI_SLAVE_ERROR};
            bins overflow = {MAC_OVERFLOW, ACCUMULATOR_OVERFLOW};
        }
    endgroup
    
    // 代码覆盖率目标
    class code_coverage_goals;
        parameter LINE_COVERAGE_TARGET = 95;      // 行覆盖率目标
        parameter BRANCH_COVERAGE_TARGET = 90;    // 分支覆盖率目标
        parameter TOGGLE_COVERAGE_TARGET = 85;    // 翻转覆盖率目标
        parameter FSM_COVERAGE_TARGET = 100;      // 状态机覆盖率目标
        parameter ASSERTION_COVERAGE_TARGET = 100; // 断言覆盖率目标
    endclass
    
    // 验证里程碑定义
    typedef enum {
        MILESTONE_UNIT_COMPLETE,      // 单元验证完成
        MILESTONE_INTEGRATION_READY,  // 集成验证就绪
        MILESTONE_RANDOM_STABLE,      // 随机测试稳定
        MILESTONE_COVERAGE_MET,       // 覆盖率达标
        MILESTONE_PERFORMANCE_VERIFIED, // 性能验证完成
        MILESTONE_TAPE_OUT_READY      // 流片就绪
    } verification_milestone_e;
    
endclass
            </div>
            
            <h4>7.0.4 资源规划与进度管理</h4>
            <div class="info-box">
                <p><strong>验证资源估算：</strong></p>
                <table class="comparison-table">
                    <tr>
                        <th>验证任务</th>
                        <th>工作量(人周)</th>
                        <th>所需资源</th>
                        <th>关键依赖</th>
                    </tr>
                    <tr>
                        <td>验证环境搭建</td>
                        <td>4-6</td>
                        <td>高级验证工程师×2</td>
                        <td>设计规格完成</td>
                    </tr>
                    <tr>
                        <td>IP级验证</td>
                        <td>8-12</td>
                        <td>验证工程师×4</td>
                        <td>RTL代码稳定</td>
                    </tr>
                    <tr>
                        <td>系统级验证</td>
                        <td>12-16</td>
                        <td>系统工程师×3</td>
                        <td>子系统验证完成</td>
                    </tr>
                    <tr>
                        <td>性能验证</td>
                        <td>6-8</td>
                        <td>性能工程师×2</td>
                        <td>功能验证稳定</td>
                    </tr>
                    <tr>
                        <td>回归测试维护</td>
                        <td>持续</td>
                        <td>验证工程师×1</td>
                        <td>CI/CD环境</td>
                    </tr>
                </table>
                
                <p><strong>计算资源需求：</strong></p>
                <ul>
                    <li>仿真服务器：128核CPU、512GB内存 × 10台</li>
                    <li>形式化验证：专用服务器 × 2台</li>
                    <li>FPGA原型：Xilinx VU19P × 4块</li>
                    <li>许可证：VCS/Verdi × 20席、Jasper × 4席</li>
                </ul>
            </div>

            <h3>7.1 验证策略与方法学</h3>
            
            <h4>7.1.1 UVM验证环境</h4>
            <p>UVM（Universal Verification Methodology）提供了标准化的验证组件和可重用的验证环境架构。</p>
            
            <div class="code-block">
// NPU卷积模块的高级UVM测试环境
class conv_sequence_item extends uvm_sequence_item;
    `uvm_object_utils(conv_sequence_item)
    
    // 输入数据
    rand bit [7:0] input_data[];
    rand bit [7:0] weight_data[];
    rand int kernel_size;
    rand int stride;
    rand int padding;
    
    // 错误注入控制
    rand bit enable_error_injection;
    rand error_type_e error_type;
    rand int error_location;
    
    // 错误类型定义
    typedef enum {
        NO_ERROR,
        DATA_CORRUPTION,      // 数据损坏
        WEIGHT_CORRUPTION,    // 权重损坏
        OVERFLOW_ERROR,       // 溢出错误
        BUS_ERROR,           // 总线错误
        MEMORY_ECC_ERROR     // 内存ECC错误
    } error_type_e;
    
    // 约束
    constraint valid_params_c {
        kernel_size inside {1, 3, 5, 7};
        stride inside {1, 2, 4};
        padding inside {0, 1, 2, 3};
        input_data.size() == 224*224*3;  // 假设输入是224x224x3
        weight_data.size() == kernel_size*kernel_size*3*64;  // 输出64通道
    }
    
    // 错误注入约束
    constraint error_injection_c {
        enable_error_injection dist {0 := 90, 1 := 10};  // 10%概率注入错误
        if (enable_error_injection) {
            error_type dist {
                NO_ERROR := 0,
                DATA_CORRUPTION := 30,
                WEIGHT_CORRUPTION := 20,
                OVERFLOW_ERROR := 20,
                BUS_ERROR := 20,
                MEMORY_ECC_ERROR := 10
            };
            error_location inside {[0:input_data.size()-1]};
        } else {
            error_type == NO_ERROR;
        }
    }
    
    function new(string name = "conv_sequence_item");
        super.new(name);
    endfunction
    
    // 后随机化处理
    function void post_randomize();
        // 根据错误类型注入错误
        if (enable_error_injection) begin
            case (error_type)
                DATA_CORRUPTION: begin
                    // 随机翻转数据中的几个比特
                    for (int i = 0; i < 5; i++) begin
                        int idx = $urandom_range(0, input_data.size()-1);
                        input_data[idx] = input_data[idx] ^ (1 << $urandom_range(0, 7));
                    end
                end
                WEIGHT_CORRUPTION: begin
                    // 将某些权重设置为极值
                    for (int i = 0; i < 10; i++) begin
                        int idx = $urandom_range(0, weight_data.size()-1);
                        weight_data[idx] = $urandom_range(0, 1) ? 8'hFF : 8'h00;
                    end
                end
            endcase
        end
    endfunction
endclass

// 增强型卷积模块Driver（支持错误注入）
class conv_driver extends uvm_driver #(conv_sequence_item);
    `uvm_component_utils(conv_driver)
    
    virtual conv_if vif;
    int error_count = 0;
    
    function new(string name, uvm_component parent);
        super.new(name, parent);
    endfunction
    
    task run_phase(uvm_phase phase);
        forever begin
            seq_item_port.get_next_item(req);
            drive_transaction(req);
            seq_item_port.item_done();
        end
    endtask
    
    task drive_transaction(conv_sequence_item trans);
        // 配置卷积参数
        vif.kernel_size <= trans.kernel_size;
        vif.stride <= trans.stride;
        vif.padding <= trans.padding;
        @(posedge vif.clk);
        
        // 根据错误类型注入总线错误
        if (trans.enable_error_injection && trans.error_type == conv_sequence_item::BUS_ERROR) begin
            inject_bus_error();
        end
        
        // 加载权重（可能注入ECC错误）
        vif.weight_valid <= 1'b1;
        foreach(trans.weight_data[i]) begin
            vif.weight_data <= trans.weight_data[i];
            
            // 注入内存ECC错误
            if (trans.enable_error_injection && 
                trans.error_type == conv_sequence_item::MEMORY_ECC_ERROR &&
                i == trans.error_location) begin
                vif.mem_ecc_error <= 1'b1;
                `uvm_info("DRIVER", $sformatf("Injecting ECC error at weight[%0d]", i), UVM_LOW)
            end else begin
                vif.mem_ecc_error <= 1'b0;
            end
            
            @(posedge vif.clk);
        end
        vif.weight_valid <= 1'b0;
        vif.mem_ecc_error <= 1'b0;
        
        // 输入数据（可能注入溢出）
        vif.data_valid <= 1'b1;
        foreach(trans.input_data[i]) begin
            vif.input_data <= trans.input_data[i];
            
            // 注入溢出错误
            if (trans.enable_error_injection && 
                trans.error_type == conv_sequence_item::OVERFLOW_ERROR &&
                i % 100 == 0) begin
                vif.force_overflow <= 1'b1;
                `uvm_info("DRIVER", "Forcing accumulator overflow", UVM_LOW)
            end else begin
                vif.force_overflow <= 1'b0;
            end
            
            @(posedge vif.clk);
        end
        vif.data_valid <= 1'b0;
        vif.force_overflow <= 1'b0;
        
        // 记录错误注入统计
        if (trans.enable_error_injection) begin
            error_count++;
            `uvm_info("DRIVER", $sformatf("Total errors injected: %0d", error_count), UVM_MEDIUM)
        end
    endtask
    
    // 注入总线错误
    task inject_bus_error();
        @(posedge vif.clk);
        vif.bus_error_inject <= 1'b1;
        vif.bus_resp <= 2'b10; // SLVERR
        @(posedge vif.clk);
        vif.bus_error_inject <= 1'b0;
        vif.bus_resp <= 2'b00; // OKAY
        `uvm_warning("DRIVER", "Bus error injected")
    endtask
endclass

// Monitor和Scoreboard
class conv_monitor extends uvm_monitor;
    `uvm_component_utils(conv_monitor)
    
    virtual conv_if vif;
    uvm_analysis_port #(conv_result_item) ap;
    
    function new(string name, uvm_component parent);
        super.new(name, parent);
        ap = new("ap", this);
    endfunction
    
    task run_phase(uvm_phase phase);
        conv_result_item res;
        forever begin
            wait(vif.output_valid);
            res = conv_result_item::type_id::create("res");
            
            // 收集输出数据
            while(vif.output_valid) begin
                res.output_data.push_back(vif.output_data);
                @(posedge vif.clk);
            end
            
            ap.write(res);
        end
    endtask
endclass

// 高级Scoreboard（支持乱序、预测和详细分析）
class conv_scoreboard extends uvm_scoreboard;
    `uvm_component_utils(conv_scoreboard)
    
    // 分析端口
    uvm_analysis_export #(conv_sequence_item) input_export;
    uvm_analysis_export #(conv_result_item) output_export;
    uvm_tlm_analysis_fifo #(conv_sequence_item) input_fifo;
    uvm_tlm_analysis_fifo #(conv_result_item) output_fifo;
    
    // Python Golden Model接口
    protected int python_model;
    
    // 预测队列（支持乱序）
    typedef struct {
        int transaction_id;
        bit [7:0] expected_data[];
        conv_sequence_item input_item;
        time start_time;
    } prediction_t;
    
    prediction_t prediction_queue[$];
    
    // 统计信息
    int total_transactions = 0;
    int matched_transactions = 0;
    int mismatched_transactions = 0;
    int error_injected_transactions = 0;
    int correct_error_detection = 0;
    real total_latency = 0;
    
    // 详细错误报告
    int mismatch_histogram[bit[7:0]];
    
    function new(string name, uvm_component parent);
        super.new(name, parent);
    endfunction
    
    function void build_phase(uvm_phase phase);
        super.build_phase(phase);
        input_export = new("input_export", this);
        output_export = new("output_export", this);
        input_fifo = new("input_fifo", this);
        output_fifo = new("output_fifo", this);
        
        // 初始化Python Golden Model
        python_model = init_python_model("conv_golden_model.py");
    endfunction
    
    function void connect_phase(uvm_phase phase);
        input_export.connect(input_fifo.analysis_export);
        output_export.connect(output_fifo.analysis_export);
    endfunction
    
    task run_phase(uvm_phase phase);
        fork
            process_inputs();
            process_outputs();
            periodic_report();
        join
    endtask
    
    // 处理输入并生成预测
    task process_inputs();
        conv_sequence_item input_item;
        prediction_t pred;
        
        forever begin
            input_fifo.get(input_item);
            
            // 生成预测
            pred.transaction_id = input_item.get_transaction_id();
            pred.input_item = input_item;
            pred.start_time = $time;
            
            // 调用Golden Model（考虑错误注入）
            if (input_item.enable_error_injection) begin
                case (input_item.error_type)
                    conv_sequence_item::DATA_CORRUPTION,
                    conv_sequence_item::WEIGHT_CORRUPTION:
                        pred.expected_data = compute_corrupted_result(input_item);
                    conv_sequence_item::OVERFLOW_ERROR:
                        pred.expected_data = compute_overflow_result(input_item);
                    default:
                        pred.expected_data = compute_golden_result(input_item);
                endcase
                error_injected_transactions++;
            end else begin
                pred.expected_data = compute_golden_result(input_item);
            end
            
            // 加入预测队列
            prediction_queue.push_back(pred);
            
            `uvm_info("SCOREBOARD", 
                $sformatf("Added prediction for transaction %0d", pred.transaction_id), 
                UVM_HIGH)
        end
    endtask
    
    // 处理输出并比较
    task process_outputs();
        conv_result_item output_item;
        prediction_t pred;
        int match_found;
        
        forever begin
            output_fifo.get(output_item);
            total_transactions++;
            
            // 在预测队列中查找匹配的transaction
            match_found = 0;
            foreach (prediction_queue[i]) begin
                if (prediction_queue[i].transaction_id == output_item.transaction_id) begin
                    pred = prediction_queue[i];
                    prediction_queue.delete(i);
                    match_found = 1;
                    break;
                end
            end
            
            if (!match_found) begin
                `uvm_error("SCOREBOARD", 
                    $sformatf("No prediction found for transaction %0d", 
                    output_item.transaction_id))
                continue;
            end
            
            // 计算延迟
            real latency = ($time - pred.start_time) / 1ns;
            total_latency += latency;
            
            // 详细比较
            if (compare_results(output_item, pred)) begin
                matched_transactions++;
                `uvm_info("SCOREBOARD", 
                    $sformatf("Transaction %0d PASSED (latency: %.2f ns)", 
                    output_item.transaction_id, latency), 
                    UVM_MEDIUM)
                    
                // 检查错误检测是否正确
                if (pred.input_item.enable_error_injection && output_item.error_detected) begin
                    correct_error_detection++;
                    `uvm_info("SCOREBOARD", "Error correctly detected by DUT", UVM_LOW)
                end
            end else begin
                mismatched_transactions++;
                report_mismatch(output_item, pred);
            end
        end
    endtask
    
    // 详细比较函数
    function bit compare_results(conv_result_item got, prediction_t exp);
        bit match = 1;
        int tolerance = exp.input_item.enable_error_injection ? 5 : 1;
        
        // 长度检查
        if (got.output_data.size() != exp.expected_data.size()) begin
            `uvm_error("SCOREBOARD", 
                $sformatf("Size mismatch: got %0d, expected %0d", 
                got.output_data.size(), exp.expected_data.size()))
            return 0;
        end
        
        // 逐元素比较（考虑容差）
        foreach (got.output_data[i]) begin
            int diff = got.output_data[i] - exp.expected_data[i];
            if (diff < 0) diff = -diff;
            
            if (diff > tolerance) begin
                match = 0;
                mismatch_histogram[diff]++;
            end
        end
        
        return match;
    endfunction
    
    // 详细错误报告
    function void report_mismatch(conv_result_item got, prediction_t exp);
        string mismatch_details;
        int first_mismatch_idx = -1;
        int mismatch_count = 0;
        
        // 找出所有不匹配的位置
        foreach (got.output_data[i]) begin
            if (got.output_data[i] != exp.expected_data[i]) begin
                if (first_mismatch_idx == -1) first_mismatch_idx = i;
                mismatch_count++;
                
                if (mismatch_count <= 10) begin  // 只报告前10个
                    mismatch_details = {mismatch_details, 
                        $sformatf("\n  [%0d]: got=%0d, exp=%0d, diff=%0d", 
                        i, got.output_data[i], exp.expected_data[i], 
                        got.output_data[i] - exp.expected_data[i])};
                end
            end
        end
        
        `uvm_error("SCOREBOARD", 
            $sformatf("Transaction %0d FAILED: %0d mismatches out of %0d%s%s",
            got.transaction_id, mismatch_count, got.output_data.size(),
            mismatch_details,
            (mismatch_count > 10) ? "\n  ..." : ""))
            
        // 如果是错误注入的情况，提供额外信息
        if (exp.input_item.enable_error_injection) begin
            `uvm_info("SCOREBOARD", 
                $sformatf("Error injection type: %s", 
                exp.input_item.error_type.name()), UVM_LOW)
        end
    endfunction
    
    // 定期报告
    task periodic_report();
        forever begin
            #10ms;
            report_phase(null);
        end
    endtask
    
    function void report_phase(uvm_phase phase);
        real pass_rate = (total_transactions > 0) ? 
            (100.0 * matched_transactions / total_transactions) : 0;
        real avg_latency = (total_transactions > 0) ? 
            (total_latency / total_transactions) : 0;
        real error_detection_rate = (error_injected_transactions > 0) ?
            (100.0 * correct_error_detection / error_injected_transactions) : 0;
            
        `uvm_info("SCOREBOARD", "==== Scoreboard Report ====", UVM_LOW)
        `uvm_info("SCOREBOARD", $sformatf("Total transactions: %0d", total_transactions), UVM_LOW)
        `uvm_info("SCOREBOARD", $sformatf("Matched: %0d (%.2f%%)", matched_transactions, pass_rate), UVM_LOW)
        `uvm_info("SCOREBOARD", $sformatf("Mismatched: %0d", mismatched_transactions), UVM_LOW)
        `uvm_info("SCOREBOARD", $sformatf("Average latency: %.2f ns", avg_latency), UVM_LOW)
        `uvm_info("SCOREBOARD", $sformatf("Error injected: %0d", error_injected_transactions), UVM_LOW)
        `uvm_info("SCOREBOARD", $sformatf("Error detection rate: %.2f%%", error_detection_rate), UVM_LOW)
        
        // 错误分布直方图
        if (mismatch_histogram.size() > 0) begin
            `uvm_info("SCOREBOARD", "Mismatch histogram:", UVM_LOW)
            foreach (mismatch_histogram[diff]) begin
                `uvm_info("SCOREBOARD", 
                    $sformatf("  Difference %0d: %0d occurrences", 
                    diff, mismatch_histogram[diff]), UVM_LOW)
            end
        end
    endfunction
    
endclass

// 高级测试序列（约束随机和错误注入）
class conv_random_sequence extends uvm_sequence #(conv_sequence_item);
    `uvm_object_utils(conv_random_sequence)
    
    // 配置参数
    rand int num_normal_trans;
    rand int num_error_trans;
    rand bit enable_back_to_back;
    rand bit enable_size_sweep;
    
    constraint sequence_config_c {
        num_normal_trans inside {[100:1000]};
        num_error_trans inside {[10:50]};
        enable_back_to_back dist {0 := 70, 1 := 30};
        enable_size_sweep dist {0 := 60, 1 := 40};
    }
    
    function new(string name = "conv_random_sequence");
        super.new(name);
    endfunction
    
    task body();
        conv_sequence_item trans;
        
        // 尺寸扫描测试
        if (enable_size_sweep) begin
            foreach (int size_list[i] = '{1, 3, 5, 7}) begin
                `uvm_info("SEQUENCE", $sformatf("Testing kernel size %0d", size_list[i]), UVM_LOW)
                repeat(10) begin
                    trans = conv_sequence_item::type_id::create("trans");
                    start_item(trans);
                    assert(trans.randomize() with {
                        kernel_size == size_list[i];
                        enable_error_injection == 0;
                    });
                    finish_item(trans);
                end
            end
        end
        
        // 正常事务
        repeat(num_normal_trans) begin
            trans = conv_sequence_item::type_id::create("trans");
            start_item(trans);
            assert(trans.randomize() with {
                enable_error_injection == 0;
            });
            finish_item(trans);
            
            // 背靠背测试
            if (!enable_back_to_back) begin
                #($urandom_range(10, 100) * 1ns);
            end
        end
        
        // 错误注入事务
        repeat(num_error_trans) begin
            trans = conv_sequence_item::type_id::create("trans");
            start_item(trans);
            assert(trans.randomize() with {
                enable_error_injection == 1;
                // 确保错误类型均匀分布
                error_type dist {
                    conv_sequence_item::DATA_CORRUPTION := 25,
                    conv_sequence_item::WEIGHT_CORRUPTION := 25,
                    conv_sequence_item::OVERFLOW_ERROR := 25,
                    conv_sequence_item::BUS_ERROR := 15,
                    conv_sequence_item::MEMORY_ECC_ERROR := 10
                };
            });
            finish_item(trans);
            
            // 给DUT时间恢复
            #($urandom_range(100, 500) * 1ns);
        end
        
        // 压力测试：最大尺寸配置
        `uvm_info("SEQUENCE", "Starting stress test with maximum configurations", UVM_LOW)
        repeat(20) begin
            trans = conv_sequence_item::type_id::create("trans");
            start_item(trans);
            assert(trans.randomize() with {
                kernel_size == 7;
                stride == 1;
                padding == 3;
                enable_error_injection == 0;
            });
            finish_item(trans);
        end
    endtask
endclass

// 专门的错误恢复测试序列
class error_recovery_sequence extends uvm_sequence #(conv_sequence_item);
    `uvm_object_utils(error_recovery_sequence)
    
    function new(string name = "error_recovery_sequence");
        super.new(name);
    endfunction
    
    task body();
        conv_sequence_item trans;
        
        // 测试每种错误类型的恢复
        foreach (conv_sequence_item::error_type_e error_type = 
                {conv_sequence_item::BUS_ERROR,
                 conv_sequence_item::MEMORY_ECC_ERROR,
                 conv_sequence_item::OVERFLOW_ERROR}) begin
            
            `uvm_info("SEQUENCE", $sformatf("Testing recovery from %s", error_type.name()), UVM_LOW)
            
            // 注入错误
            trans = conv_sequence_item::type_id::create("trans");
            start_item(trans);
            assert(trans.randomize() with {
                enable_error_injection == 1;
                error_type == error_type;
            });
            finish_item(trans);
            
            // 等待错误处理
            #1us;
            
            // 发送正常事务验证恢复
            repeat(5) begin
                trans = conv_sequence_item::type_id::create("trans");
                start_item(trans);
                assert(trans.randomize() with {
                    enable_error_injection == 0;
                    kernel_size == 3;  // 使用标准配置
                });
                finish_item(trans);
                #100ns;
            end
        end
    endtask
endclass
            </div>

            <h4>7.1.2 形式化验证</h4>
            <p>形式化验证通过数学方法证明设计的正确性，特别适合控制密集型逻辑。</p>
            
            <div class="code-block">
// NPU指令调度单元的形式化验证属性
module instruction_scheduler_properties (
    input clk,
    input rst_n,
    input [3:0] inst_valid,
    input [3:0] inst_ready,
    output [3:0] inst_grant
);

    // 假设和约束
    assume property (@(posedge clk) disable iff (!rst_n)
        $countones(inst_grant) <= 1  // 最多授权一个指令
    );
    
    // 属性1：没有饥饿（no starvation）
    property no_starvation(int idx);
        @(posedge clk) disable iff (!rst_n)
        inst_valid[idx] && !inst_grant[idx] |-> 
            ##[1:16] inst_grant[idx];  // 16周期内必须得到授权
    endproperty
    
    generate
        for (genvar i = 0; i < 4; i++) begin : starvation_check
            assert property (no_starvation(i))
            else $error("Instruction %0d starved", i);
        end
    endgenerate
    
    // 属性2：互斥（mutual exclusion）
    property mutual_exclusion;
        @(posedge clk) disable iff (!rst_n)
        $onehot0(inst_grant);  // 最多一位为1
    endproperty
    
    assert property (mutual_exclusion)
    else $error("Multiple grants detected");
    
    // 属性3：有效授权（valid grant）
    property valid_grant;
        @(posedge clk) disable iff (!rst_n)
        |inst_grant |-> inst_grant & inst_valid;
    endproperty
    
    assert property (valid_grant)
    else $error("Grant to invalid instruction");
    
    // 覆盖属性
    covergroup scheduler_coverage @(posedge clk);
        valid_cp: coverpoint inst_valid {
            bins no_req = {4'b0000};
            bins single_req[] = {4'b0001, 4'b0010, 4'b0100, 4'b1000};
            bins multi_req = {[4'b0011:4'b1111]};
        }
        
        grant_cp: coverpoint inst_grant {
            bins no_grant = {4'b0000};
            bins grants[] = {4'b0001, 4'b0010, 4'b0100, 4'b1000};
        }
        
        valid_grant_cross: cross valid_cp, grant_cp {
            illegal_bins invalid = binsof(valid_cp.no_req) && 
                                  !binsof(grant_cp.no_grant);
        }
    endgroup
    
    scheduler_coverage cov_inst = new();

endmodule
            </div>

            <h4>7.1.3 硬件仿真加速</h4>
            <p>使用FPGA进行硬件仿真，实现MHz级别的验证速度。</p>
            
            <div class="code-block">
// Emulation环境配置示例
class npu_emulation_env extends uvm_env;
    `uvm_component_utils(npu_emulation_env)
    
    // 仿真加速器接口
    virtual emulator_if emu_if;
    
    // 软件栈组件
    npu_driver_agent driver_agent;
    npu_runtime_agent runtime_agent;
    
    function new(string name, uvm_component parent);
        super.new(name, parent);
    endfunction
    
    function void build_phase(uvm_phase phase);
        super.build_phase(phase);
        
        // 配置仿真环境
        if (!uvm_config_db#(virtual emulator_if)::get(
            this, "", "emu_if", emu_if))
            `uvm_fatal("CONFIG", "Cannot get emulator interface")
        
        // 创建软件栈代理
        driver_agent = npu_driver_agent::type_id::create("driver_agent", this);
        runtime_agent = npu_runtime_agent::type_id::create("runtime_agent", this);
    endfunction
    
    task run_phase(uvm_phase phase);
        // 加载NPU固件
        load_firmware("npu_firmware.bin");
        
        // 运行MLPerf基准测试
        run_mlperf_benchmark("mobilenet_v2");
        run_mlperf_benchmark("resnet50");
        run_mlperf_benchmark("bert");
    endtask
    
    task load_firmware(string firmware_path);
        int firmware_data[];
        
        // 读取固件文件
        $readmemh(firmware_path, firmware_data);
        
        // 通过JTAG加载到NPU
        foreach(firmware_data[i]) begin
            emu_if.jtag_write(32'h1000_0000 + i*4, firmware_data[i]);
        end
    endtask
    
    task run_mlperf_benchmark(string model_name);
        real start_time, end_time;
        int inference_count;
        
        `uvm_info("EMULATION", $sformatf("Running %s benchmark", model_name), UVM_LOW)
        
        // 加载模型
        runtime_agent.load_model(model_name);
        
        // 预热
        repeat(10) runtime_agent.run_inference();
        
        // 性能测试
        start_time = $realtime;
        repeat(1000) begin
            runtime_agent.run_inference();
            inference_count++;
        end
        end_time = $realtime;
        
        // 报告性能
        `uvm_info("EMULATION", 
            $sformatf("%s: %0.2f inferences/sec", 
            model_name, inference_count/(end_time-start_time)), 
            UVM_LOW)
    endtask
endclass
            </div>

            <h3>7.2 功能验证层次</h3>
            
            <h4>7.2.1 IP级验证</h4>
            <div class="code-block">
// 优化的MAC单元定向测试 - Verilog版本
module mac_unit_test;
    
    parameter DATA_WIDTH = 8;
    parameter ACC_WIDTH = 32;
    parameter PIPE_STAGES = 3;
    
    reg clk, rst_n;
    reg signed [DATA_WIDTH-1:0] a, b;
    reg signed [ACC_WIDTH-1:0] c_in;
    reg valid_in;
    wire signed [ACC_WIDTH-1:0] c_out;
    wire valid_out;
    
    // 测试结果跟踪
    reg [31:0] test_count;
    reg [31:0] pass_count;
    reg [31:0] fail_count;
    
    // 流水线延迟跟踪
    reg signed [DATA_WIDTH-1:0] a_pipe [PIPE_STAGES-1:0];
    reg signed [DATA_WIDTH-1:0] b_pipe [PIPE_STAGES-1:0];
    reg signed [ACC_WIDTH-1:0] c_pipe [PIPE_STAGES-1:0];
    reg valid_pipe [PIPE_STAGES-1:0];
    
    // DUT实例化 - 使用流水线化的MAC
    mac_unit_pipelined #(
        .DATA_WIDTH(DATA_WIDTH),
        .ACC_WIDTH(ACC_WIDTH),
        .PIPE_STAGES(PIPE_STAGES)
    ) dut (
        .clk(clk),
        .rst_n(rst_n),
        .a(a),
        .b(b),
        .c_in(c_in),
        .valid_in(valid_in),
        .c_out(c_out),
        .valid_out(valid_out)
    );
    
    // 时钟生成
    initial clk = 0;
    always #5 clk = ~clk;
    
    // 流水线延迟跟踪
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            for (int i = 0; i < PIPE_STAGES; i++) begin
                a_pipe[i] <= 0;
                b_pipe[i] <= 0;
                c_pipe[i] <= 0;
                valid_pipe[i] <= 0;
            end
        end else begin
            a_pipe[0] <= a;
            b_pipe[0] <= b;
            c_pipe[0] <= c_in;
            valid_pipe[0] <= valid_in;
            
            for (int i = 1; i < PIPE_STAGES; i++) begin
                a_pipe[i] <= a_pipe[i-1];
                b_pipe[i] <= b_pipe[i-1];
                c_pipe[i] <= c_pipe[i-1];
                valid_pipe[i] <= valid_pipe[i-1];
            end
        end
    end
    
    // 测试激励
    initial begin
        // 初始化
        rst_n = 0;
        a = 0; b = 0; c_in = 0; valid_in = 0;
        test_count = 0; pass_count = 0; fail_count = 0;
        #20 rst_n = 1;
        
        // 测试1：基本MAC操作
        run_test("Basic MAC", 8'd10, 8'd20, 32'd100, 32'd300);
        
        // 测试2：负数处理
        run_test("Negative MAC", -8'd50, 8'd4, 32'd0, -32'd200);
        
        // 测试3：溢出处理
        run_overflow_test();
        
        // 测试4：连续累加测试
        run_accumulation_test();
        
        // 测试5：随机测试
        run_random_test(1000);
        
        // 测试6：边界值测试
        run_boundary_test();
        
        // 打印测试结果
        $display("\n\n=== TEST SUMMARY ===");
        $display("Total tests: %d", test_count);
        $display("Passed: %d", pass_count);
        $display("Failed: %d", fail_count);
        $display("Pass rate: %.2f%%", pass_count * 100.0 / test_count);
        
        $finish;
    end
    
    // 基本测试任务
    task run_test(input string test_name,
                  input signed [DATA_WIDTH-1:0] test_a,
                  input signed [DATA_WIDTH-1:0] test_b,
                  input signed [ACC_WIDTH-1:0] test_c,
                  input signed [ACC_WIDTH-1:0] expected);
        
        @(posedge clk);
        a = test_a;
        b = test_b;
        c_in = test_c;
        valid_in = 1'b1;
        
        @(posedge clk);
        valid_in = 1'b0;
        
        // 等待流水线延迟
        wait(valid_out);
        @(posedge clk);
        
        test_count = test_count + 1;
        if (c_out == expected) begin
            $display("[PASS] %s: %d * %d + %d = %d", 
                    test_name, test_a, test_b, test_c, c_out);
            pass_count = pass_count + 1;
        end else begin
            $display("[FAIL] %s: Expected %d, got %d", 
                    test_name, expected, c_out);
            fail_count = fail_count + 1;
        end
    endtask
    
    // 溢出测试
    task run_overflow_test();
        reg signed [ACC_WIDTH+8:0] expected;
        
        // 正溢出测试
        @(posedge clk);
        a = 8'd127;
        b = 8'd127;
        c_in = {1'b0, {(ACC_WIDTH-1){1'b1}}} - 16000;
        valid_in = 1'b1;
        
        @(posedge clk);
        valid_in = 1'b0;
        
        wait(valid_out);
        @(posedge clk);
        
        expected = a * b + c_in;
        test_count = test_count + 1;
        
        if (expected > $signed({1'b0, {(ACC_WIDTH-1){1'b1}}}) && 
            c_out == {1'b0, {(ACC_WIDTH-1){1'b1}}}) begin
            $display("[PASS] Positive overflow handling");
            pass_count = pass_count + 1;
        end else begin
            $display("[FAIL] Positive overflow handling");
            fail_count = fail_count + 1;
        end
        
        // 负溢出测试
        @(posedge clk);
        a = -8'd128;
        b = 8'd127;
        c_in = {1'b1, {(ACC_WIDTH-1){1'b0}}} + 16000;
        valid_in = 1'b1;
        
        @(posedge clk);
        valid_in = 1'b0;
        
        wait(valid_out);
        @(posedge clk);
        
        expected = a * b + c_in;
        test_count = test_count + 1;
        
        if (expected < $signed({1'b1, {(ACC_WIDTH-1){1'b0}}}) && 
            c_out == {1'b1, {(ACC_WIDTH-1){1'b0}}}) begin
            $display("[PASS] Negative overflow handling");
            pass_count = pass_count + 1;
        end else begin
            $display("[FAIL] Negative overflow handling");
            fail_count = fail_count + 1;
        end
    endtask
    
    // 累加测试
    task run_accumulation_test();
        reg signed [ACC_WIDTH-1:0] accumulated;
        
        accumulated = 0;
        
        // 连续10次累加
        for (int i = 0; i < 10; i++) begin
            @(posedge clk);
            a = i + 1;
            b = 2;
            c_in = (i == 0) ? 0 : c_out;
            valid_in = 1'b1;
            
            @(posedge clk);
            valid_in = 1'b0;
            
            accumulated = accumulated + (i + 1) * 2;
            
            wait(valid_out);
            @(posedge clk);
        end
        
        test_count = test_count + 1;
        if (c_out == accumulated) begin
            $display("[PASS] Accumulation test: Sum = %d", c_out);
            pass_count = pass_count + 1;
        end else begin
            $display("[FAIL] Accumulation test: Expected %d, got %d", 
                    accumulated, c_out);
            fail_count = fail_count + 1;
        end
    endtask
    
    // 随机测试
    task run_random_test(input int num_tests);
        reg signed [ACC_WIDTH-1:0] expected;
        int errors;
        
        errors = 0;
        
        for (int i = 0; i < num_tests; i++) begin
            @(posedge clk);
            a = $random;
            b = $random;
            c_in = $random;
            valid_in = 1'b1;
            
            expected = a * b + c_in;
            
            @(posedge clk);
            valid_in = 1'b0;
            
            wait(valid_out);
            @(posedge clk);
            
            if (c_out != expected) begin
                errors = errors + 1;
            end
        end
        
        test_count = test_count + 1;
        if (errors == 0) begin
            $display("[PASS] Random test: %d iterations", num_tests);
            pass_count = pass_count + 1;
        end else begin
            $display("[FAIL] Random test: %d errors in %d tests", 
                    errors, num_tests);
            fail_count = fail_count + 1;
        end
    endtask
    
    // 边界值测试
    task run_boundary_test();
        // 测试所有边界值组合
        reg signed [DATA_WIDTH-1:0] boundary_values [4];
        boundary_values[0] = {1'b0, {(DATA_WIDTH-1){1'b1}}}; // 最大正数
        boundary_values[1] = {1'b1, {(DATA_WIDTH-1){1'b0}}}; // 最小负数
        boundary_values[2] = 0;
        boundary_values[3] = -1;
        
        for (int i = 0; i < 4; i++) begin
            for (int j = 0; j < 4; j++) begin
                @(posedge clk);
                a = boundary_values[i];
                b = boundary_values[j];
                c_in = 0;
                valid_in = 1'b1;
                
                @(posedge clk);
                valid_in = 1'b0;
                
                wait(valid_out);
                @(posedge clk);
            end
        end
        
        test_count = test_count + 1;
        $display("[INFO] Boundary test completed");
        pass_count = pass_count + 1;
    endtask
    
endmodule

// 流水线化的MAC单元（用于测试）
module mac_unit_pipelined #(
    parameter DATA_WIDTH = 8,
    parameter ACC_WIDTH = 32,
    parameter PIPE_STAGES = 3
)(
    input wire clk,
    input wire rst_n,
    input wire signed [DATA_WIDTH-1:0] a,
    input wire signed [DATA_WIDTH-1:0] b,
    input wire signed [ACC_WIDTH-1:0] c_in,
    input wire valid_in,
    output reg signed [ACC_WIDTH-1:0] c_out,
    output reg valid_out
);
    
    // 流水线寄存器
    reg signed [DATA_WIDTH-1:0] a_reg1, a_reg2;
    reg signed [DATA_WIDTH-1:0] b_reg1, b_reg2;
    reg signed [ACC_WIDTH-1:0] c_reg1, c_reg2;
    reg signed [DATA_WIDTH*2-1:0] mult_reg;
    reg valid_reg1, valid_reg2, valid_reg3;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            a_reg1 <= 0; a_reg2 <= 0;
            b_reg1 <= 0; b_reg2 <= 0;
            c_reg1 <= 0; c_reg2 <= 0;
            mult_reg <= 0;
            c_out <= 0;
            valid_reg1 <= 0; valid_reg2 <= 0; valid_reg3 <= 0;
            valid_out <= 0;
        end else begin
            // Stage 1: 输入寄存
            a_reg1 <= a;
            b_reg1 <= b;
            c_reg1 <= c_in;
            valid_reg1 <= valid_in;
            
            // Stage 2: 乘法
            a_reg2 <= a_reg1;
            b_reg2 <= b_reg1;
            mult_reg <= a_reg1 * b_reg1;
            c_reg2 <= c_reg1;
            valid_reg2 <= valid_reg1;
            
            // Stage 3: 加法和饱和处理
            if (valid_reg2) begin
                reg signed [ACC_WIDTH+1:0] sum;
                sum = mult_reg + c_reg2;
                
                // 饱和处理
                if (sum > $signed({1'b0, {(ACC_WIDTH-1){1'b1}}})) begin
                    c_out <= {1'b0, {(ACC_WIDTH-1){1'b1}}};
                end else if (sum < $signed({1'b1, {(ACC_WIDTH-1){1'b0}}})) begin
                    c_out <= {1'b1, {(ACC_WIDTH-1){1'b0}}};
                end else begin
                    c_out <= sum[ACC_WIDTH-1:0];
                end
            end
            valid_reg3 <= valid_reg2;
            valid_out <= valid_reg3;
        end
    end
    
endmodule
            </div>
            
            <p>Chisel版本的MAC单元测试：</p>
            <div class="code-block">
import chisel3._
import chisel3.util._
import chiseltest._

class MACUnitTest extends FlatSpec with ChiselScalatestTester {
  behavior of "MACUnit"
  
  it should "perform basic MAC operations" in {
    test(new MACUnitPipelined(8, 32, 3)) { dut =>
      // 初始化
      dut.io.a.poke(0.S)
      dut.io.b.poke(0.S)
      dut.io.c_in.poke(0.S)
      dut.io.valid_in.poke(false.B)
      dut.clock.step(5)
      
      // 基本MAC测试
      dut.io.a.poke(10.S)
      dut.io.b.poke(20.S)
      dut.io.c_in.poke(100.S)
      dut.io.valid_in.poke(true.B)
      dut.clock.step(1)
      dut.io.valid_in.poke(false.B)
      
      // 等待输出
      while (!dut.io.valid_out.peek().litToBoolean) {
        dut.clock.step(1)
      }
      
      dut.io.c_out.expect(300.S)
      
      // 负数测试
      dut.io.a.poke((-50).S)
      dut.io.b.poke(4.S)
      dut.io.c_in.poke(0.S)
      dut.io.valid_in.poke(true.B)
      dut.clock.step(1)
      dut.io.valid_in.poke(false.B)
      
      while (!dut.io.valid_out.peek().litToBoolean) {
        dut.clock.step(1)
      }
      
      dut.io.c_out.expect((-200).S)
    }
  }
  
  it should "handle overflow correctly" in {
    test(new MACUnitPipelined(8, 32, 3)) { dut =>
      // 正溢出测试
      dut.io.a.poke(127.S)
      dut.io.b.poke(127.S)
      dut.io.c_in.poke((Int.MaxValue - 16000).S)
      dut.io.valid_in.poke(true.B)
      dut.clock.step(1)
      dut.io.valid_in.poke(false.B)
      
      while (!dut.io.valid_out.peek().litToBoolean) {
        dut.clock.step(1)
      }
      
      dut.io.c_out.expect(Int.MaxValue.S)
    }
  }
}
            </div>

            <h4>7.2.2 子系统级验证</h4>
            <div class="code-block">
// PE阵列的随机测试
class pe_array_test extends uvm_test;
    `uvm_component_utils(pe_array_test)
    
    pe_array_env env;
    
    function new(string name, uvm_component parent);
        super.new(name, parent);
    endfunction
    
    function void build_phase(uvm_phase phase);
        super.build_phase(phase);
        env = pe_array_env::type_id::create("env", this);
        
        // 配置测试参数
        uvm_config_db#(int)::set(this, "env.agent", "array_size", 16);
        uvm_config_db#(int)::set(this, "env.agent", "data_width", 8);
    endfunction
    
    task run_phase(uvm_phase phase);
        pe_array_sequence seq;
        
        phase.raise_objection(this);
        
        // 运行不同的测试序列
        
        // 1. 单位矩阵测试
        seq = identity_matrix_seq::type_id::create("seq");
        seq.start(env.agent.sequencer);
        
        // 2. 稀疏矩阵测试
        seq = sparse_matrix_seq::type_id::create("seq");
        seq.sparsity = 0.9;  // 90%稀疏
        seq.start(env.agent.sequencer);
        
        // 3. 随机矩阵测试
        seq = random_matrix_seq::type_id::create("seq");
        seq.num_iterations = 1000;
        seq.start(env.agent.sequencer);
        
        // 4. 边界条件测试
        seq = boundary_test_seq::type_id::create("seq");
        seq.start(env.agent.sequencer);
        
        phase.drop_objection(this);
    endtask
    
endclass

// 覆盖率收集
class pe_array_coverage extends uvm_subscriber #(pe_array_transaction);
    `uvm_component_utils(pe_array_coverage)
    
    covergroup pe_cg;
        // 数据模式覆盖
        data_pattern_cp: coverpoint trans.get_data_pattern() {
            bins zeros = {PATTERN_ZEROS};
            bins ones = {PATTERN_ONES};
            bins sparse = {PATTERN_SPARSE};
            bins dense = {PATTERN_DENSE};
            bins random = {PATTERN_RANDOM};
        }
        
        // 计算模式覆盖
        compute_mode_cp: coverpoint trans.compute_mode {
            bins matmul = {MODE_MATMUL};
            bins conv = {MODE_CONV};
            bins pooling = {MODE_POOLING};
        }
        
        // 精度覆盖
        precision_cp: coverpoint trans.precision {
            bins int8 = {PREC_INT8};
            bins int16 = {PREC_INT16};
            bins fp16 = {PREC_FP16};
        }
        
        // 交叉覆盖
        mode_precision_cross: cross compute_mode_cp, precision_cp;
    endgroup
    
    function new(string name, uvm_component parent);
        super.new(name, parent);
        pe_cg = new();
    endfunction
    
    function void write(pe_array_transaction t);
        trans = t;
        pe_cg.sample();
    endfunction
endclass
            </div>

            <h3>7.3 系统级验证</h3>
            
            <p>系统级验证验证完整的NPU功能，包括多模块协同工作、真实神经网络层的执行，以及与主机的交互。</p>
            
            <h4>7.3.1 端到端网络层验证</h4>
            
            <div class="code-block">
// Conv-ReLU-Pooling完整链条验证环境
class conv_relu_pooling_env extends uvm_env;
    `uvm_component_utils(conv_relu_pooling_env)
    
    // 各模块的代理
    conv_agent conv_agt;
    relu_agent relu_agt;
    pooling_agent pool_agt;
    memory_agent mem_agt;
    
    // 系统级监控器
    system_monitor sys_mon;
    system_scoreboard sys_scb;
    
    // 虚拟序列器
    virtual_sequencer v_sqr;
    
    function new(string name, uvm_component parent);
        super.new(name, parent);
    endfunction
    
    function void build_phase(uvm_phase phase);
        super.build_phase(phase);
        
        // 创建代理
        conv_agt = conv_agent::type_id::create("conv_agt", this);
        relu_agt = relu_agent::type_id::create("relu_agt", this);
        pool_agt = pooling_agent::type_id::create("pool_agt", this);
        mem_agt = memory_agent::type_id::create("mem_agt", this);
        
        // 创建系统级组件
        sys_mon = system_monitor::type_id::create("sys_mon", this);
        sys_scb = system_scoreboard::type_id::create("sys_scb", this);
        v_sqr = virtual_sequencer::type_id::create("v_sqr", this);
        
        // 配置内存映射
        uvm_config_db#(memory_map)::set(this, "*", "mem_map", create_memory_map());
    endfunction
    
    function void connect_phase(uvm_phase phase);
        // 连接虚拟序列器
        v_sqr.conv_sqr = conv_agt.sequencer;
        v_sqr.relu_sqr = relu_agt.sequencer;
        v_sqr.pool_sqr = pool_agt.sequencer;
        v_sqr.mem_sqr = mem_agt.sequencer;
        
        // 连接监控器到记分板
        conv_agt.monitor.ap.connect(sys_scb.conv_export);
        relu_agt.monitor.ap.connect(sys_scb.relu_export);
        pool_agt.monitor.ap.connect(sys_scb.pool_export);
        sys_mon.ap.connect(sys_scb.sys_export);
    endfunction
    
    function memory_map create_memory_map();
        memory_map mmap = new();
        mmap.add_region("input_buffer", 32'h0000_0000, 32'h000F_FFFF);
        mmap.add_region("weight_buffer", 32'h0010_0000, 32'h001F_FFFF);
        mmap.add_region("inter_buffer", 32'h0020_0000, 32'h002F_FFFF);
        mmap.add_region("output_buffer", 32'h0030_0000, 32'h003F_FFFF);
        return mmap;
    endfunction
endclass

// 端到端测试序列
class end_to_end_sequence extends uvm_sequence;
    `uvm_object_utils(end_to_end_sequence)
    `uvm_declare_p_sequencer(virtual_sequencer)
    
    // 测试参数
    rand int input_height, input_width, input_channels;
    rand int conv_filters, kernel_size, stride;
    rand int pool_size, pool_stride;
    
    constraint valid_dims_c {
        input_height inside {[16:256]};
        input_width inside {[16:256]};
        input_channels inside {[3:64]};
        conv_filters inside {[16:128]};
        kernel_size inside {3, 5};
        stride inside {1, 2};
        pool_size inside {2, 3};
        pool_stride inside {1, 2};
        
        // 确保维度兼容
        (input_height - kernel_size) % stride == 0;
        (input_width - kernel_size) % stride == 0;
    }
    
    function new(string name = "end_to_end_sequence");
        super.new(name);
    endfunction
    
    task body();
        // 子序列
        load_input_sequence load_seq;
        load_weight_sequence weight_seq;
        conv_compute_sequence conv_seq;
        relu_sequence relu_seq;
        pooling_sequence pool_seq;
        verify_output_sequence verify_seq;
        
        `uvm_info("E2E_SEQ", 
            $sformatf("Starting Conv(%0dx%0d)→ReLU→Pool(%0dx%0d) test", 
            kernel_size, kernel_size, pool_size, pool_size), UVM_LOW)
        
        // 1. 加载输入数据到内存
        load_seq = load_input_sequence::type_id::create("load_seq");
        load_seq.height = input_height;
        load_seq.width = input_width;
        load_seq.channels = input_channels;
        load_seq.start(p_sequencer.mem_sqr);
        
        // 2. 加载卷积权重
        weight_seq = load_weight_sequence::type_id::create("weight_seq");
        weight_seq.filters = conv_filters;
        weight_seq.kernel_size = kernel_size;
        weight_seq.input_channels = input_channels;
        weight_seq.randomize_weights();
        weight_seq.start(p_sequencer.mem_sqr);
        
        // 3. 配置并执行卷积
        conv_seq = conv_compute_sequence::type_id::create("conv_seq");
        conv_seq.configure(
            .input_addr(32'h0000_0000),
            .weight_addr(32'h0010_0000),
            .output_addr(32'h0020_0000),
            .input_dims('{input_height, input_width, input_channels}),
            .kernel_size(kernel_size),
            .stride(stride),
            .filters(conv_filters)
        );
        conv_seq.start(p_sequencer.conv_sqr);
        
        // 等待卷积完成
        wait_for_completion("CONV");
        
        // 4. 执行ReLU激活
        relu_seq = relu_sequence::type_id::create("relu_seq");
        relu_seq.configure(
            .input_addr(32'h0020_0000),
            .output_addr(32'h0020_0000),  // 原地操作
            .size(calculate_conv_output_size())
        );
        relu_seq.start(p_sequencer.relu_sqr);
        
        wait_for_completion("RELU");
        
        // 5. 执行池化
        pool_seq = pooling_sequence::type_id::create("pool_seq");
        pool_seq.configure(
            .input_addr(32'h0020_0000),
            .output_addr(32'h0030_0000),
            .input_dims(calculate_conv_output_dims()),
            .pool_size(pool_size),
            .pool_stride(pool_stride),
            .pool_type(MAX_POOLING)
        );
        pool_seq.start(p_sequencer.pool_sqr);
        
        wait_for_completion("POOL");
        
        // 6. 验证最终输出
        verify_seq = verify_output_sequence::type_id::create("verify_seq");
        verify_seq.golden_model = create_golden_model();
        verify_seq.output_addr = 32'h0030_0000;
        verify_seq.output_size = calculate_final_output_size();
        verify_seq.start(p_sequencer.mem_sqr);
        
        `uvm_info("E2E_SEQ", "End-to-end test completed", UVM_LOW)
    endtask
    
    // 辅助函数
    function int calculate_conv_output_size();
        int h_out = (input_height - kernel_size) / stride + 1;
        int w_out = (input_width - kernel_size) / stride + 1;
        return h_out * w_out * conv_filters;
    endfunction
    
    function int_array_t calculate_conv_output_dims();
        int h_out = (input_height - kernel_size) / stride + 1;
        int w_out = (input_width - kernel_size) / stride + 1;
        return '{h_out, w_out, conv_filters};
    endfunction
    
    function golden_model create_golden_model();
        golden_model gm = new();
        gm.add_layer(new conv_layer(kernel_size, stride, conv_filters));
        gm.add_layer(new relu_layer());
        gm.add_layer(new pooling_layer(pool_size, pool_stride));
        return gm;
    endfunction
    
    task wait_for_completion(string module_name);
        // 等待特定模块完成处理
        @(posedge p_sequencer.completion_event[module_name]);
        `uvm_info("E2E_SEQ", $sformatf("%s processing completed", module_name), UVM_MEDIUM)
    endtask
endclass

// 系统级记分板
class system_scoreboard extends uvm_scoreboard;
    `uvm_component_utils(system_scoreboard)
    
    // 分析端口
    uvm_analysis_export #(conv_transaction) conv_export;
    uvm_analysis_export #(relu_transaction) relu_export;
    uvm_analysis_export #(pooling_transaction) pool_export;
    uvm_analysis_export #(system_transaction) sys_export;
    
    // 内部FIFO
    uvm_tlm_analysis_fifo #(conv_transaction) conv_fifo;
    uvm_tlm_analysis_fifo #(relu_transaction) relu_fifo;
    uvm_tlm_analysis_fifo #(pooling_transaction) pool_fifo;
    uvm_tlm_analysis_fifo #(system_transaction) sys_fifo;
    
    // 参考模型
    npu_reference_model ref_model;
    
    // 流水线跟踪
    pipeline_tracker tracker;
    
    function new(string name, uvm_component parent);
        super.new(name, parent);
    endfunction
    
    function void build_phase(uvm_phase phase);
        super.build_phase(phase);
        
        conv_export = new("conv_export", this);
        relu_export = new("relu_export", this);
        pool_export = new("pool_export", this);
        sys_export = new("sys_export", this);
        
        conv_fifo = new("conv_fifo", this);
        relu_fifo = new("relu_fifo", this);
        pool_fifo = new("pool_fifo", this);
        sys_fifo = new("sys_fifo", this);
        
        ref_model = npu_reference_model::type_id::create("ref_model", this);
        tracker = new("pipeline_tracker");
    endfunction
    
    function void connect_phase(uvm_phase phase);
        conv_export.connect(conv_fifo.analysis_export);
        relu_export.connect(relu_fifo.analysis_export);
        pool_export.connect(pool_fifo.analysis_export);
        sys_export.connect(sys_fifo.analysis_export);
    endfunction
    
    task run_phase(uvm_phase phase);
        fork
            process_pipeline();
            check_data_consistency();
            monitor_performance();
        join
    endtask
    
    task process_pipeline();
        forever begin
            system_transaction sys_trans;
            sys_fifo.get(sys_trans);
            
            // 跟踪事务流经流水线
            tracker.add_transaction(sys_trans);
            
            // 在每个阶段验证
            case (sys_trans.stage)
                STAGE_CONV: verify_conv_stage(sys_trans);
                STAGE_RELU: verify_relu_stage(sys_trans);
                STAGE_POOL: verify_pool_stage(sys_trans);
                STAGE_COMPLETE: verify_complete(sys_trans);
            endcase
        end
    endtask
    
    task verify_complete(system_transaction trans);
        real_array_t expected, actual;
        real error_rate;
        
        // 获取参考模型结果
        expected = ref_model.compute(trans.input_data);
        actual = trans.output_data;
        
        // 计算误差
        error_rate = calculate_error_rate(expected, actual);
        
        if (error_rate > 0.01) begin  // 1%容差
            `uvm_error("SCOREBOARD", 
                $sformatf("Output mismatch! Error rate: %.2f%%", error_rate * 100))
            dump_comparison(expected, actual);
        end else begin
            `uvm_info("SCOREBOARD", 
                $sformatf("Pipeline verification PASSED. Error: %.4f%%", 
                error_rate * 100), UVM_MEDIUM)
        end
        
        // 更新统计
        tracker.update_statistics(trans, error_rate);
    endtask
    
    function real calculate_error_rate(real_array_t expected, real_array_t actual);
        real total_error = 0;
        int num_elements = expected.size();
        
        foreach (expected[i]) begin
            real diff = expected[i] - actual[i];
            total_error += (diff * diff);
        end
        
        return $sqrt(total_error / num_elements) / get_data_range();
    endfunction
endclass
            </div>
            
            <h4>7.3.2 多核NPU同步验证</h4>
            
            <div class="code-block">
// 多核NPU验证环境
class multi_core_npu_env extends uvm_env;
    `uvm_component_utils(multi_core_npu_env)
    
    parameter NUM_CORES = 4;
    parameter NUM_CLUSTERS = 2;
    
    // 每个核心的代理
    npu_core_agent core_agents[NUM_CLUSTERS][NUM_CORES];
    
    // 共享资源代理
    memory_controller_agent mem_ctrl_agent;
    interconnect_agent noc_agent;
    
    // 同步监控器
    synchronization_monitor sync_mon;
    coherence_checker coherence_chk;
    
    function new(string name, uvm_component parent);
        super.new(name, parent);
    endfunction
    
    function void build_phase(uvm_phase phase);
        super.build_phase(phase);
        
        // 创建核心代理
        foreach (core_agents[i,j]) begin
            core_agents[i][j] = npu_core_agent::type_id::create(
                $sformatf("core_agent[%0d][%0d]", i, j), this);
        end
        
        // 创建共享组件
        mem_ctrl_agent = memory_controller_agent::type_id::create("mem_ctrl_agent", this);
        noc_agent = interconnect_agent::type_id::create("noc_agent", this);
        
        sync_mon = synchronization_monitor::type_id::create("sync_mon", this);
        coherence_chk = coherence_checker::type_id::create("coherence_chk", this);
    endfunction
endclass

// 多核同步测试
class multi_core_sync_test extends uvm_test;
    `uvm_component_utils(multi_core_sync_test)
    
    multi_core_npu_env env;
    
    function new(string name, uvm_component parent);
        super.new(name, parent);
    endfunction
    
    task run_phase(uvm_phase phase);
        parallel_conv_sequence para_seq;
        barrier_sync_sequence barrier_seq;
        data_sharing_sequence share_seq;
        
        phase.raise_objection(this);
        
        // 测试1: 并行卷积with同步
        `uvm_info("TEST", "Starting parallel convolution test", UVM_LOW)
        para_seq = parallel_conv_sequence::type_id::create("para_seq");
        para_seq.configure_workload_distribution();
        para_seq.start(env.v_sqr);
        
        // 测试2: Barrier同步
        `uvm_info("TEST", "Testing barrier synchronization", UVM_LOW)
        barrier_seq = barrier_sync_sequence::type_id::create("barrier_seq");
        barrier_seq.num_sync_points = 5;
        barrier_seq.start(env.v_sqr);
        
        // 测试3: 核间数据共享
        `uvm_info("TEST", "Testing inter-core data sharing", UVM_LOW)
        share_seq = data_sharing_sequence::type_id::create("share_seq");
        share_seq.sharing_pattern = NEIGHBOR_EXCHANGE;
        share_seq.start(env.v_sqr);
        
        phase.drop_objection(this);
    endtask
endclass

// 并行卷积序列
class parallel_conv_sequence extends uvm_sequence;
    `uvm_object_utils(parallel_conv_sequence)
    
    // 工作负载分配
    typedef struct {
        int core_id;
        int start_channel;
        int end_channel;
        bit is_master;
    } workload_t;
    
    workload_t workload_map[4];
    
    task body();
        // 主核心初始化
        init_master_core();
        
        // 分发工作负载
        fork
            foreach (workload_map[i]) begin
                automatic int idx = i;
                execute_core_workload(idx);
            end
        join
        
        // 收集并合并结果
        collect_results();
    endtask
    
    task execute_core_workload(int core_idx);
        core_conv_sequence core_seq;
        workload_t wl = workload_map[core_idx];
        
        core_seq = core_conv_sequence::type_id::create(
            $sformatf("core_seq_%0d", core_idx));
        
        core_seq.core_id = wl.core_id;
        core_seq.channel_start = wl.start_channel;
        core_seq.channel_end = wl.end_channel;
        core_seq.sync_mode = BARRIER_SYNC;
        
        // 在对应核心的序列器上启动
        core_seq.start(p_sequencer.core_sqr[core_idx]);
        
        `uvm_info("PARA_SEQ", 
            $sformatf("Core %0d completed channels [%0d:%0d]", 
            core_idx, wl.start_channel, wl.end_channel), UVM_MEDIUM)
    endtask
endclass
            </div>

            <h3>7.4 性能验证</h3>
            
            <h4>7.4.1 性能计数器设计</h4>
            <div class="code-block">
// NPU性能监控模块
module npu_performance_monitor (
    input wire clk,
    input wire rst_n,
    
    // 监控信号
    input wire mac_valid,
    input wire [15:0] mac_count,
    input wire cache_hit,
    input wire cache_miss,
    input wire dma_busy,
    input wire compute_stall,
    
    // APB接口
    input wire psel,
    input wire penable,
    input wire pwrite,
    input wire [11:0] paddr,
    output reg [31:0] prdata
);

    // 性能计数器
    reg [63:0] cycle_count;
    reg [63:0] mac_op_count;
    reg [31:0] cache_hit_count;
    reg [31:0] cache_miss_count;
    reg [31:0] dma_busy_cycles;
    reg [31:0] compute_stall_cycles;
    
    // 性能指标计算
    wire [31:0] mac_utilization;
    wire [31:0] cache_hit_rate;
    wire [31:0] bandwidth_efficiency;
    
    // 计数器更新
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            cycle_count <= 64'h0;
            mac_op_count <= 64'h0;
            cache_hit_count <= 32'h0;
            cache_miss_count <= 32'h0;
            dma_busy_cycles <= 32'h0;
            compute_stall_cycles <= 32'h0;
        end else begin
            cycle_count <= cycle_count + 1;
            
            if (mac_valid)
                mac_op_count <= mac_op_count + mac_count;
            
            if (cache_hit)
                cache_hit_count <= cache_hit_count + 1;
                
            if (cache_miss)
                cache_miss_count <= cache_miss_count + 1;
                
            if (dma_busy)
                dma_busy_cycles <= dma_busy_cycles + 1;
                
            if (compute_stall)
                compute_stall_cycles <= compute_stall_cycles + 1;
        end
    end
    
    // 性能指标计算
    assign mac_utilization = (mac_op_count * 100) / (cycle_count * 256); // 假设256个MAC单元
    assign cache_hit_rate = (cache_hit_count * 100) / (cache_hit_count + cache_miss_count);
    assign bandwidth_efficiency = ((cycle_count - dma_busy_cycles) * 100) / cycle_count;
    
    // APB读操作
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            prdata <= 32'h0;
        end else if (psel && !pwrite && penable) begin
            case (paddr[11:0])
                12'h000: prdata <= cycle_count[31:0];
                12'h004: prdata <= cycle_count[63:32];
                12'h008: prdata <= mac_op_count[31:0];
                12'h00C: prdata <= mac_op_count[63:32];
                12'h010: prdata <= cache_hit_count;
                12'h014: prdata <= cache_miss_count;
                12'h018: prdata <= cache_hit_rate;
                12'h01C: prdata <= mac_utilization;
                12'h020: prdata <= bandwidth_efficiency;
                12'h024: prdata <= compute_stall_cycles;
                12'h028: prdata <= dma_busy_cycles;
                default: prdata <= 32'h0;
            endcase
        end
    end

endmodule
            </div>

            <h4>7.3.2 性能测试基准</h4>
            <div class="code-block">
// 性能基准测试类
class npu_performance_benchmark extends uvm_sequence;
    `uvm_object_utils(npu_performance_benchmark)
    
    // 测试配置
    int num_iterations = 100;
    string model_name = "resnet50";
    
    // 性能统计
    real total_inference_time;
    int total_mac_operations;
    real power_consumption;
    
    function new(string name = "npu_performance_benchmark");
        super.new(name);
    endfunction
    
    task body();
        npu_model_config cfg;
        npu_inference_seq inference_seq;
        real start_time, end_time;
        
        // 加载模型配置
        cfg = load_model_config(model_name);
        
        // 配置NPU
        configure_npu(cfg);
        
        // 预热
        repeat(10) begin
            inference_seq = npu_inference_seq::type_id::create("inference_seq");
            inference_seq.model_cfg = cfg;
            inference_seq.start(m_sequencer);
        end
        
        // 性能测试
        start_time = $realtime;
        repeat(num_iterations) begin
            inference_seq = npu_inference_seq::type_id::create("inference_seq");
            inference_seq.model_cfg = cfg;
            inference_seq.start(m_sequencer);
        end
        end_time = $realtime;
        
        // 收集性能数据
        collect_performance_data();
        
        // 报告结果
        report_performance();
    endtask
    
    function void collect_performance_data();
        // 从性能计数器读取数据
        total_inference_time = $realtime;
        total_mac_operations = read_performance_counter(PERF_MAC_OPS);
        power_consumption = read_power_monitor();
    endfunction
    
    function void report_performance();
        real throughput, efficiency, tops;
        
        throughput = num_iterations / total_inference_time;
        tops = total_mac_operations / total_inference_time / 1e12;
        efficiency = tops / power_consumption;  // TOPS/W
        
        `uvm_info("PERF", "=== Performance Report ===", UVM_LOW)
        `uvm_info("PERF", $sformatf("Model: %s", model_name), UVM_LOW)
        `uvm_info("PERF", $sformatf("Throughput: %.2f inferences/sec", throughput), UVM_LOW)
        `uvm_info("PERF", $sformatf("Performance: %.2f TOPS", tops), UVM_LOW)
        `uvm_info("PERF", $sformatf("Power: %.2f W", power_consumption), UVM_LOW)
        `uvm_info("PERF", $sformatf("Efficiency: %.2f TOPS/W", efficiency), UVM_LOW)
    endfunction
    
endclass
            </div>

            <div class="exercise">
                <h4>练习 7.1-7.3</h4>
                <div class="question">
                    <p><strong>题目：</strong>设计一个完整的UVM验证环境来验证一个4x4 MAC阵列，要求：
                    1) 实现完整的UVM组件（Driver、Monitor、Scoreboard）
                    2) 使用Python golden model进行结果比较
                    3) 实现功能覆盖率收集
                    4) 支持随机和定向测试</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：UVM环境包括agent（driver+monitor）、scoreboard、env等层次。使用DPI-C接口调用Python模型。功能覆盖率应包括数据范围、操作模式、边界条件。随机约束应考虑实际使用场景。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
// MAC阵列接口定义
interface mac_array_if(input clk);
    logic rst_n;
    logic enable;
    logic [7:0] a_in[3:0];
    logic [7:0] b_in[3:0][3:0];
    logic [31:0] c_out[3:0][3:0];
    logic valid_out;
    
    modport dut(
        input clk, rst_n, enable, a_in, b_in,
        output c_out, valid_out
    );
    
    modport tb(
        input clk, c_out, valid_out,
        output rst_n, enable, a_in, b_in
    );
endinterface

// Transaction定义
class mac_array_trans extends uvm_sequence_item;
    `uvm_object_utils(mac_array_trans)
    
    rand bit [7:0] a_matrix[3:0][3:0];
    rand bit [7:0] b_matrix[3:0][3:0];
    bit [31:0] c_matrix[3:0][3:0];
    
    constraint data_c {
        foreach(a_matrix[i,j]) {
            a_matrix[i][j] inside {[0:255]};
            b_matrix[i][j] inside {[0:255]};
        }
    }
    
    function new(string name = "mac_array_trans");
        super.new(name);
    endfunction
    
    function void do_copy(uvm_object rhs);
        mac_array_trans t;
        super.do_copy(rhs);
        $cast(t, rhs);
        a_matrix = t.a_matrix;
        b_matrix = t.b_matrix;
        c_matrix = t.c_matrix;
    endfunction
endclass

// Driver实现
class mac_array_driver extends uvm_driver#(mac_array_trans);
    `uvm_component_utils(mac_array_driver)
    
    virtual mac_array_if.tb vif;
    
    function new(string name, uvm_component parent);
        super.new(name, parent);
    endfunction
    
    function void build_phase(uvm_phase phase);
        super.build_phase(phase);
        if (!uvm_config_db#(virtual mac_array_if.tb)::get(
            this, "", "vif", vif))
            `uvm_fatal("NOVIF", "Virtual interface not found")
    endfunction
    
    task run_phase(uvm_phase phase);
        forever begin
            seq_item_port.get_next_item(req);
            drive_trans(req);
            seq_item_port.item_done();
        end
    endtask
    
    task drive_trans(mac_array_trans t);
        // 复位
        vif.rst_n = 0;
        vif.enable = 0;
        repeat(5) @(posedge vif.clk);
        vif.rst_n = 1;
        
        // 发送数据（脉动输入）
        for (int cycle = 0; cycle < 7; cycle++) begin
            @(posedge vif.clk);
            vif.enable = 1;
            
            // 对角线输入模式
            for (int i = 0; i < 4; i++) begin
                if (cycle >= i && cycle - i < 4) begin
                    vif.a_in[i] = t.a_matrix[i][cycle-i];
                    for (int j = 0; j < 4; j++) begin
                        if (i == 0)
                            vif.b_in[j][i] = t.b_matrix[cycle-j][j];
                    end
                end else begin
                    vif.a_in[i] = 0;
                end
            end
        end
        
        vif.enable = 0;
        
        // 等待计算完成
        wait(vif.valid_out);
        repeat(2) @(posedge vif.clk);
    endtask
endclass

// Monitor实现
class mac_array_monitor extends uvm_monitor;
    `uvm_component_utils(mac_array_monitor)
    
    virtual mac_array_if.tb vif;
    uvm_analysis_port#(mac_array_trans) ap;
    
    function new(string name, uvm_component parent);
        super.new(name, parent);
        ap = new("ap", this);
    endfunction
    
    function void build_phase(uvm_phase phase);
        super.build_phase(phase);
        if (!uvm_config_db#(virtual mac_array_if.tb)::get(
            this, "", "vif", vif))
            `uvm_fatal("NOVIF", "Virtual interface not found")
    endfunction
    
    task run_phase(uvm_phase phase);
        mac_array_trans t;
        
        forever begin
            // 监控输入
            t = mac_array_trans::type_id::create("t");
            collect_input(t);
            
            // 等待输出
            wait(vif.valid_out);
            @(posedge vif.clk);
            
            // 收集输出
            for (int i = 0; i < 4; i++) begin
                for (int j = 0; j < 4; j++) begin
                    t.c_matrix[i][j] = vif.c_out[i][j];
                end
            end
            
            ap.write(t);
        end
    endtask
    
    task collect_input(mac_array_trans t);
        // 收集输入矩阵（简化版）
        @(posedge vif.clk iff vif.enable);
        // 实际实现需要根据脉动输入模式重建完整矩阵
    endtask
endclass

// Scoreboard with Python Golden Model
class mac_array_scoreboard extends uvm_scoreboard;
    `uvm_component_utils(mac_array_scoreboard)
    
    uvm_analysis_export#(mac_array_trans) analysis_export;
    
    // Python接口
    int python_fd;
    
    function new(string name, uvm_component parent);
        super.new(name, parent);
    endfunction
    
    function void build_phase(uvm_phase phase);
        super.build_phase(phase);
        analysis_export = new("analysis_export", this);
        
        // 启动Python进程
        python_fd = $system("python3 mac_golden_model.py &");
    endfunction
    
    function void write(mac_array_trans t);
        bit [31:0] expected[3:0][3:0];
        
        // 调用Python计算期望结果
        compute_expected(t.a_matrix, t.b_matrix, expected);
        
        // 比较结果
        for (int i = 0; i < 4; i++) begin
            for (int j = 0; j < 4; j++) begin
                if (t.c_matrix[i][j] !== expected[i][j]) begin
                    `uvm_error("SCOREBOARD", 
                        $sformatf("Mismatch at [%0d][%0d]: got=%0d, exp=%0d",
                        i, j, t.c_matrix[i][j], expected[i][j]))
                end
            end
        end
        
        `uvm_info("SCOREBOARD", "Matrix multiplication passed", UVM_MEDIUM)
    endfunction
    
    function void compute_expected(
        bit [7:0] a[3:0][3:0], 
        bit [7:0] b[3:0][3:0],
        ref bit [31:0] c[3:0][3:0]
    );
        // 与Python通信计算结果
        // 简化示例：直接计算
        for (int i = 0; i < 4; i++) begin
            for (int j = 0; j < 4; j++) begin
                c[i][j] = 0;
                for (int k = 0; k < 4; k++) begin
                    c[i][j] += a[i][k] * b[k][j];
                end
            end
        end
    endfunction
endclass

// 覆盖率收集
class mac_array_coverage extends uvm_subscriber#(mac_array_trans);
    `uvm_component_utils(mac_array_coverage)
    
    mac_array_trans t;
    
    covergroup mac_cg;
        // 输入数据模式
        a_pattern: coverpoint get_pattern(t.a_matrix) {
            bins zero = {0};
            bins identity = {1};
            bins sparse = {2};
            bins dense = {3};
        }
        
        b_pattern: coverpoint get_pattern(t.b_matrix) {
            bins zero = {0};
            bins identity = {1};
            bins sparse = {2};
            bins dense = {3};
        }
        
        // 交叉覆盖
        pattern_cross: cross a_pattern, b_pattern;
        
        // 数值范围覆盖
        a_values: coverpoint t.a_matrix[0][0] {
            bins low = {[0:63]};
            bins mid = {[64:191]};
            bins high = {[192:255]};
        }
    endgroup
    
    function new(string name, uvm_component parent);
        super.new(name, parent);
        mac_cg = new();
    endfunction
    
    function void write(mac_array_trans tr);
        t = tr;
        mac_cg.sample();
    endfunction
    
    function int get_pattern(bit [7:0] matrix[3:0][3:0]);
        int zero_count = 0;
        
        // 检查零矩阵
        foreach(matrix[i,j]) if (matrix[i][j] == 0) zero_count++;
        if (zero_count == 16) return 0;
        
        // 检查单位矩阵
        bit is_identity = 1;
        foreach(matrix[i,j]) begin
            if (i == j && matrix[i][j] != 1) is_identity = 0;
            if (i != j && matrix[i][j] != 0) is_identity = 0;
        end
        if (is_identity) return 1;
        
        // 稀疏/稠密
        if (zero_count > 12) return 2;
        else return 3;
    endfunction
endclass
                        </div>
                    </div>
                </div>
            </div>

            <h3>7.4 可测试性设计（DFT）</h3>
            
            <p>可测试性设计（Design for Testability, DFT）是在芯片设计阶段加入的专门电路，用于提高芯片的可测试性，确保能够高效地检测制造缺陷。NPU由于其高集成度和复杂性，DFT设计尤为重要。</p>
            
            <div class="info-box">
                <p><strong>DFT核心概念：</strong></p>
                <ul>
                    <li><strong>故障模型：</strong>
                        <ul>
                            <li>固定型故障（Stuck-at faults）：信号固定在0或1</li>
                            <li>转换故障（Transition faults）：信号无法在规定时间内转换</li>
                            <li>桥接故障（Bridging faults）：信号间短路</li>
                            <li>开路故障（Open faults）：信号断开</li>
                        </ul>
                    </li>
                    <li><strong>测试目标：</strong>
                        <ul>
                            <li>故障覆盖率 > 99%（汽车级要求99.5%+）</li>
                            <li>测试时间最小化</li>
                            <li>测试成本优化</li>
                            <li>良率提升</li>
                        </ul>
                    </li>
                    <li><strong>DFT技术分类：</strong>
                        <ul>
                            <li>结构测试：扫描链、边界扫描</li>
                            <li>内建自测试：MBIST、LBIST</li>
                            <li>功能测试：at-speed测试</li>
                            <li>诊断功能：故障定位、修复</li>
                        </ul>
                    </li>
                </ul>
            </div>
            
            <h4>7.4.1 扫描链设计</h4>
            <p>扫描链是DFT的基础技术，通过将设计中的触发器连接成移位寄存器链，实现对内部节点的可控性和可观测性。</p>
            
            <div class="info-box">
                <p><strong>扫描链设计要点：</strong></p>
                <div style="text-align: center; margin: 20px 0;">
                    <pre style="display: inline-block; text-align: left;">
    功能模式：     D ──→ [FF] ──→ Q ──→ 组合逻辑
                        ↑
                       CLK
    
    扫描模式：  SI ──→ [MUX] ──→ [FF] ──→ Q/SO ──→ 下一个FF
                       ↑  ↑           ↑
                      SE  D          CLK
                    </pre>
                </div>
                <ul>
                    <li><strong>扫描链分组：</strong>按时钟域、电压域、功能模块分组</li>
                    <li><strong>链长平衡：</strong>各扫描链长度均衡，减少测试时间</li>
                    <li><strong>扫描压缩：</strong>使用压缩技术减少测试数据量</li>
                    <li><strong>时序考虑：</strong>扫描路径的时序约束相对宽松</li>
                </ul>
            </div>
            
            <div class="code-block">
// 扫描触发器实现
module scan_ff (
    input wire clk,
    input wire rst_n,
    input wire d,          // 功能数据输入
    input wire si,         // 扫描输入
    input wire se,         // 扫描使能
    output reg q,          // 数据输出
    output wire so         // 扫描输出
);

    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            q <= 1'b0;
        end else begin
            q <= se ? si : d;  // 扫描模式时选择扫描输入
        end
    end
    
    assign so = q;  // 扫描输出连接到Q

endmodule

// NPU控制器的扫描链插入
module npu_controller_with_scan (
    input wire clk,
    input wire rst_n,
    
    // 功能接口
    input wire [31:0] instruction,
    input wire inst_valid,
    output reg inst_ready,
    output reg [7:0] control_signals,
    
    // DFT接口
    input wire scan_enable,
    input wire scan_in,
    output wire scan_out
);

    // 状态机寄存器（使用扫描触发器）
    wire [2:0] state_d, state_q;
    wire [2:0] state_scan_chain;
    
    scan_ff state_ff[2:0] (
        .clk(clk),
        .rst_n(rst_n),
        .d(state_d),
        .si({state_scan_chain[1:0], scan_in}),
        .se(scan_enable),
        .q(state_q),
        .so(state_scan_chain)
    );
    
    // 指令寄存器（使用扫描触发器）
    wire [31:0] inst_reg_d, inst_reg_q;
    wire [31:0] inst_scan_chain;
    
    genvar i;
    generate
        for (i = 0; i < 32; i = i + 1) begin : inst_scan_gen
            scan_ff inst_ff (
                .clk(clk),
                .rst_n(rst_n),
                .d(inst_reg_d[i]),
                .si(i == 0 ? state_scan_chain[2] : inst_scan_chain[i-1]),
                .se(scan_enable),
                .q(inst_reg_q[i]),
                .so(inst_scan_chain[i])
            );
        end
    endgenerate
    
    // 控制逻辑
    always @(*) begin
        // 状态机逻辑
        case (state_q)
            3'b000: begin  // IDLE
                if (inst_valid) begin
                    state_d = 3'b001;  // DECODE
                    inst_reg_d = instruction;
                end else begin
                    state_d = state_q;
                    inst_reg_d = inst_reg_q;
                end
            end
            // ... 其他状态
        endcase
    end
    
    assign scan_out = inst_scan_chain[31];

endmodule

// ATPG测试模式生成
module atpg_controller (
    input wire clk,
    input wire rst_n,
    
    // ATPG控制
    input wire test_mode,
    input wire scan_enable,
    input wire [3:0] test_pattern_sel,
    
    // 扫描链接口
    output reg [7:0] scan_in_ports,
    input wire [7:0] scan_out_ports,
    
    // 测试结果
    output reg test_done,
    output reg test_pass
);

    // 测试向量ROM
    reg [7:0] test_vectors [0:1023];
    reg [7:0] expected_responses [0:1023];
    
    // 测试状态机
    localparam TEST_IDLE = 2'b00;
    localparam TEST_SHIFT = 2'b01;
    localparam TEST_CAPTURE = 2'b10;
    localparam TEST_COMPARE = 2'b11;
    
    reg [1:0] test_state;
    reg [9:0] vector_cnt;
    reg [7:0] shift_cnt;
    reg [7:0] captured_data [0:127];
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            test_state <= TEST_IDLE;
            test_done <= 1'b0;
            test_pass <= 1'b1;
        end else if (test_mode) begin
            case (test_state)
                TEST_IDLE: begin
                    if (scan_enable) begin
                        test_state <= TEST_SHIFT;
                        vector_cnt <= 0;
                        shift_cnt <= 0;
                    end
                end
                
                TEST_SHIFT: begin
                    // 移入测试向量
                    scan_in_ports <= test_vectors[vector_cnt];
                    shift_cnt <= shift_cnt + 1;
                    
                    if (shift_cnt == 127) begin  // 假设链长128
                        test_state <= TEST_CAPTURE;
                    end
                end
                
                TEST_CAPTURE: begin
                    // 捕获响应
                    captured_data[shift_cnt] <= scan_out_ports;
                    shift_cnt <= shift_cnt + 1;
                    
                    if (shift_cnt == 127) begin
                        test_state <= TEST_COMPARE;
                    end
                end
                
                TEST_COMPARE: begin
                    // 比较结果
                    for (int i = 0; i < 128; i++) begin
                        if (captured_data[i] != expected_responses[vector_cnt + i]) begin
                            test_pass <= 1'b0;
                        end
                    end
                    
                    vector_cnt <= vector_cnt + 128;
                    if (vector_cnt >= 1024) begin
                        test_done <= 1'b1;
                        test_state <= TEST_IDLE;
                    end else begin
                        test_state <= TEST_SHIFT;
                        shift_cnt <= 0;
                    end
                end
            endcase
        end
    end

endmodule
            </div>

            <h4>7.4.2 存储器内建自测试（MBIST）</h4>
            
            <p>NPU包含大量SRAM用于存储权重、激活值和中间结果。MBIST是测试这些存储器的关键技术，能够以全速测试存储单元，检测各种故障模式。</p>
            
            <div class="info-box">
                <p><strong>MBIST关键特性：</strong></p>
                <ul>
                    <li><strong>测试算法：</strong>
                        <ul>
                            <li>March C-：检测所有SAF、TF、耦合故障</li>
                            <li>March C+：增强版，更高故障覆盖率</li>
                            <li>Checkerboard：检测相邻单元耦合</li>
                            <li>Walking 1/0：检测地址解码故障</li>
                        </ul>
                    </li>
                    <li><strong>NPU特殊考虑：</strong>
                        <ul>
                            <li>权重存储器：需要retention测试</li>
                            <li>激活值缓存：需要高速测试</li>
                            <li>多端口SRAM：端口间干扰测试</li>
                            <li>ECC保护：需要ECC逻辑测试</li>
                        </ul>
                    </li>
                    <li><strong>测试效率优化：</strong>
                        <ul>
                            <li>并行测试多个存储器</li>
                            <li>分层测试大容量存储器</li>
                            <li>可编程测试算法</li>
                            <li>故障诊断和修复支持</li>
                        </ul>
                    </li>
                </ul>
            </div>
            
            <div class="code-block">
// 增强型MBIST控制器（支持多种算法和诊断）
module mbist_controller #(
    parameter ADDR_WIDTH = 10,
    parameter DATA_WIDTH = 32
)(
    input wire clk,
    input wire rst_n,
    
    // BIST控制
    input wire bist_en,
    input wire bist_mode,  // 0: March C-, 1: Checkerboard
    
    // 存储器接口
    output reg mem_en,
    output reg mem_we,
    output reg [ADDR_WIDTH-1:0] mem_addr,
    output reg [DATA_WIDTH-1:0] mem_wdata,
    input wire [DATA_WIDTH-1:0] mem_rdata,
    
    // BIST状态
    output reg bist_done,
    output reg bist_fail,
    output reg [ADDR_WIDTH-1:0] fail_addr,
    output reg [DATA_WIDTH-1:0] fail_data
);

    // March C- 算法状态
    localparam IDLE = 4'b0000;
    localparam W0_UP = 4'b0001;    // 写0，地址递增
    localparam R0W1_UP = 4'b0010;  // 读0写1，地址递增
    localparam R1W0_UP = 4'b0011;  // 读1写0，地址递增
    localparam R0W1_DN = 4'b0100;  // 读0写1，地址递减
    localparam R1W0_DN = 4'b0101;  // 读1写0，地址递减
    localparam R0_UP = 4'b0110;    // 读0，地址递增
    localparam DONE = 4'b0111;
    
    reg [3:0] state, next_state;
    reg [ADDR_WIDTH-1:0] addr_cnt;
    reg addr_dir;  // 0: up, 1: down
    reg [DATA_WIDTH-1:0] expected_data;
    
    // 状态机
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            state <= IDLE;
            bist_done <= 1'b0;
            bist_fail <= 1'b0;
        end else begin
            state <= next_state;
            
            // 错误检测
            if (mem_en && !mem_we && state != IDLE) begin
                if (mem_rdata !== expected_data) begin
                    bist_fail <= 1'b1;
                    fail_addr <= mem_addr;
                    fail_data <= mem_rdata;
                end
            end
        end
    end
    
    // 下一状态逻辑
    always @(*) begin
        next_state = state;
        
        case (state)
            IDLE: begin
                if (bist_en) begin
                    if (bist_mode == 0)  // March C-
                        next_state = W0_UP;
                    else  // 其他算法
                        next_state = W0_UP;
                end
            end
            
            W0_UP: begin
                if (addr_cnt == {ADDR_WIDTH{1'b1}})
                    next_state = R0W1_UP;
            end
            
            R0W1_UP: begin
                if (addr_cnt == {ADDR_WIDTH{1'b1}})
                    next_state = R1W0_UP;
            end
            
            R1W0_UP: begin
                if (addr_cnt == {ADDR_WIDTH{1'b1}})
                    next_state = R0W1_DN;
            end
            
            R0W1_DN: begin
                if (addr_cnt == 0)
                    next_state = R1W0_DN;
            end
            
            R1W0_DN: begin
                if (addr_cnt == 0)
                    next_state = R0_UP;
            end
            
            R0_UP: begin
                if (addr_cnt == {ADDR_WIDTH{1'b1}})
                    next_state = DONE;
            end
            
            DONE: begin
                next_state = IDLE;
            end
        endcase
    end
    
    // 地址和数据生成
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            addr_cnt <= 0;
            mem_en <= 1'b0;
            mem_we <= 1'b0;
            mem_addr <= 0;
            mem_wdata <= 0;
            expected_data <= 0;
        end else begin
            case (state)
                W0_UP: begin  // 写0
                    mem_en <= 1'b1;
                    mem_we <= 1'b1;
                    mem_addr <= addr_cnt;
                    mem_wdata <= 0;
                    addr_cnt <= addr_cnt + 1;
                end
                
                R0W1_UP: begin  // 读0写1
                    mem_en <= 1'b1;
                    if (mem_we) begin  // 写周期
                        mem_we <= 1'b0;
                        expected_data <= 0;
                    end else begin  // 读周期
                        mem_we <= 1'b1;
                        mem_wdata <= {DATA_WIDTH{1'b1}};
                        addr_cnt <= addr_cnt + 1;
                    end
                    mem_addr <= addr_cnt;
                end
                
                // 类似处理其他状态...
                
                DONE: begin
                    bist_done <= 1'b1;
                    mem_en <= 1'b0;
                end
            endcase
        end
    end

endmodule

// 逻辑BIST（LBIST）
module lbist_controller (
    input wire clk,
    input wire rst_n,
    
    // LBIST控制
    input wire lbist_en,
    input wire [15:0] pattern_count,
    
    // PRPG（伪随机图形生成器）
    output reg [31:0] prpg_out,
    
    // MISR（多输入特征寄存器）
    input wire [31:0] response_in,
    output reg [31:0] signature,
    
    // 状态输出
    output reg lbist_done,
    output reg signature_valid
);

    // LFSR用于PRPG
    reg [31:0] lfsr;
    wire feedback = lfsr[31] ^ lfsr[21] ^ lfsr[1] ^ lfsr[0];
    
    // MISR寄存器
    reg [31:0] misr;
    
    // 模式计数器
    reg [15:0] pattern_cnt;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            lfsr <= 32'h12345678;  // 非零种子
            misr <= 32'h0;
            pattern_cnt <= 0;
            lbist_done <= 1'b0;
            signature_valid <= 1'b0;
        end else if (lbist_en) begin
            // PRPG: LFSR更新
            lfsr <= {lfsr[30:0], feedback};
            prpg_out <= lfsr;
            
            // MISR: 特征压缩
            misr <= {misr[30:0], misr[31]} ^ response_in;
            
            // 模式计数
            pattern_cnt <= pattern_cnt + 1;
            if (pattern_cnt == pattern_count - 1) begin
                lbist_done <= 1'b1;
                signature <= misr;
                signature_valid <= 1'b1;
            end
        end
    end

endmodule
            </div>

            <h4>7.4.3 JTAG与TAP控制器设计</h4>
            
            <p>JTAG（Joint Test Action Group）提供标准化的测试访问接口，TAP（Test Access Port）控制器是其核心。</p>

            <div class="code-block">
// TAP控制器状态机
module tap_controller (
    input  wire        tck,      // 测试时钟
    input  wire        tms,      // 测试模式选择
    input  wire        tdi,      // 测试数据输入
    input  wire        trst_n,   // 测试复位
    output reg         tdo,      // 测试数据输出
    output reg         tdo_en,   // TDO输出使能
    
    // TAP状态输出
    output reg         capture_dr,
    output reg         shift_dr,
    output reg         update_dr,
    output reg         capture_ir,
    output reg         shift_ir,
    output reg         update_ir,
    output reg  [3:0]  tap_state
);

    // TAP状态编码
    localparam TEST_LOGIC_RESET = 4'h0;
    localparam RUN_TEST_IDLE    = 4'h1;
    localparam SELECT_DR_SCAN   = 4'h2;
    localparam CAPTURE_DR       = 4'h3;
    localparam SHIFT_DR         = 4'h4;
    localparam EXIT1_DR         = 4'h5;
    localparam PAUSE_DR         = 4'h6;
    localparam EXIT2_DR         = 4'h7;
    localparam UPDATE_DR        = 4'h8;
    localparam SELECT_IR_SCAN   = 4'h9;
    localparam CAPTURE_IR       = 4'hA;
    localparam SHIFT_IR         = 4'hB;
    localparam EXIT1_IR         = 4'hC;
    localparam PAUSE_IR         = 4'hD;
    localparam EXIT2_IR         = 4'hE;
    localparam UPDATE_IR        = 4'hF;

    // TAP状态机
    always @(posedge tck or negedge trst_n) begin
        if (!trst_n) begin
            tap_state <= TEST_LOGIC_RESET;
        end else begin
            case (tap_state)
                TEST_LOGIC_RESET: tap_state <= tms ? TEST_LOGIC_RESET : RUN_TEST_IDLE;
                RUN_TEST_IDLE:    tap_state <= tms ? SELECT_DR_SCAN : RUN_TEST_IDLE;
                SELECT_DR_SCAN:   tap_state <= tms ? SELECT_IR_SCAN : CAPTURE_DR;
                CAPTURE_DR:       tap_state <= tms ? EXIT1_DR : SHIFT_DR;
                SHIFT_DR:         tap_state <= tms ? EXIT1_DR : SHIFT_DR;
                EXIT1_DR:         tap_state <= tms ? UPDATE_DR : PAUSE_DR;
                PAUSE_DR:         tap_state <= tms ? EXIT2_DR : PAUSE_DR;
                EXIT2_DR:         tap_state <= tms ? UPDATE_DR : SHIFT_DR;
                UPDATE_DR:        tap_state <= tms ? SELECT_DR_SCAN : RUN_TEST_IDLE;
                SELECT_IR_SCAN:   tap_state <= tms ? TEST_LOGIC_RESET : CAPTURE_IR;
                CAPTURE_IR:       tap_state <= tms ? EXIT1_IR : SHIFT_IR;
                SHIFT_IR:         tap_state <= tms ? EXIT1_IR : SHIFT_IR;
                EXIT1_IR:         tap_state <= tms ? UPDATE_IR : PAUSE_IR;
                PAUSE_IR:         tap_state <= tms ? EXIT2_IR : PAUSE_IR;
                EXIT2_IR:         tap_state <= tms ? UPDATE_IR : SHIFT_IR;
                UPDATE_IR:        tap_state <= tms ? SELECT_DR_SCAN : RUN_TEST_IDLE;
            endcase
        end
    end

    // 状态解码
    always @(*) begin
        capture_dr = (tap_state == CAPTURE_DR);
        shift_dr   = (tap_state == SHIFT_DR);
        update_dr  = (tap_state == UPDATE_DR);
        capture_ir = (tap_state == CAPTURE_IR);
        shift_ir   = (tap_state == SHIFT_IR);
        update_ir  = (tap_state == UPDATE_IR);
        tdo_en     = shift_dr || shift_ir;
    end

endmodule

// NPU JTAG包装器
module npu_jtag_wrapper (
    input  wire        tck,
    input  wire        tms,
    input  wire        tdi,
    input  wire        trst_n,
    output wire        tdo,
    
    // NPU接口
    input  wire        npu_clk,
    input  wire        npu_rst_n,
    output reg         jtag_access_req,
    output reg  [31:0] jtag_addr,
    output reg  [31:0] jtag_wdata,
    output reg         jtag_write,
    input  wire [31:0] jtag_rdata,
    input  wire        jtag_ready
);

    // 指令寄存器
    localparam EXTEST   = 4'b0000;
    localparam BYPASS   = 4'b1111;
    localparam IDCODE   = 4'b0010;
    localparam NPU_ACC  = 4'b1000;  // NPU访问指令
    localparam NPU_CTRL = 4'b1001;  // NPU控制指令
    
    reg [3:0] instruction_reg;
    reg [31:0] idcode_reg = 32'h12345678;  // 示例ID
    reg [31:0] data_reg;
    
    // TAP控制器实例
    wire capture_dr, shift_dr, update_dr;
    wire capture_ir, shift_ir, update_ir;
    wire [3:0] tap_state;
    wire tdo_en;
    reg tdo_reg;
    
    tap_controller u_tap (
        .tck(tck),
        .tms(tms),
        .tdi(tdi),
        .trst_n(trst_n),
        .tdo(tdo_reg),
        .tdo_en(tdo_en),
        .capture_dr(capture_dr),
        .shift_dr(shift_dr),
        .update_dr(update_dr),
        .capture_ir(capture_ir),
        .shift_ir(shift_ir),
        .update_ir(update_ir),
        .tap_state(tap_state)
    );
    
    // TDO输出多路选择
    assign tdo = tdo_en ? tdo_reg : 1'bz;
    
    // 指令寄存器操作
    always @(posedge tck or negedge trst_n) begin
        if (!trst_n) begin
            instruction_reg <= IDCODE;
        end else if (capture_ir) begin
            instruction_reg <= BYPASS;
        end else if (shift_ir) begin
            instruction_reg <= {tdi, instruction_reg[3:1]};
        end
    end
    
    // 数据寄存器操作
    always @(posedge tck or negedge trst_n) begin
        if (!trst_n) begin
            data_reg <= 32'h0;
        end else if (capture_dr) begin
            case (instruction_reg)
                IDCODE:   data_reg <= idcode_reg;
                NPU_ACC:  data_reg <= jtag_rdata;
                default:  data_reg <= 32'h0;
            endcase
        end else if (shift_dr) begin
            data_reg <= {tdi, data_reg[31:1]};
        end
    end
    
    // TDO输出选择
    always @(*) begin
        if (shift_ir) begin
            tdo_reg = instruction_reg[0];
        end else if (shift_dr) begin
            case (instruction_reg)
                BYPASS:   tdo_reg = tdi;  // 旁路
                default:  tdo_reg = data_reg[0];
            endcase
        end else begin
            tdo_reg = 1'b0;
        end
    end
    
    // NPU访问控制（跨时钟域）
    reg update_dr_sync1, update_dr_sync2, update_dr_sync3;
    always @(posedge npu_clk or negedge npu_rst_n) begin
        if (!npu_rst_n) begin
            update_dr_sync1 <= 1'b0;
            update_dr_sync2 <= 1'b0;
            update_dr_sync3 <= 1'b0;
        end else begin
            update_dr_sync1 <= update_dr;
            update_dr_sync2 <= update_dr_sync1;
            update_dr_sync3 <= update_dr_sync2;
        end
    end
    
    wire update_dr_pulse = update_dr_sync2 && !update_dr_sync3;
    
    always @(posedge npu_clk or negedge npu_rst_n) begin
        if (!npu_rst_n) begin
            jtag_access_req <= 1'b0;
            jtag_addr <= 32'h0;
            jtag_wdata <= 32'h0;
            jtag_write <= 1'b0;
        end else if (update_dr_pulse && (instruction_reg == NPU_ACC)) begin
            jtag_access_req <= 1'b1;
            jtag_addr <= data_reg;
            jtag_wdata <= data_reg;  // 简化示例
            jtag_write <= data_reg[31];  // MSB表示读/写
        end else if (jtag_ready) begin
            jtag_access_req <= 1'b0;
        end
    end

endmodule
            </div>

            <h4>7.4.4 DFT验证流程</h4>
            
            <p>DFT特性的验证同样重要，需要确保所有测试结构正确工作。</p>

            <div class="code-block">
// DFT验证测试平台
class dft_test_env extends uvm_env;
    `uvm_component_utils(dft_test_env)
    
    // DFT代理
    jtag_agent     jtag_agt;
    scan_agent     scan_agt;
    mbist_monitor  mbist_mon;
    
    // 记分板
    dft_scoreboard scb;
    
    function new(string name = "dft_test_env", uvm_component parent);
        super.new(name, parent);
    endfunction
    
    function void build_phase(uvm_phase phase);
        super.build_phase(phase);
        
        jtag_agt = jtag_agent::type_id::create("jtag_agt", this);
        scan_agt = scan_agent::type_id::create("scan_agt", this);
        mbist_mon = mbist_monitor::type_id::create("mbist_mon", this);
        scb = dft_scoreboard::type_id::create("scb", this);
    endfunction
    
    function void connect_phase(uvm_phase phase);
        super.connect_phase(phase);
        
        jtag_agt.ap.connect(scb.jtag_export);
        scan_agt.ap.connect(scb.scan_export);
        mbist_mon.ap.connect(scb.mbist_export);
    endfunction
endclass

// 扫描链测试序列
class scan_chain_test_seq extends uvm_sequence;
    `uvm_object_utils(scan_chain_test_seq)
    
    rand int chain_length;
    rand bit [1023:0] scan_pattern;
    
    constraint c_chain_length {
        chain_length inside {[100:1000]};
    }
    
    task body();
        scan_seq_item req;
        
        // 1. 进入扫描模式
        req = scan_seq_item::type_id::create("req");
        req.scan_mode = 1'b1;
        req.scan_enable = 1'b0;
        start_item(req);
        finish_item(req);
        
        // 2. 移入测试向量
        req.scan_enable = 1'b1;
        for (int i = 0; i < chain_length; i++) begin
            req.scan_in = scan_pattern[i];
            start_item(req);
            finish_item(req);
        end
        
        // 3. 捕获响应
        req.scan_enable = 1'b0;
        start_item(req);
        finish_item(req);
        
        // 4. 移出响应
        req.scan_enable = 1'b1;
        for (int i = 0; i < chain_length; i++) begin
            start_item(req);
            finish_item(req);
            // 收集scan_out用于比较
        end
        
        // 5. 退出扫描模式
        req.scan_mode = 1'b0;
        req.scan_enable = 1'b0;
        start_item(req);
        finish_item(req);
    endtask
endclass

// DFT覆盖率收集
class dft_coverage extends uvm_subscriber #(uvm_sequence_item);
    `uvm_component_utils(dft_coverage)
    
    // 覆盖率组
    covergroup scan_cg;
        scan_length: coverpoint scan_length {
            bins short = {[1:100]};
            bins medium = {[101:500]};
            bins long = {[501:1000]};
        }
        
        scan_pattern: coverpoint scan_pattern_type {
            bins all_zeros = {ALL_ZEROS};
            bins all_ones = {ALL_ONES};
            bins checkerboard = {CHECKERBOARD};
            bins random = {RANDOM};
        }
        
        fault_coverage: coverpoint fault_cov_percent {
            bins low = {[0:85]};
            bins medium = {[85:95]};
            bins high = {[95:99]};
            bins excellent = {[99:100]};
        }
    endgroup
    
    covergroup mbist_cg;
        algorithm: coverpoint mbist_algorithm {
            bins march_c = {MARCH_C};
            bins march_c_minus = {MARCH_C_MINUS};
            bins checkerboard = {CHECKERBOARD};
            bins address_decoder = {ADDR_DECODER};
        }
        
        memory_size: coverpoint mem_size {
            bins small = {[0:1024]};
            bins medium = {[1024:64*1024]};
            bins large = {[64*1024:$]};
        }
        
        fault_type: coverpoint detected_fault {
            bins stuck_at = {STUCK_AT};
            bins transition = {TRANSITION};
            bins coupling = {COUPLING};
            bins address = {ADDRESS};
        }
    endgroup
    
    function new(string name = "dft_coverage", uvm_component parent);
        super.new(name, parent);
        scan_cg = new();
        mbist_cg = new();
    endfunction
    
    function void write(uvm_sequence_item t);
        // 根据事务类型采样覆盖率
        if ($cast(scan_item, t)) begin
            scan_length = scan_item.chain_length;
            scan_pattern_type = scan_item.pattern_type;
            fault_cov_percent = scan_item.fault_coverage;
            scan_cg.sample();
        end else if ($cast(mbist_item, t)) begin
            mbist_algorithm = mbist_item.algorithm;
            mem_size = mbist_item.memory_size;
            detected_fault = mbist_item.fault_type;
            mbist_cg.sample();
        end
    endfunction
endclass
            </div>

            <div class="info-box">
                <strong>DFT验证要点：</strong>
                <ul>
                    <li>扫描链连通性测试：验证所有扫描链路径</li>
                    <li>ATPG向量仿真：运行自动生成的测试向量</li>
                    <li>故障注入测试：验证故障检测能力</li>
                    <li>时序验证：确保扫描模式时序满足要求</li>
                    <li>功耗分析：评估测试模式功耗</li>
                </ul>
            </div>

            <h3>7.5 软硬件协同验证</h3>
            
            <p>NPU是软件驱动的硬件，其功能正确性高度依赖于编译器、驱动程序和固件。软硬件协同验证确保整个系统栈的正确性。</p>
            
            <h4>7.5.1 协同验证平台架构</h4>
            
            <div class="code-block">
// 软硬件协同验证环境
class sw_hw_co_verification_env extends uvm_env;
    `uvm_component_utils(sw_hw_co_verification_env)
    
    // CPU模型（QEMU或ARM Fast Model）
    virtual cpu_model_if cpu_if;
    
    // NPU RTL包装器
    npu_rtl_wrapper npu_wrapper;
    
    // 系统总线
    axi_interconnect_agent axi_agent;
    
    // 内存模型
    memory_model sys_mem;
    
    // 软件代理
    software_agent sw_agent;
    driver_monitor drv_mon;
    
    function new(string name, uvm_component parent);
        super.new(name, parent);
    endfunction
    
    function void build_phase(uvm_phase phase);
        super.build_phase(phase);
        
        // 获取CPU模型接口
        if (!uvm_config_db#(virtual cpu_model_if)::get(this, "", "cpu_if", cpu_if))
            `uvm_fatal("CONFIG", "Cannot get CPU model interface")
        
        // 创建组件
        npu_wrapper = npu_rtl_wrapper::type_id::create("npu_wrapper", this);
        axi_agent = axi_interconnect_agent::type_id::create("axi_agent", this);
        sys_mem = memory_model::type_id::create("sys_mem", this);
        sw_agent = software_agent::type_id::create("sw_agent", this);
        drv_mon = driver_monitor::type_id::create("drv_mon", this);
        
        // 配置地址映射
        configure_address_map();
    endfunction
    
    function void configure_address_map();
        // NPU寄存器空间
        uvm_config_db#(addr_range)::set(this, "*", "npu_reg_base", 32'h4000_0000);
        uvm_config_db#(addr_range)::set(this, "*", "npu_reg_size", 32'h0001_0000);
        
        // NPU本地内存
        uvm_config_db#(addr_range)::set(this, "*", "npu_mem_base", 32'h8000_0000);
        uvm_config_db#(addr_range)::set(this, "*", "npu_mem_size", 32'h0400_0000);
        
        // 系统内存
        uvm_config_db#(addr_range)::set(this, "*", "sys_mem_base", 32'h0000_0000);
        uvm_config_db#(addr_range)::set(this, "*", "sys_mem_size", 32'h4000_0000);
    endfunction
endclass

// NPU驱动程序监控器
class driver_monitor extends uvm_monitor;
    `uvm_component_utils(driver_monitor)
    
    // 分析端口
    uvm_analysis_port #(driver_transaction) ap;
    
    // 驱动API跟踪
    typedef enum {
        DRV_INIT,
        DRV_LOAD_MODEL,
        DRV_SET_INPUT,
        DRV_RUN_INFERENCE,
        DRV_GET_OUTPUT,
        DRV_CLEANUP
    } driver_api_e;
    
    function new(string name, uvm_component parent);
        super.new(name, parent);
        ap = new("ap", this);
    endfunction
    
    task run_phase(uvm_phase phase);
        driver_transaction trans;
        
        forever begin
            // 监控驱动程序API调用
            wait_for_driver_call();
            
            trans = driver_transaction::type_id::create("trans");
            trans.api_type = get_api_type();
            trans.timestamp = $time;
            
            case (trans.api_type)
                DRV_INIT: capture_init_params(trans);
                DRV_LOAD_MODEL: capture_model_info(trans);
                DRV_RUN_INFERENCE: capture_inference_params(trans);
                default: ;
            endcase
            
            ap.write(trans);
            
            // 验证寄存器访问序列
            verify_register_sequence(trans);
        end
    endtask
    
    task verify_register_sequence(driver_transaction trans);
        // 检查驱动程序是否按照正确顺序访问寄存器
        case (trans.api_type)
            DRV_INIT: begin
                // 验证初始化序列
                check_register_write(NPU_CTRL_REG, NPU_RESET);
                check_register_write(NPU_CTRL_REG, NPU_ENABLE);
                check_register_read(NPU_STATUS_REG);
            end
            
            DRV_LOAD_MODEL: begin
                // 验证模型加载序列
                check_dma_setup();
                check_weight_loading();
                check_config_update();
            end
        endcase
    endtask
endclass

// 软硬件协同测试用例
class sw_hw_co_test extends uvm_test;
    `uvm_component_utils(sw_hw_co_test)
    
    sw_hw_co_verification_env env;
    
    function new(string name, uvm_component parent);
        super.new(name, parent);
    endfunction
    
    task run_phase(uvm_phase phase);
        driver_api_sequence drv_seq;
        ml_inference_sequence ml_seq;
        stress_test_sequence stress_seq;
        
        phase.raise_objection(this);
        
        // 测试1: 基本驱动API测试
        `uvm_info("TEST", "Testing driver API compliance", UVM_LOW)
        drv_seq = driver_api_sequence::type_id::create("drv_seq");
        drv_seq.test_all_apis = 1;
        drv_seq.start(env.sw_agent.sequencer);
        
        // 测试2: 真实ML模型推理
        `uvm_info("TEST", "Testing ML model inference", UVM_LOW)
        ml_seq = ml_inference_sequence::type_id::create("ml_seq");
        ml_seq.model_path = "models/mobilenet_v2.tflite";
        ml_seq.input_data = load_test_image("test_data/cat.jpg");
        ml_seq.expected_class = 281; // Cat class ID
        ml_seq.start(env.sw_agent.sequencer);
        
        // 测试3: 压力测试
        `uvm_info("TEST", "Running stress test", UVM_LOW)
        stress_seq = stress_test_sequence::type_id::create("stress_seq");
        stress_seq.num_threads = 4;
        stress_seq.iterations_per_thread = 100;
        stress_seq.start(env.sw_agent.sequencer);
        
        phase.drop_objection(this);
    endtask
endclass
            </div>
            
            <h4>7.5.2 驱动程序验证</h4>
            
            <div class="code-block">
// NPU驱动程序验证检查器
class npu_driver_checker extends uvm_component;
    `uvm_component_utils(npu_driver_checker)
    
    // 寄存器模型
    npu_reg_model reg_model;
    
    // 状态跟踪
    typedef enum {
        NPU_UNINITIALIZED,
        NPU_IDLE,
        NPU_CONFIGURING,
        NPU_RUNNING,
        NPU_ERROR
    } npu_state_e;
    
    npu_state_e current_state = NPU_UNINITIALIZED;
    
    // 寄存器访问历史
    typedef struct {
        bit [31:0] addr;
        bit [31:0] data;
        bit is_write;
        time timestamp;
    } reg_access_t;
    
    reg_access_t access_history[$];
    
    function new(string name, uvm_component parent);
        super.new(name, parent);
    endfunction
    
    // 验证初始化序列
    function bit verify_init_sequence();
        int idx = 0;
        
        // 检查软复位
        if (!check_reg_write(idx++, NPU_CTRL_REG, 32'h0000_0001))
            return 0;
            
        // 检查复位释放
        if (!check_reg_write(idx++, NPU_CTRL_REG, 32'h0000_0000))
            return 0;
            
        // 检查中断使能
        if (!check_reg_write(idx++, NPU_INT_ENABLE_REG, 32'hFFFF_FFFF))
            return 0;
            
        // 检查DMA配置
        if (!check_reg_write(idx++, NPU_DMA_CTRL_REG, 32'h0000_0003))
            return 0;
            
        current_state = NPU_IDLE;
        return 1;
    endfunction
    
    // 验证模型配置序列
    function bit verify_model_config();
        // 检查是否在正确状态
        if (current_state != NPU_IDLE) begin
            `uvm_error("DRV_CHECK", $sformatf(
                "Model config in wrong state: %s", current_state.name()))
            return 0;
        end
        
        // 验证层配置顺序
        if (!verify_layer_config_sequence())
            return 0;
            
        // 验证权重加载
        if (!verify_weight_loading_sequence())
            return 0;
            
        current_state = NPU_CONFIGURING;
        return 1;
    endfunction
    
    // 验证推理执行
    function bit verify_inference_execution();
        bit [31:0] status;
        
        // 检查输入数据DMA
        if (!verify_input_dma_setup())
            return 0;
            
        // 检查启动命令
        if (!check_reg_write_recent(NPU_CMD_REG, NPU_CMD_START))
            return 0;
            
        // 检查状态轮询
        if (!verify_status_polling())
            return 0;
            
        // 检查完成中断处理
        if (!verify_interrupt_handling())
            return 0;
            
        // 检查输出数据DMA
        if (!verify_output_dma_setup())
            return 0;
            
        return 1;
    endfunction
    
    // 检测常见驱动错误
    function void detect_driver_errors();
        // 错误1: 未初始化就使用
        foreach (access_history[i]) begin
            if (access_history[i].addr != NPU_CTRL_REG && 
                i == 0) begin
                `uvm_error("DRV_CHECK", 
                    "NPU accessed before initialization")
            end
        end
        
        // 错误2: 重复初始化
        int init_count = 0;
        foreach (access_history[i]) begin
            if (access_history[i].addr == NPU_CTRL_REG &&
                access_history[i].data == 32'h0000_0001) begin
                init_count++;
            end
        end
        if (init_count > 1) begin
            `uvm_warning("DRV_CHECK", 
                $sformatf("NPU initialized %0d times", init_count))
        end
        
        // 错误3: 未等待操作完成
        check_operation_completion();
        
        // 错误4: 资源泄露
        check_resource_cleanup();
    endfunction
endclass

// 驱动API一致性测试
class driver_api_test_sequence extends uvm_sequence;
    `uvm_object_utils(driver_api_test_sequence)
    
    task body();
        // 测试正常流程
        test_normal_flow();
        
        // 测试错误处理
        test_error_handling();
        
        // 测试并发访问
        test_concurrent_access();
        
        // 测试资源管理
        test_resource_management();
    endtask
    
    task test_normal_flow();
        cpu_instruction_seq cpu_seq;
        
        // 初始化NPU
        cpu_seq = cpu_instruction_seq::type_id::create("cpu_seq");
        cpu_seq.inline_c_code = "npu_init()";
        cpu_seq.start(p_sequencer.cpu_sqr);
        
        // 加载模型
        cpu_seq = cpu_instruction_seq::type_id::create("cpu_seq");
        cpu_seq.inline_c_code = "npu_load_model('resnet50.model')";
        cpu_seq.start(p_sequencer.cpu_sqr);
        
        // 运行推理
        cpu_seq = cpu_instruction_seq::type_id::create("cpu_seq");
        cpu_seq.inline_c_code = "npu_run_inference(input_buffer, output_buffer)";
        cpu_seq.start(p_sequencer.cpu_sqr);
        
        // 验证结果
        verify_inference_result();
    endtask
    
    task test_error_handling();
        // 测试无效参数
        test_invalid_parameters();
        
        // 测试超时处理
        test_timeout_handling();
        
        // 测试中断处理
        test_interrupt_handling();
        
        // 测试恢复机制
        test_error_recovery();
    endtask
endclass
            </div>
            
            <h4>7.5.3 固件验证</h4>
            
            <div class="code-block">
// NPU固件验证环境
class npu_firmware_verification extends uvm_component;
    `uvm_component_utils(npu_firmware_verification)
    
    // 固件加载器
    firmware_loader fw_loader;
    
    // 指令跟踪器
    instruction_tracer inst_tracer;
    
    // 性能分析器
    firmware_profiler fw_profiler;
    
    function new(string name, uvm_component parent);
        super.new(name, parent);
    endfunction
    
    task verify_firmware_boot();
        bit [31:0] boot_status;
        
        // 加载固件到NPU内部RAM
        fw_loader.load_firmware("npu_firmware.bin", 32'h0000_0000);
        
        // 释放NPU复位
        write_register(NPU_CTRL_REG, 32'h0000_0010); // RELEASE_RESET
        
        // 等待启动完成
        wait_boot_complete(boot_status);
        
        // 验证启动状态
        if (boot_status != 32'hBOOT_SUCCESS) begin
            `uvm_error("FW_VERIFY", 
                $sformatf("Firmware boot failed: 0x%08x", boot_status))
        end
        
        // 验证固件版本
        verify_firmware_version();
        
        // 验证功能模块初始化
        verify_module_initialization();
    endtask
    
    task verify_firmware_scheduler();
        scheduler_test_sequence sched_seq;
        
        // 测试任务调度
        sched_seq = scheduler_test_sequence::type_id::create("sched_seq");
        sched_seq.num_tasks = 10;
        sched_seq.task_priorities = '{3, 1, 2, 1, 3, 2, 1, 3, 2, 1};
        sched_seq.start(null);
        
        // 验证调度顺序
        verify_task_execution_order();
        
        // 验证资源分配
        verify_resource_allocation();
        
        // 验证死锁避免
        verify_deadlock_avoidance();
    endtask
    
    task verify_firmware_power_management();
        power_state_e current_state, expected_state;
        
        // 测试空闲时进入低功耗
        force_idle_state(100us);
        current_state = read_power_state();
        expected_state = POWER_STATE_SLEEP;
        
        if (current_state != expected_state) begin
            `uvm_error("FW_VERIFY", 
                $sformatf("Wrong power state: got %s, expected %s",
                current_state.name(), expected_state.name()))
        end
        
        // 测试唤醒延迟
        measure_wakeup_latency();
        
        // 测试动态电压频率调节
        verify_dvfs_operation();
    endtask
endclass

// 固件与驱动交互验证
class fw_driver_interaction_test extends uvm_test;
    `uvm_component_utils(fw_driver_interaction_test)
    
    task run_phase(uvm_phase phase);
        phase.raise_objection(this);
        
        // 测试命令队列
        test_command_queue();
        
        // 测试事件通知
        test_event_notification();
        
        // 测试共享内存
        test_shared_memory();
        
        // 测试同步机制
        test_synchronization();
        
        phase.drop_objection(this);
    endtask
    
    task test_command_queue();
        // 驱动发送多个命令
        for (int i = 0; i < 10; i++) begin
            send_driver_command(CMD_LOAD_LAYER, i);
        end
        
        // 验证固件按序处理
        verify_command_processing_order();
        
        // 测试队列满处理
        fill_command_queue();
        verify_queue_full_handling();
        
        // 测试优先级命令
        test_priority_commands();
    endtask
endclass
            </div>

            <h3>7.6 后硅验证</h3>
            
            <h4>7.6.1 芯片带起（Bring-up）</h4>
            <div class="code-block">
// JTAG调试接口
module jtag_debug_interface (
    // JTAG接口
    input wire tck,
    input wire tms,
    input wire tdi,
    output reg tdo,
    input wire trst_n,
    
    // 内部调试接口
    output reg [31:0] debug_addr,
    output reg [31:0] debug_wdata,
    output reg debug_wen,
    output reg debug_ren,
    input wire [31:0] debug_rdata,
    input wire debug_ready
);

    // TAP状态机
    localparam TEST_LOGIC_RESET = 4'h0;
    localparam RUN_TEST_IDLE = 4'h1;
    localparam SELECT_DR_SCAN = 4'h2;
    localparam CAPTURE_DR = 4'h3;
    localparam SHIFT_DR = 4'h4;
    localparam EXIT1_DR = 4'h5;
    localparam PAUSE_DR = 4'h6;
    localparam EXIT2_DR = 4'h7;
    localparam UPDATE_DR = 4'h8;
    localparam SELECT_IR_SCAN = 4'h9;
    localparam CAPTURE_IR = 4'hA;
    localparam SHIFT_IR = 4'hB;
    localparam EXIT1_IR = 4'hC;
    localparam PAUSE_IR = 4'hD;
    localparam EXIT2_IR = 4'hE;
    localparam UPDATE_IR = 4'hF;
    
    reg [3:0] tap_state;
    reg [4:0] ir_reg;  // 指令寄存器
    reg [63:0] dr_reg;  // 数据寄存器
    
    // 指令定义
    localparam IDCODE = 5'b00001;
    localparam ADDR = 5'b00010;
    localparam DATA = 5'b00011;
    localparam CONTROL = 5'b00100;
    
    // TAP控制器状态机
    always @(posedge tck or negedge trst_n) begin
        if (!trst_n) begin
            tap_state <= TEST_LOGIC_RESET;
        end else begin
            case (tap_state)
                TEST_LOGIC_RESET: tap_state <= tms ? TEST_LOGIC_RESET : RUN_TEST_IDLE;
                RUN_TEST_IDLE: tap_state <= tms ? SELECT_DR_SCAN : RUN_TEST_IDLE;
                SELECT_DR_SCAN: tap_state <= tms ? SELECT_IR_SCAN : CAPTURE_DR;
                CAPTURE_DR: tap_state <= tms ? EXIT1_DR : SHIFT_DR;
                SHIFT_DR: tap_state <= tms ? EXIT1_DR : SHIFT_DR;
                EXIT1_DR: tap_state <= tms ? UPDATE_DR : PAUSE_DR;
                PAUSE_DR: tap_state <= tms ? EXIT2_DR : PAUSE_DR;
                EXIT2_DR: tap_state <= tms ? UPDATE_DR : SHIFT_DR;
                UPDATE_DR: tap_state <= tms ? SELECT_DR_SCAN : RUN_TEST_IDLE;
                SELECT_IR_SCAN: tap_state <= tms ? TEST_LOGIC_RESET : CAPTURE_IR;
                CAPTURE_IR: tap_state <= tms ? EXIT1_IR : SHIFT_IR;
                SHIFT_IR: tap_state <= tms ? EXIT1_IR : SHIFT_IR;
                EXIT1_IR: tap_state <= tms ? UPDATE_IR : PAUSE_IR;
                PAUSE_IR: tap_state <= tms ? EXIT2_IR : PAUSE_IR;
                EXIT2_IR: tap_state <= tms ? UPDATE_IR : SHIFT_IR;
                UPDATE_IR: tap_state <= tms ? SELECT_DR_SCAN : RUN_TEST_IDLE;
            endcase
        end
    end
    
    // IR和DR操作
    always @(posedge tck) begin
        case (tap_state)
            SHIFT_IR: begin
                ir_reg <= {tdi, ir_reg[4:1]};
                tdo <= ir_reg[0];
            end
            
            CAPTURE_DR: begin
                case (ir_reg)
                    IDCODE: dr_reg[31:0] <= 32'h12345678;  // 芯片ID
                    DATA: dr_reg[31:0] <= debug_rdata;
                endcase
            end
            
            SHIFT_DR: begin
                dr_reg <= {tdi, dr_reg[63:1]};
                tdo <= dr_reg[0];
            end
            
            UPDATE_DR: begin
                case (ir_reg)
                    ADDR: debug_addr <= dr_reg[31:0];
                    DATA: begin
                        debug_wdata <= dr_reg[31:0];
                        debug_wen <= dr_reg[32];
                        debug_ren <= dr_reg[33];
                    end
                endcase
            end
        endcase
    end

endmodule

// 片上调试监控器
module on_chip_debug_monitor (
    input wire clk,
    input wire rst_n,
    
    // 监控信号
    input wire [31:0] pc,
    input wire [31:0] instruction,
    input wire inst_valid,
    input wire [31:0] npu_status,
    
    // 触发控制
    input wire [31:0] trigger_pc,
    input wire trigger_en,
    
    // Trace缓冲区接口
    output reg trace_wen,
    output reg [63:0] trace_data,
    output reg [9:0] trace_addr
);

    // 触发检测
    wire trigger_hit = trigger_en && (pc == trigger_pc);
    reg triggered;
    reg [9:0] trace_cnt;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            triggered <= 1'b0;
            trace_cnt <= 0;
            trace_wen <= 1'b0;
        end else begin
            if (trigger_hit) begin
                triggered <= 1'b1;
                trace_cnt <= 0;
            end
            
            if (triggered && inst_valid) begin
                trace_wen <= 1'b1;
                trace_data <= {pc, instruction};
                trace_addr <= trace_cnt;
                trace_cnt <= trace_cnt + 1;
                
                if (trace_cnt == 1023) begin  // Trace buffer满
                    triggered <= 1'b0;
                end
            end else begin
                trace_wen <= 1'b0;
            end
        end
    end

endmodule
            </div>

            <h4>7.5.2 性能调优与Shmoo测试</h4>
            <div class="code-block">
// 优化的Shmoo测试控制器 - Verilog版本
module shmoo_test_controller (
    input wire clk,
    input wire rst_n,
    
    // 测试控制
    input wire shmoo_start,
    input wire [7:0] vdd_start,      // 起始电压（单位：10mV）
    input wire [7:0] vdd_end,        // 结束电压
    input wire [7:0] vdd_step,       // 电压步进
    input wire [9:0] freq_start,     // 起始频率（单位：MHz）
    input wire [9:0] freq_end,       // 结束频率
    input wire [9:0] freq_step,      // 频率步进
    
    // 电源和时钟控制
    output reg [7:0] vdd_ctrl,
    output reg [9:0] freq_ctrl,
    output reg pll_reconfig,
    output reg vdd_stable,           // 电压稳定指示
    output reg pll_locked,           // PLL锁定指示
    
    // 测试执行
    output reg test_trigger,
    input wire test_done,
    input wire test_pass,
    input wire test_error,           // 测试错误标志
    
    // 结果存储
    output reg result_wen,
    output reg [17:0] result_addr,   // [17:10]=VDD, [9:0]=Freq
    output reg [1:0] result_data,    // 00=Fail, 01=Pass, 10=Error, 11=Skip
    
    // 状态输出
    output reg shmoo_done,
    output reg [2:0] current_state,  // 调试用状态输出
    output reg [31:0] test_count,    // 测试计数
    output reg [31:0] pass_count     // 通过计数
);

    // 状态机定义
    localparam IDLE = 3'b000;
    localparam SET_VDD = 3'b001;
    localparam WAIT_VDD = 3'b010;
    localparam SET_FREQ = 3'b011;
    localparam WAIT_PLL = 3'b100;
    localparam RUN_TEST = 3'b101;
    localparam STORE_RESULT = 3'b110;
    localparam NEXT_POINT = 3'b111;
    
    // 内部寄存器
    reg [2:0] state, next_state;
    reg [7:0] current_vdd, next_vdd;
    reg [9:0] current_freq, next_freq;
    reg [15:0] settle_cnt;
    reg [3:0] retry_cnt;
    
    // 流水线寄存器 - 避免组合逻辑
    reg [7:0] vdd_target;
    reg [9:0] freq_target;
    reg test_in_progress;
    reg result_pending;
    
    // 配置参数寄存器（避免直接使用输入）
    reg [7:0] vdd_start_reg, vdd_end_reg, vdd_step_reg;
    reg [9:0] freq_start_reg, freq_end_reg, freq_step_reg;
    
    // 参数锁存
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            vdd_start_reg <= 8'd70;   // 默认0.7V
            vdd_end_reg <= 8'd120;    // 默认1.2V
            vdd_step_reg <= 8'd5;     // 默认50mV步进
            freq_start_reg <= 10'd100; // 默认100MHz
            freq_end_reg <= 10'd1000;  // 默认1GHz
            freq_step_reg <= 10'd50;   // 默认50MHz步进
        end else if (state == IDLE && shmoo_start) begin
            vdd_start_reg <= vdd_start;
            vdd_end_reg <= vdd_end;
            vdd_step_reg <= vdd_step;
            freq_start_reg <= freq_start;
            freq_end_reg <= freq_end;
            freq_step_reg <= freq_step;
        end
    end
    
    // 状态机 - 时序逻辑
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            state <= IDLE;
            current_vdd <= 8'd0;
            current_freq <= 10'd0;
            settle_cnt <= 16'd0;
            retry_cnt <= 4'd0;
            test_count <= 32'd0;
            pass_count <= 32'd0;
        end else begin
            state <= next_state;
            current_vdd <= next_vdd;
            current_freq <= next_freq;
            
            // 稳定计数器
            if (state == SET_VDD || state == SET_FREQ) begin
                settle_cnt <= 16'hFFFF;
            end else if (settle_cnt > 0) begin
                settle_cnt <= settle_cnt - 1;
            end
            
            // 重试计数器
            if (state == RUN_TEST && test_error) begin
                retry_cnt <= retry_cnt + 1;
            end else if (state == IDLE) begin
                retry_cnt <= 4'd0;
            end
        end
    end
    
    // 状态机 - 组合逻辑（完全打拍子）
    always @(*) begin
        next_state = state;
        next_vdd = current_vdd;
        next_freq = current_freq;
        
        case (state)
            IDLE: begin
                if (shmoo_start) begin
                    next_state = SET_VDD;
                    next_vdd = vdd_start_reg;
                    next_freq = freq_start_reg;
                end
            end
            
            SET_VDD: begin
                next_state = WAIT_VDD;
            end
            
            WAIT_VDD: begin
                if (settle_cnt == 0) begin
                    next_state = SET_FREQ;
                end
            end
            
            SET_FREQ: begin
                next_state = WAIT_PLL;
            end
            
            WAIT_PLL: begin
                if (settle_cnt == 0) begin
                    next_state = RUN_TEST;
                end
            end
            
            RUN_TEST: begin
                if (test_done || retry_cnt > 4'd3) begin
                    next_state = STORE_RESULT;
                end
            end
            
            STORE_RESULT: begin
                next_state = NEXT_POINT;
            end
            
            NEXT_POINT: begin
                if (current_freq + freq_step_reg <= freq_end_reg) begin
                    next_freq = current_freq + freq_step_reg;
                    next_state = SET_FREQ;
                end else if (current_vdd + vdd_step_reg <= vdd_end_reg) begin
                    next_vdd = current_vdd + vdd_step_reg;
                    next_freq = freq_start_reg;
                    next_state = SET_VDD;
                end else begin
                    next_state = IDLE;
                end
            end
        endcase
    end
    
    // 输出逻辑 - 全部寄存器化
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            vdd_ctrl <= 8'd0;
            freq_ctrl <= 10'd0;
            pll_reconfig <= 1'b0;
            vdd_stable <= 1'b0;
            pll_locked <= 1'b0;
            test_trigger <= 1'b0;
            result_wen <= 1'b0;
            result_addr <= 18'd0;
            result_data <= 2'b00;
            shmoo_done <= 1'b0;
            current_state <= 3'd0;
            test_in_progress <= 1'b0;
            result_pending <= 1'b0;
        end else begin
            // 默认值
            pll_reconfig <= 1'b0;
            test_trigger <= 1'b0;
            result_wen <= 1'b0;
            shmoo_done <= 1'b0;
            
            // 状态输出
            current_state <= state;
            
            case (state)
                SET_VDD: begin
                    vdd_ctrl <= current_vdd;
                    vdd_stable <= 1'b0;
                end
                
                WAIT_VDD: begin
                    vdd_stable <= (settle_cnt < 16'd256);
                end
                
                SET_FREQ: begin
                    freq_ctrl <= current_freq;
                    pll_reconfig <= 1'b1;
                    pll_locked <= 1'b0;
                end
                
                WAIT_PLL: begin
                    pll_locked <= (settle_cnt < 16'd256);
                end
                
                RUN_TEST: begin
                    if (!test_in_progress && !test_done) begin
                        test_trigger <= 1'b1;
                        test_in_progress <= 1'b1;
                    end else if (test_done) begin
                        test_in_progress <= 1'b0;
                        result_pending <= 1'b1;
                    end
                end
                
                STORE_RESULT: begin
                    if (result_pending) begin
                        result_wen <= 1'b1;
                        result_addr <= {current_vdd, current_freq};
                        
                        // 结果编码
                        if (retry_cnt > 4'd3) begin
                            result_data <= 2'b10; // Error
                        end else if (test_pass) begin
                            result_data <= 2'b01; // Pass
                            pass_count <= pass_count + 1;
                        end else begin
                            result_data <= 2'b00; // Fail
                        end
                        
                        test_count <= test_count + 1;
                        result_pending <= 1'b0;
                    end
                end
                
                IDLE: begin
                    if (test_count > 0 && !shmoo_start) begin
                        shmoo_done <= 1'b1;
                    end
                end
            endcase
        end
    end

endmodule
            </div>
            
            <div class="code-block">
// Chisel版本对比：
import chisel3._
import chisel3.util._

class ShmooTestController extends Module {
  val io = IO(new Bundle {
    // 测试控制
    val shmoo_start = Input(Bool())
    val vdd_start = Input(UInt(8.W))
    val vdd_end = Input(UInt(8.W))
    val vdd_step = Input(UInt(8.W))
    val freq_start = Input(UInt(10.W))
    val freq_end = Input(UInt(10.W))
    val freq_step = Input(UInt(10.W))
    
    // 电源和时钟控制
    val vdd_ctrl = Output(UInt(8.W))
    val freq_ctrl = Output(UInt(10.W))
    val pll_reconfig = Output(Bool())
    val vdd_stable = Output(Bool())
    val pll_locked = Output(Bool())
    
    // 测试执行
    val test_trigger = Output(Bool())
    val test_done = Input(Bool())
    val test_pass = Input(Bool())
    val test_error = Input(Bool())
    
    // 结果存储
    val result_wen = Output(Bool())
    val result_addr = Output(UInt(18.W))
    val result_data = Output(UInt(2.W))
    
    // 状态输出
    val shmoo_done = Output(Bool())
    val current_state = Output(UInt(3.W))
    val test_count = Output(UInt(32.W))
    val pass_count = Output(UInt(32.W))
  })
  
  // 状态机定义
  val idle :: setVdd :: waitVdd :: setFreq :: waitPll :: runTest :: storeResult :: nextPoint :: Nil = Enum(8)
  
  val state = RegInit(idle)
  val currentVdd = RegInit(0.U(8.W))
  val currentFreq = RegInit(0.U(10.W))
  val settleCnt = RegInit(0.U(16.W))
  val retryCnt = RegInit(0.U(4.W))
  val testCount = RegInit(0.U(32.W))
  val passCount = RegInit(0.U(32.W))
  
  // 配置参数寄存器
  val vddStartReg = RegInit(70.U(8.W))
  val vddEndReg = RegInit(120.U(8.W))
  val vddStepReg = RegInit(5.U(8.W))
  val freqStartReg = RegInit(100.U(10.W))
  val freqEndReg = RegInit(1000.U(10.W))
  val freqStepReg = RegInit(50.U(10.W))
  
  // 参数锁存
  when(state === idle && io.shmoo_start) {
    vddStartReg := io.vdd_start
    vddEndReg := io.vdd_end
    vddStepReg := io.vdd_step
    freqStartReg := io.freq_start
    freqEndReg := io.freq_end
    freqStepReg := io.freq_step
  }
  
  // 稳定计数器
  when(state === setVdd || state === setFreq) {
    settleCnt := "hFFFF".U
  }.elsewhen(settleCnt > 0.U) {
    settleCnt := settleCnt - 1.U
  }
  
  // 状态机
  switch(state) {
    is(idle) {
      when(io.shmoo_start) {
        state := setVdd
        currentVdd := vddStartReg
        currentFreq := freqStartReg
      }
    }
    is(setVdd) {
      state := waitVdd
    }
    is(waitVdd) {
      when(settleCnt === 0.U) {
        state := setFreq
      }
    }
    is(setFreq) {
      state := waitPll
    }
    is(waitPll) {
      when(settleCnt === 0.U) {
        state := runTest
      }
    }
    is(runTest) {
      when(io.test_done || retryCnt > 3.U) {
        state := storeResult
      }
    }
    is(storeResult) {
      state := nextPoint
      testCount := testCount + 1.U
      when(!io.test_error && io.test_pass) {
        passCount := passCount + 1.U
      }
    }
    is(nextPoint) {
      when(currentFreq + freqStepReg <= freqEndReg) {
        currentFreq := currentFreq + freqStepReg
        state := setFreq
      }.elsewhen(currentVdd + vddStepReg <= vddEndReg) {
        currentVdd := currentVdd + vddStepReg
        currentFreq := freqStartReg
        state := setVdd
      }.otherwise {
        state := idle
      }
    }
  }
  
  // 输出逻辑
  io.vdd_ctrl := RegNext(Mux(state === setVdd, currentVdd, io.vdd_ctrl))
  io.freq_ctrl := RegNext(Mux(state === setFreq, currentFreq, io.freq_ctrl))
  io.pll_reconfig := RegNext(state === setFreq)
  io.vdd_stable := RegNext(state === waitVdd && settleCnt < 256.U)
  io.pll_locked := RegNext(state === waitPll && settleCnt < 256.U)
  
  val testInProgress = RegInit(false.B)
  io.test_trigger := RegNext(state === runTest && !testInProgress && !io.test_done)
  when(io.test_trigger) {
    testInProgress := true.B
  }.elsewhen(io.test_done) {
    testInProgress := false.B
  }
  
  // 结果存储
  io.result_wen := RegNext(state === storeResult)
  io.result_addr := RegNext(Cat(currentVdd, currentFreq))
  io.result_data := RegNext(MuxCase(0.U, Seq(
    (retryCnt > 3.U) -> 2.U,  // Error
    io.test_pass -> 1.U,       // Pass
    true.B -> 0.U              // Fail
  )))
  
  // 状态输出
  io.shmoo_done := RegNext(state === idle && testCount > 0.U && !io.shmoo_start)
  io.current_state := state
  io.test_count := testCount
  io.pass_count := passCount
}
            </div>

            <h3>7.6 测试向量生成</h3>
            
            <h4>7.6.1 基于模型的向量生成</h4>
            <div class="code-block">
// Python脚本：从神经网络模型生成测试向量
"""
npu_test_vector_generator.py
从PyTorch/TensorFlow模型生成NPU测试向量
"""

import numpy as np
import torch
import struct

class NPUTestVectorGenerator:
    def __init__(self, model, quantization_bits=8):
        self.model = model
        self.quant_bits = quantization_bits
        self.test_vectors = []
        
    def quantize(self, tensor, scale, zero_point):
        """量化浮点张量到定点"""
        q_min = -(2**(self.quant_bits-1))
        q_max = 2**(self.quant_bits-1) - 1
        
        q_tensor = np.round(tensor / scale + zero_point)
        q_tensor = np.clip(q_tensor, q_min, q_max)
        return q_tensor.astype(np.int8)
    
    def generate_conv_test(self, layer_name, input_shape):
        """生成卷积层测试向量"""
        # 创建测试输入
        test_input = torch.randn(input_shape)
        
        # 获取层参数
        conv_layer = getattr(self.model, layer_name)
        weight = conv_layer.weight.detach().numpy()
        bias = conv_layer.bias.detach().numpy() if conv_layer.bias is not None else None
        
        # 执行前向传播获取golden输出
        with torch.no_grad():
            golden_output = conv_layer(test_input).numpy()
        
        # 量化参数计算
        input_scale = np.max(np.abs(test_input.numpy())) / 127
        weight_scale = np.max(np.abs(weight)) / 127
        output_scale = input_scale * weight_scale
        
        # 量化
        q_input = self.quantize(test_input.numpy(), input_scale, 0)
        q_weight = self.quantize(weight, weight_scale, 0)
        q_output = self.quantize(golden_output, output_scale, 0)
        
        # 生成测试向量
        test_vector = {
            'layer': layer_name,
            'operation': 'conv2d',
            'input_shape': input_shape,
            'kernel_size': conv_layer.kernel_size,
            'stride': conv_layer.stride,
            'padding': conv_layer.padding,
            'input_data': q_input.flatten().tolist(),
            'weight_data': q_weight.flatten().tolist(),
            'bias_data': bias.tolist() if bias is not None else None,
            'expected_output': q_output.flatten().tolist(),
            'scales': {
                'input': input_scale,
                'weight': weight_scale,
                'output': output_scale
            }
        }
        
        self.test_vectors.append(test_vector)
        return test_vector
    
    def generate_corner_cases(self):
        """生成边界测试用例"""
        corner_cases = []
        
        # 全零输入
        zero_input = np.zeros((1, 3, 224, 224), dtype=np.int8)
        corner_cases.append({
            'name': 'all_zeros',
            'input': zero_input,
            'expected_behavior': 'zero_output'
        })
        
        # 最大值输入
        max_input = np.full((1, 3, 224, 224), 127, dtype=np.int8)
        corner_cases.append({
            'name': 'max_values',
            'input': max_input,
            'expected_behavior': 'saturation_check'
        })
        
        # 稀疏输入（90%零值）
        sparse_input = np.random.choice([0, 1], size=(1, 3, 224, 224), p=[0.9, 0.1])
        sparse_input = sparse_input.astype(np.int8) * 127
        corner_cases.append({
            'name': 'sparse_input',
            'input': sparse_input,
            'expected_behavior': 'sparse_optimization'
        })
        
        return corner_cases
    
    def export_to_npu_format(self, filename):
        """导出为NPU可读的二进制格式"""
        with open(filename, 'wb') as f:
            # 文件头
            f.write(struct.pack('I', 0x4E505554))  # 'NPUT' magic
            f.write(struct.pack('I', len(self.test_vectors)))
            
            for vector in self.test_vectors:
                # 向量头
                layer_name = vector['layer'].encode('utf-8')
                f.write(struct.pack('I', len(layer_name)))
                f.write(layer_name)
                
                # 操作类型
                op_type = vector['operation'].encode('utf-8')
                f.write(struct.pack('I', len(op_type)))
                f.write(op_type)
                
                # 数据
                input_data = vector['input_data']
                f.write(struct.pack('I', len(input_data)))
                for val in input_data:
                    f.write(struct.pack('b', val))
                
                # 权重
                weight_data = vector['weight_data']
                f.write(struct.pack('I', len(weight_data)))
                for val in weight_data:
                    f.write(struct.pack('b', val))
                
                # 期望输出
                output_data = vector['expected_output']
                f.write(struct.pack('I', len(output_data)))
                for val in output_data:
                    f.write(struct.pack('b', val))

# 使用示例
if __name__ == "__main__":
    # 加载模型
    model = torch.load('mobilenet_v2.pth')
    model.eval()
    
    # 创建测试向量生成器
    generator = NPUTestVectorGenerator(model)
    
    # 生成各层测试向量
    generator.generate_conv_test('features.0.0', (1, 3, 224, 224))
    generator.generate_conv_test('features.1.conv.0', (1, 32, 112, 112))
    
    # 生成边界测试
    corner_cases = generator.generate_corner_cases()
    
    # 导出测试向量
    generator.export_to_npu_format('npu_test_vectors.bin')
            </div>

            <h4>7.6.2 测试向量验证框架</h4>
            <div class="code-block">
// SystemVerilog测试向量加载和验证框架
class test_vector_loader extends uvm_component;
    `uvm_component_utils(test_vector_loader)
    
    // 测试向量数据结构
    typedef struct {
        string layer_name;
        string operation;
        int input_size;
        int weight_size;
        int output_size;
        byte input_data[];
        byte weight_data[];
        byte expected_output[];
        real input_scale;
        real weight_scale;
        real output_scale;
    } test_vector_t;
    
    test_vector_t test_vectors[$];
    
    function new(string name, uvm_component parent);
        super.new(name, parent);
    endfunction
    
    // 从文件加载测试向量
    function void load_vectors(string filename);
        int fd;
        bit [31:0] magic, num_vectors;
        
        fd = $fopen(filename, "rb");
        if (fd == 0) begin
            `uvm_fatal("LOADER", $sformatf("Cannot open file %s", filename))
        end
        
        // 读取文件头
        $fread(magic, fd);
        if (magic != 32'h4E505554) begin  // 'NPUT'
            `uvm_fatal("LOADER", "Invalid file format")
        end
        
        $fread(num_vectors, fd);
        `uvm_info("LOADER", $sformatf("Loading %0d test vectors", num_vectors), UVM_LOW)
        
        // 读取每个测试向量
        for (int i = 0; i < num_vectors; i++) begin
            test_vector_t vec;
            int name_len, op_len;
            
            // 读取层名称
            $fread(name_len, fd);
            vec.layer_name = "";
            for (int j = 0; j < name_len; j++) begin
                byte ch;
                $fread(ch, fd);
                vec.layer_name = {vec.layer_name, ch};
            end
            
            // 读取操作类型
            $fread(op_len, fd);
            vec.operation = "";
            for (int j = 0; j < op_len; j++) begin
                byte ch;
                $fread(ch, fd);
                vec.operation = {vec.operation, ch};
            end
            
            // 读取数据
            $fread(vec.input_size, fd);
            vec.input_data = new[vec.input_size];
            for (int j = 0; j < vec.input_size; j++) begin
                $fread(vec.input_data[j], fd);
            end
            
            $fread(vec.weight_size, fd);
            vec.weight_data = new[vec.weight_size];
            for (int j = 0; j < vec.weight_size; j++) begin
                $fread(vec.weight_data[j], fd);
            end
            
            $fread(vec.output_size, fd);
            vec.expected_output = new[vec.output_size];
            for (int j = 0; j < vec.output_size; j++) begin
                $fread(vec.expected_output[j], fd);
            end
            
            test_vectors.push_back(vec);
        end
        
        $fclose(fd);
    endfunction
    
    // 获取下一个测试向量
    function test_vector_t get_next_vector();
        if (test_vectors.size() > 0) begin
            return test_vectors.pop_front();
        end else begin
            `uvm_warning("LOADER", "No more test vectors")
            return null;
        end
    endfunction
    
endclass

// 测试执行序列
class npu_test_vector_sequence extends uvm_sequence;
    `uvm_object_utils(npu_test_vector_sequence)
    
    test_vector_loader loader;
    
    function new(string name = "npu_test_vector_sequence");
        super.new(name);
    endfunction
    
    task body();
        test_vector_loader::test_vector_t vec;
        npu_layer_config_seq config_seq;
        npu_data_load_seq data_seq;
        npu_compute_seq compute_seq;
        npu_result_check_seq check_seq;
        
        // 加载测试向量
        loader = test_vector_loader::type_id::create("loader");
        loader.load_vectors("npu_test_vectors.bin");
        
        // 执行每个测试向量
        while (1) begin
            vec = loader.get_next_vector();
            if (vec == null) break;
            
            `uvm_info("TEST", $sformatf("Testing layer: %s", vec.layer_name), UVM_LOW)
            
            // 配置NPU层参数
            config_seq = npu_layer_config_seq::type_id::create("config_seq");
            config_seq.layer_name = vec.layer_name;
            config_seq.operation = vec.operation;
            config_seq.start(m_sequencer);
            
            // 加载输入数据和权重
            data_seq = npu_data_load_seq::type_id::create("data_seq");
            data_seq.input_data = vec.input_data;
            data_seq.weight_data = vec.weight_data;
            data_seq.start(m_sequencer);
            
            // 执行计算
            compute_seq = npu_compute_seq::type_id::create("compute_seq");
            compute_seq.start(m_sequencer);
            
            // 检查结果
            check_seq = npu_result_check_seq::type_id::create("check_seq");
            check_seq.expected_output = vec.expected_output;
            check_seq.tolerance = 1;  // INT8量化容差
            check_seq.start(m_sequencer);
        end
    endtask
    
endclass
            </div>

            <div class="exercise">
                <h4>练习 7.4-7.6</h4>
                <div class="question">
                    <p><strong>题目：</strong>设计一个完整的MBIST控制器用于测试NPU中的SRAM，要求：
                    1) 支持March C-和Checkerboard算法
                    2) 支持多个SRAM并行测试
                    3) 实现故障诊断和修复
                    4) 提供测试结果统计</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：March算法是顺序访问模式，Checkerboard是棋盘图案。并行测试需要考虑功耗限制。故障诊断需要记录失败地址和数据。修复可以使用冗余行/列替换。状态机设计要清晰。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module npu_mbist_top #(
    parameter NUM_SRAMS = 4,
    parameter ADDR_WIDTH = 10,
    parameter DATA_WIDTH = 32,
    parameter REPAIR_WIDTH = 4  // 修复行数
)(
    input wire clk,
    input wire rst_n,
    
    // MBIST控制
    input wire mbist_en,
    input wire [1:0] mbist_mode,  // 00: March C-, 01: Checkerboard, 10: Walking 1/0
    input wire repair_en,
    
    // SRAM接口（简化）
    output wire [NUM_SRAMS-1:0] sram_en,
    output wire [NUM_SRAMS-1:0] sram_we,
    output wire [ADDR_WIDTH-1:0] sram_addr [NUM_SRAMS-1:0],
    output wire [DATA_WIDTH-1:0] sram_wdata [NUM_SRAMS-1:0],
    input wire [DATA_WIDTH-1:0] sram_rdata [NUM_SRAMS-1:0],
    
    // 测试结果
    output reg mbist_done,
    output reg [NUM_SRAMS-1:0] mbist_fail,
    output reg [31:0] total_faults,
    output reg [31:0] repaired_faults,
    
    // 诊断接口
    output reg diag_valid,
    output reg [7:0] diag_sram_id,
    output reg [ADDR_WIDTH-1:0] diag_addr,
    output reg [DATA_WIDTH-1:0] diag_expected,
    output reg [DATA_WIDTH-1:0] diag_actual
);

    // MBIST FSM状态
    localparam IDLE = 4'h0;
    localparam INIT = 4'h1;
    localparam MARCH_W0 = 4'h2;
    localparam MARCH_R0W1_UP = 4'h3;
    localparam MARCH_R1W0_UP = 4'h4;
    localparam MARCH_R0W1_DN = 4'h5;
    localparam MARCH_R1W0_DN = 4'h6;
    localparam MARCH_R0 = 4'h7;
    localparam CHECKER_W0 = 4'h8;
    localparam CHECKER_W1 = 4'h9;
    localparam CHECKER_R = 4'hA;
    localparam DIAGNOSE = 4'hB;
    localparam REPAIR = 4'hC;
    localparam DONE = 4'hD;
    
    reg [3:0] state, next_state;
    reg [ADDR_WIDTH-1:0] addr_cnt;
    reg addr_dir;  // 0: up, 1: down
    reg [1:0] phase;
    
    // 每个SRAM的独立控制
    reg [NUM_SRAMS-1:0] sram_fail_flag;
    reg [ADDR_WIDTH-1:0] fail_addr [NUM_SRAMS-1:0];
    reg [DATA_WIDTH-1:0] fail_data [NUM_SRAMS-1:0];
    
    // 修复信息
    reg [ADDR_WIDTH-1:0] repair_rows [NUM_SRAMS-1:0][REPAIR_WIDTH-1:0];
    reg [REPAIR_WIDTH-1:0] repair_used [NUM_SRAMS-1:0];
    
    // 生成期望数据
    function [DATA_WIDTH-1:0] generate_pattern;
        input [1:0] mode;
        input [ADDR_WIDTH-1:0] addr;
        input [1:0] phase;
        
        case (mode)
            2'b00: begin  // March C-
                case (phase)
                    2'b00: generate_pattern = {DATA_WIDTH{1'b0}};
                    2'b01: generate_pattern = {DATA_WIDTH{1'b1}};
                    default: generate_pattern = {DATA_WIDTH{1'b0}};
                endcase
            end
            
            2'b01: begin  // Checkerboard
                generate_pattern = {DATA_WIDTH/2{addr[0] ? 2'b10 : 2'b01}};
            end
            
            2'b10: begin  // Walking 1/0
                generate_pattern = phase[0] ? (1 << (addr % DATA_WIDTH)) : 
                                             ~(1 << (addr % DATA_WIDTH));
            end
            
            default: generate_pattern = {DATA_WIDTH{1'b0}};
        endcase
    endfunction
    
    // 主状态机
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            state <= IDLE;
            mbist_done <= 1'b0;
            total_faults <= 0;
        end else begin
            state <= next_state;
        end
    end
    
    // 下一状态逻辑
    always @(*) begin
        next_state = state;
        
        case (state)
            IDLE: begin
                if (mbist_en) begin
                    case (mbist_mode)
                        2'b00: next_state = MARCH_W0;
                        2'b01: next_state = CHECKER_W0;
                        2'b10: next_state = INIT;
                    endcase
                end
            end
            
            MARCH_W0: begin
                if (addr_cnt == {ADDR_WIDTH{1'b1}})
                    next_state = MARCH_R0W1_UP;
            end
            
            MARCH_R0W1_UP: begin
                if (addr_cnt == {ADDR_WIDTH{1'b1}} && phase == 2'b01)
                    next_state = MARCH_R1W0_UP;
            end
            
            MARCH_R1W0_UP: begin
                if (addr_cnt == {ADDR_WIDTH{1'b1}} && phase == 2'b01)
                    next_state = MARCH_R0W1_DN;
            end
            
            MARCH_R0W1_DN: begin
                if (addr_cnt == 0 && phase == 2'b01)
                    next_state = MARCH_R1W0_DN;
            end
            
            MARCH_R1W0_DN: begin
                if (addr_cnt == 0 && phase == 2'b01)
                    next_state = MARCH_R0;
            end
            
            MARCH_R0: begin
                if (addr_cnt == {ADDR_WIDTH{1'b1}})
                    next_state = repair_en ? DIAGNOSE : DONE;
            end
            
            DIAGNOSE: begin
                if (total_faults == 0)
                    next_state = DONE;
                else
                    next_state = REPAIR;
            end
            
            REPAIR: begin
                next_state = DONE;
            end
            
            DONE: begin
                next_state = IDLE;
            end
        endcase
    end
    
    // 地址生成和SRAM控制
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            addr_cnt <= 0;
            phase <= 0;
            for (int i = 0; i < NUM_SRAMS; i++) begin
                sram_fail_flag[i] <= 1'b0;
                repair_used[i] <= 0;
            end
        end else begin
            case (state)
                MARCH_W0: begin
                    // 所有SRAM并行写0
                    for (int i = 0; i < NUM_SRAMS; i++) begin
                        sram_en[i] <= 1'b1;
                        sram_we[i] <= 1'b1;
                        sram_addr[i] <= addr_cnt;
                        sram_wdata[i] <= {DATA_WIDTH{1'b0}};
                    end
                    addr_cnt <= addr_cnt + 1;
                end
                
                MARCH_R0W1_UP: begin
                    for (int i = 0; i < NUM_SRAMS; i++) begin
                        sram_en[i] <= 1'b1;
                        if (phase == 0) begin  // 读阶段
                            sram_we[i] <= 1'b0;
                            // 检查读出数据
                            if (sram_rdata[i] !== {DATA_WIDTH{1'b0}}) begin
                                sram_fail_flag[i] <= 1'b1;
                                fail_addr[i] <= addr_cnt;
                                fail_data[i] <= sram_rdata[i];
                                total_faults <= total_faults + 1;
                            end
                        end else begin  // 写阶段
                            sram_we[i] <= 1'b1;
                            sram_wdata[i] <= {DATA_WIDTH{1'b1}};
                        end
                        sram_addr[i] <= addr_cnt;
                    end
                    
                    if (phase == 1) begin
                        addr_cnt <= addr_cnt + 1;
                        phase <= 0;
                    end else begin
                        phase <= 1;
                    end
                end
                
                // 类似处理其他状态...
                
                DIAGNOSE: begin
                    // 输出诊断信息
                    for (int i = 0; i < NUM_SRAMS; i++) begin
                        if (sram_fail_flag[i]) begin
                            diag_valid <= 1'b1;
                            diag_sram_id <= i;
                            diag_addr <= fail_addr[i];
                            diag_expected <= {DATA_WIDTH{1'b0}};  // 根据状态确定
                            diag_actual <= fail_data[i];
                            break;
                        end
                    end
                end
                
                REPAIR: begin
                    // 简单的行修复策略
                    for (int i = 0; i < NUM_SRAMS; i++) begin
                        if (sram_fail_flag[i] && repair_used[i] < REPAIR_WIDTH) begin
                            repair_rows[i][repair_used[i]] <= fail_addr[i];
                            repair_used[i] <= repair_used[i] + 1;
                            repaired_faults <= repaired_faults + 1;
                            sram_fail_flag[i] <= 1'b0;
                        end
                    end
                end
                
                DONE: begin
                    mbist_done <= 1'b1;
                    mbist_fail <= sram_fail_flag;
                    diag_valid <= 1'b0;
                end
            endcase
        end
    end
    
    // 地址重映射（修复后）
    function [ADDR_WIDTH-1:0] remap_address;
        input [7:0] sram_id;
        input [ADDR_WIDTH-1:0] addr;
        
        remap_address = addr;
        
        // 检查是否需要重映射
        for (int i = 0; i < REPAIR_WIDTH; i++) begin
            if (repair_used[sram_id] > i && 
                repair_rows[sram_id][i] == addr) begin
                // 重映射到备用行
                remap_address = {ADDR_WIDTH{1'b1}} - i;
                break;
            end
        end
    endfunction

endmodule
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <div id="chapter8" class="chapter">
            <h2>第8章：物理设计</h2>
            
            <p>物理设计是将RTL设计转化为可制造芯片版图的关键步骤。对于NPU这样的高性能、高密度芯片，物理设计面临着功耗、性能、面积等多方面的挑战。本章将详细介绍NPU物理设计的完整流程、关键技术和优化方法。</p>

            <h3>8.1 物理设计流程概述</h3>
            
            <p>NPU的物理设计流程涵盖从逻辑综合到版图验证的完整过程。每个阶段都需要在性能、功耗、面积之间进行精细的权衡，以满足设计目标。</p>

            <h4>8.1.1 设计输入与约束</h4>
            <div class="info-box">
                <p><strong>NPU物理设计的输入：</strong></p>
                <ul>
                    <li><strong>RTL代码和网表：</strong>经过综合后的门级网表</li>
                    <li><strong>工艺库文件：</strong>
                        <ul>
                            <li><strong>.lib (Liberty)：</strong>定义单元的时序和功耗特性（逻辑层面）</li>
                            <li><strong>.lef (Library Exchange Format)：</strong>定义单元的物理版图信息，如尺寸、引脚位置（物理层面）</li>
                        </ul>
                    </li>
                    <li><strong>设计约束（SDC）：</strong>时序、功耗、面积约束</li>
                    <li><strong>功耗意图（UPF/CPF）：</strong>定义电源域、电源模式、隔离策略</li>
                    <li><strong>物理约束（DEF）：</strong>芯片布局、宏单元位置等物理信息</li>
                </ul>
            </div>

            <div class="code-block">
# 典型的NPU设计约束示例 (SDC)
# 时钟定义
create_clock -name sys_clk -period 1.0 [get_ports clk]
create_clock -name noc_clk -period 0.8 [get_ports noc_clk]

# 时钟不确定性
set_clock_uncertainty -setup 0.05 [get_clocks sys_clk]
set_clock_uncertainty -hold 0.03 [get_clocks sys_clk]

# 输入/输出延迟
set_input_delay -clock sys_clk -max 0.2 [all_inputs]
set_output_delay -clock sys_clk -max 0.15 [all_outputs]

# 多周期路径（针对MAC阵列）
# 为什么：MAC操作本身需要多个周期完成，强制单周期会导致时序过紧
set_multicycle_path -setup 2 -from [get_pins mac_array/*/mult_reg*] \
                    -to [get_pins mac_array/*/acc_reg*]

# 伪路径（跨时钟域）
set_false_path -from [get_clocks sys_clk] -to [get_clocks noc_clk]

# 最大过渡时间和电容
set_max_transition 0.1 [current_design]
set_max_capacitance 0.05 [all_outputs]
            </div>

            <h4>8.1.2 物理设计主要步骤</h4>
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>设计阶段</th>
                            <th>主要任务</th>
                            <th>关键指标</th>
                            <th>NPU特殊考虑</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Floorplan</td>
                            <td>芯片布局规划</td>
                            <td>利用率、引脚分配</td>
                            <td>MAC阵列规则布局</td>
                        </tr>
                        <tr>
                            <td>Power Planning</td>
                            <td>电源网络设计</td>
                            <td>IR Drop、EM</td>
                            <td>高功耗密度区域</td>
                        </tr>
                        <tr>
                            <td>Placement</td>
                            <td>标准单元布局</td>
                            <td>拥塞度、时序</td>
                            <td>数据通路对齐</td>
                        </tr>
                        <tr>
                            <td>CTS</td>
                            <td>时钟树综合</td>
                            <td>Skew、功耗</td>
                            <td>多时钟域处理</td>
                        </tr>
                        <tr>
                            <td>Routing</td>
                            <td>信号线布线</td>
                            <td>DRC、时序收敛</td>
                            <td>高密度互连</td>
                        </tr>
                        <tr>
                            <td>Sign-off</td>
                            <td>最终验证</td>
                            <td>时序、功耗、DRC</td>
                            <td>全芯片验证</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h3>8.2 布局规划（Floorplan）</h3>
            
            <p>布局规划是物理设计的第一步，决定了芯片的整体架构和性能上限。对于NPU，合理的布局规划对于实现高性能和低功耗至关重要。</p>

            <h4>8.2.1 NPU典型布局架构</h4>
            <div class="code-block">
// NPU芯片典型布局
+----------------------------------------------------------+
|                      IO Ring / Pad                       |
|  +--------------------------------------------------+    |
|  |          Global Control & Configuration          |    |
|  +--------------------------------------------------+    |
|  |                                                  |    |
|  |   +----------+  +----------+  +----------+      |    |
|  |   | MAC      |  | MAC      |  | MAC      | ... |    |
|  |   | Cluster  |  | Cluster  |  | Cluster  |     |    |
|  |   | 0        |  | 1        |  | 2        |     |    |
|  |   +----------+  +----------+  +----------+      |    |
|  |                                                  |    |
|  |   +---------------------------------------+      |    |
|  |   |          Global SRAM Buffer          |      |    |
|  |   +---------------------------------------+      |    |
|  |                                                  |    |
|  |   +----------+  +----------+  +----------+      |    |
|  |   | NoC      |  | DMA      |  | Memory   |     |    |
|  |   | Router   |  | Engine   |  | Control  |     |    |
|  |   +----------+  +----------+  +----------+      |    |
|  |                                                  |    |
|  +--------------------------------------------------+    |
|                      IO Ring / Pad                       |
+----------------------------------------------------------+
            </div>

            <h4>8.2.2 布局优化策略</h4>
            <div class="warning-box">
                <p><strong>NPU布局的关键挑战：</strong></p>
                <ul>
                    <li>MAC阵列的规则性布局要求</li>
                    <li>高带宽数据通路的布线资源</li>
                    <li>功耗密度的均匀分布</li>
                    <li>时钟域的物理隔离</li>
                </ul>
            </div>

            <div class="code-block">
# Floorplan TCL脚本示例
# 设置芯片尺寸和利用率
create_floorplan -die_size {0 0 5000 5000} \
                 -core_offset {100 100 100 100} \
                 -utilization 0.7

# 创建电压域
create_voltage_area -name CORE_PD -coordinate {500 500 4500 4500}
create_voltage_area -name AON_PD -coordinate {100 100 500 4900}

# 放置硬宏（Hard Macro）
# MAC集群规则排列
set mac_width 800
set mac_height 600
set mac_spacing 50

for {set i 0} {$i < 8} {incr i} {
    for {set j 0} {$j < 8} {incr j} {
        set x_loc [expr 600 + $i * ($mac_width + $mac_spacing)]
        set y_loc [expr 600 + $j * ($mac_height + $mac_spacing)]
        create_macro_placement -inst_name mac_cluster_${i}_${j} \
                             -coordinate [list $x_loc $y_loc] \
                             -orientation N
    }
}

# 放置SRAM
create_macro_placement -inst_name global_buffer_sram \
                      -coordinate {1500 3500} \
                      -orientation N

# 创建placement blockage
# 目的：在MAC阵列区域内阻止标准单元的自动布局，
# 为后续手动或半自动的数据通路布线预留空间
create_placement_blockage -name mac_blockage \
                         -type hard \
                         -coordinate {600 600 4400 3400}

# 设置Halo（硬宏周围的禁布区）
# 目的：防止标准单元紧贴硬宏放置
# 1. 避免硬宏引脚附近的布线拥塞
# 2. 为硬宏的电源连接和信号缓冲提供空间
create_keepout_margin -type hard -outer {20 20 20 20} \
                     [get_cells -hier -filter "is_hard_macro==true"]
            </div>

            <h3>8.3 电源规划与实现</h3>
            
            <p>NPU的高功耗密度对电源网络设计提出了严苛要求。良好的电源规划不仅影响芯片的功能正确性，还直接决定了性能和可靠性。</p>

            <h4>8.3.1 电源网格设计</h4>
            <div class="code-block">
# 电源网格规划脚本
# 定义电源网络
create_net -power VDD
create_net -ground VSS

# 创建电源环（Power Ring）
create_power_ring -nets {VDD VSS} \
                  -layers {M9 M10} \
                  -widths {20 20} \
                  -spacings {5 5} \
                  -core_offset 10

# 创建电源条带（Power Stripe）
# 垂直条带 - M9
create_power_stripes -nets {VDD VSS} \
                     -layer M9 \
                     -direction vertical \
                     -width 10 \
                     -spacing 5 \
                     -pitch 100 \
                     -start_x 100 \
                     -stop_x 4900

# 水平条带 - M10  
create_power_stripes -nets {VDD VSS} \
                     -layer M10 \
                     -direction horizontal \
                     -width 10 \
                     -spacing 5 \
                     -pitch 100 \
                     -start_y 100 \
                     -stop_y 4900

# MAC阵列区域加密电源网格
create_power_stripes -nets {VDD VSS} \
                     -layer M9 \
                     -direction vertical \
                     -width 5 \
                     -spacing 2.5 \
                     -pitch 25 \
                     -region {600 600 4400 3400}
            </div>

            <h4>8.3.2 IR Drop分析与优化</h4>
            <div class="info-box">
                <p><strong>IR Drop优化技术及原理：</strong></p>
                <ol>
                    <li><strong>电源网格加密：</strong>在高功耗区域增加电源条带密度
                        <ul>
                            <li>原理：降低电流密度，减少I×R压降</li>
                        </ul>
                    </li>
                    <li><strong>Via阵列优化：</strong>增加层间连接via数量，降低电阻
                        <ul>
                            <li>原理：并联via降低接触电阻，改善垂直方向电流路径</li>
                        </ul>
                    </li>
                    <li><strong>去耦电容插入：</strong>在空白区域填充去耦电容
                        <ul>
                            <li>原理：去耦电容在高频开关时提供瞬时电流，如同微型"蓄水池"，稳定局部电源电压</li>
                        </ul>
                    </li>
                    <li><strong>电源门控优化：</strong>合理规划电源开关位置
                        <ul>
                            <li>原理：减少关断区域的漏电流，降低总体功耗</li>
                        </ul>
                    </li>
                </ol>
            </div>

            <h3>8.4 布局优化（Placement）</h3>
            
            <p>布局阶段将标准单元和宏单元放置在芯片上的合适位置。NPU的布局优化需要特别关注数据通路的规则性和时序关键路径。</p>

            <h4>8.4.1 分层布局策略</h4>
            <div class="code-block">
# 布局优化脚本
# 设置布局选项
set_placement_options -congestion_effort high \
                     -timing_driven true \
                     -global_route_based true

# 数据通路规则化布局
# 创建相对布局约束
create_relative_placement -name mac_datapath \
                         -pattern {
                             {mult_stage_0 mult_stage_1 mult_stage_2}
                             {add_stage_0  add_stage_1  add_stage_2}
                             {acc_stage_0  acc_stage_1  acc_stage_2}
                         } \
                         -x_pitch 50 \
                         -y_pitch 40

# 关键路径优化
set_critical_path_groups -from [get_pins mac_array/*/data_in*] \
                        -to [get_pins mac_array/*/data_out*]

# 执行布局
place_design -concurrent_optimization \
            -incremental \
            -density_gradient

# 布局后优化
optimize_placement -critical_path \
                  -congestion \
                  -setup_target_slack 0.05
            </div>

            <h4>8.4.2 拥塞分析与缓解</h4>
            <div class="warning-box">
                <p><strong>NPU布局常见拥塞问题：</strong></p>
                <ul>
                    <li>MAC阵列间的密集互连</li>
                    <li>控制信号的扇出过大</li>
                    <li>数据总线的布线资源竞争</li>
                    <li>时钟网络与信号线的冲突</li>
                </ul>
            </div>

            <h3>8.5 时钟树综合（CTS）</h3>
            
            <p>时钟树综合是确保时序收敛的关键步骤。NPU通常包含多个时钟域，需要精心设计时钟树结构以最小化时钟偏斜和功耗。</p>

            <h4>8.5.1 时钟树规划</h4>
            <div class="code-block">
# CTS配置脚本
# 定义时钟树约束
create_clock_tree_spec -name clk_spec \
                      -period 1.0 \
                      -root_pin clk \
                      -leaf_pins [get_pins -hier */clk] \
                      -buffers {CKBUF_X16 CKBUF_X32} \
                      -inverters {CKINV_X16 CKINV_X32}

# 设置时钟树目标
set_clock_tree_options -target_skew 0.02 \
                      -target_latency 0.3 \
                      -max_transition 0.08 \
                      -max_capacitance 0.1

# 多时钟域处理
foreach clk [get_clocks] {
    set_clock_tree_options -clock $clk \
                          -routing_rule clk_routing_rule \
                          -use_inverters true \
                          -buffer_sizing true
}

# 时钟门控感知CTS
set_clock_gating_options -max_fanout 32 \
                        -min_bitwidth 8

# 执行CTS
clock_tree_synthesis -propagate_all_clocks \
                    -timing_driven \
                    -balance_groups
            </div>

            <h4>8.5.2 时钟域交叉（CDC）处理</h4>
            <div class="code-block">
// CDC同步器设计
module cdc_sync #(
    parameter WIDTH = 1,
    parameter SYNC_STAGES = 2
)(
    input wire src_clk,
    input wire dst_clk,
    input wire src_rst_n,
    input wire dst_rst_n,
    input wire [WIDTH-1:0] src_data,
    output reg [WIDTH-1:0] dst_data
);
    
    // 多级同步器
    reg [WIDTH-1:0] sync_regs[SYNC_STAGES-1:0];
    
    // 目标时钟域同步
    always @(posedge dst_clk or negedge dst_rst_n) begin
        if (!dst_rst_n) begin
            for (int i = 0; i < SYNC_STAGES; i++) begin
                sync_regs[i] <= '0;
            end
            dst_data <= '0;
        end else begin
            sync_regs[0] <= src_data;
            for (int i = 1; i < SYNC_STAGES; i++) begin
                sync_regs[i] <= sync_regs[i-1];
            end
            dst_data <= sync_regs[SYNC_STAGES-1];
        end
    end
    
    // 时序约束
    // synthesis attribute ASYNC_REG of sync_regs is TRUE
    // 作用：告诉综合工具不要对同步寄存器进行逻辑优化，
    // 以保证亚稳态的有效过滤
    
endmodule

// 注意：对于多位数据总线，简单的多级同步器可能导致数据不一致
// 通常需要使用异步FIFO或握手协议进行更可靠的跨时钟域传输
            </div>

            <h3>8.6 布线与优化（Routing）</h3>
            
            <p>布线阶段完成所有信号的物理连接。NPU的高密度和高性能要求使得布线变得极具挑战性，需要采用先进的布线策略和优化技术。</p>

            <h4>8.6.1 全局布线策略</h4>
            <div class="code-block">
# 布线配置脚本
# 设置布线规则
define_routing_rule high_speed_rule \
                   -widths {M1:0.1 M2:0.1 M3:0.15 M4:0.15 M5:0.2 M6:0.2} \
                   -spacings {M1:0.1 M2:0.1 M3:0.15 M4:0.15 M5:0.2 M6:0.2} \
                   -vias {VIA12_FAT VIA23_FAT VIA34_FAT}

# 关键信号布线约束
set_net_routing_rule [get_nets -of [get_pins mac_array/*/clk]] \
                     high_speed_rule

# 设置布线选项
set_route_options -groute_timing_driven true \
                  -groute_incremental true \
                  -track_assign_timing_driven true \
                  -droute_ECO_mode true

# 屏蔽层设置（针对噪声敏感信号）
create_shield -nets {clk rst_n} \
              -with_net VSS \
              -side_spacing 0.2

# 执行全局布线
route_global -congestion_map_only false \
            -timing_driven true \
            -effort_level high

# 详细布线
route_detail -incremental true \
            -timing_driven true \
            -si_driven true
            </div>

            <h4>8.6.2 信号完整性优化</h4>
            <div class="info-box">
                <p><strong>SI优化技术：</strong></p>
                <ol>
                    <li><strong>串扰避免：</strong>增加关键信号间距</li>
                    <li><strong>屏蔽插入：</strong>在敏感信号两侧添加地线屏蔽</li>
                    <li><strong>驱动优化：</strong>调整驱动强度减少噪声</li>
                    <li><strong>时序修复：</strong>考虑SI影响的时序优化</li>
                </ol>
            </div>

            <h3>8.7 物理验证与签收</h3>
            
            <p>物理验证确保设计满足所有制造规则和性能要求。这是流片前的最后关卡，必须严格把关。</p>

            <h4>8.7.1 DRC/LVS检查</h4>
            <div class="code-block">
# DRC检查脚本
# 加载规则文件
load_tech_file ./tech/drc_rules.tf

# 运行DRC
run_drc -cell TOP \
        -report drc_report.txt \
        -error_view drc_errors

# 常见DRC违例类型
# 1. 最小宽度违例 (Min Width)
# 2. 最小间距违例 (Min Spacing)  
# 3. 最小面积违例 (Min Area)
# 4. Via覆盖违例 (Via Enclosure)
# 5. 密度违例 (Density)
# 6. 天线效应违例 (Antenna Rule)

# LVS检查
run_lvs -schematic ../netlist/npu_top.v \
        -layout ./npu_top.gds \
        -report lvs_report.txt \
        -extract_rc true

# 天线效应检查与修复
check_antenna -report antenna_report.txt
# 修复方法：插入antenna diode或jumper

# 电迁移与IR Drop签收
# 使用专用工具（如Voltus/RedHawk）进行全芯片分析
run_em_ir_analysis -tool voltus \
                   -mode {normal turbo sleep} \
                   -report em_ir_signoff.rpt
            </div>

            <h4>8.7.2 时序签收</h4>
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>检查项目</th>
                            <th>目标值</th>
                            <th>检查方法</th>
                            <th>修复策略</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Setup时序</td>
                            <td>slack > 0</td>
                            <td>STA分析</td>
                            <td>插入buffer、调整尺寸</td>
                        </tr>
                        <tr>
                            <td>Hold时序</td>
                            <td>slack > 0</td>
                            <td>STA分析</td>
                            <td>插入delay buffer</td>
                        </tr>
                        <tr>
                            <td>转换时间</td>
                            <td>< 100ps</td>
                            <td>Transition检查</td>
                            <td>调整驱动强度</td>
                        </tr>
                        <tr>
                            <td>时钟偏斜</td>
                            <td>< 20ps</td>
                            <td>时钟报告</td>
                            <td>CTS重新平衡</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h3>8.8 低功耗物理设计</h3>
            
            <p>NPU的功耗优化贯穿整个物理设计流程。从架构级到晶体管级，每个层次都有相应的优化技术。</p>

            <h4>8.8.1 多阈值电压优化</h4>
            <div class="code-block">
# 多Vt优化脚本
# 定义Vt类型
set_attribute [get_libs */LVT] default_threshold_voltage_group LVT
set_attribute [get_libs */RVT] default_threshold_voltage_group RVT  
set_attribute [get_libs */HVT] default_threshold_voltage_group HVT

# 设置优化策略
set_power_optimization_options -leakage_power true \
                              -dynamic_power true \
                              -total_power true

# Vt分配策略
# 关键路径使用LVT
set_threshold_voltage_group [get_cells -of [all_critical_paths]] LVT

# 非关键路径使用HVT
set_threshold_voltage_group [get_cells -of [all_non_critical_paths]] HVT

# 执行功耗优化
optimize_power -multi_vt \
               -size_only false \
               -preserve_paths [all_critical_paths]
            </div>

            <h4>8.8.2 电源门控实现</h4>
            
            <p>电源门控通过切断空闲模块的电源来降低漏电功耗。关键组件包括：</p>
            <ul>
                <li><strong>隔离单元（Isolation Cell）：</strong>当模块断电时，将其输出钳位到确定状态，防止不确定信号传播</li>
                <li><strong>电源开关（Power Switch）：</strong>由特殊大尺寸MOS管组成，用于切断/接通电源</li>
                <li><strong>状态保持寄存器（Retention Register）：</strong>保存关键状态，支持快速唤醒</li>
            </ul>
            
            <div class="code-block">
// 电源门控控制器
// 状态转换顺序：ACTIVE -> ISOLATE -> POWER_DOWN（先隔离再断电）
// 唤醒顺序：POWER_UP -> RESET -> WAKE_UP（先上电再撤销隔离）
module power_gating_controller (
    input wire clk,
    input wire rst_n,
    input wire sleep_req,
    output reg sleep_ack,
    output reg isolate_n,
    output reg pwr_switch_n,
    output reg reset_n
);

    // 状态机定义
    typedef enum logic [2:0] {
        ACTIVE,
        ISOLATE,
        POWER_DOWN,
        SLEEP,
        POWER_UP,
        RESET,
        WAKE_UP
    } state_t;
    
    state_t current_state, next_state;
    
    // 状态转换
    always_ff @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            current_state <= ACTIVE;
        end else begin
            current_state <= next_state;
        end
    end
    
    // 状态机逻辑
    always_comb begin
        next_state = current_state;
        
        case (current_state)
            ACTIVE: begin
                if (sleep_req) next_state = ISOLATE;
            end
            
            ISOLATE: begin
                next_state = POWER_DOWN;
            end
            
            POWER_DOWN: begin
                next_state = SLEEP;
            end
            
            SLEEP: begin
                if (!sleep_req) next_state = POWER_UP;
            end
            
            POWER_UP: begin
                next_state = RESET;
            end
            
            RESET: begin
                next_state = WAKE_UP;
            end
            
            WAKE_UP: begin
                next_state = ACTIVE;
            end
        endcase
    end
    
    // 输出控制
    always_comb begin
        isolate_n = 1'b1;
        pwr_switch_n = 1'b0;
        reset_n = 1'b1;
        sleep_ack = 1'b0;
        
        case (current_state)
            ISOLATE: begin
                isolate_n = 1'b0;  // 激活隔离
            end
            
            POWER_DOWN, SLEEP: begin
                isolate_n = 1'b0;
                pwr_switch_n = 1'b1;  // 关闭电源
                sleep_ack = 1'b1;
            end
            
            POWER_UP: begin
                isolate_n = 1'b0;
                pwr_switch_n = 1'b0;  // 打开电源
            end
            
            RESET: begin
                isolate_n = 1'b0;
                reset_n = 1'b0;  // 复位
            end
        endcase
    end

endmodule
            </div>

            <h3>8.9 设计可测试性（DFT）</h3>
            
            <p>DFT是物理设计中至关重要的一环。没有良好的DFT设计，芯片即使制造出来也无法有效测试，无法实现量产。</p>

            <h4>8.9.1 扫描链设计</h4>
            <div class="code-block">
# 扫描链插入脚本
# 设置扫描链配置
set_scan_configuration -chain_count 32 \
                      -clock_mixing mix_clocks \
                      -add_lockup true \
                      -reorder true

# 插入扫描链
# 原理：将所有触发器串联成移位寄存器链
compile_scan

# 扫描链重排序（减少布线长度）
# 根据物理位置优化扫描链顺序
place_scan_chains -reorder \
                  -optimize_routing_length

# 扫描链平衡
balance_scan_chains -max_length 500
            </div>

            <h4>8.9.2 内建自测试（BIST）</h4>
            <div class="info-box">
                <p><strong>NPU中的BIST应用：</strong></p>
                <ul>
                    <li><strong>Memory BIST：</strong>针对大量片上SRAM的测试</li>
                    <li><strong>Logic BIST：</strong>针对MAC阵列等规则逻辑的测试</li>
                    <li><strong>IO BIST：</strong>高速接口的自测试</li>
                </ul>
            </div>

            <div class="code-block">
// Memory BIST控制器示例
module mbist_controller (
    input wire clk,
    input wire rst_n,
    input wire bist_en,
    output reg bist_done,
    output reg bist_fail,
    // 存储器接口
    output reg [ADDR_WIDTH-1:0] mem_addr,
    output reg [DATA_WIDTH-1:0] mem_wdata,
    output reg mem_we,
    output reg mem_ce,
    input wire [DATA_WIDTH-1:0] mem_rdata
);
    
    // BIST算法：March C-
    // { ⇑(w0); ⇑(r0,w1); ⇑(r1,w0); 
    //   ⇓(r0,w1); ⇓(r1,w0); ⇑(r0) }
    
    reg [2:0] phase;
    reg [ADDR_WIDTH-1:0] addr_cnt;
    reg up_direction;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            phase <= 0;
            addr_cnt <= 0;
            bist_done <= 0;
            bist_fail <= 0;
        end else if (bist_en) begin
            // March C- 算法实现
            case (phase)
                0: begin // ⇑(w0)
                    mem_we <= 1;
                    mem_wdata <= 0;
                    if (addr_cnt == MAX_ADDR) begin
                        phase <= 1;
                        addr_cnt <= 0;
                    end else begin
                        addr_cnt <= addr_cnt + 1;
                    end
                end
                // ... 其他phases
            endcase
        end
    end
endmodule
            </div>

            <h4>8.9.3 先进工艺节点的挑战</h4>
            
            <p>7nm及以下工艺给物理设计带来了新的挑战：</p>
            
            <div class="info-box">
                <p><strong>FinFET/GAA工艺影响：</strong></p>
                <ul>
                    <li><strong>离散单元高度：</strong>标准单元高度必须是鳍片间距的整数倍</li>
                    <li><strong>引脚位置受限：</strong>引脚只能放在特定轨道上</li>
                    <li><strong>多重曝光（Multi-Patterning）：</strong>需要颜色感知的布局布线</li>
                    <li><strong>复杂DRC规则：</strong>规则数量从28nm的数千条增加到7nm的数万条</li>
                </ul>
            </div>
            
            <h4>8.9.4 封装协同设计</h4>
            
            <p>对于高性能NPU，芯片设计必须与封装设计紧密配合：</p>
            
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>设计阶段</th>
                            <th>封装考虑</th>
                            <th>影响</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>IO规划</td>
                            <td>凸点（Bump）分布</td>
                            <td>信号完整性、电源分配</td>
                        </tr>
                        <tr>
                            <td>电源规划</td>
                            <td>封装基板PDN</td>
                            <td>IR Drop、去耦策略</td>
                        </tr>
                        <tr>
                            <td>热设计</td>
                            <td>热界面材料（TIM）</td>
                            <td>结温、可靠性</td>
                        </tr>
                        <tr>
                            <td>顶层金属</td>
                            <td>RDL层设计</td>
                            <td>凸点重分布</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <div class="exercise">
                <h4>练习题集 8</h4>
                
                <div class="question">
                    <p><strong>题目8.1：</strong>某NPU芯片采用7nm工艺，芯片面积100mm²，功耗50W。计算功耗密度，并分析可能的散热挑战。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：功耗密度=总功耗/芯片面积。参考其他处理器的功耗密度（通常<0.3W/mm²）。考虑热点、封装、散热方案、可靠性影响等因素。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p>功耗密度计算：</p>
                        <ul>
                            <li>功耗密度 = 50W / 100mm² = 0.5 W/mm²</li>
                            <li>这是非常高的功耗密度，接近现代处理器的极限</li>
                        </ul>
                        <p>散热挑战：</p>
                        <ol>
                            <li><strong>热点问题：</strong>MAC阵列区域可能出现局部热点，温度可能超过100°C</li>
                            <li><strong>封装要求：</strong>需要高性能封装，如flip-chip + 热界面材料</li>
                            <li><strong>散热方案：</strong>可能需要主动散热（风扇）或液冷</li>
                            <li><strong>可靠性影响：</strong>高温会加速电迁移，影响芯片寿命</li>
                        </ol>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目8.2：</strong>设计一个简单的电源网格，为16×16的MAC阵列供电。每个MAC单元功耗100mW，电源电压0.8V。假设使用M9和M10层构建电源网格，金属层的最大电流密度为1mA/μm。请估算在MAC阵列区域，M9层垂直电源条带的总截面宽度需要达到多少，才能满足总电流需求？并讨论为什么实际设计中需要远大于这个估算值。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：先计算总电流(I=P/V)。电流密度限制决定了最小金属宽度。实际设计需要考虑电流分布不均、峰值电流、IR压降限制、可靠性裕量等因素。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p><strong>基本计算：</strong></p>
                        <ol>
                            <li>总功耗：16 × 16 × 100mW = 25.6W</li>
                            <li>总电流：I = P/V = 25.6W / 0.8V = 32A</li>
                            <li>电流密度限制：1mA/μm</li>
                            <li>理论最小宽度：32A / 1mA/μm = 32,000μm = 32mm</li>
                        </ol>
                        
                        <p><strong>为什么实际设计需要更大宽度：</strong></p>
                        <ol>
                            <li><strong>电流分布不均：</strong>
                                <ul>
                                    <li>MAC阵列中心区域电流密度更高</li>
                                    <li>需要2-3倍裕量处理局部热点</li>
                                </ul>
                            </li>
                            <li><strong>峰值电流考虑：</strong>
                                <ul>
                                    <li>开关瞬态电流可能是平均值的2-5倍</li>
                                    <li>同时切换噪声（SSN）影响</li>
                                </ul>
                            </li>
                            <li><strong>IR压降限制：</strong>
                                <ul>
                                    <li>允许压降通常<5% VDD = 40mV</li>
                                    <li>需要更低的电阻，意味着更宽的金属</li>
                                </ul>
                            </li>
                            <li><strong>可靠性要求：</strong>
                                <ul>
                                    <li>电迁移寿命要求（>10年）</li>
                                    <li>温度降额（derating）</li>
                                </ul>
                            </li>
                        </ol>
                        
                        <p><strong>实际设计：</strong>总宽度可能需要80-100mm，分布在多层金属和网格结构中。</p>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目8.3：</strong>某NPU设计中，关键路径延迟为900ps，其中逻辑延迟400ps，互连延迟500ps。如何优化以达到1GHz的目标频率？</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：1GHz需要路径延迟<1000ps。互连延迟占比过高。可以从<strong>物理实现</strong>（插入buffer/repeater、优化布局减少线长、使用更优的布线层）和<strong>逻辑设计</strong>（在长路径中插入流水线寄存器）两个层面进行优化。请分别讨论两种方法的优缺点。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p>当前时序裕量：1000ps - 900ps = 100ps（已满足1GHz）</p>
                        <p>但裕量太小，建议优化：</p>
                        <ol>
                            <li><strong>逻辑优化（减少100ps）：</strong>
                                <ul>
                                    <li>使用低Vt单元替换关键路径</li>
                                    <li>逻辑重构，减少级数</li>
                                    <li>使用复合门减少延迟</li>
                                </ul>
                            </li>
                            <li><strong>互连优化（减少150ps）：</strong>
                                <ul>
                                    <li>增加驱动buffer尺寸</li>
                                    <li>使用更高金属层（低电阻）</li>
                                    <li>插入中继器（repeater）</li>
                                    <li>减少线长（布局优化）</li>
                                </ul>
                            </li>
                            <li><strong>目标：</strong>总延迟650ps，时序裕量350ps（35%）</li>
                        </ol>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目8.4：</strong>编写一个简单的时钟门控单元（Clock Gating Cell），并说明其在NPU中的应用。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：时钟门控需要避免glitch。使用latch来保持enable信号在时钟低电平期间稳定。NPU中可以对空闲的MAC单元、未使用的内存bank等进行门控。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module clock_gating_cell (
    input wire clk,
    input wire enable,
    input wire test_enable,  // DFT信号
    output wire gclk
);
    
    reg enable_latch;
    
    // Latch防止毛刺
    always @(clk or enable or test_enable) begin
        if (!clk) begin
            enable_latch <= enable | test_enable;
        end
    end
    
    // AND门输出门控时钟
    assign gclk = clk & enable_latch;
    
    // 综合指令
    // synthesis attribute clock_gating_cell of clock_gating_cell is true
    
endmodule

// NPU中的应用示例
module mac_unit_with_cg (
    input wire clk,
    input wire rst_n,
    input wire enable,      // 计算使能
    input wire [7:0] a,
    input wire [7:0] b,
    output reg [15:0] result
);
    
    wire gclk;
    
    // 实例化时钟门控
    clock_gating_cell cg_inst (
        .clk(clk),
        .enable(enable),
        .test_enable(1'b0),
        .gclk(gclk)
    );
    
    // 使用门控时钟
    always @(posedge gclk or negedge rst_n) begin
        if (!rst_n) begin
            result <= 16'd0;
        end else begin
            result <= a * b;
        end
    end
    
endmodule
                        </div>
                        <p><strong>NPU应用场景：</strong></p>
                        <ul>
                            <li>MAC阵列的动态关断：当某些MAC单元空闲时关闭时钟</li>
                            <li>层级时钟门控：整个计算簇的时钟控制</li>
                            <li>功耗节省：可节省20-40%的动态功耗</li>
                        </ul>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目8.5：</strong>分析并设计一个NPU芯片的IO规划，需要支持：DDR4接口（128位）、PCIe Gen4 x16、千兆以太网、JTAG调试。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：高速IO（DDR4、PCIe）需要放在芯片边缘并考虑信号完整性。不同类型的IO需要不同的电源域。考虑封装类型和引脚数量。高速IO需要差分对布线。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p><strong>IO需求分析：</strong></p>
                        <table>
                            <tr>
                                <th>接口</th>
                                <th>信号数量</th>
                                <th>IO类型</th>
                                <th>位置建议</th>
                            </tr>
                            <tr>
                                <td>DDR4-3200</td>
                                <td>~280 pins</td>
                                <td>SSTL</td>
                                <td>芯片一侧（最短走线）</td>
                            </tr>
                            <tr>
                                <td>PCIe Gen4 x16</td>
                                <td>~164 pins</td>
                                <td>差分对</td>
                                <td>靠近边缘（易于走线）</td>
                            </tr>
                            <tr>
                                <td>千兆以太网</td>
                                <td>~16 pins</td>
                                <td>LVDS</td>
                                <td>任意角落</td>
                            </tr>
                            <tr>
                                <td>JTAG</td>
                                <td>5 pins</td>
                                <td>LVCMOS</td>
                                <td>便于访问的位置</td>
                            </tr>
                            <tr>
                                <td>电源/地</td>
                                <td>~200 pins</td>
                                <td>Power</td>
                                <td>均匀分布</td>
                            </tr>
                        </table>
                        
                        <p><strong>IO规划方案：</strong></p>
                        <div class="code-block">
芯片IO布局（俯视图）：
        North (DDR4接口)
     +-------------------+
     |  D D D ... D D D  |
     |D                 P|  East
West |D    NPU Core     C| (PCIe)
     |R                 I|
     |4                 e|
     |  G G J J J E E E  |
     +-------------------+
        South (GPIO/JTAG/Ethernet)

布局原则：
1. DDR4放北侧：最短距离到内存控制器
2. PCIe放东侧：便于板级走线到插槽
3. 低速IO放南侧：JTAG方便调试访问
4. 电源均匀分布四周：降低IR drop
                        </div>
                    </div>
                </div>
                
                <div class="question">
                    <p><strong>题目8.6：</strong>在DRC报告中，你发现了一个最小间距违例（Min Spacing Violation）和一个天线效应违例（Antenna Violation）。请分别描述这两种违例的物理原因，并提出至少一种可能的修复方法。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：最小间距违例与制造工艺限制有关。天线效应是制造过程中的电荷积累问题。修复方法要考虑对设计的影响最小化。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        
                        <p><strong>1. 最小间距违例（Min Spacing Violation）：</strong></p>
                        <ul>
                            <li><strong>物理原因：</strong>
                                <ul>
                                    <li>光刻分辨率限制：两条线太近会导致短路</li>
                                    <li>刻蚀工艺限制：间距太小无法完全刻蚀</li>
                                    <li>寄生电容考虑：间距影响信号串扰</li>
                                </ul>
                            </li>
                            <li><strong>修复方法：</strong>
                                <ul>
                                    <li>移动违例的金属线，增加间距</li>
                                    <li>改变布线层，使用间距规则更宽松的层</li>
                                    <li>减小线宽（如果不违反最小宽度规则）</li>
                                    <li>ECO（Engineering Change Order）重新布线</li>
                                </ul>
                            </li>
                        </ul>
                        
                        <p><strong>2. 天线效应违例（Antenna Violation）：</strong></p>
                        <ul>
                            <li><strong>物理原因：</strong>
                                <ul>
                                    <li>等离子刻蚀时，长金属线收集电荷</li>
                                    <li>电荷通过栅极放电，可能击穿氧化层</li>
                                    <li>天线比（金属面积/栅极面积）超过限制</li>
                                </ul>
                            </li>
                            <li><strong>修复方法：</strong>
                                <ul>
                                    <li><strong>插入跳线（Jumper）：</strong>将长线分段，通过上层金属连接</li>
                                    <li><strong>添加天线二极管：</strong>提供电荷泄放路径</li>
                                    <li><strong>增加栅极面积：</strong>降低天线比（较少使用）</li>
                                    <li><strong>改变布线路径：</strong>减少连接到栅极的金属面积</li>
                                </ul>
                            </li>
                        </ul>
                        
                        <div class="code-block">
// 天线二极管插入示例
// 原始连接：长金属线直接连到栅极
wire long_metal_wire;
assign gate_signal = long_metal_wire;

// 修复后：添加反偏二极管
wire long_metal_wire;
assign gate_signal = long_metal_wire;

// 天线二极管（在布局中自动插入）
// antenna_diode ant_diode(.anode(gate_signal), .cathode(VSS));
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <div id="chapter9" class="chapter">
            <h2>第9章：先进工艺与封装技术</h2>
            
            <p>随着NPU算力需求的不断增长，先进工艺和封装技术成为突破性能瓶颈的关键。本章深入探讨最新的半导体工艺技术、先进封装方案，以及它们如何推动NPU性能的跨越式发展。</p>

            <h3>9.1 先进工艺技术</h3>
            
            <h4>9.1.1 FinFET到GAA的演进</h4>
            
            <p>晶体管结构的演进是推动NPU性能提升的基础。从平面晶体管到FinFET，再到即将量产的GAA（Gate-All-Around），每一代技术都带来了显著的性能和功耗改善。</p>
            
            <div class="code-block">
// 不同工艺节点的关键参数对比
工艺节点    晶体管结构    晶体管密度      性能提升    功耗降低    设计成本
28nm       Planar       ~50M/mm²        基准        基准        ~$30M
16nm       FinFET       ~100M/mm²       +40%        -50%        ~$80M
7nm        FinFET       ~250M/mm²       +30%        -40%        ~$300M
5nm        FinFET       ~300M/mm²       +15%        -30%        ~$540M
3nm        GAA          ~400M/mm²       +18%        -25%        ~$1B+
2nm        GAA          ~500M/mm²       +15%        -20%        ~$1.5B+

// 注：设计成本包括EDA工具、IP授权、验证、光罩制作等
// 7nm及以下节点采用EUV（极紫外光刻）技术，避免了多重曝光的复杂性

// NPU在不同工艺下的性能表现
// 以256x256 MAC阵列为例
28nm: 面积~100mm², 功耗~50W, 频率~500MHz
7nm:  面积~25mm²,  功耗~15W, 频率~1.5GHz
3nm:  面积~12mm²,  功耗~8W,  频率~2.0GHz
            </div>
            
            <p><strong>FinFET技术特点：</strong></p>
            <ul>
                <li><strong>三维栅极结构：</strong>栅极包围鳍片三个面，增强栅控能力</li>
                <li><strong>短沟道效应抑制：</strong>有效控制漏电流，降低静态功耗</li>
                <li><strong>驱动能力增强：</strong>相同面积下提供更大的驱动电流</li>
                <li><strong>工艺复杂度：</strong>需要精确控制鳍片高度和间距</li>
            </ul>
            
            <p><strong>GAA技术优势：</strong></p>
            <ul>
                <li><strong>全包围栅极：</strong>栅极完全包围沟道，最大化栅控能力</li>
                <li><strong>纳米片堆叠：</strong>垂直堆叠多个纳米片，增加有效宽度</li>
                <li><strong>灵活性提升：</strong>可独立调节纳米片宽度和间距</li>
                <li><strong>性能功耗比：</strong>相比FinFET进一步提升20-30%</li>
            </ul>
            
            <div class="info-box">
                <p><strong>EUV光刻技术的关键作用：</strong></p>
                <ul>
                    <li><strong>波长优势：</strong>13.5nm极紫外光，远小于193nm深紫外光</li>
                    <li><strong>简化工艺：</strong>单次曝光替代多重曝光，降低工艺复杂度</li>
                    <li><strong>成本效益：</strong>虽然设备昂贵（>1.5亿美元），但减少了光罩层数</li>
                    <li><strong>良率提升：</strong>减少对准误差，提高关键尺寸的一致性</li>
                </ul>
            </div>

            <h4>9.1.2 先进工艺对NPU设计的影响</h4>
            
            <p>先进工艺不仅仅是简单的尺寸缩放，它对NPU的架构设计产生深远影响：</p>
            
            <div class="code-block">
// 工艺特性对NPU设计的影响
module ProcessImpactAnalysis;
    
    // 1. 互连延迟主导
    // 7nm以下，互连延迟 > 逻辑延迟
    parameter LOGIC_DELAY_7NM = 10;  // ps
    parameter WIRE_DELAY_7NM = 15;   // ps per mm
    
    // 2. 功耗密度挑战
    // 功耗密度随工艺缩放快速增加
    parameter POWER_DENSITY_7NM = 1.0;   // W/mm²
    parameter POWER_DENSITY_5NM = 1.3;   // W/mm²
    parameter POWER_DENSITY_3NM = 1.6;   // W/mm²
    
    // 3. SRAM缩放放缓
    // SRAM单元面积缩放率 < 逻辑缩放率
    parameter SRAM_SCALING_7TO5 = 0.7;   // 70%缩放
    parameter LOGIC_SCALING_7TO5 = 0.5;  // 50%缩放
    
    // 设计策略调整
    // - 增加流水线级数应对互连延迟
    // - 采用分布式架构减少长距离互连
    // - 使用先进冷却技术应对功耗密度
    // - 探索新型存储器（如MRAM）替代SRAM
    
endmodule
            </div>
            
            <p><strong>设计挑战与应对策略：</strong></p>
            <ol>
                <li><strong>互连优化：</strong>
                    <ul>
                        <li>采用分层互连架构，短距离用低层金属，长距离用厚层金属</li>
                        <li>使用中继器（Repeater）优化长距离信号传输</li>
                        <li>局部化设计，减少跨模块通信</li>
                    </ul>
                </li>
                <li><strong>功耗管理：</strong>
                    <ul>
                        <li>细粒度电源门控，空闲单元及时关断</li>
                        <li>动态电压频率调节（DVFS）</li>
                        <li>近阈值电压（NTV）设计探索</li>
                    </ul>
                </li>
                <li><strong>良率优化：</strong>
                    <ul>
                        <li>冗余设计，MAC阵列包含备用单元</li>
                        <li>自适应电路，补偿工艺偏差</li>
                        <li>统计时序分析（SSTA）</li>
                    </ul>
                </li>
            </ol>
            
            <div class="warning-box">
                <p><strong>设计-技术协同优化（DTCO）的重要性：</strong></p>
                <p>先进工艺节点的开发不再是单纯的器件物理问题，而需要设计与工艺的深度融合：</p>
                <ul>
                    <li><strong>SRAM缩放困境：</strong>SRAM单元面积缩放速度远慢于逻辑单元，这反过来影响NPU的缓存层次设计，需要更多依赖片外存储或探索新型存储器</li>
                    <li><strong>标准单元库优化：</strong>与代工厂合作开发NPU专用的高密度MAC单元库</li>
                    <li><strong>互连层定制：</strong>为NPU的规则数据流定制金属层分配策略</li>
                    <li><strong>早期pathfinding：</strong>在工艺开发阶段就考虑NPU的特殊需求</li>
                </ul>
            </div>

            <h3>9.2 先进封装技术</h3>
            
            <h4>9.2.1 2.5D/3D封装架构</h4>
            
            <p>先进封装技术通过缩短芯片间互连距离、增加互连带宽，为NPU系统集成提供了新的可能性。</p>
            
            <div class="code-block">
// 2.5D封装：硅中介层（Interposer）方案
class Silicon_Interposer_2_5D {
    // 关键参数
    const int MICROBUMP_PITCH = 40;      // μm
    const int TSV_PITCH = 100;           // μm
    const int INTERPOSER_THICKNESS = 100; // μm
    const int HBM_BANDWIDTH = 1024;      // GB/s per stack
    
    // 典型配置：NPU + 4 HBM
    struct ChipletConfig {
        int npu_die_size = 400;          // mm²
        int hbm_stacks = 4;
        int total_bandwidth = 4096;      // GB/s
        int interposer_size = 1200;      // mm²
    };
    
    // 优势
    // 1. 超高内存带宽：4TB/s+
    // 2. 低延迟：<5ns chip-to-chip
    // 3. 低功耗：pJ/bit级别传输能耗
    
    // 挑战
    // 1. 制造成本高：硅中介层+TSV工艺
    // 2. 热管理复杂：多芯片热耦合
    // 3. 供应链：需要OSAT厂商配合
};

// 3D封装：芯片堆叠方案
class Chip_Stacking_3D {
    // Hybrid Bonding技术参数
    const float BOND_PITCH = 1.0;        // μm (最先进)
    const int CONNECTIONS_PER_MM2 = 1e6; // 每mm²百万连接
    
    // 典型架构：Logic + SRAM堆叠
    struct StackConfig {
        int logic_die_thickness = 10;     // μm (减薄后)
        int sram_die_thickness = 20;      // μm
        int total_layers = 4;
        int vertical_bandwidth = 10000;   // GB/s
    };
    
    // 热仿真模型
    float thermal_resistance(int layers) {
        // 每增加一层，热阻增加
        return 0.5 * layers + 0.2 * (layers * layers);
    }
};
            </div>
            
            <p><strong>2.5D封装的NPU应用：</strong></p>
            <ul>
                <li><strong>计算与存储分离：</strong>NPU计算die + HBM存储die</li>
                <li><strong>多芯片扩展：</strong>多个NPU die通过硅中介层互连</li>
                <li><strong>异构集成：</strong>NPU + CPU + 专用加速器集成</li>
            </ul>
            
            <div class="info-box">
                <p><strong>其他2.5D封装方案对比：</strong></p>
                <table>
                    <tr>
                        <th>技术方案</th>
                        <th>成本</th>
                        <th>互连密度</th>
                        <th>应用场景</th>
                    </tr>
                    <tr>
                        <td>Silicon Interposer</td>
                        <td>高（需要完整硅片）</td>
                        <td>最高（40μm pitch）</td>
                        <td>HBM集成、超高带宽需求</td>
                    </tr>
                    <tr>
                        <td>EMIB（Intel）</td>
                        <td>中（局部硅桥）</td>
                        <td>高（55μm pitch）</td>
                        <td>选择性高速互连</td>
                    </tr>
                    <tr>
                        <td>RDL Fan-out</td>
                        <td>低（有机基板）</td>
                        <td>中（2μm线宽）</td>
                        <td>成本敏感的芯片集成</td>
                    </tr>
                </table>
            </div>
            
            <p><strong>3D封装的创新应用：</strong></p>
            <ul>
                <li><strong>存算一体：</strong>SRAM直接堆叠在计算单元上方</li>
                <li><strong>冷却集成：</strong>微流道散热器集成在封装内</li>
                <li><strong>光电集成：</strong>硅光子层用于芯片间高速通信</li>
            </ul>
            
            <div class="warning-box">
                <p><strong>3D封装的关键挑战：</strong></p>
                <ul>
                    <li><strong>埋层散热困境：</strong>被夹在中间层的芯片热量极难导出，限制了功耗密度</li>
                    <li><strong>供电挑战：</strong>
                        <ul>
                            <li>TSV占用面积影响信号布线</li>
                            <li>中间层供电路径长，IR drop严重</li>
                            <li>需要专门的供电TSV和PDN设计</li>
                        </ul>
                    </li>
                    <li><strong>良率影响：</strong>堆叠良率 = 各层良率的乘积，成本急剧上升</li>
                    <li><strong>测试复杂性：</strong>堆叠前后都需要完整测试</li>
                </ul>
            </div>

            <h4>9.2.2 Chiplet技术与异构集成</h4>
            
            <p>Chiplet（小芯片）技术将大型SoC分解为多个功能模块，通过先进封装技术集成，提供了更灵活的设计和制造方案。</p>
            
            <div class="code-block">
// Chiplet架构设计示例
module ChipletBasedNPU;
    
    // Chiplet类型定义
    typedef enum {
        COMPUTE_CHIPLET,    // 计算核心：MAC阵列
        MEMORY_CHIPLET,     // 存储：HBM/SRAM
        IO_CHIPLET,         // 接口：PCIe/Ethernet
        CONTROL_CHIPLET     // 控制：调度器/DMA
    } chiplet_type_t;
    
    // Die-to-Die接口标准
    interface D2D_Interface;
        parameter LANES = 16;
        parameter RATE = 32;  // Gbps per lane
        parameter PROTOCOL = "UCIe";  // Universal Chiplet Interconnect
        
        // 物理层
        logic [LANES-1:0] tx_data;
        logic [LANES-1:0] rx_data;
        logic tx_clock, rx_clock;
        
        // 协议层
        modport transmitter (output tx_data, tx_clock);
        modport receiver (input rx_data, rx_clock);
    endinterface
    
    // Chiplet间通信架构
    class ChipletMesh {
        // 2x2 Chiplet网格
        Chiplet compute[2][2];
        Chiplet memory[4];
        
        // 互连拓扑
        void build_topology() {
            // Mesh网络：每个计算Chiplet连接相邻节点
            // 环形总线：内存Chiplet共享高速环
            // 星型连接：所有Chiplet连接到中央NoC
        }
        
        // 带宽分配
        int allocate_bandwidth(int src, int dst) {
            if (is_neighbor(src, dst)) {
                return 512;  // GB/s for adjacent
            } else {
                return 256;  // GB/s for remote
            }
        }
    };
    
endmodule
            </div>
            
            <p><strong>Chiplet的优势：</strong></p>
            <ol>
                <li><strong>良率提升：</strong>小die良率远高于大die，总体成本降低</li>
                <li><strong>灵活组合：</strong>不同工艺节点的chiplet可以混合使用</li>
                <li><strong>快速迭代：</strong>只需更新特定功能的chiplet</li>
                <li><strong>IP复用：</strong>标准化接口支持第三方chiplet</li>
            </ol>
            
            <p><strong>设计考量：</strong></p>
            <ul>
                <li><strong>接口标准化：</strong>采用UCIe等标准确保互操作性</li>
                <li><strong>功耗优化：</strong>D2D PHY功耗需要精心设计</li>
                <li><strong>延迟管理：</strong>跨chiplet通信延迟的架构优化</li>
                <li><strong>测试策略：</strong>已知良好芯片（KGD）测试流程</li>
            </ul>
            
            <div class="info-box">
                <p><strong>KGD（Known Good Die）测试的挑战：</strong></p>
                <ul>
                    <li><strong>探针测试限制：</strong>高速接口难以在晶圆级完全测试</li>
                    <li><strong>成本压力：</strong>完整的KGD测试可能占芯片成本的20-30%</li>
                    <li><strong>测试覆盖率：</strong>需要在速度、功耗、温度等多个维度测试</li>
                    <li><strong>已知良好die库存管理：</strong>不同批次、角落的die匹配</li>
                </ul>
                
                <p><strong>系统软件视角：</strong></p>
                <ul>
                    <li><strong>统一视图 vs 分离视图：</strong>
                        <ul>
                            <li>对OS呈现为单一大型NPU：需要芯片间缓存一致性</li>
                            <li>呈现为多个独立NPU：软件负责任务分配和同步</li>
                        </ul>
                    </li>
                    <li><strong>NUMA感知：</strong>不同chiplet访问延迟差异需要NUMA优化</li>
                    <li><strong>故障隔离：</strong>单个chiplet故障不应影响整个系统</li>
                    <li><strong>动态配置：</strong>支持chiplet级别的热插拔和功耗管理</li>
                </ul>
            </div>

            <h3>9.3 新型存储器技术</h3>
            
            <h4>9.3.1 HBM与存储器演进</h4>
            
            <p>高带宽存储器（HBM）已成为高性能NPU的标配，而新一代存储技术正在不断突破带宽和容量的极限。</p>
            
            <div class="code-block">
// HBM技术演进
class HBM_Evolution {
    struct HBM_Generation {
        string name;
        int stack_height;      // 层数
        float bandwidth;       // GB/s per stack
        float capacity;        // GB per stack
        float voltage;         // V
        int prefetch;         // bits
        float pJ_per_bit;     // 能效
    };
    
    // HBM代际对比
    HBM_Generation hbm2 = {
        "HBM2", 8, 256, 8, 1.2, 256, 3.5
    };
    
    HBM_Generation hbm2e = {
        "HBM2E", 8, 410, 16, 1.2, 256, 3.0
    };
    
    HBM_Generation hbm3 = {
        "HBM3", 12, 819, 24, 1.1, 256, 2.5
    };
    
    HBM_Generation hbm3e = {
        "HBM3E", 12, 1200, 36, 1.1, 256, 2.0
    };
    
    // NPU集成方案
    class NPU_HBM_Integration {
        // 物理集成
        const int HBM_STACKS = 6;        // 6个HBM3E
        const int TOTAL_BW = 7200;       // GB/s
        const int TOTAL_CAPACITY = 216;  // GB
        
        // 逻辑分区
        void partition_memory() {
            // 权重专用：2 stacks (72GB)
            // 激活值：2 stacks (72GB)
            // 中间结果：2 stacks (72GB)
        }
        
        // 访问优化
        void optimize_access() {
            // Bank级并行
            // Channel交织
            // 预取优化
            // 刷新隐藏
        }
    };
};
            </div>
            
            <p><strong>新型存储器技术：</strong></p>
            <ul>
                <li><strong>MRAM（磁阻存储器）：</strong>
                    <ul>
                        <li>非易失性，断电数据保持</li>
                        <li>无限耐久性，适合频繁更新</li>
                        <li>读写速度接近SRAM</li>
                        <li>适用于片上缓存和权重存储</li>
                    </ul>
                </li>
                <li><strong>ReRAM（阻变存储器）：</strong>
                    <ul>
                        <li>高密度，3D堆叠能力</li>
                        <li>可实现存算一体架构</li>
                        <li>多值存储能力（MLC）</li>
                        <li>适用于权重存储和模拟计算</li>
                    </ul>
                </li>
                <li><strong>PCM（相变存储器）：</strong>
                    <ul>
                        <li>介于DRAM和闪存之间的性能</li>
                        <li>字节可寻址</li>
                        <li>适合大容量权重存储</li>
                    </ul>
                </li>
            </ul>

            <h4>9.3.2 存算一体架构</h4>
            
            <p>存算一体（Processing-In-Memory, PIM）通过在存储器内部集成计算能力，从根本上解决冯·诺依曼瓶颈。</p>
            
            <div class="code-block">
// 存算一体架构实现
module ProcessingInMemory;
    
    // 基于ReRAM的矩阵乘法器
    class ReRAM_Crossbar {
        // 交叉阵列参数
        parameter ROWS = 128;
        parameter COLS = 128;
        parameter LEVELS = 8;     // 3-bit 权重
        
        // 权重映射到电导
        real conductance[ROWS][COLS];
        
        // 模拟矩阵向量乘法
        function real[COLS-1:0] compute_mvm(real[ROWS-1:0] input_vector);
            real[COLS-1:0] output_current;
            
            // 欧姆定律：I = V × G
            for (int j = 0; j < COLS; j++) begin
                output_current[j] = 0;
                for (int i = 0; i < ROWS; i++) begin
                    output_current[j] += input_vector[i] * conductance[i][j];
                end
            end
            
            return output_current;
        endfunction
        
        // 功耗模型
        function real calculate_power();
            // 静态功耗：漏电流
            real static_power = ROWS * COLS * 1e-9;  // 1nW per cell
            
            // 动态功耗：取决于激活的行数
            real dynamic_power = active_rows * 1e-6;  // 1μW per row
            
            return static_power + dynamic_power;
        endfunction
    };
    
    // 数字PIM架构
    class Digital_PIM {
        // SRAM bank内集成ALU
        parameter BANK_SIZE = 256;  // KB
        parameter ALU_WIDTH = 32;   // bits
        parameter NUM_ALUS = 16;    // per bank
        
        // PIM指令集
        typedef enum {
            PIM_ADD,      // 向量加法
            PIM_MUL,      // 向量乘法
            PIM_MAC,      // 乘累加
            PIM_REDUCE,   // 归约操作
            PIM_COMPARE   // 比较操作
        } pim_op_t;
        
        // 执行模型
        task execute_pim_op(pim_op_t op, int addr1, int addr2, int dst);
            // 数据不移动，计算在存储器内完成
            case (op)
                PIM_MAC: begin
                    // 本地MAC操作
                    for (int i = 0; i < BANK_SIZE/4; i++) begin
                        mem[dst+i] += mem[addr1+i] * mem[addr2+i];
                    end
                end
                // 其他操作...
            endcase
        endtask
    };
    
endmodule
            </div>
            
            <p><strong>PIM架构的优势：</strong></p>
            <ol>
                <li><strong>带宽提升：</strong>内部带宽可达TB/s级别</li>
                <li><strong>能效改善：</strong>减少数据移动，降低功耗90%+</li>
                <li><strong>延迟降低：</strong>就地计算，避免内存墙</li>
                <li><strong>扩展性好：</strong>计算能力随存储容量线性扩展</li>
            </ol>
            
            <p><strong>实现挑战：</strong></p>
            <ul>
                <li><strong>工艺兼容性：</strong>逻辑工艺vs存储工艺的平衡</li>
                <li><strong>编程模型：</strong>需要新的编程抽象和工具链</li>
                <li><strong>精度控制：</strong>模拟计算的精度和稳定性</li>
                <li><strong>标准化：</strong>接口和架构标准尚未统一</li>
            </ul>
            
            <div class="warning-box">
                <p><strong>模拟PIM的隐藏成本：</strong></p>
                <ul>
                    <li><strong>ADC/DAC开销：</strong>
                        <ul>
                            <li>输入需要DAC（数模转换），每个8bit DAC约占100μm²</li>
                            <li>输出需要ADC（模数转换），功耗可达10-100mW</li>
                            <li>转换延迟限制了实际吞吐量</li>
                        </ul>
                    </li>
                    <li><strong>精度限制：</strong>模拟计算通常限于4-8bit，需要特殊训练方法</li>
                    <li><strong>工艺偏差：</strong>需要校准和补偿电路，增加复杂度</li>
                </ul>
                
                <p><strong>编程模型的根本挑战：</strong></p>
                <ul>
                    <li><strong>框架集成：</strong>如何让PyTorch/TensorFlow自动识别并映射PIM操作</li>
                    <li><strong>数据布局：</strong>传统行主序vs PIM友好的列主序</li>
                    <li><strong>调度复杂性：</strong>PIM操作与传统操作的混合调度</li>
                    <li><strong>抽象层设计：</strong>在性能和易用性之间找到平衡</li>
                </ul>
            </div>

            <h3>9.4 热管理与供电技术</h3>
            
            <h4>9.4.1 先进冷却技术</h4>
            
            <p>随着功耗密度的急剧增加，传统风冷已无法满足高性能NPU的散热需求，液冷和其他创新冷却技术成为必然选择。</p>
            
            <div class="code-block">
// 热管理系统设计
class ThermalManagementSystem {
    // 热设计参数
    struct ThermalSpec {
        float tjunction_max = 105.0;    // °C 结温上限
        float power_density = 2.0;       // W/mm² @ 3nm
        float thermal_resistance = 0.3;  // °C/W junction-to-case
        float ambient_temp = 35.0;       // °C 环境温度
    };
    
    // 液冷系统设计
    class LiquidCooling {
        // 冷板设计
        struct ColdPlate {
            float thickness = 5.0;       // mm
            int microchannels = 100;     // 微通道数量
            float channel_width = 0.2;   // mm
            float flow_rate = 2.0;       // L/min
            string coolant = "water";    // 冷却液类型
        };
        
        // 热阻计算
        float calculate_thermal_resistance() {
            float r_junction_case = 0.3;
            float r_case_coldplate = 0.1;
            float r_coldplate_fluid = 0.05;
            float r_fluid_ambient = 0.2;
            
            return r_junction_case + r_case_coldplate + 
                   r_coldplate_fluid + r_fluid_ambient;
        }
        
        // 温度预测
        float predict_junction_temp(float power) {
            float r_total = calculate_thermal_resistance();
            return ambient_temp + power * r_total;
        }
    };
    
    // 浸没式冷却
    class ImmersionCooling {
        // 介电流体特性
        struct DielectricFluid {
            string type = "3M Novec";
            float boiling_point = 49.0;   // °C
            float thermal_capacity = 1.1;  // kJ/kg·K
            float breakdown_voltage = 25;  // kV
        };
        
        // 两相冷却优势
        // 1. 相变潜热大，散热能力强
        // 2. 温度均匀性好
        // 3. 无需泵，依靠自然对流
        
        float cooling_capacity() {
            // 两相冷却能力可达 1000 W/cm²
            return 1000.0;
        }
    };
    
    // 集成式微流道冷却
    class MicrofluidicCooling {
        // 硅通孔集成微流道
        parameter CHANNEL_DIAMETER = 50;    // μm
        parameter CHANNEL_PITCH = 200;      // μm
        parameter CHANNELS_PER_MM2 = 25;
        
        // 直接在芯片内部冷却
        task embedded_cooling();
            // TSV中集成冷却液通道
            // 热源附近直接散热
            // 3D堆叠每层独立冷却
        endtask
    };
};
            </div>
            
            <p><strong>热管理策略：</strong></p>
            <ol>
                <li><strong>动态热管理（DTM）：</strong>
                    <ul>
                        <li>实时温度监控，分布式温度传感器</li>
                        <li>基于温度的DVFS调节</li>
                        <li>热点迁移，工作负载动态分配</li>
                        <li>预测性热管理，基于历史数据</li>
                    </ul>
                </li>
                <li><strong>封装级优化：</strong>
                    <ul>
                        <li>高导热界面材料（TIM）</li>
                        <li>均热板（Vapor Chamber）集成</li>
                        <li>热通孔（Thermal TSV）设计</li>
                    </ul>
                </li>
                <li><strong>系统级方案：</strong>
                    <ul>
                        <li>冷板直接接触（Direct-to-Chip）</li>
                        <li>两相浸没冷却系统</li>
                        <li>热回收利用方案</li>
                    </ul>
                </li>
            </ol>
            
            <div class="info-box">
                <p><strong>热设计与架构协同设计：</strong></p>
                <p>现代NPU设计需要在架构阶段就考虑热管理，而非事后补救：</p>
                <ul>
                    <li><strong>Floorplan热感知：</strong>
                        <ul>
                            <li>将高功耗MAC单元分散布置，避免热点集中</li>
                            <li>在热敏感区域预留冷却通道</li>
                            <li>考虑热梯度对时序的影响</li>
                        </ul>
                    </li>
                    <li><strong>计算调度优化：</strong>
                        <ul>
                            <li>工作负载在空间上轮转，均衡热分布</li>
                            <li>利用热惯性，短时过载后强制冷却</li>
                            <li>温度感知的任务映射算法</li>
                        </ul>
                    </li>
                    <li><strong>设计裕量分配：</strong>
                        <ul>
                            <li>热关键路径额外的时序裕量</li>
                            <li>温度相关的电压调节</li>
                        </ul>
                    </li>
                </ul>
            </div>

            <h4>9.4.2 先进供电架构</h4>
            
            <p>高效的供电系统是NPU稳定运行的基础，先进的电源管理技术能够显著提升系统能效。</p>
            
            <div class="code-block">
// 先进供电系统设计
module PowerDeliverySystem;
    
    // 集成电压调节器（IVR）
    class IntegratedVoltageRegulator {
        // 片上集成优势
        // 1. 快速响应：<10ns
        // 2. 细粒度控制：每个模块独立供电
        // 3. 高效率：>90% @ 轻载
        
        parameter NUM_DOMAINS = 16;
        parameter VDD_NOMINAL = 0.75;  // V
        parameter VDD_RANGE = 0.2;     // +/- 0.2V
        
        // 多相交错Buck转换器
        struct BuckConverter {
            int phases = 4;
            float switching_freq = 100e6;  // Hz
            float inductance = 1e-9;       // H
            float efficiency = 0.92;
        };
        
        // 动态电压调节
        task adjust_voltage(int domain_id, real target_vdd);
            // 数字控制环路
            real error = target_vdd - current_vdd[domain_id];
            real duty_cycle = calculate_duty_cycle(error);
            set_pwm(domain_id, duty_cycle);
            
            // 自适应调节
            if (load_current[domain_id] > threshold) begin
                increase_phases(domain_id);
            end
        endtask
    };
    
    // 供电网络（PDN）设计
    class PowerDistributionNetwork {
        // 分层PDN结构
        // PCB -> Package -> Die
        
        // 目标阻抗计算
        function real calculate_target_impedance();
            real vdd = 0.75;
            real tolerance = 0.05;  // 5%纹波
            real max_current = 200; // A
            
            return (vdd * tolerance) / max_current; // 1.875 mΩ
        endfunction
        
        // 去耦电容优化
        struct DecapStrategy {
            // Die上电容
            real die_cap = 100e-9;      // 100nF
            int die_cap_count = 10000;
            
            // 封装电容
            real pkg_cap = 10e-6;       // 10μF
            int pkg_cap_count = 100;
            
            // PCB电容
            real pcb_cap = 100e-6;      // 100μF
            int pcb_cap_count = 20;
        };
        
        // PDN仿真模型
        task simulate_pdn();
            // 频域阻抗分析
            for (freq = 1e3; freq <= 1e9; freq *= 10) begin
                complex_impedance z = calculate_z(freq);
                assert(abs(z) < target_impedance);
            end
            
            // 时域电压跌落分析
            real voltage_droop = simulate_load_step(100A, 1ns);
            assert(voltage_droop < vdd * 0.05);
        endtask
    };
    
    // 能量采集与回收
    class EnergyHarvesting {
        // 热电转换
        struct ThermoelectricGenerator {
            float seebeck_coefficient = 200e-6;  // V/K
            float temp_difference = 50;          // K
            float conversion_efficiency = 0.05;  // 5%
            
            float harvest_power(float waste_heat) {
                return waste_heat * conversion_efficiency;
            }
        };
        
        // 电磁能量回收
        // 从高速信号线回收能量
        task electromagnetic_harvesting();
            // RF整流器设计
            // 阻抗匹配网络
            // DC-DC转换
        endtask
    };
    
endmodule
            </div>
            
            <p><strong>供电系统创新：</strong></p>
            <ul>
                <li><strong>数字低压差稳压器（DLDO）：</strong>全数字控制，易于集成</li>
                <li><strong>自适应电压缩放（AVS）：</strong>根据工艺角和温度动态调整</li>
                <li><strong>谐振时钟分配：</strong>降低时钟网络功耗50%+</li>
                <li><strong>无线功率传输：</strong>用于3D堆叠芯片供电</li>
            </ul>
            
            <div class="warning-box">
                <p><strong>时钟网络功耗挑战：</strong></p>
                <p>在高性能NPU中，时钟网络功耗可占总功耗的20-40%，是功耗优化的关键目标：</p>
                <ul>
                    <li><strong>传统时钟网络问题：</strong>
                        <ul>
                            <li>大量缓冲器的开关功耗</li>
                            <li>长距离时钟线的充放电损耗</li>
                            <li>时钟偏斜补偿带来的额外功耗</li>
                        </ul>
                    </li>
                    <li><strong>谐振时钟技术原理：</strong>
                        <ul>
                            <li>利用LC谐振回收充放电能量</li>
                            <li>正弦波时钟减少高频谐波</li>
                            <li>分布式电感设计优化</li>
                        </ul>
                    </li>
                    <li><strong>其他时钟优化技术：</strong>
                        <ul>
                            <li>多级时钟门控层次</li>
                            <li>局部时钟生成（分频/倍频）</li>
                            <li>自适应时钟stretching</li>
                        </ul>
                    </li>
                </ul>
            </div>

            <div class="exercise">
                <h4>练习题集 9</h4>
                
                <div class="question">
                    <p><strong>题目9.1：</strong>计算一个7nm工艺下的NPU芯片（包含1024×1024 MAC阵列）迁移到3nm GAA工艺后，在相同功耗预算（100W）下，理论上可以集成多少个MAC单元？假设MAC单元面积缩放70%，功耗缩放60%。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：先计算7nm下单个MAC的功耗，然后应用功耗缩放比例得到3nm下的单MAC功耗。在相同功耗预算下计算可容纳的MAC数量。别忘了验证面积约束是否满足。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p>7nm工艺参数：</p>
                        <ul>
                            <li>MAC阵列：1024 × 1024 = 1,048,576个MAC</li>
                            <li>功耗：100W</li>
                            <li>单个MAC功耗：100W / 1,048,576 ≈ 95.4μW</li>
                        </ul>
                        
                        <p>3nm工艺参数：</p>
                        <ul>
                            <li>单个MAC功耗：95.4μW × 0.6 = 57.2μW</li>
                            <li>相同功耗预算下MAC数量：100W / 57.2μW ≈ 1,748,252个</li>
                            <li>MAC阵列大小：√1,748,252 ≈ 1322 × 1322</li>
                        </ul>
                        
                        <p><strong>验证面积约束：</strong></p>
                        <ul>
                            <li>面积缩放：1,748,252 × 0.7 / 1,048,576 ≈ 1.17</li>
                            <li>面积增加17%，在合理范围内</li>
                        </ul>
                        
                        <p><strong>结论：</strong>3nm工艺下可集成约175万个MAC单元，性能提升67%。</p>
                    </div>
                </div>
                
                <div class="question">
                    <p><strong>题目9.2：</strong>设计一个基于Chiplet的NPU系统，包含4个计算chiplet（每个200mm²）和4个HBM3 chiplet。计算系统总带宽，并分析chiplet间互连的功耗占比。假设D2D PHY功耗为2pJ/bit。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：HBM3单个通道带宽约1TB/s。Chiplet间互连可以使用UCIe或其他高速D2D接口。计算总带宽时考虑所有接口。功耗=带宽×pJ/bit。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        
                        <p><strong>系统配置：</strong></p>
                        <ul>
                            <li>计算Chiplet：4个，每个200mm²</li>
                            <li>HBM3 Chiplet：4个，每个819GB/s带宽</li>
                            <li>总内存带宽：4 × 819 = 3,276 GB/s</li>
                        </ul>
                        
                        <p><strong>Chiplet互连设计：</strong></p>
                        <ul>
                            <li>采用2×2 mesh拓扑连接计算chiplet</li>
                            <li>每条链路：16通道 × 32Gbps = 512Gbps = 64GB/s</li>
                            <li>总互连带宽：6条链路 × 64GB/s = 384GB/s</li>
                        </ul>
                        
                        <p><strong>功耗分析：</strong></p>
                        <div class="code-block">
// D2D互连功耗
D2D功耗 = 数据率 × pJ/bit
       = 384GB/s × 8bit/B × 2pJ/bit
       = 6.144W

// HBM接口功耗（假设3pJ/bit）
HBM功耗 = 3,276GB/s × 8 × 3pJ/bit
       = 78.6W

// 假设计算功耗200W
总功耗 = 200W + 6.144W + 78.6W = 284.7W

// 互连功耗占比
D2D占比 = 6.144W / 284.7W = 2.2%
内存接口占比 = 78.6W / 284.7W = 27.6%
                        </div>
                        
                        <p><strong>优化建议：</strong></p>
                        <ul>
                            <li>采用更先进的D2D PHY，降至1pJ/bit</li>
                            <li>使用数据压缩减少传输量</li>
                            <li>优化数据布局，增加局部性</li>
                            <li>考虑3D堆叠减少互连距离</li>
                        </ul>
                    </div>
                </div>
                
                <div class="question">
                    <p><strong>题目9.3：</strong>比较SRAM、HBM3和基于ReRAM的存算一体架构在执行矩阵乘法时的能效。计算1TOPS运算需要的能耗，考虑数据访问和计算两部分。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：传统架构需要数据移动（读取、计算、写回）。存算一体在存储单元内完成计算，减少数据移动。考虑不同存储媒介的访问能耗和计算能耗。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        
                        <p><strong>1. SRAM架构：</strong></p>
                        <ul>
                            <li>SRAM读取能耗：5pJ/byte</li>
                            <li>MAC运算能耗：0.5pJ/op (7nm)</li>
                            <li>每次MAC需要读取：2个操作数 + 1个部分和 = 3×4bytes = 12bytes</li>
                            <li>总能耗/op = 12bytes × 5pJ/byte + 0.5pJ = 60.5pJ/op</li>
                            <li>1TOPS能耗 = 10¹² × 60.5pJ = 60.5W</li>
                        </ul>
                        
                        <p><strong>2. HBM3架构：</strong></p>
                        <ul>
                            <li>HBM3访问能耗：15pJ/byte（含PHY）</li>
                            <li>片上缓存命中率：假设90%</li>
                            <li>有效访问能耗：0.9×5pJ + 0.1×15pJ = 6pJ/byte</li>
                            <li>总能耗/op = 12bytes × 6pJ/byte + 0.5pJ = 72.5pJ/op</li>
                            <li>1TOPS能耗 = 72.5W</li>
                        </ul>
                        
                        <p><strong>3. ReRAM存算一体：</strong></p>
                        <ul>
                            <li>模拟MAC能耗：0.1pJ/op（含DA/AD转换）</li>
                            <li>权重已存储在ReRAM中，无需读取</li>
                            <li>输入数据加载：4bytes × 2pJ/byte = 8pJ（每个向量元素）</li>
                            <li>假设向量长度128，共享摊销：8pJ/128 = 0.0625pJ/op</li>
                            <li>总能耗/op = 0.1pJ + 0.0625pJ = 0.1625pJ/op</li>
                            <li>1TOPS能耗 = 0.1625W</li>
                        </ul>
                        
                        <p><strong>能效对比：</strong></p>
                        <table>
                            <tr>
                                <th>架构</th>
                                <th>能耗(pJ/op)</th>
                                <th>1TOPS功耗(W)</th>
                                <th>能效提升</th>
                            </tr>
                            <tr>
                                <td>SRAM</td>
                                <td>60.5</td>
                                <td>60.5</td>
                                <td>1×</td>
                            </tr>
                            <tr>
                                <td>HBM3</td>
                                <td>72.5</td>
                                <td>72.5</td>
                                <td>0.83×</td>
                            </tr>
                            <tr>
                                <td>ReRAM PIM</td>
                                <td>0.1625</td>
                                <td>0.1625</td>
                                <td>372×</td>
                            </tr>
                        </table>
                        
                        <p><strong>结论：</strong>存算一体架构在能效上具有数量级优势，但需要考虑精度、良率和编程复杂度等因素。</p>
                    </div>
                </div>
                
                <div class="question">
                    <p><strong>题目9.4：</strong>设计一个液冷系统用于冷却300W的NPU芯片（芯片面积600mm²）。计算所需的流量、温升，并选择合适的冷却方案。环境温度35°C，芯片最高结温105°C。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：热阻链：芯片→TIM→冷头→冷却液→环境。使用Q=m×c×ΔT计算流量。功耗密度=300W/600mm²=0.5W/mm²很高，需要高效冷却。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        
                        <p><strong>热设计参数：</strong></p>
                        <ul>
                            <li>总功耗：300W</li>
                            <li>芯片面积：600mm²</li>
                            <li>功耗密度：300W / 6cm² = 50W/cm²</li>
                            <li>允许温升：105°C - 35°C = 70°C</li>
                        </ul>
                        
                        <p><strong>热阻预算：</strong></p>
                        <ul>
                            <li>总热阻要求：70°C / 300W = 0.233°C/W</li>
                            <li>结到壳热阻（TIM）：0.05°C/W</li>
                            <li>冷板热阻预算：0.233 - 0.05 = 0.183°C/W</li>
                        </ul>
                        
                        <p><strong>冷板设计：</strong></p>
                        <div class="code-block">
// 微通道冷板参数
通道宽度 = 0.2mm
通道高度 = 2mm
通道间距 = 0.3mm
通道数量 = 600mm / 0.5mm = 1200条

// 流量计算（水冷）
比热容 = 4.18 kJ/(kg·°C)
密度 = 1000 kg/m³
允许温升 = 10°C

所需流量 = Q / (ρ × Cp × ΔT)
        = 300W / (1000 × 4180 × 10)
        = 7.18 × 10⁻⁶ m³/s
        = 0.43 L/min

// 考虑安全裕量
设计流量 = 0.43 × 2 = 0.86 L/min
                        </div>
                        
                        <p><strong>压降和泵功率：</strong></p>
                        <ul>
                            <li>微通道压降：约50kPa</li>
                            <li>系统总压降：约100kPa</li>
                            <li>泵功率：(0.86L/min × 100kPa) / (60 × 0.7) ≈ 2W</li>
                        </ul>
                        
                        <p><strong>方案对比：</strong></p>
                        <table>
                            <tr>
                                <th>冷却方案</th>
                                <th>能力(W/cm²)</th>
                                <th>复杂度</th>
                                <th>成本</th>
                            </tr>
                            <tr>
                                <td>微通道液冷</td>
                                <td>100</td>
                                <td>中</td>
                                <td>中</td>
                            </tr>
                            <tr>
                                <td>喷雾冷却</td>
                                <td>200</td>
                                <td>高</td>
                                <td>高</td>
                            </tr>
                            <tr>
                                <td>浸没式冷却</td>
                                <td>500</td>
                                <td>中</td>
                                <td>高</td>
                            </tr>
                        </table>
                        
                        <p><strong>推荐方案：</strong>微通道液冷，配合冗余设计，确保可靠性。</p>
                    </div>
                </div>
            </div>
        </div>

        <div id="chapter10" class="chapter">
            <h2>第10章：软件栈与编译优化</h2>
            
            <p>NPU的硬件性能再强，也需要优秀的软件栈才能充分发挥。本章深入探讨NPU软件栈的架构设计、编译优化技术，以及如何实现高效的软硬件协同。</p>

            <h3>10.1 NPU软件栈架构</h3>
            
            <p>NPU软件栈是连接上层AI框架和底层硬件的桥梁。一个完整的软件栈需要处理模型解析、图优化、算子映射、内存管理、指令生成等复杂任务。</p>

            <h4>10.1.1 软件栈分层架构</h4>
            <div class="code-block">
// NPU软件栈典型架构
┌─────────────────────────────────────────┐
│      AI Frameworks (TensorFlow/PyTorch) │
├─────────────────────────────────────────┤
│         Graph Representation            │
│         (ONNX, TorchScript)            │
├─────────────────────────────────────────┤
│         High-Level IR (HIR)            │
│     (Graph Optimization Pass)          │
├─────────────────────────────────────────┤
│         Mid-Level IR (MIR)             │
│    (Operator Fusion, Tiling)          │
├─────────────────────────────────────────┤
│         Low-Level IR (LIR)             │
│   (Memory Allocation, Scheduling)      │
├─────────────────────────────────────────┤
│      Code Generation Backend           │
│    (NPU Instruction Generation)        │
├─────────────────────────────────────────┤
│         Runtime Library                │
│    (Execution, Memory Management)      │
├─────────────────────────────────────────┤
│         NPU Hardware                   │
└─────────────────────────────────────────┘
            </div>

            <h4>10.1.2 关键组件功能</h4>
            <div class="info-box">
                <p><strong>软件栈核心组件：</strong></p>
                <ul>
                    <li><strong>前端解析器：</strong>支持多种框架模型格式，转换为统一的内部表示</li>
                    <li><strong>图优化器：</strong>执行算子融合、常量折叠、死代码消除等优化</li>
                    <li><strong>量化工具：</strong>支持训练后量化和量化感知训练</li>
                    <li><strong>内存分配器：</strong>优化片上内存使用，最小化数据搬移</li>
                    <li><strong>指令调度器：</strong>生成高效的指令序列，最大化硬件利用率</li>
                    <li><strong>运行时系统：</strong>管理任务执行、内存管理、多核调度</li>
                </ul>
            </div>

            <h4>10.1.3 核心枢纽：中间表示（IR）</h4>
            <p>中间表示（Intermediate Representation, IR）是现代AI编译器的灵魂，它在前端（框架模型）和后端（硬件指令）之间架起桥梁。NPU编译器通常采用多层IR设计，每层针对不同的优化目标。</p>
            
            <div class="code-block">
// 多层IR架构示例
// 1. Graph IR - 高层计算图表示
class GraphIR {
    // 节点表示算子
    struct Node {
        string op_type;        // "Conv2D", "MatMul", "Add", etc.
        vector<Tensor> inputs;
        vector<Tensor> outputs;
        map<string, Attribute> attrs;  // kernel_size, stride, etc.
    };
    
    // 边表示数据流
    struct Edge {
        Node* src;
        Node* dst;
        int src_output_idx;
        int dst_input_idx;
    };
};

// 2. Tensor IR - 张量程序表示
class TensorIR {
    // 类似TVM的张量表达式
    Tensor conv2d_tir(Tensor input, Tensor weight) {
        // 定义计算维度
        auto N = input.shape[0];
        auto H = input.shape[1];
        auto W = input.shape[2];
        auto C = input.shape[3];
        auto K = weight.shape[0];
        
        // 定义输出张量
        Tensor output({N, H-2, W-2, K});
        
        // 定义计算
        output(n, h, w, k) = sum(
            input(n, h+rh, w+rw, c) * weight(k, rh, rw, c),
            {rh, rw, c}  // reduction axes
        );
        
        return output;
    }
};

// 3. Hardware IR - 硬件指令表示
class HardwareIR {
    enum OpCode {
        LOAD_WEIGHT,    // 加载权重到片上
        LOAD_ACT,       // 加载激活值
        COMPUTE_MAC,    // MAC阵列计算
        STORE_RESULT,   // 存储结果
        SYNC            // 同步指令
    };
    
    struct Instruction {
        OpCode opcode;
        vector<int> operands;
        map<string, int> config;  // 硬件配置参数
    };
};
            </div>
            
            <div class="info-box">
                <p><strong>为什么需要多层IR？</strong></p>
                <ul>
                    <li><strong>Graph IR：</strong>适合做图级别优化，如算子融合、常量折叠、死代码消除</li>
                    <li><strong>Tensor IR：</strong>适合做算子内部优化，如循环变换、向量化、内存访问优化</li>
                    <li><strong>Hardware IR：</strong>贴近硬件，便于指令调度、寄存器分配、硬件特性利用</li>
                </ul>
                <p>现代框架如<strong>MLIR（Multi-Level IR）</strong>提供了构建多层IR的基础设施，被Google、Intel等公司广泛采用于下一代AI编译器。</p>
            </div>

            <h3>10.2 计算图优化</h3>
            
            <p>计算图优化是NPU编译器的核心功能，通过各种变换技术，将原始的计算图转换为更适合硬件执行的形式。</p>

            <h4>10.2.1 算子融合技术</h4>
            <div class="code-block">
// 算子融合示例：Conv + BN + ReLU融合
// 原始计算图
class OriginalGraph:
    def forward(self, x):
        # 卷积操作
        conv_out = self.conv2d(x)  # 需要写回内存
        # 批归一化
        bn_out = self.batch_norm(conv_out)  # 需要读写内存
        # 激活函数
        relu_out = self.relu(bn_out)  # 需要读写内存
        return relu_out

// 融合后的计算图
class FusedGraph:
    def forward(self, x):
        # 融合的算子，一次内存读写完成三个操作
        return self.conv_bn_relu_fused(x)

// 融合实现（伪代码）
def conv_bn_relu_fused(input, conv_weight, bn_params):
    # 在NPU内部完成所有计算
    for (oc in output_channels):
        for (oh, ow in output_positions):
            # 卷积计算
            acc = 0
            for (ic, kh, kw in kernel):
                acc += input[ic][oh+kh][ow+kw] * conv_weight[oc][ic][kh][kw]
            
            # BN计算（在线融合）
            acc = (acc - bn_mean[oc]) / sqrt(bn_var[oc] + eps)
            acc = acc * bn_scale[oc] + bn_bias[oc]
            
            # ReLU计算
            output[oc][oh][ow] = max(0, acc)
    
    return output
            </div>

            <h4>10.2.2 算子融合的类型与限制</h4>
            <div class="code-block">
// 不同类型的算子融合模式
// 1. 垂直融合（Vertical Fusion）- 将element-wise操作融入计算密集型操作
class VerticalFusion {
    // 融合前：Conv -> Add(bias) -> BN -> ReLU
    void unfused_forward(Tensor input) {
        Tensor conv_out = conv2d(input, weight);      // 写回DDR
        Tensor bias_out = add(conv_out, bias);        // 读写DDR
        Tensor bn_out = batch_norm(bias_out);         // 读写DDR
        Tensor relu_out = relu(bn_out);               // 读写DDR
        return relu_out;
    }
    
    // 融合后：所有操作在片上完成
    void fused_forward(Tensor input) {
        // 一次性完成所有计算，只写最终结果
        return conv_bias_bn_relu_fused(input, weight, bias, bn_params);
    }
};

// 2. 水平融合（Horizontal Fusion）- 合并相同类型的并行操作
class HorizontalFusion {
    // 融合前：多个小矩阵乘法分别执行
    void unfused_multi_matmul(vector<Tensor> A_list, vector<Tensor> B_list) {
        vector<Tensor> results;
        for (int i = 0; i < A_list.size(); i++) {
            results.push_back(matmul(A_list[i], B_list[i]));
        }
        return results;
    }
    
    // 融合后：打包成一个大矩阵乘法
    void fused_batched_matmul(vector<Tensor> A_list, vector<Tensor> B_list) {
        Tensor A_packed = pack_tensors(A_list);  // [batch, M, K]
        Tensor B_packed = pack_tensors(B_list);  // [batch, K, N]
        Tensor C_packed = batched_matmul(A_packed, B_packed);
        return unpack_tensors(C_packed);
    }
};

// 3. 融合的限制条件
bool can_fuse(Node* node1, Node* node2) {
    // 检查数据依赖
    if (has_external_dependency(node1, node2)) {
        return false;  // 中间结果被其他节点使用
    }
    
    // 检查内存限制
    size_t fused_memory = estimate_memory(node1) + estimate_memory(node2);
    if (fused_memory > on_chip_memory_size) {
        return false;  // 融合后超出片上内存
    }
    
    // 检查硬件支持
    if (!hardware_supports_fused_op(node1->op_type, node2->op_type)) {
        return false;  // 硬件没有对应的融合指令
    }
    
    // 检查数值稳定性
    if (fusion_affects_numerical_stability(node1, node2)) {
        return false;  // 融合可能导致精度损失
    }
    
    return true;
}
            </div>
            
            <div class="warning-box">
                <p><strong>算子融合的权衡：</strong></p>
                <ul>
                    <li><strong>收益：</strong>减少内存访问、降低带宽压力、减少kernel启动开销</li>
                    <li><strong>代价：</strong>增加代码复杂度、可能降低硬件利用率、限制并行度</li>
                    <li><strong>原则：</strong>优先融合内存受限（memory-bound）的操作，计算受限（compute-bound）的操作谨慎融合</li>
                </ul>
            </div>

            <h4>10.2.3 图优化策略</h4>
            <div class="table-wrapper">
                <table>
                    <thead>
                        <tr>
                            <th>优化技术</th>
                            <th>描述</th>
                            <th>收益</th>
                            <th>适用场景</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>算子融合</td>
                            <td>将多个算子合并为一个</td>
                            <td>减少内存访问</td>
                            <td>连续的element-wise操作</td>
                        </tr>
                        <tr>
                            <td>常量折叠</td>
                            <td>预计算常量表达式</td>
                            <td>减少运行时计算</td>
                            <td>包含常量的子图</td>
                        </tr>
                        <tr>
                            <td>公共子表达式消除</td>
                            <td>复用相同计算结果</td>
                            <td>减少重复计算</td>
                            <td>重复的计算模式</td>
                        </tr>
                        <tr>
                            <td>死代码消除</td>
                            <td>删除无用计算</td>
                            <td>减少计算量</td>
                            <td>条件分支、未使用输出</td>
                        </tr>
                        <tr>
                            <td>布局转换优化</td>
                            <td>优化数据布局</td>
                            <td>提高访存效率</td>
                            <td>不同算子间的数据传递</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h4>10.2.4 数据布局优化</h4>
            <p>数据布局（Data Layout）对NPU性能影响巨大。不同的布局方式直接影响内存访问模式和计算效率。编译器需要根据硬件特性选择最优布局。</p>
            
            <div class="code-block">
// 常见的数据布局格式
// NCHW vs NHWC 对比示例
class DataLayoutOptimization {
    // NCHW布局：适合传统CPU和某些GPU
    // 内存排列：[batch][channel][height][width]
    // 例：shape=(1,3,224,224)的图像，RGB三通道是连续存储的
    
    // NHWC布局：适合移动端GPU和很多NPU
    // 内存排列：[batch][height][width][channel]
    // 例：shape=(1,224,224,3)的图像，每个像素的RGB是连续的
    
    // 为什么NHWC对某些硬件更友好？
    void convolution_nhwc(float* input, float* weight, float* output) {
        // NHWC布局下，卷积的内层循环访问模式
        for (int h = 0; h < H; h++) {
            for (int w = 0; w < W; w++) {
                for (int oc = 0; oc < OUT_C; oc++) {
                    float sum = 0;
                    for (int kh = 0; kh < KH; kh++) {
                        for (int kw = 0; kw < KW; kw++) {
                            for (int ic = 0; ic < IN_C; ic++) {
                                // 访问是连续的！有利于向量化
                                int in_idx = ((h+kh)*W + (w+kw))*IN_C + ic;
                                int wt_idx = (oc*KH*KW + kh*KW + kw)*IN_C + ic;
                                sum += input[in_idx] * weight[wt_idx];
                            }
                        }
                    }
                    output[(h*W + w)*OUT_C + oc] = sum;
                }
            }
        }
    }
    
    // NPU特定的分块布局（Tiled Layout）
    // 例如：NC/32HW32c - 将通道维度按32分块
    struct TiledTensor {
        // 原始shape: [N, C, H, W]
        // 分块后shape: [N, C/32, H, W, 32]
        // 好处：每个32通道块可以完美映射到SIMD宽度
        
        float* transform_to_tiled(float* nchw_data, int N, int C, int H, int W) {
            int C_outer = (C + 31) / 32;  // 向上取整
            float* tiled = new float[N * C_outer * H * W * 32];
            
            for (int n = 0; n < N; n++) {
                for (int co = 0; co < C_outer; co++) {
                    for (int h = 0; h < H; h++) {
                        for (int w = 0; w < W; w++) {
                            for (int ci = 0; ci < 32; ci++) {
                                int c = co * 32 + ci;
                                if (c < C) {
                                    int src_idx = ((n*C + c)*H + h)*W + w;
                                    int dst_idx = ((((n*C_outer + co)*H + h)*W + w)*32 + ci;
                                    tiled[dst_idx] = nchw_data[src_idx];
                                }
                            }
                        }
                    }
                }
            }
            return tiled;
        }
    };
};

// 编译器的布局选择策略
class LayoutSelector {
    Layout selectOptimalLayout(Graph& graph, NPUTarget& target) {
        // 1. 分析硬件特性
        bool supports_nhwc = target.hasEfficientNHWC();
        int simd_width = target.getSIMDWidth();
        
        // 2. 分析模型特征
        int avg_channel_size = graph.getAverageChannelSize();
        bool has_depthwise = graph.hasDepthwiseConv();
        
        // 3. 决策逻辑
        if (has_depthwise && supports_nhwc) {
            return NHWC;  // Depthwise卷积在NHWC下效率更高
        }
        
        if (avg_channel_size % simd_width == 0) {
            return TiledLayout(simd_width);  // 通道数适合分块
        }
        
        return NCHW;  // 默认布局
    }
};
            </div>
            
            <div class="info-box">
                <p><strong>布局转换的时机：</strong></p>
                <ul>
                    <li><strong>早期转换：</strong>在图优化阶段就确定目标布局，所有算子使用统一布局</li>
                    <li><strong>延迟转换：</strong>让每个算子选择最优布局，必要时插入转换节点</li>
                    <li><strong>混合策略：</strong>将图分区，每个区域使用最适合的布局</li>
                </ul>
            </div>

            <h3>10.3 内存优化技术</h3>
            
            <p>内存带宽是NPU的主要瓶颈。高效的内存管理和优化技术对于发挥NPU性能至关重要。</p>

            <h4>10.3.1 内存分配策略</h4>
            <div class="code-block">
// 内存池管理器
class MemoryPoolManager {
public:
    struct MemoryBlock {
        size_t offset;
        size_t size;
        int lifetime_start;
        int lifetime_end;
        bool is_allocated;
    };
    
    // 内存分配算法
    size_t allocate(size_t size, int start_time, int end_time) {
        // 1. 首先尝试复用已释放的内存块
        for (auto& block : memory_blocks) {
            if (!block.is_allocated && 
                block.size >= size &&
                (block.lifetime_end < start_time || 
                 block.lifetime_start > end_time)) {
                block.is_allocated = true;
                block.lifetime_start = start_time;
                block.lifetime_end = end_time;
                return block.offset;
            }
        }
        
        // 2. 分配新的内存块
        size_t offset = findFreeSpace(size);
        memory_blocks.push_back({
            offset, size, start_time, end_time, true
        });
        
        return offset;
    }
    
    // 内存碎片整理
    void defragment() {
        // 基于生命周期的内存压缩
        std::sort(memory_blocks.begin(), memory_blocks.end(),
            [](const MemoryBlock& a, const MemoryBlock& b) {
                return a.lifetime_start < b.lifetime_start;
            });
        
        // 重新排列内存布局
        size_t current_offset = 0;
        for (auto& block : memory_blocks) {
            if (block.is_allocated) {
                block.offset = current_offset;
                current_offset += block.size;
            }
        }
    }
    
private:
    std::vector<MemoryBlock> memory_blocks;
    size_t total_memory_size;
};
            </div>

            <h4>10.3.2 数据布局优化</h4>
            <div class="info-box">
                <p><strong>常见数据布局格式：</strong></p>
                <ul>
                    <li><strong>NCHW：</strong>批次-通道-高度-宽度，适合卷积运算</li>
                    <li><strong>NHWC：</strong>批次-高度-宽度-通道，适合深度可分离卷积</li>
                    <li><strong>NC/HW[n]c：</strong>分块布局，适合SIMD指令</li>
                    <li><strong>Custom Layout：</strong>NPU特定的优化布局</li>
                </ul>
            </div>

            <div class="code-block">
// 数据布局转换优化
class LayoutOptimizer {
public:
    // 分析最优布局
    Layout analyzeOptimalLayout(const Graph& graph) {
        std::map<Layout, float> layout_costs;
        
        // 遍历所有可能的布局
        for (auto layout : {NCHW, NHWC, NCHW16c, CUSTOM}) {
            float cost = 0;
            
            // 计算每个算子的执行成本
            for (auto& op : graph.operators) {
                cost += getOperatorCost(op, layout);
            }
            
            // 计算布局转换成本
            for (auto& edge : graph.edges) {
                if (requiresTranspose(edge, layout)) {
                    cost += getTransposeCost(edge);
                }
            }
            
            layout_costs[layout] = cost;
        }
        
        // 返回成本最低的布局
        return std::min_element(layout_costs.begin(), layout_costs.end(),
            [](const auto& a, const auto& b) {
                return a.second < b.second;
            })->first;
    }
    
    // 插入布局转换节点
    void insertLayoutTransforms(Graph& graph, const Layout& target_layout) {
        for (auto& edge : graph.edges) {
            if (edge.src_layout != target_layout || 
                edge.dst_layout != target_layout) {
                // 插入转换节点
                auto transform_op = createTransformOp(
                    edge.src_layout, target_layout
                );
                graph.insertOperator(transform_op, edge);
            }
        }
    }
};
            </div>

            <h3>10.4 指令生成与调度</h3>
            
            <p>将优化后的计算图转换为NPU可执行的指令序列，需要考虑指令级并行、数据依赖关系和硬件资源约束。</p>

            <h4>10.4.1 指令调度算法</h4>
            <div class="code-block">
// NPU指令调度器
class InstructionScheduler {
public:
    struct Instruction {
        enum Type { LOAD, STORE, COMPUTE, SYNC };
        Type type;
        int cycle_start;
        int cycle_end;
        std::vector<int> dependencies;
        std::vector<int> resources;  // 使用的硬件资源
    };
    
    // 基于资源约束的指令调度
    std::vector<Instruction> schedule(const std::vector<Instruction>& instructions) {
        // 构建依赖图
        DependencyGraph dep_graph(instructions);
        
        // 初始化就绪队列
        std::priority_queue<int, std::vector<int>, ComparePriority> ready_queue;
        std::vector<bool> scheduled(instructions.size(), false);
        std::vector<int> finish_time(instructions.size(), 0);
        
        // 将无依赖的指令加入就绪队列
        for (int i = 0; i < instructions.size(); i++) {
            if (dep_graph.getPredecessors(i).empty()) {
                ready_queue.push(i);
            }
        }
        
        // 资源使用表
        ResourceTable resource_table;
        int current_cycle = 0;
        
        // 调度主循环
        while (!ready_queue.empty()) {
            int inst_id = ready_queue.top();
            ready_queue.pop();
            
            // 找到最早可以执行的时间
            int earliest_start = current_cycle;
            for (int pred : dep_graph.getPredecessors(inst_id)) {
                earliest_start = std::max(earliest_start, finish_time[pred]);
            }
            
            // 检查资源冲突
            int start_cycle = resource_table.findAvailableSlot(
                instructions[inst_id].resources, 
                earliest_start,
                instructions[inst_id].cycle_end - instructions[inst_id].cycle_start
            );
            
            // 分配资源并调度
            instructions[inst_id].cycle_start = start_cycle;
            instructions[inst_id].cycle_end = start_cycle + 
                (instructions[inst_id].cycle_end - instructions[inst_id].cycle_start);
            
            resource_table.allocate(instructions[inst_id]);
            scheduled[inst_id] = true;
            finish_time[inst_id] = instructions[inst_id].cycle_end;
            
            // 更新就绪队列
            for (int succ : dep_graph.getSuccessors(inst_id)) {
                bool ready = true;
                for (int pred : dep_graph.getPredecessors(succ)) {
                    if (!scheduled[pred]) {
                        ready = false;
                        break;
                    }
                }
                if (ready) {
                    ready_queue.push(succ);
                }
            }
        }
        
        return instructions;
    }
};
            </div>

            <h4>10.4.2 指令级优化</h4>
            <div class="warning-box">
                <p><strong>NPU指令优化技术：</strong></p>
                <ul>
                    <li><strong>指令合并：</strong>将多个简单指令合并为复合指令</li>
                    <li><strong>软件流水线：</strong>重叠不同迭代的指令执行</li>
                    <li><strong>双缓冲：</strong>计算与数据传输并行</li>
                    <li><strong>向量化：</strong>利用SIMD指令处理多个数据</li>
                </ul>
            </div>

            <h3>10.5 量化与精度优化</h3>
            
            <p>量化是将浮点模型转换为低精度定点模型的过程，对于NPU的性能和功耗优化至关重要。现代NPU通常支持INT8甚至INT4计算，相比FP32可以提供4-8倍的性能提升。</p>

            <h4>10.5.1 量化技术分类</h4>
            <div class="info-box">
                <p><strong>主流量化技术对比：</strong></p>
                <table>
                    <tr>
                        <th>量化方法</th>
                        <th>优点</th>
                        <th>缺点</th>
                        <th>适用场景</th>
                    </tr>
                    <tr>
                        <td>训练后量化（PTQ）</td>
                        <td>• 无需重新训练<br>• 快速部署<br>• 只需少量校准数据</td>
                        <td>• 精度损失较大<br>• 对异常值敏感</td>
                        <td>• 精度要求不高的场景<br>• 快速原型验证</td>
                    </tr>
                    <tr>
                        <td>量化感知训练（QAT）</td>
                        <td>• 精度损失小<br>• 可以学习量化友好的权重</td>
                        <td>• 需要完整训练流程<br>• 训练时间长</td>
                        <td>• 高精度要求场景<br>• 量产部署</td>
                    </tr>
                    <tr>
                        <td>混合精度量化</td>
                        <td>• 平衡精度和性能<br>• 灵活性高</td>
                        <td>• 需要逐层分析<br>• 硬件支持复杂</td>
                        <td>• 大型模型<br>• 精度敏感层保护</td>
                    </tr>
                </table>
            </div>

            <h4>10.5.2 训练后量化（PTQ）实现</h4>
            <div class="code-block">
// PTQ实现示例
class PostTrainingQuantization {
public:
    // 校准阶段：收集统计信息
    void calibrate(Model& model, DataLoader& calibration_data) {
        model.eval();  // 设置为评估模式
        
        // 为每层创建统计收集器
        map<string, StatsCollector> layer_stats;
        
        // 运行校准数据
        for (auto& batch : calibration_data) {
            auto activations = model.forward(batch);
            
            // 收集每层的激活值统计
            for (auto& [layer_name, tensor] : activations) {
                layer_stats[layer_name].update(tensor);
            }
        }
        
        // 计算量化参数
        for (auto& [layer_name, stats] : layer_stats) {
            auto quant_params = calculateQuantParams(stats);
            model.setQuantParams(layer_name, quant_params);
        }
    }
    
    // 量化参数计算策略
    QuantParams calculateQuantParams(const StatsCollector& stats) {
        QuantParams params;
        
        if (use_percentile) {
            // 百分位数方法：去除异常值影响
            float min_val = stats.getPercentile(0.1);   // 0.1%
            float max_val = stats.getPercentile(99.9);  // 99.9%
            
            params.scale = (max_val - min_val) / 255.0f;
            params.zero_point = round(-min_val / params.scale);
        } else if (use_mse) {
            // 最小化MSE方法：找到最优的scale和zero_point
            auto [scale, zp] = optimizeQuantParamsMSE(stats.getData());
            params.scale = scale;
            params.zero_point = zp;
        } else {
            // 简单最大最小值方法
            params.scale = (stats.max - stats.min) / 255.0f;
            params.zero_point = round(-stats.min / params.scale);
        }
        
        return params;
    }
    
private:
    // MSE优化：通过网格搜索找到最佳量化参数
    pair<float, int> optimizeQuantParamsMSE(const vector<float>& data) {
        float best_scale = 1.0f;
        int best_zp = 0;
        float min_error = INFINITY;
        
        // 网格搜索
        for (float scale_factor = 0.8f; scale_factor <= 1.2f; scale_factor += 0.02f) {
            float scale = (max_val - min_val) / 255.0f * scale_factor;
            
            for (int zp_offset = -10; zp_offset <= 10; zp_offset++) {
                int zp = base_zero_point + zp_offset;
                
                // 计算量化误差
                float error = 0;
                for (float val : data) {
                    int q = clamp(round(val / scale + zp), 0, 255);
                    float dq = (q - zp) * scale;
                    error += (val - dq) * (val - dq);
                }
                
                if (error < min_error) {
                    min_error = error;
                    best_scale = scale;
                    best_zp = zp;
                }
            }
        }
        
        return {best_scale, best_zp};
    }
};
            </div>

            <h4>10.5.3 量化感知训练（QAT）实现</h4>
            <div class="code-block">
// 量化框架实现
class QuantizationFramework {
public:
    // 对称量化
    struct SymmetricQuantizer {
        float scale;
        int bit_width;
        
        int quantize(float value) {
            int q_max = (1 << (bit_width - 1)) - 1;
            int q_min = -(1 << (bit_width - 1));
            
            int q_value = std::round(value / scale);
            return std::clamp(q_value, q_min, q_max);
        }
        
        float dequantize(int q_value) {
            return q_value * scale;
        }
        
        // 计算量化参数
        void calibrate(const std::vector<float>& values) {
            float max_abs = 0;
            for (float v : values) {
                max_abs = std::max(max_abs, std::abs(v));
            }
            
            int q_max = (1 << (bit_width - 1)) - 1;
            scale = max_abs / q_max;
        }
    };
    
    // 非对称量化
    struct AsymmetricQuantizer {
        float scale;
        int zero_point;
        int bit_width;
        
        int quantize(float value) {
            int q_max = (1 << bit_width) - 1;
            int q_min = 0;
            
            int q_value = std::round(value / scale + zero_point);
            return std::clamp(q_value, q_min, q_max);
        }
        
        float dequantize(int q_value) {
            return (q_value - zero_point) * scale;
        }
        
        // 计算量化参数
        void calibrate(const std::vector<float>& values) {
            float min_val = *std::min_element(values.begin(), values.end());
            float max_val = *std::max_element(values.begin(), values.end());
            
            int q_max = (1 << bit_width) - 1;
            scale = (max_val - min_val) / q_max;
            zero_point = std::round(-min_val / scale);
        }
    };
    
    // 混合精度量化
    void mixedPrecisionQuantize(Graph& graph) {
        // 敏感度分析
        std::map<std::string, float> layer_sensitivity;
        
        for (auto& layer : graph.layers) {
            // 计算每层对精度的敏感度
            float sensitivity = analyzeSensitivity(layer);
            layer_sensitivity[layer.name] = sensitivity;
        }
        
        // 基于敏感度分配位宽
        for (auto& layer : graph.layers) {
            if (layer_sensitivity[layer.name] > 0.9) {
                layer.quantization_bits = 16;  // 高敏感度层使用高精度
            } else if (layer_sensitivity[layer.name] > 0.5) {
                layer.quantization_bits = 8;
            } else {
                layer.quantization_bits = 4;   // 低敏感度层使用低精度
            }
        }
    }
};
            </div>

            <h4>10.5.2 量化感知训练</h4>
            <div class="code-block">
// 量化感知训练（QAT）实现
class QuantizationAwareTraining {
public:
    // 伪量化操作
    class FakeQuantize : public torch::nn::Module {
    public:
        FakeQuantize(int num_bits, bool symmetric = true) 
            : num_bits_(num_bits), symmetric_(symmetric) {
            if (symmetric_) {
                q_max_ = (1 << (num_bits_ - 1)) - 1;
                q_min_ = -(1 << (num_bits_ - 1));
            } else {
                q_max_ = (1 << num_bits_) - 1;
                q_min_ = 0;
            }
        }
        
        torch::Tensor forward(torch::Tensor x) {
            // 计算scale和zero_point
            torch::Tensor scale, zero_point;
            
            if (symmetric_) {
                auto max_val = x.abs().max();
                scale = max_val / q_max_;
                zero_point = torch::zeros_like(scale);
            } else {
                auto min_val = x.min();
                auto max_val = x.max();
                scale = (max_val - min_val) / (q_max_ - q_min_);
                zero_point = torch::round(-min_val / scale);
            }
            
            // 量化和反量化
            auto x_int = torch::round(x / scale + zero_point);
            x_int = torch::clamp(x_int, q_min_, q_max_);
            auto x_dequant = (x_int - zero_point) * scale;
            
            // 直通估计器（STE）用于反向传播
            return x + (x_dequant - x).detach();
        }
        
    private:
        int num_bits_;
        bool symmetric_;
        float q_max_, q_min_;
    };
    
    // 量化感知的卷积层
    class QuantizedConv2d : public torch::nn::Module {
    public:
        QuantizedConv2d(int in_channels, int out_channels, 
                       int kernel_size, int weight_bits = 8, 
                       int activation_bits = 8) {
            conv_ = torch::nn::Conv2d(
                torch::nn::Conv2dOptions(in_channels, out_channels, kernel_size)
            );
            
            weight_quantizer_ = FakeQuantize(weight_bits, true);
            activation_quantizer_ = FakeQuantize(activation_bits, false);
            
            register_module("conv", conv_);
        }
        
        torch::Tensor forward(torch::Tensor x) {
            // 量化输入激活
            x = activation_quantizer_->forward(x);
            
            // 量化权重
            auto quantized_weight = weight_quantizer_->forward(conv_->weight);
            
            // 执行量化卷积
            return torch::nn::functional::conv2d(
                x, quantized_weight, conv_->bias,
                conv_->options.stride(),
                conv_->options.padding()
            );
        }
        
    private:
        torch::nn::Conv2d conv_{nullptr};
        std::shared_ptr<FakeQuantize> weight_quantizer_;
        std::shared_ptr<FakeQuantize> activation_quantizer_;
    };
};
            </div>

            <h3>10.6 运行时系统设计</h3>
            
            <p>运行时系统（Runtime System）是NPU软件栈的执行引擎，负责将编译器生成的指令序列高效地在硬件上执行。一个优秀的运行时需要处理设备管理、内存管理、任务调度、同步控制等复杂任务。</p>

            <h4>10.6.1 运行时核心职责</h4>
            <div class="info-box">
                <p><strong>NPU运行时的五大核心职责：</strong></p>
                <ol>
                    <li><strong>设备管理：</strong>
                        <ul>
                            <li>NPU硬件初始化和状态管理</li>
                            <li>多设备管理和负载均衡</li>
                            <li>异常处理和错误恢复</li>
                        </ul>
                    </li>
                    <li><strong>内存管理：</strong>
                        <ul>
                            <li>设备内存分配和释放</li>
                            <li>主机-设备数据传输（DMA）</li>
                            <li>内存池管理和碎片整理</li>
                        </ul>
                    </li>
                    <li><strong>任务调度：</strong>
                        <ul>
                            <li>指令序列解析和分发</li>
                            <li>多核/多引擎任务调度</li>
                            <li>依赖关系管理</li>
                        </ul>
                    </li>
                    <li><strong>同步控制：</strong>
                        <ul>
                            <li>主机-设备同步</li>
                            <li>设备内部同步（核间同步）</li>
                            <li>异步执行和事件管理</li>
                        </ul>
                    </li>
                    <li><strong>性能监控：</strong>
                        <ul>
                            <li>执行时间统计</li>
                            <li>资源利用率监控</li>
                            <li>性能瓶颈分析</li>
                        </ul>
                    </li>
                </ol>
            </div>

            <h4>10.6.2 运行时API设计</h4>
            <div class="code-block">
// NPU运行时C++ API示例
class NPURuntime {
public:
    // 1. 设备管理API
    struct DeviceInfo {
        int device_id;
        string device_name;
        size_t memory_size;
        int compute_units;
        float peak_tflops;
    };
    
    static int getDeviceCount();
    static DeviceInfo getDeviceInfo(int device_id);
    void setDevice(int device_id);
    
    // 2. 内存管理API
    class DeviceMemory {
    public:
        void* allocate(size_t size, size_t alignment = 64);
        void free(void* ptr);
        void copyHostToDevice(void* dst, const void* src, size_t size);
        void copyDeviceToHost(void* dst, const void* src, size_t size);
        void copyDeviceToDevice(void* dst, const void* src, size_t size);
        
        // 异步版本
        void copyHostToDeviceAsync(void* dst, const void* src, size_t size, Stream& stream);
    };
    
    // 3. 模型加载与执行API
    class Model {
    public:
        // 加载编译后的模型
        static unique_ptr<Model> load(const string& model_path);
        
        // 获取输入输出信息
        int getNumInputs() const;
        int getNumOutputs() const;
        TensorInfo getInputInfo(int index) const;
        TensorInfo getOutputInfo(int index) const;
        
        // 设置输入
        void setInput(int index, const Tensor& tensor);
        
        // 执行推理
        void run();                    // 同步执行
        Future<void> runAsync();       // 异步执行
        
        // 获取输出
        Tensor getOutput(int index);
    };
    
    // 4. 流（Stream）管理 - 用于异步执行
    class Stream {
    public:
        Stream(int priority = 0);
        
        // 在流中执行任务
        void enqueue(function<void()> task);
        
        // 同步点
        void synchronize();           // 等待流中所有任务完成
        Event recordEvent();          // 记录事件
        void waitEvent(const Event& event);  // 等待事件
    };
    
    // 5. 性能分析API
    class Profiler {
    public:
        void start();
        void stop();
        
        struct ProfileResult {
            string layer_name;
            float time_ms;
            float memory_mb;
            float utilization;
        };
        
        vector<ProfileResult> getResults();
        void exportTrace(const string& filename);  // 导出Chrome Tracing格式
    };
};

// 使用示例
void example_inference() {
    // 1. 初始化运行时
    NPURuntime runtime;
    runtime.setDevice(0);  // 使用第一个NPU设备
    
    // 2. 加载模型
    auto model = NPURuntime::Model::load("resnet50_compiled.npumodel");
    
    // 3. 准备输入数据
    Tensor input_tensor({1, 3, 224, 224}, DataType::FLOAT32);
    fill_input_data(input_tensor);
    
    // 4. 设置输入
    model->setInput(0, input_tensor);
    
    // 5. 执行推理
    model->run();
    
    // 6. 获取输出
    auto output = model->getOutput(0);
    process_output(output);
}

// 异步执行示例
void example_async_inference() {
    NPURuntime runtime;
    auto model = NPURuntime::Model::load("model.npumodel");
    
    // 创建流
    NPURuntime::Stream stream;
    
    // 异步拷贝输入
    runtime.getMemory().copyHostToDeviceAsync(
        device_input, host_input, input_size, stream
    );
    
    // 异步执行
    auto future = model->runAsync();
    
    // 异步拷贝输出
    runtime.getMemory().copyDeviceToHostAsync(
        host_output, device_output, output_size, stream
    );
    
    // 在需要结果时同步
    stream.synchronize();
    
    // 处理结果
    process_output(host_output);
}
            </div>

            <h4>10.6.3 运行时实现架构</h4>
            <div class="code-block">
// NPU运行时系统
class NPURuntime {
public:
    // 执行上下文
    class ExecutionContext {
    public:
        ExecutionContext(NPUDevice* device) : device_(device) {
            // 初始化内存池
            memory_pool_ = std::make_unique<MemoryPool>(
                device->getMemorySize()
            );
            
            // 创建命令队列
            cmd_queue_ = device->createCommandQueue();
            
            // 初始化性能计数器
            perf_counter_ = std::make_unique<PerformanceCounter>();
        }
        
        // 执行推理
        void execute(const CompiledModel& model, 
                    const std::vector<Tensor>& inputs,
                    std::vector<Tensor>& outputs) {
            // 1. 分配输入/输出内存
            auto input_buffers = allocateBuffers(inputs);
            auto output_buffers = allocateBuffers(model.getOutputShapes());
            
            // 2. 拷贝输入数据到设备
            for (size_t i = 0; i < inputs.size(); i++) {
                device_->copyHostToDevice(
                    inputs[i].data(), 
                    input_buffers[i],
                    inputs[i].size()
                );
            }
            
            // 3. 构建执行命令
            CommandBuffer cmd_buffer;
            buildCommandBuffer(cmd_buffer, model, input_buffers, output_buffers);
            
            // 4. 提交执行
            auto fence = cmd_queue_->submit(cmd_buffer);
            
            // 5. 等待完成
            fence->wait();
            
            // 6. 拷贝输出数据
            outputs.resize(output_buffers.size());
            for (size_t i = 0; i < outputs.size(); i++) {
                outputs[i].resize(model.getOutputShapes()[i]);
                device_->copyDeviceToHost(
                    output_buffers[i],
                    outputs[i].data(),
                    outputs[i].size()
                );
            }
            
            // 7. 更新性能统计
            perf_counter_->update(fence->getTimingInfo());
        }
        
    private:
        NPUDevice* device_;
        std::unique_ptr<MemoryPool> memory_pool_;
        std::unique_ptr<CommandQueue> cmd_queue_;
        std::unique_ptr<PerformanceCounter> perf_counter_;
        
        void buildCommandBuffer(CommandBuffer& cmd_buffer,
                              const CompiledModel& model,
                              const std::vector<DeviceBuffer>& inputs,
                              const std::vector<DeviceBuffer>& outputs) {
            // 遍历所有指令
            for (const auto& inst : model.getInstructions()) {
                switch (inst.opcode) {
                    case OPCODE_CONV:
                        cmd_buffer.addConvCommand(inst.params, 
                            inputs[inst.input_idx],
                            outputs[inst.output_idx]);
                        break;
                    
                    case OPCODE_GEMM:
                        cmd_buffer.addGemmCommand(inst.params,
                            inputs[inst.input_idx],
                            outputs[inst.output_idx]);
                        break;
                    
                    case OPCODE_ACTIVATION:
                        cmd_buffer.addActivationCommand(inst.params,
                            inputs[inst.input_idx],
                            outputs[inst.output_idx]);
                        break;
                    
                    case OPCODE_SYNC:
                        cmd_buffer.addSyncCommand();
                        break;
                }
            }
        }
    };
    
    // 多核调度器
    class MultiCoreScheduler {
    public:
        void scheduleSubgraphs(const Graph& graph, 
                             std::vector<NPUCore*>& cores) {
            // 1. 图分割
            auto subgraphs = partitionGraph(graph, cores.size());
            
            // 2. 负载均衡
            balanceWorkload(subgraphs, cores);
            
            // 3. 生成同步点
            insertSynchronization(subgraphs);
            
            // 4. 分配到各个核心
            for (size_t i = 0; i < cores.size(); i++) {
                cores[i]->loadSubgraph(subgraphs[i]);
            }
        }
        
    private:
        std::vector<Subgraph> partitionGraph(const Graph& graph, int num_cores) {
            // 基于最小割的图分割算法
            GraphPartitioner partitioner;
            return partitioner.partition(graph, num_cores);
        }
        
        void balanceWorkload(std::vector<Subgraph>& subgraphs,
                           const std::vector<NPUCore*>& cores) {
            // 估算每个子图的计算量
            std::vector<float> workloads(subgraphs.size());
            for (size_t i = 0; i < subgraphs.size(); i++) {
                workloads[i] = estimateWorkload(subgraphs[i]);
            }
            
            // 动态调整分割边界
            while (!isBalanced(workloads)) {
                adjustPartitionBoundaries(subgraphs, workloads);
            }
        }
    };
};
            </div>

            <h3>10.7 性能分析与调优</h3>
            
            <p>性能分析工具帮助开发者理解模型在NPU上的执行情况，找出性能瓶颈并进行优化。</p>

            <h4>10.7.1 性能分析框架</h4>
            <div class="code-block">
// 性能分析器
class NPUProfiler {
public:
    struct LayerProfile {
        std::string name;
        float compute_time_ms;
        float memory_read_mb;
        float memory_write_mb;
        float utilization;
        std::map<std::string, float> metrics;
    };
    
    // 开始性能分析
    void startProfiling() {
        // 清空之前的数据
        layer_profiles_.clear();
        
        // 启用硬件性能计数器
        enableHardwareCounters();
        
        // 记录开始时间
        start_time_ = getCurrentTime();
        is_profiling_ = true;
    }
    
    // 记录层执行信息
    void recordLayer(const std::string& layer_name,
                    const ExecutionStats& stats) {
        if (!is_profiling_) return;
        
        LayerProfile profile;
        profile.name = layer_name;
        profile.compute_time_ms = stats.compute_cycles / clock_freq_ * 1000;
        profile.memory_read_mb = stats.memory_read_bytes / (1024.0 * 1024.0);
        profile.memory_write_mb = stats.memory_write_bytes / (1024.0 * 1024.0);
        
        // 计算硬件利用率
        profile.utilization = calculateUtilization(stats);
        
        // 收集详细指标
        profile.metrics["mac_efficiency"] = 
            stats.mac_operations / (stats.compute_cycles * max_mac_per_cycle_);
        profile.metrics["memory_bandwidth_utilization"] = 
            (stats.memory_read_bytes + stats.memory_write_bytes) / 
            (stats.compute_cycles / clock_freq_ * memory_bandwidth_);
        profile.metrics["cache_hit_rate"] = 
            stats.cache_hits / float(stats.cache_hits + stats.cache_misses);
        
        layer_profiles_.push_back(profile);
    }
    
    // 生成性能报告
    void generateReport(const std::string& filename) {
        std::ofstream report(filename);
        
        report << "NPU Performance Analysis Report\n";
        report << "================================\n\n";
        
        // 总体统计
        float total_time = 0;
        float total_memory = 0;
        for (const auto& profile : layer_profiles_) {
            total_time += profile.compute_time_ms;
            total_memory += profile.memory_read_mb + profile.memory_write_mb;
        }
        
        report << "Total Execution Time: " << total_time << " ms\n";
        report << "Total Memory Transfer: " << total_memory << " MB\n";
        report << "Average Throughput: " << 
                  (total_ops_ / total_time / 1e6) << " GOPS\n\n";
        
        // 层级详细信息
        report << "Layer-wise Breakdown:\n";
        report << std::setw(30) << "Layer" 
               << std::setw(15) << "Time (ms)"
               << std::setw(15) << "Time %"
               << std::setw(15) << "Utilization"
               << std::setw(20) << "Memory (MB)\n";
        
        for (const auto& profile : layer_profiles_) {
            report << std::setw(30) << profile.name
                   << std::setw(15) << std::fixed << std::setprecision(2) 
                   << profile.compute_time_ms
                   << std::setw(15) << std::fixed << std::setprecision(1)
                   << (profile.compute_time_ms / total_time * 100) << "%"
                   << std::setw(15) << std::fixed << std::setprecision(1)
                   << (profile.utilization * 100) << "%"
                   << std::setw(20) << std::fixed << std::setprecision(2)
                   << (profile.memory_read_mb + profile.memory_write_mb) << "\n";
        }
        
        // 性能瓶颈分析
        report << "\nPerformance Bottlenecks:\n";
        identifyBottlenecks(report);
        
        // 优化建议
        report << "\nOptimization Suggestions:\n";
        generateOptimizationSuggestions(report);
    }
    
private:
    std::vector<LayerProfile> layer_profiles_;
    bool is_profiling_ = false;
    double start_time_;
    float clock_freq_;
    float memory_bandwidth_;
    int max_mac_per_cycle_;
    int64_t total_ops_;
    
    void identifyBottlenecks(std::ofstream& report) {
        // 找出执行时间最长的层
        auto max_time_layer = std::max_element(
            layer_profiles_.begin(), layer_profiles_.end(),
            [](const LayerProfile& a, const LayerProfile& b) {
                return a.compute_time_ms < b.compute_time_ms;
            });
        
        report << "- Slowest layer: " << max_time_layer->name 
               << " (" << max_time_layer->compute_time_ms << " ms)\n";
        
        // 找出内存带宽受限的层
        for (const auto& profile : layer_profiles_) {
            if (profile.metrics.at("memory_bandwidth_utilization") > 0.8) {
                report << "- Memory bandwidth bottleneck in layer: " 
                       << profile.name << "\n";
            }
        }
        
        // 找出利用率低的层
        for (const auto& profile : layer_profiles_) {
            if (profile.utilization < 0.5) {
                report << "- Low utilization in layer: " << profile.name 
                       << " (" << (profile.utilization * 100) << "%)\n";
            }
        }
    }
};
            </div>

            <div class="exercise">
                <h4>练习题集 10</h4>
                
                <div class="question">
                    <p><strong>题目10.1：</strong>解释算子融合的原理，并举例说明Conv+BN+ReLU融合能带来多少内存访问的节省。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：算子融合避免了中间结果的存储。分别计算未融合时每个算子的输入输出内存访问量，然后计算融合后的访问量。Conv输出→BN输入、BN输出→ReLU输入这些中间结果可以保持在片上。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p>算子融合原理：将多个连续的算子合并为一个复合算子，在片上完成所有计算，避免中间结果写回内存。</p>
                        
                        <p>Conv+BN+ReLU融合的内存访问分析：</p>
                        <p>假设特征图大小为H×W×C，数据类型为FP16（2字节）</p>
                        
                        <p><strong>未融合时：</strong></p>
                        <ul>
                            <li>Conv输出写内存：H×W×C×2 字节</li>
                            <li>BN读Conv输出：H×W×C×2 字节</li>
                            <li>BN输出写内存：H×W×C×2 字节</li>
                            <li>ReLU读BN输出：H×W×C×2 字节</li>
                            <li>ReLU输出写内存：H×W×C×2 字节</li>
                            <li>总计：5×H×W×C×2 字节</li>
                        </ul>
                        
                        <p><strong>融合后：</strong></p>
                        <ul>
                            <li>只有最终结果写内存：H×W×C×2 字节</li>
                            <li>节省：80%的内存访问</li>
                        </ul>
                        
                        <p>实际例子：224×224×64的特征图，可节省约24.5MB的内存访问。</p>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目10.2：</strong>设计一个简单的内存分配算法，支持tensor的生命周期管理和内存复用。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：跟踪每个tensor的创建和最后使用时间。使用空闲列表管理可复用的内存块。考虑内存对齐和碎片化问题。可以使用图着色算法来最小化内存使用。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
class SimpleMemoryAllocator {
private:
    struct Allocation {
        size_t offset;
        size_t size;
        int start_time;
        int end_time;
    };
    
    size_t total_size;
    std::vector<Allocation> allocations;
    
public:
    SimpleMemoryAllocator(size_t size) : total_size(size) {}
    
    size_t allocate(size_t size, int start, int end) {
        // 按结束时间排序现有分配
        std::sort(allocations.begin(), allocations.end(),
            [](const Allocation& a, const Allocation& b) {
                return a.end_time < b.end_time;
            });
        
        // 尝试找到可复用的内存块
        for (auto& alloc : allocations) {
            if (alloc.end_time <= start && alloc.size >= size) {
                // 复用这块内存
                size_t offset = alloc.offset;
                alloc.start_time = start;
                alloc.end_time = end;
                alloc.size = size;
                return offset;
            }
        }
        
        // 找不到可复用的，分配新的
        size_t offset = 0;
        if (!allocations.empty()) {
            // 找到第一个空闲位置
            std::sort(allocations.begin(), allocations.end(),
                [](const Allocation& a, const Allocation& b) {
                    return a.offset < b.offset;
                });
            
            for (size_t i = 0; i < allocations.size(); i++) {
                if (i == 0 && allocations[i].offset >= size) {
                    offset = 0;
                    break;
                }
                if (i < allocations.size() - 1) {
                    size_t gap_start = allocations[i].offset + allocations[i].size;
                    size_t gap_end = allocations[i+1].offset;
                    if (gap_end - gap_start >= size) {
                        offset = gap_start;
                        break;
                    }
                } else {
                    offset = allocations[i].offset + allocations[i].size;
                }
            }
        }
        
        // 检查是否超出总内存
        if (offset + size > total_size) {
            throw std::runtime_error("Out of memory");
        }
        
        allocations.push_back({offset, size, start, end});
        return offset;
    }
    
    size_t getMaxMemoryUsage() {
        size_t max_usage = 0;
        
        // 对每个时间点计算内存使用
        std::set<int> time_points;
        for (const auto& alloc : allocations) {
            time_points.insert(alloc.start_time);
            time_points.insert(alloc.end_time);
        }
        
        for (int t : time_points) {
            size_t usage = 0;
            for (const auto& alloc : allocations) {
                if (alloc.start_time <= t && t < alloc.end_time) {
                    usage = std::max(usage, alloc.offset + alloc.size);
                }
            }
            max_usage = std::max(max_usage, usage);
        }
        
        return max_usage;
    }
};
                        </div>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目10.3：</strong>实现一个简单的INT8量化函数，支持对称和非对称量化模式。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：对称量化：zero_point=0，范围[-127,127]。非对称量化：有zero_point，范围[0,255]。量化公式：q = round(x/scale) + zero_point。反量化：x = (q - zero_point) * scale。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
#include <vector>
#include <algorithm>
#include <cmath>

class INT8Quantizer {
public:
    enum Mode { SYMMETRIC, ASYMMETRIC };
    
private:
    Mode mode;
    float scale;
    int zero_point;
    
public:
    INT8Quantizer(Mode m = SYMMETRIC) : mode(m), scale(1.0f), zero_point(0) {}
    
    // 校准：计算量化参数
    void calibrate(const std::vector<float>& data) {
        if (data.empty()) return;
        
        float min_val = *std::min_element(data.begin(), data.end());
        float max_val = *std::max_element(data.begin(), data.end());
        
        if (mode == SYMMETRIC) {
            // 对称量化：zero_point = 0
            float max_abs = std::max(std::abs(min_val), std::abs(max_val));
            scale = max_abs / 127.0f;
            zero_point = 0;
        } else {
            // 非对称量化
            scale = (max_val - min_val) / 255.0f;
            zero_point = std::round(-min_val / scale);
            zero_point = std::clamp(zero_point, 0, 255);
        }
    }
    
    // 量化单个值
    int8_t quantize(float value) const {
        int quantized = std::round(value / scale + zero_point);
        
        if (mode == SYMMETRIC) {
            return static_cast<int8_t>(std::clamp(quantized, -128, 127));
        } else {
            // 非对称量化结果需要转换到int8范围
            quantized = std::clamp(quantized, 0, 255);
            return static_cast<int8_t>(quantized - 128);
        }
    }
    
    // 反量化
    float dequantize(int8_t qvalue) const {
        if (mode == SYMMETRIC) {
            return qvalue * scale;
        } else {
            // 非对称量化需要先转换回uint8范围
            int value = static_cast<int>(qvalue) + 128;
            return (value - zero_point) * scale;
        }
    }
    
    // 量化向量
    std::vector<int8_t> quantizeVector(const std::vector<float>& input) const {
        std::vector<int8_t> output(input.size());
        for (size_t i = 0; i < input.size(); i++) {
            output[i] = quantize(input[i]);
        }
        return output;
    }
    
    // 计算量化误差
    float calculateError(const std::vector<float>& original) const {
        float total_error = 0;
        for (float val : original) {
            float dequantized = dequantize(quantize(val));
            total_error += std::pow(val - dequantized, 2);
        }
        return std::sqrt(total_error / original.size());
    }
    
    // 获取量化参数
    float getScale() const { return scale; }
    int getZeroPoint() const { return zero_point; }
};

// 使用示例
void testQuantization() {
    std::vector<float> weights = {-1.5, -0.5, 0.0, 0.5, 1.5, 2.0};
    
    // 对称量化
    INT8Quantizer sym_quantizer(INT8Quantizer::SYMMETRIC);
    sym_quantizer.calibrate(weights);
    
    std::cout << "Symmetric Quantization:\n";
    std::cout << "Scale: " << sym_quantizer.getScale() << "\n";
    for (float w : weights) {
        int8_t q = sym_quantizer.quantize(w);
        float dq = sym_quantizer.dequantize(q);
        std::cout << w << " -> " << (int)q << " -> " << dq << "\n";
    }
    
    // 非对称量化
    INT8Quantizer asym_quantizer(INT8Quantizer::ASYMMETRIC);
    asym_quantizer.calibrate(weights);
    
    std::cout << "\nAsymmetric Quantization:\n";
    std::cout << "Scale: " << asym_quantizer.getScale() 
              << ", Zero Point: " << asym_quantizer.getZeroPoint() << "\n";
    for (float w : weights) {
        int8_t q = asym_quantizer.quantize(w);
        float dq = asym_quantizer.dequantize(q);
        std::cout << w << " -> " << (int)q << " -> " << dq << "\n";
    }
}
                        </div>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目10.4：</strong>设计一个简单的指令调度算法，考虑数据依赖和硬件资源限制。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：构建依赖图（DAG）。使用拓扑排序找到可执行指令。考虑资源约束（MAC单元、内存带宽）。优先级可以基于关键路径或资源利用率。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
#include <vector>
#include <queue>
#include <unordered_set>

class SimpleScheduler {
public:
    struct Instruction {
        int id;
        std::string type;  // "LOAD", "COMPUTE", "STORE"
        std::vector<int> dependencies;
        int cycles;        // 执行所需周期数
        int resource;      // 所需资源类型
    };
    
    struct ScheduledInst {
        int id;
        int start_cycle;
        int end_cycle;
    };
    
private:
    // 资源使用表
    std::vector<std::vector<bool>> resource_table;
    int num_resources;
    int max_cycles;
    
public:
    SimpleScheduler(int resources, int cycles) 
        : num_resources(resources), max_cycles(cycles) {
        resource_table.resize(resources, std::vector<bool>(cycles, false));
    }
    
    std::vector<ScheduledInst> schedule(const std::vector<Instruction>& instructions) {
        std::vector<ScheduledInst> result;
        std::vector<int> finish_time(instructions.size(), -1);
        std::vector<bool> scheduled(instructions.size(), false);
        
        // 构建依赖关系图
        std::vector<std::vector<int>> dependents(instructions.size());
        std::vector<int> in_degree(instructions.size(), 0);
        
        for (size_t i = 0; i < instructions.size(); i++) {
            in_degree[i] = instructions[i].dependencies.size();
            for (int dep : instructions[i].dependencies) {
                dependents[dep].push_back(i);
            }
        }
        
        // 初始化就绪队列（使用贪心策略：优先调度执行时间长的）
        auto cmp = [&](int a, int b) {
            return instructions[a].cycles < instructions[b].cycles;
        };
        std::priority_queue<int, std::vector<int>, decltype(cmp)> ready_queue(cmp);
        
        // 将无依赖的指令加入就绪队列
        for (size_t i = 0; i < instructions.size(); i++) {
            if (in_degree[i] == 0) {
                ready_queue.push(i);
            }
        }
        
        // 调度主循环
        while (!ready_queue.empty()) {
            int inst_id = ready_queue.top();
            ready_queue.pop();
            
            const auto& inst = instructions[inst_id];
            
            // 计算最早开始时间
            int earliest_start = 0;
            for (int dep : inst.dependencies) {
                if (finish_time[dep] != -1) {
                    earliest_start = std::max(earliest_start, finish_time[dep]);
                }
            }
            
            // 找到可用的资源时间槽
            int start_cycle = findAvailableSlot(inst.resource, 
                                               earliest_start, 
                                               inst.cycles);
            
            if (start_cycle == -1 || start_cycle + inst.cycles > max_cycles) {
                // 资源不足或超出最大周期限制
                continue;
            }
            
            // 分配资源
            for (int c = start_cycle; c < start_cycle + inst.cycles; c++) {
                resource_table[inst.resource][c] = true;
            }
            
            // 记录调度结果
            finish_time[inst_id] = start_cycle + inst.cycles;
            scheduled[inst_id] = true;
            result.push_back({inst_id, start_cycle, start_cycle + inst.cycles});
            
            // 更新依赖关系，将新的就绪指令加入队列
            for (int dependent : dependents[inst_id]) {
                in_degree[dependent]--;
                if (in_degree[dependent] == 0) {
                    ready_queue.push(dependent);
                }
            }
        }
        
        return result;
    }
    
private:
    int findAvailableSlot(int resource, int start_time, int duration) {
        for (int t = start_time; t <= max_cycles - duration; t++) {
            bool available = true;
            for (int d = 0; d < duration; d++) {
                if (resource_table[resource][t + d]) {
                    available = false;
                    break;
                }
            }
            if (available) {
                return t;
            }
        }
        return -1;
    }
};

// 使用示例
void testScheduler() {
    SimpleScheduler scheduler(3, 20);  // 3个资源，20个周期
    
    std::vector<SimpleScheduler::Instruction> instructions = {
        {0, "LOAD", {}, 2, 0},          // 加载数据
        {1, "LOAD", {}, 2, 0},          // 加载权重
        {2, "COMPUTE", {0, 1}, 5, 1},   // 计算，依赖0和1
        {3, "COMPUTE", {0, 1}, 5, 1},   // 并行计算
        {4, "STORE", {2}, 2, 2},        // 存储结果
        {5, "STORE", {3}, 2, 2}         // 存储结果
    };
    
    auto scheduled = scheduler.schedule(instructions);
    
    std::cout << "Scheduled Instructions:\n";
    for (const auto& s : scheduled) {
        std::cout << "Instruction " << s.id 
                  << ": Cycle " << s.start_cycle 
                  << " - " << s.end_cycle << "\n";
    }
}
                        </div>
                    </div>
                </div>

                <div class="question">
                    <p><strong>题目10.5：</strong>分析并优化一个简单的神经网络层在NPU上的内存访问模式。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：分析数据复用机会（输入、权重、输出）。考虑tiling策略来适应片上内存大小。计算内存带宽需求和计算强度。优化数据布局减少bank冲突。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p>以1×1卷积层为例（通常用于通道数变换）：</p>
                        
                        <p><strong>原始实现的内存访问模式：</strong></p>
                        <div class="code-block">
// 朴素实现
for (int n = 0; n < N; n++) {           // batch
    for (int oc = 0; oc < C_out; oc++) { // 输出通道
        for (int h = 0; h < H; h++) {     // 高度
            for (int w = 0; w < W; w++) { // 宽度
                float sum = 0;
                for (int ic = 0; ic < C_in; ic++) { // 输入通道
                    sum += input[n][ic][h][w] * weight[oc][ic];
                }
                output[n][oc][h][w] = sum;
            }
        }
    }
}

// 内存访问分析：
// - Input: 每个元素被读取C_out次
// - Weight: 每个元素被读取N×H×W次
// - 缓存不友好：跳跃式访问input的通道维度
                        </div>
                        
                        <p><strong>优化后的实现：</strong></p>
                        <div class="code-block">
// 优化1：循环重排序，提高数据局部性
for (int n = 0; n < N; n++) {
    for (int h = 0; h < H; h++) {
        for (int w = 0; w < W; w++) {
            // 将输入数据加载到本地缓存
            float local_input[C_in];
            for (int ic = 0; ic < C_in; ic++) {
                local_input[ic] = input[n][ic][h][w];
            }
            
            // 计算所有输出通道
            for (int oc = 0; oc < C_out; oc++) {
                float sum = 0;
                // 向量化计算
                #pragma unroll 8
                for (int ic = 0; ic < C_in; ic++) {
                    sum += local_input[ic] * weight[oc][ic];
                }
                output[n][oc][h][w] = sum;
            }
        }
    }
}

// 优化2：分块（tiling）处理
const int TILE_H = 8, TILE_W = 8, TILE_OC = 32;

for (int n = 0; n < N; n++) {
    for (int h_tile = 0; h_tile < H; h_tile += TILE_H) {
        for (int w_tile = 0; w_tile < W; w_tile += TILE_W) {
            for (int oc_tile = 0; oc_tile < C_out; oc_tile += TILE_OC) {
                // 预加载权重到片上缓存
                float local_weight[TILE_OC][C_in];
                for (int oc = 0; oc < TILE_OC && oc_tile + oc < C_out; oc++) {
                    for (int ic = 0; ic < C_in; ic++) {
                        local_weight[oc][ic] = weight[oc_tile + oc][ic];
                    }
                }
                
                // 处理tile内的计算
                for (int h = 0; h < TILE_H && h_tile + h < H; h++) {
                    for (int w = 0; w < TILE_W && w_tile + w < W; w++) {
                        // 加载输入到寄存器
                        float local_input[C_in];
                        for (int ic = 0; ic < C_in; ic++) {
                            local_input[ic] = input[n][ic][h_tile + h][w_tile + w];
                        }
                        
                        // 计算输出
                        for (int oc = 0; oc < TILE_OC && oc_tile + oc < C_out; oc++) {
                            float sum = 0;
                            for (int ic = 0; ic < C_in; ic++) {
                                sum += local_input[ic] * local_weight[oc][ic];
                            }
                            output[n][oc_tile + oc][h_tile + h][w_tile + w] = sum;
                        }
                    }
                }
            }
        }
    }
}
                        </div>
                        
                        <p><strong>优化效果分析：</strong></p>
                        <ul>
                            <li>输入数据复用：从C_out次降低到C_out/TILE_OC次</li>
                            <li>权重数据复用：在每个tile内复用TILE_H×TILE_W次</li>
                            <li>缓存友好：连续访问，提高缓存命中率</li>
                            <li>向量化友好：内层循环可以SIMD并行</li>
                        </ul>
                    </div>
                </div>
                
                <div class="question">
                    <p><strong>题目10.6：</strong>设计一个NPU软件栈的架构，包含从AI框架到硬件指令的完整流程。说明每层的主要功能和接口。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：参考编译器的分层设计。前端解析框架模型，中间表示进行各种优化，后端生成目标代码。每层之间通过定义良好的IR传递信息。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p>NPU软件栈架构设计：</p>
                        
                        <div class="code-block">
// 1. 框架适配层
class FrameworkAdapter {
    // 支持TensorFlow、PyTorch、ONNX等
    Graph parseModel(string model_path) {
        if (model_path.endswith(".pb")) {
            return parseTensorFlow(model_path);
        } else if (model_path.endswith(".onnx")) {
            return parseONNX(model_path);
        }
        // 统一转换为内部图表示
    }
};

// 2. 高层IR（图级优化）
class HighLevelOptimizer {
    void optimize(Graph& graph) {
        // 算子融合：Conv+BN+ReLU
        fuseOperators(graph);
        // 常量折叠
        foldConstants(graph);
        // 死代码消除
        eliminateDeadCode(graph);
        // 代数简化
        algebraicSimplification(graph);
    }
};

// 3. 中层IR（算子级优化）
class OperatorOptimizer {
    void optimize(Graph& graph) {
        // 数据布局优化
        optimizeDataLayout(graph);
        // Tiling策略
        applyTiling(graph);
        // 并行化分析
        analyzeParallelism(graph);
    }
};

// 4. 低层IR（指令生成）
class CodeGenerator {
    Program generate(Graph& graph) {
        // 内存分配
        allocateMemory(graph);
        // 指令调度
        scheduleInstructions(graph);
        // 寄存器分配
        allocateRegisters(graph);
        // 生成二进制代码
        return generateBinary(graph);
    }
};
                        </div>
                    </div>
                </div>
                
                <div class="question">
                    <p><strong>题目10.7：</strong>比较训练后量化（PTQ）和量化感知训练（QAT）的优缺点，并给出选择建议。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：PTQ不需要重新训练，但精度损失可能较大。QAT需要重新训练，但可以获得更好的精度。考虑部署场景、精度要求、计算资源等因素。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p>PTQ vs QAT比较：</p>
                        
                        <table>
                            <tr>
                                <th>特性</th>
                                <th>训练后量化（PTQ）</th>
                                <th>量化感知训练（QAT）</th>
                            </tr>
                            <tr>
                                <td>实现复杂度</td>
                                <td>简单，不需要修改训练代码</td>
                                <td>复杂，需要修改训练流程</td>
                            </tr>
                            <tr>
                                <td>时间成本</td>
                                <td>快速，只需要校准数据集</td>
                                <td>慢，需要完整训练过程</td>
                            </tr>
                            <tr>
                                <td>精度损失</td>
                                <td>较大，特别是低比特量化</td>
                                <td>较小，模型学习适应量化</td>
                            </tr>
                            <tr>
                                <td>适用场景</td>
                                <td>8bit量化、精度要求不高</td>
                                <td>4bit或更低、精度要求高</td>
                            </tr>
                            <tr>
                                <td>硬件要求</td>
                                <td>推理硬件即可</td>
                                <td>需要训练硬件（GPU）</td>
                            </tr>
                        </table>
                        
                        <p><strong>选择建议：</strong></p>
                        <ul>
                            <li>ResNet等CNN网络：PTQ通常足够（8bit精度损失<1%）</li>
                            <li>MobileNet等轻量网络：建议QAT（对量化更敏感）</li>
                            <li>Transformer类模型：混合策略（权重PTQ，激活值QAT）</li>
                            <li>部署受限场景（4bit或更低）：必须使用QAT</li>
                        </ul>
                    </div>
                </div>
                
                <div class="question">
                    <p><strong>题目10.8：</strong>实现一个简单的内存访问优化算法，通过数据重排减少cache miss。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：分析数据访问模式，识别stride访问。通过数据重排让访问变为连续。考虑cache line大小（通常64字节）。使用循环交换、数据打包等技术。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <div class="code-block">
// 内存访问优化器
class MemoryAccessOptimizer {
    // 分析访问模式
    struct AccessPattern {
        int stride;         // 访问步长
        int frequency;      // 访问频率
        int data_size;      // 数据大小
        bool is_sequential; // 是否顺序访问
    };
    
    // 数据重排算法
    void optimizeDataLayout(float* data, int N, int C, int H, int W) {
        // 原始布局：NCHW
        // 如果发现频繁访问不同通道的相同位置
        // 转换为NHWC布局
        
        float* temp = new float[N * C * H * W];
        
        // NCHW -> NHWC转换
        for (int n = 0; n < N; n++) {
            for (int h = 0; h < H; h++) {
                for (int w = 0; w < W; w++) {
                    for (int c = 0; c < C; c++) {
                        // 新索引计算
                        int old_idx = n*C*H*W + c*H*W + h*W + w;
                        int new_idx = n*H*W*C + h*W*C + w*C + c;
                        temp[new_idx] = data[old_idx];
                    }
                }
            }
        }
        
        memcpy(data, temp, N*C*H*W*sizeof(float));
        delete[] temp;
    }
    
    // Cache预取优化
    void insertPrefetch(void* addr, int distance) {
        #ifdef __x86_64__
        __builtin_prefetch(addr + distance, 0, 3);
        #endif
    }
    
    // 循环分块优化
    void tiledAccess(float* matrix, int M, int N) {
        const int TILE = 64;  // Cache line size
        
        for (int i0 = 0; i0 < M; i0 += TILE) {
            for (int j0 = 0; j0 < N; j0 += TILE) {
                // 在tile内顺序访问
                for (int i = i0; i < min(i0+TILE, M); i++) {
                    for (int j = j0; j < min(j0+TILE, N); j++) {
                        process(matrix[i*N + j]);
                    }
                }
            }
        }
    }
};
                        </div>
                    </div>
                </div>
                
                <div class="question">
                    <p><strong>题目10.9：</strong>设计一个NPU运行时的API，支持模型加载、输入输出管理、异步执行等功能。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：参考TensorRT、ONNX Runtime等推理框架的API设计。考虑易用性、性能、错误处理。支持批处理、流式执行、多模型并发等高级特性。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <div class="code-block">
// NPU运行时API设计
class NPURuntime {
public:
    // 初始化运行时
    static NPURuntime* create(const Config& config) {
        auto runtime = new NPURuntime();
        runtime->initialize(config);
        return runtime;
    }
    
    // 模型管理
    class Model {
    public:
        // 从文件加载模型
        static Model* load(const string& path, 
                          const ModelConfig& config = {}) {
            auto model = new Model();
            model->loadFromFile(path);
            model->compile(config);
            return model;
        }
        
        // 获取输入输出信息
        vector<TensorInfo> getInputs() const;
        vector<TensorInfo> getOutputs() const;
        
        // 创建执行会话
        Session* createSession(const SessionConfig& config = {});
    };
    
    // 执行会话
    class Session {
    public:
        // 同步执行
        Status run(const vector<Tensor>& inputs,
                  vector<Tensor>& outputs) {
            // 验证输入
            if (!validateInputs(inputs)) {
                return Status::INVALID_INPUT;
            }
            
            // 分配输出
            allocateOutputs(outputs);
            
            // 执行推理
            return executeSync(inputs, outputs);
        }
        
        // 异步执行
        Future<Status> runAsync(const vector<Tensor>& inputs,
                               vector<Tensor>& outputs) {
            return std::async(std::launch::async, [=]() {
                return run(inputs, outputs);
            });
        }
        
        // 批处理执行
        Status runBatch(const vector<vector<Tensor>>& batch_inputs,
                       vector<vector<Tensor>>& batch_outputs) {
            // 动态批处理优化
            return executeBatch(batch_inputs, batch_outputs);
        }
        
        // 流式执行
        class Stream {
            queue<Task> task_queue;
            thread worker;
            
        public:
            void enqueue(const vector<Tensor>& inputs,
                        function<void(vector<Tensor>&)> callback) {
                task_queue.push({inputs, callback});
            }
        };
    };
    
    // 内存管理
    class MemoryPool {
    public:
        Tensor allocate(const TensorInfo& info) {
            return Tensor(allocateBuffer(info.size), info);
        }
        
        void deallocate(Tensor& tensor) {
            releaseBuffer(tensor.data());
        }
    };
    
    // 性能分析
    class Profiler {
    public:
        void start() { profiling = true; }
        void stop() { profiling = false; }
        Report getReport() const;
    };
};

// 使用示例
void example() {
    // 创建运行时
    auto runtime = NPURuntime::create({
        .device_id = 0,
        .memory_limit = 4_GB
    });
    
    // 加载模型
    auto model = runtime->loadModel("model.npubin", {
        .optimization_level = 3,
        .precision = Precision::INT8
    });
    
    // 创建会话
    auto session = model->createSession({
        .max_batch_size = 32,
        .enable_profiling = true
    });
    
    // 准备输入
    vector<Tensor> inputs = {
        runtime->allocate({1, 3, 224, 224})
    };
    
    // 执行推理
    vector<Tensor> outputs;
    auto status = session->run(inputs, outputs);
    
    if (status == Status::SUCCESS) {
        // 处理输出
        processResults(outputs);
    }
}
                        </div>
                    </div>
                </div>
                
                <div class="question">
                    <p><strong>题目10.10：</strong>分析NCHW和NHWC两种数据布局在NPU上的性能差异，并给出选择建议。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：NCHW适合卷积的向量化计算，NHWC适合depthwise卷积。考虑不同算子的访问模式、向量化能力、内存带宽利用率。现代NPU可能有专门的布局转换单元。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <p><strong>答案：</strong></p>
                        <p>NCHW vs NHWC性能分析：</p>
                        
                        <table>
                            <tr>
                                <th>算子类型</th>
                                <th>NCHW性能</th>
                                <th>NHWC性能</th>
                                <th>原因分析</th>
                            </tr>
                            <tr>
                                <td>标准卷积</td>
                                <td>优秀</td>
                                <td>良好</td>
                                <td>NCHW可以向量化处理整个通道</td>
                            </tr>
                            <tr>
                                <td>Depthwise卷积</td>
                                <td>较差</td>
                                <td>优秀</td>
                                <td>NHWC连续访问同一位置的所有通道</td>
                            </tr>
                            <tr>
                                <td>BatchNorm</td>
                                <td>良好</td>
                                <td>一般</td>
                                <td>NCHW便于收集通道统计信息</td>
                            </tr>
                            <tr>
                                <td>池化操作</td>
                                <td>优秀</td>
                                <td>良好</td>
                                <td>两种布局差异不大</td>
                            </tr>
                            <tr>
                                <td>Element-wise</td>
                                <td>相同</td>
                                <td>相同</td>
                                <td>顺序访问，无差异</td>
                            </tr>
                        </table>
                        
                        <p><strong>NPU实现考虑：</strong></p>
                        <div class="code-block">
// 布局感知的算子实现
class LayoutAwareConvolution {
    void execute(Tensor input, Layout layout) {
        if (layout == NCHW) {
            // SIMD处理整个输出通道
            for (int oc = 0; oc < C_out; oc += SIMD_WIDTH) {
                // 向量化计算
                computeNCHW_SIMD(input, oc);
            }
        } else { // NHWC
            // 适合MAC阵列的数据流
            for (int h = 0; h < H; h++) {
                for (int w = 0; w < W; w++) {
                    // 所有通道并行计算
                    computeNHWC_Parallel(input, h, w);
                }
            }
        }
    }
};
                        </div>
                        
                        <p><strong>选择建议：</strong></p>
                        <ul>
                            <li>ResNet类网络：NCHW（标准卷积为主）</li>
                            <li>MobileNet类网络：NHWC（大量depthwise卷积）</li>
                            <li>混合网络：动态转换或使用NC/HW[n]c分块布局</li>
                            <li>硬件特定：根据NPU的MAC阵列设计选择</li>
                            <li>带宽受限场景：选择减少内存访问的布局</li>
                        </ul>
                    </div>
                </div>
            </div>
        </section>
        
        <!-- Chapter 11: Performance Optimization Techniques -->
        <section id="chapter11" class="chapter">
            <h2>第11章：性能优化技术</h2>
            
            <p>NPU的性能优化是一个系统工程，涉及算法、架构、实现等多个层面。本章深入探讨NPU性能优化的四个关键维度：算法优化、数据流优化、功耗优化和面积优化，以及它们之间的相互关系和权衡。</p>

            <h3>11.1 算法优化</h3>
            
            <p>算法优化是从根本上减少计算量和参数量的有效方法。通过模型压缩、量化等技术，可以在保持精度的同时显著提升NPU的运行效率。</p>

            <h4>11.1.1 模型量化技术</h4>
            <div class="warning-box">
                <p><strong>重要说明：</strong>本章的部分代码示例是为了说明概念而设计的行为模型，并非可直接综合的RTL代码。在实际硬件设计中，需要根据具体的工艺库和设计约束进行相应调整。</p>
            </div>
            <div class="code-block">
// 量化方案对比
┌──────────────┬────────┬────────┬────────┬──────────┐
│   量化方案    │  精度  │ 模型大小│ 推理速度│ 精度损失 │
├──────────────┼────────┼────────┼────────┼──────────┤
│    FP32      │ 100%   │  100%  │  1.0x  │   0%     │
│    FP16      │ 99.9%  │   50%  │  2.0x  │  <0.1%   │
│    INT8      │ 99.5%  │   25%  │  4.0x  │  ~0.5%   │
│    INT4      │ 98.5%  │  12.5% │  8.0x  │  ~1.5%   │
│  Binary/1-bit│ 92-95% │  3.1%  │  32x   │  5-8%    │
└──────────────┴────────┴────────┴────────┴──────────┘

// INT8量化器 - 定点数实现
// 注意：这是一个简化的行为模型，展示量化的基本原理
// 实际设计中，输入数据通常已经是定点格式
module INT8_Quantizer #(
    parameter INPUT_WIDTH = 16,      // 输入定点数位宽
    parameter INPUT_FRAC_BITS = 8,   // 输入小数位数
    parameter SCALE_WIDTH = 16,      // 缩放因子位宽
    parameter SCALE_FRAC_BITS = 12  // 缩放因子小数位数
)(
    input wire clk,
    input wire rst_n,
    
    // 定点数输入
    input wire signed [INPUT_WIDTH-1:0] fixed_input,
    input wire input_valid,
    
    // 量化参数（定点格式）
    input wire [SCALE_WIDTH-1:0] scale,      // 缩放因子
    input wire [7:0] zero_point,             // 零点偏移
    
    // INT8输出
    output reg [7:0] int8_output,
    output reg output_valid
);
    
    // 流水线寄存器和有效信号
    reg signed [INPUT_WIDTH+SCALE_WIDTH-1:0] scaled_value;
    reg signed [INPUT_WIDTH-1:0] rounded_value;
    reg signed [8:0] with_zp_value;
    
    reg stage1_valid, stage2_valid, stage3_valid;
    
    // 第一级：定点数乘法（缩放）
    always @(posedge clk) begin
        if (!rst_n) begin
            scaled_value <= 0;
            stage1_valid <= 1'b0;
        end else if (input_valid) begin
            // 定点数乘法：结果需要右移以对齐小数点
            scaled_value <= fixed_input * $signed({1'b0, scale});
            stage1_valid <= 1'b1;
        end else begin
            stage1_valid <= 1'b0;
        end
    end
    
    // 第二级：舍入处理
    always @(posedge clk) begin
        if (!rst_n) begin
            rounded_value <= 0;
            stage2_valid <= 1'b0;
        end else if (stage1_valid) begin
            // 右移对齐并四舍五入
            localparam SHIFT = INPUT_FRAC_BITS + SCALE_FRAC_BITS;
            rounded_value <= (scaled_value + (1 << (SHIFT-1))) >>> SHIFT;
            stage2_valid <= 1'b1;
        end else begin
            stage2_valid <= 1'b0;
        end
    end
    
    // 第三级：加零点
    always @(posedge clk) begin
        if (!rst_n) begin
            with_zp_value <= 0;
            stage3_valid <= 1'b0;
        end else if (stage2_valid) begin
            with_zp_value <= rounded_value + zero_point;
            stage3_valid <= 1'b1;
        end else begin
            stage3_valid <= 1'b0;
        end
    end
    
    // 第四级：饱和到INT8范围
    always @(posedge clk) begin
        if (!rst_n) begin
            int8_output <= 8'h0;
            output_valid <= 1'b0;
        end else if (stage3_valid) begin
            // 饱和到[0, 255]
            if (with_zp_value > 255)
                int8_output <= 8'hFF;
            else if (with_zp_value < 0)
                int8_output <= 8'h00;
            else
                int8_output <= with_zp_value[7:0];
                
            output_valid <= 1'b1;
        end else begin
            output_valid <= 1'b0;
        end
    end
endmodule
            </div>
            
            <h4>11.1.2 知识蒸馏技术</h4>
            <div class="info-box">
                <p><strong>知识蒸馏（Knowledge Distillation）：</strong>使用大型教师模型指导小型学生模型的训练，在保持高精度的同时显著减小模型规模。这是部署前优化的重要技术。</p>
            </div>
            <div class="code-block">
// 知识蒸馏在NPU中的应用
// 1. 离线阶段：使用教师模型生成软标签
// 2. 训练阶段：学生模型同时学习硬标签和软标签
// 3. 部署阶段：只需要学生模型，大幅减少计算量

知识蒸馏的硬件优势：
┌─────────────┬──────────┬──────────┬──────────┐
│   模型类型   │ 参数量   │ 计算量   │ 精度     │
├─────────────┼──────────┼──────────┼──────────┤
│ 教师模型     │ 100M     │ 10 GOPS  │ 95.0%    │
│ 学生模型     │ 10M      │ 1 GOPS   │ 93.5%    │
│ 直接训练小模型│ 10M      │ 1 GOPS   │ 91.0%    │
└─────────────┴──────────┴──────────┴──────────┘

// NPU推理加速比：10x（相比教师模型）
// 精度损失：仅1.5%（相比教师模型）
            </div>

            <h4>11.1.3 模型剪枝技术</h4>
            <div class="info-box">
                <p><strong>剪枝策略对比：</strong></p>
                <ul>
                    <li><strong>非结构化剪枝：</strong>细粒度移除单个权重，稀疏度高但硬件加速困难</li>
                    <li><strong>结构化剪枝：</strong>移除整个通道/滤波器，硬件友好但灵活性低</li>
                    <li><strong>块稀疏剪枝：</strong>以小块为单位剪枝，平衡稀疏度和硬件效率</li>
                    <li><strong>动态剪枝：</strong>运行时根据输入动态决定剪枝，灵活但开销大</li>
                </ul>
            </div>

            <div class="code-block">
// 结构化剪枝的硬件实现 - 并行化设计
module ChannelPruningUnit #(
    parameter NUM_CHANNELS = 64,
    parameter CHANNEL_WIDTH = 8,
    parameter DATA_WIDTH = 8,
    parameter MAX_ACTIVE = 32    // 最大活跃通道数
)(
    input wire clk,
    input wire rst_n,
    
    // 输入特征图
    input wire [NUM_CHANNELS-1:0][CHANNEL_WIDTH-1:0][DATA_WIDTH-1:0] input_channels,
    input wire input_valid,
    
    // 剪枝配置（在配置阶段设置）
    input wire config_en,
    input wire [NUM_CHANNELS-1:0] pruning_mask,
    
    // 输出（压缩后的通道）
    output wire [MAX_ACTIVE-1:0][CHANNEL_WIDTH-1:0][DATA_WIDTH-1:0] output_channels,
    output reg [$clog2(NUM_CHANNELS):0] active_channels,
    output reg output_valid
);
    
    // 通道映射表（配置时设置）
    reg [$clog2(NUM_CHANNELS)-1:0] channel_map [MAX_ACTIVE-1:0];
    reg [$clog2(NUM_CHANNELS):0] num_active;
    
    // 配置阶段：计算通道映射（只在pruning_mask改变时执行）
    // 这通常由软件完成，硬件只存储结果
    always @(posedge clk) begin
        if (!rst_n) begin
            num_active <= 0;
            active_channels <= 0;
        end else if (config_en) begin
            // 简化的配置逻辑 - 实际中由外部控制器提供
            num_active <= $countones(pruning_mask);
            active_channels <= $countones(pruning_mask);
        end
    end
    
    // 使用优先编码器生成通道映射
    genvar ch;
    generate
        // 为每个可能的输出位置生成选择逻辑
        for (ch = 0; ch < MAX_ACTIVE; ch = ch + 1) begin : channel_select
            // 多路选择器选择对应的输入通道
            wire [CHANNEL_WIDTH-1:0][DATA_WIDTH-1:0] selected_channel;
            
            // 64选1多路选择器
            assign selected_channel = (ch < num_active) ? 
                                    input_channels[channel_map[ch]] : 
                                    '0;
            
            // 寄存输出
            reg [CHANNEL_WIDTH-1:0][DATA_WIDTH-1:0] output_reg;
            always @(posedge clk) begin
                if (!rst_n) begin
                    output_reg <= '0;
                end else if (input_valid) begin
                    output_reg <= selected_channel;
                end
            end
            
            assign output_channels[ch] = output_reg;
        end
    endgenerate
    
    // 输出有效信号
    always @(posedge clk) begin
        if (!rst_n) begin
            output_valid <= 1'b0;
        end else begin
            output_valid <= input_valid;
        end
    end
    
endmodule

// 配套的通道映射配置器（通常由软件或固件控制）
module ChannelMapConfigurator #(
    parameter NUM_CHANNELS = 64,
    parameter MAX_ACTIVE = 32
)(
    input wire clk,
    input wire rst_n,
    
    input wire [NUM_CHANNELS-1:0] pruning_mask,
    input wire config_start,
    
    output reg [$clog2(NUM_CHANNELS)-1:0] channel_map [MAX_ACTIVE-1:0],
    output reg config_done
);
    // 这个模块展示了如何生成channel_map
    // 实际设计中，这通常在软件中完成
    
    reg [5:0] write_ptr;
    reg [5:0] scan_ptr;
    
    always @(posedge clk) begin
        if (!rst_n) begin
            write_ptr <= 0;
            scan_ptr <= 0;
            config_done <= 0;
        end else if (config_start) begin
            write_ptr <= 0;
            scan_ptr <= 0;
            config_done <= 0;
        end else if (!config_done && scan_ptr < NUM_CHANNELS) begin
            if (pruning_mask[scan_ptr] && write_ptr < MAX_ACTIVE) begin
                channel_map[write_ptr] <= scan_ptr;
                write_ptr <= write_ptr + 1;
            end
            scan_ptr <= scan_ptr + 1;
            
            if (scan_ptr == NUM_CHANNELS - 1) begin
                config_done <= 1;
            end
        end
    end
endmodule
            </div>

            <h4>11.1.4 算子融合优化</h4>
            <div class="info-box">
                <p><strong>算子融合的核心价值：</strong>通过将多个算子合并，避免中间结果的内存读写，显著提升能效。Conv+BN+ReLU是最常见的融合模式。</p>
            </div>
            <div class="code-block">
// Conv-BN-ReLU融合实现 - 真实硬件并行化设计
// 注意：这里展示的是单个输出像素的计算单元
// 完整的卷积层需要多个这样的单元并行工作
module ConvBNReLU_ProcessingElement #(
    parameter KERNEL_SIZE = 3,
    parameter IN_CHANNELS = 32,
    parameter DATA_WIDTH = 8,
    parameter WEIGHT_WIDTH = 8,
    parameter BN_PARAM_WIDTH = 16
)(
    input wire clk,
    input wire rst_n,
    
    // 输入窗口数据（已经准备好的卷积窗口）
    input wire [KERNEL_SIZE*KERNEL_SIZE*IN_CHANNELS-1:0][DATA_WIDTH-1:0] input_window,
    input wire input_valid,
    
    // 权重（一个输出通道的所有权重）
    input wire [KERNEL_SIZE*KERNEL_SIZE*IN_CHANNELS-1:0][WEIGHT_WIDTH-1:0] weights,
    
    // BN参数（预融合：scale和bias已经预计算）
    input wire signed [BN_PARAM_WIDTH-1:0] bn_scale,   // Q2.14格式
    input wire signed [BN_PARAM_WIDTH-1:0] bn_bias,    // Q8.8格式
    
    // 输出
    output reg [DATA_WIDTH-1:0] output_pixel,
    output reg output_valid
);
    
    // 计算MAC总数
    localparam NUM_MACS = KERNEL_SIZE * KERNEL_SIZE * IN_CHANNELS;
    
    // 并行MAC单元的输出
    wire signed [DATA_WIDTH+WEIGHT_WIDTH-1:0] mac_results [NUM_MACS-1:0];
    
    // 使用generate创建并行MAC单元
    genvar i;
    generate
        for (i = 0; i < NUM_MACS; i = i + 1) begin : mac_unit
            // 每个MAC执行一次乘法
            assign mac_results[i] = $signed(input_window[i]) * $signed(weights[i]);
        end
    endgenerate
    
    // 加法树 - 将所有MAC结果累加
    // 这里展示3级加法树的概念（实际实现需要根据NUM_MACS调整）
    reg signed [DATA_WIDTH+WEIGHT_WIDTH+$clog2(NUM_MACS)-1:0] conv_sum;
    reg signed [DATA_WIDTH+WEIGHT_WIDTH+$clog2(NUM_MACS)+BN_PARAM_WIDTH-1:0] bn_result;
    
    // 流水线有效信号
    reg stage1_valid, stage2_valid;
    
    // 第一级：并行累加（加法树）
    // 实际硬件中会用Wallace Tree或其他高效加法树结构
    integer j;
    always @(posedge clk) begin
        if (!rst_n) begin
            conv_sum <= 0;
            stage1_valid <= 1'b0;
        end else if (input_valid) begin
            conv_sum <= 0;
            // 简化的累加 - 实际应该用加法树
            for (j = 0; j < NUM_MACS; j = j + 1) begin
                conv_sum <= conv_sum + mac_results[j];
            end
            stage1_valid <= 1'b1;
        end else begin
            stage1_valid <= 1'b0;
        end
    end
    
    // 第二级：BN计算（使用预融合的参数）
    always @(posedge clk) begin
        if (!rst_n) begin
            bn_result <= 0;
            stage2_valid <= 1'b0;
        end else if (stage1_valid) begin
            // BN融合计算：y = conv_sum * scale + bias
            // scale是Q2.14格式，需要右移14位
            bn_result <= (conv_sum * bn_scale) >>> 14 + (bn_bias <<< 8);
            stage2_valid <= 1'b1;
        end else begin
            stage2_valid <= 1'b0;
        end
    end
    
    // 第三级：ReLU和量化回INT8
    always @(posedge clk) begin
        if (!rst_n) begin
            output_pixel <= 0;
            output_valid <= 1'b0;
        end else if (stage2_valid) begin
            // ReLU: max(0, x)
            if (bn_result < 0) begin
                output_pixel <= 0;
            end else if (bn_result > (255 << 16)) begin  // 饱和到255（考虑定点偏移）
                output_pixel <= 255;
            end else begin
                output_pixel <= bn_result[23:16];  // 取合适的位
            end
            output_valid <= 1'b1;
        end else begin
            output_valid <= 1'b0;
        end
    end
endmodule

// 高效的并行加法树实现示例
module AdderTree #(
    parameter NUM_INPUTS = 288,  // 3x3x32 = 288
    parameter DATA_WIDTH = 16
)(
    input wire [NUM_INPUTS-1:0][DATA_WIDTH-1:0] inputs,
    output wire [DATA_WIDTH+$clog2(NUM_INPUTS)-1:0] sum
);
    // Wallace Tree加法器的简化实现
    // 实际设计中会使用更优化的结构
    
    // 第一级：将输入两两相加
    localparam STAGE1_OUTPUTS = (NUM_INPUTS + 1) / 2;
    wire [DATA_WIDTH:0] stage1 [STAGE1_OUTPUTS-1:0];
    
    genvar i;
    generate
        for (i = 0; i < STAGE1_OUTPUTS; i = i + 1) begin : stage1_add
            if (2*i+1 < NUM_INPUTS) begin
                assign stage1[i] = inputs[2*i] + inputs[2*i+1];
            end else begin
                assign stage1[i] = inputs[2*i];
            end
        end
    endgenerate
    
    // 后续级使用类似的方式递归构建...
    // 最终输出sum
endmodule
            </div>

            <h3>11.2 数据流优化</h3>
            
            <p>数据流优化的核心是最小化数据搬运，最大化数据复用。NPU中数据搬运的能耗远高于计算本身，因此优化数据流是提升能效的关键。</p>

            <h4>11.2.1 数据复用策略</h4>
            <div class="info-box">
                <p><strong>三种主要的数据复用模式：</strong></p>
                <ul>
                    <li><strong>权重固定（Weight Stationary）：</strong>权重驻留在PE中，输入数据流动</li>
                    <li><strong>输出固定（Output Stationary）：</strong>部分和驻留在PE中累加，减少写回</li>
                    <li><strong>行固定（Row Stationary）：</strong>卷积行数据驻留，最大化局部数据复用</li>
                </ul>
            </div>
            
            <div class="code-block">
// 数据流策略对比
┌────────────────┬─────────────┬──────────────┬────────────┐
│   数据流类型    │ 驻留数据    │ 优点         │ 适用场景   │
├────────────────┼─────────────┼──────────────┼────────────┤
│ Weight Stationary│ 权重       │ 权重读取最少 │ 大batch    │
│ Output Stationary│ 部分和     │ 部分和写回少 │ 深度网络   │
│ Row Stationary  │ 卷积行     │ 总体能效最优 │ 通用场景   │
└────────────────┴─────────────┴──────────────┴────────────┘
            </div>

            <div class="code-block">
// 输出固定数据流（Output Stationary）实现
// 特点：部分和在PE内累加，直到完成所有计算才输出
module OutputStationaryPE #(
    parameter DATA_WIDTH = 8,
    parameter WEIGHT_WIDTH = 8,
    parameter ACCUM_WIDTH = 32
)(
    input wire clk,
    input wire rst_n,
    
    // 控制信号
    input wire new_output,       // 开始新的输出计算
    input wire compute_en,       // 计算使能
    input wire output_ready,     // 输出就绪
    
    // 数据输入（每周期新数据）
    input wire [DATA_WIDTH-1:0] input_data,
    input wire [WEIGHT_WIDTH-1:0] weight,
    
    // 累加结果输出
    output reg [ACCUM_WIDTH-1:0] accumulator,
    output reg acc_valid
);
    
    // 内部累加器
    reg [ACCUM_WIDTH-1:0] partial_sum;
    
    // MAC运算
    wire [DATA_WIDTH+WEIGHT_WIDTH-1:0] product;
    assign product = input_data * weight;
    
    // 累加逻辑
    always @(posedge clk) begin
        if (!rst_n) begin
            partial_sum <= 0;
            acc_valid <= 1'b0;
        end else if (new_output) begin
            // 开始新的输出计算
            partial_sum <= 0;
            acc_valid <= 1'b0;
        end else if (compute_en) begin
            // 累加新的乘积
            partial_sum <= partial_sum + product;
        end else if (output_ready) begin
            // 输出最终结果
            accumulator <= partial_sum;
            acc_valid <= 1'b1;
        end else begin
            acc_valid <= 1'b0;
        end
    end
    
endmodule

// 输出固定脉动阵列
module OutputStationaryArray #(
    parameter ARRAY_SIZE = 16,
    parameter DATA_WIDTH = 8
)(
    input wire clk,
    input wire rst_n,
    
    // 控制信号
    input wire start_compute,
    input wire [15:0] num_accumulations,  // 需要累加的次数
    
    // 输入数据和权重
    input wire [ARRAY_SIZE-1:0][DATA_WIDTH-1:0] input_vector,
    input wire [ARRAY_SIZE-1:0][DATA_WIDTH-1:0] weight_vector,
    
    // 输出向量
    output wire [ARRAY_SIZE-1:0][31:0] output_vector,
    output wire output_valid
);
    
    // 控制状态机
    reg [15:0] acc_counter;
    reg computing;
    wire last_accumulation;
    
    assign last_accumulation = (acc_counter == num_accumulations - 1);
    
    always @(posedge clk) begin
        if (!rst_n) begin
            acc_counter <= 0;
            computing <= 0;
        end else if (start_compute) begin
            acc_counter <= 0;
            computing <= 1;
        end else if (computing) begin
            if (last_accumulation) begin
                computing <= 0;
            end else begin
                acc_counter <= acc_counter + 1;
            end
        end
    end
    
    // PE阵列实例化
    genvar i;
    generate
        for (i = 0; i < ARRAY_SIZE; i = i + 1) begin : pe_array
            OutputStationaryPE pe (
                .clk(clk),
                .rst_n(rst_n),
                .new_output(start_compute),
                .compute_en(computing),
                .output_ready(last_accumulation),
                .input_data(input_vector[i]),
                .weight(weight_vector[i]),
                .accumulator(output_vector[i]),
                .acc_valid(output_valid)
            );
        end
    endgenerate
    
endmodule
            </div>

            <div class="code-block">
// 行固定数据流（Row Stationary）实现 - 修正版
module RowStationaryPE #(
    parameter DATA_WIDTH = 8,
    parameter WEIGHT_WIDTH = 8,
    parameter ACCUM_WIDTH = 32
)(
    input wire clk,
    input wire rst_n,
    
    // 控制信号
    input wire load_weight,      // 加载权重
    input wire shift_enable,     // 数据移位使能
    input wire accumulate,       // 累加使能
    input wire output_enable,    // 输出使能
    
    // 数据输入
    input wire [DATA_WIDTH-1:0] input_data,
    input wire [WEIGHT_WIDTH-1:0] weight_in,
    
    // 数据输出（向相邻PE传递）
    output reg [DATA_WIDTH-1:0] input_out,    // 输入数据向右传递
    output reg [WEIGHT_WIDTH-1:0] weight_out, // 权重向下传递
    output reg [ACCUM_WIDTH-1:0] partial_sum
);
    
    // 内部寄存器
    reg [WEIGHT_WIDTH-1:0] weight_reg;     // 权重寄存器
    reg [DATA_WIDTH-1:0] input_reg;        // 输入寄存器
    reg [ACCUM_WIDTH-1:0] accumulator;     // 累加器
    
    // MAC运算结果
    wire [DATA_WIDTH+WEIGHT_WIDTH-1:0] mac_result;
    assign mac_result = input_reg * weight_reg;
    
    // 权重加载和传递
    always @(posedge clk) begin
        if (!rst_n) begin
            weight_reg <= 0;
            weight_out <= 0;
        end else if (load_weight) begin
            weight_reg <= weight_in;
            weight_out <= weight_in;  // 同时向下传递
        end
    end
    
    // 输入数据移位
    always @(posedge clk) begin
        if (!rst_n) begin
            input_reg <= 0;
            input_out <= 0;
        end else if (shift_enable) begin
            input_reg <= input_data;
            input_out <= input_data;  // 同时向右传递
        end
    end
    
    // 累加器
    always @(posedge clk) begin
        if (!rst_n) begin
            accumulator <= 0;
        end else if (accumulate) begin
            accumulator <= accumulator + mac_result;
        end else if (output_enable) begin
            accumulator <= 0;  // 输出后清零
        end
    end
    
    // 输出逻辑
    always @(posedge clk) begin
        if (!rst_n) begin
            partial_sum <= 0;
        end else if (output_enable) begin
            partial_sum <= accumulator;
        end
    end
endmodule

// 2D PE阵列实现 - 真正的脉动阵列
module RowStationaryArray #(
    parameter ARRAY_HEIGHT = 16,
    parameter ARRAY_WIDTH = 16,
    parameter DATA_WIDTH = 8
)(
    input wire clk,
    input wire rst_n,
    
    // 全局控制
    input wire [2:0] operation_mode,  // 0:空闲 1:加载权重 2:计算 3:输出
    
    // 数据输入（从左侧输入）
    input wire [ARRAY_HEIGHT-1:0][DATA_WIDTH-1:0] input_data,
    
    // 权重输入（从上方输入）
    input wire [ARRAY_WIDTH-1:0][DATA_WIDTH-1:0] weight_data,
    
    // 输出接口
    output wire [ARRAY_HEIGHT-1:0][ARRAY_WIDTH-1:0][31:0] output_matrix
);
    
    // PE间的连接线
    wire [ARRAY_HEIGHT-1:0][ARRAY_WIDTH:0][DATA_WIDTH-1:0] horizontal_data;
    wire [ARRAY_HEIGHT:0][ARRAY_WIDTH-1:0][DATA_WIDTH-1:0] vertical_weight;
    
    // 连接输入到阵列边界
    genvar i, j;
    generate
        // 左侧输入
        for (i = 0; i < ARRAY_HEIGHT; i = i + 1) begin : left_input
            assign horizontal_data[i][0] = input_data[i];
        end
        // 上方输入
        for (j = 0; j < ARRAY_WIDTH; j = j + 1) begin : top_input
            assign vertical_weight[0][j] = weight_data[j];
        end
    endgenerate
    
    // 实例化PE阵列
    generate
        for (i = 0; i < ARRAY_HEIGHT; i = i + 1) begin : pe_row
            for (j = 0; j < ARRAY_WIDTH; j = j + 1) begin : pe_col
                RowStationaryPE pe_inst (
                    .clk(clk),
                    .rst_n(rst_n),
                    .load_weight(operation_mode == 3'b001),
                    .shift_enable(operation_mode == 3'b010),
                    .accumulate(operation_mode == 3'b010),
                    .output_enable(operation_mode == 3'b011),
                    
                    // 输入连接
                    .input_data(horizontal_data[i][j]),
                    .weight_in(vertical_weight[i][j]),
                    
                    // 输出连接到相邻PE
                    .input_out(horizontal_data[i][j+1]),
                    .weight_out(vertical_weight[i+1][j]),
                    
                    // 结果输出
                    .partial_sum(output_matrix[i][j])
                );
            end
        end
    endgenerate
endmodule
            </div>

            <h4>11.2.2 分块（Tiling）优化</h4>
            <div class="info-box">
                <p><strong>分块优化说明：</strong>分块参数的计算通常由编译器离线完成，硬件只负责执行。下面展示的是执行分块数据传输的DMA控制器。</p>
            </div>
            <div class="code-block">
// 分块数据传输DMA控制器
// 接收编译器计算好的分块参数，执行高效的数据搬运
module TilingDMAController #(
    parameter ADDR_WIDTH = 32,
    parameter DATA_WIDTH = 256,     // 256位宽数据总线
    parameter SRAM_ADDR_WIDTH = 18, // 256KB SRAM
    parameter MAX_TILE_SIZE = 64
)(
    input wire clk,
    input wire rst_n,
    
    // 分块参数（由编译器/驱动程序设置）
    input wire config_valid,
    input wire [7:0] tile_h,
    input wire [7:0] tile_w,
    input wire [7:0] tile_ic,
    input wire [7:0] tile_oc,
    input wire [15:0] total_h,
    input wire [15:0] total_w,
    
    // DDR接口
    output reg [ADDR_WIDTH-1:0] ddr_addr,
    output reg ddr_read_req,
    input wire [DATA_WIDTH-1:0] ddr_read_data,
    input wire ddr_read_valid,
    
    // SRAM接口
    output reg [SRAM_ADDR_WIDTH-1:0] sram_addr,
    output reg sram_write_en,
    output reg [DATA_WIDTH-1:0] sram_write_data,
    
    // 状态输出
    output reg dma_busy,
    output reg tile_ready,
    output reg [15:0] current_tile_h,
    output reg [15:0] current_tile_w
);
    
    // DMA状态机
    typedef enum logic [2:0] {
        IDLE,
        LOAD_INPUT_TILE,
        LOAD_WEIGHT_TILE,
        WAIT_COMPUTE,
        STORE_OUTPUT_TILE,
        NEXT_TILE
    } dma_state_t;
    
    dma_state_t state, next_state;
    
    // 分块迭代计数器
    reg [15:0] tile_h_idx, tile_w_idx;
    reg [15:0] tile_ic_idx, tile_oc_idx;
    
    // 地址生成器
    reg [ADDR_WIDTH-1:0] input_base_addr;
    reg [ADDR_WIDTH-1:0] weight_base_addr;
    reg [ADDR_WIDTH-1:0] output_base_addr;
    
    // 传输计数器
    reg [15:0] transfer_count;
    reg [15:0] transfers_per_tile;
    
    // 计算每个tile需要的传输次数
    always @(posedge clk) begin
        if (!rst_n) begin
            transfers_per_tile <= 0;
        end else if (config_valid) begin
            // 假设每次传输32字节，计算需要多少次传输
            transfers_per_tile <= (tile_h * tile_w * tile_ic + 31) >> 5;
        end
    end
    
    // 状态机主逻辑
    always @(posedge clk) begin
        if (!rst_n) begin
            state <= IDLE;
            dma_busy <= 0;
            tile_ready <= 0;
        end else begin
            state <= next_state;
            
            case (state)
                IDLE: begin
                    if (config_valid) begin
                        dma_busy <= 1;
                        tile_h_idx <= 0;
                        tile_w_idx <= 0;
                        tile_ic_idx <= 0;
                        tile_oc_idx <= 0;
                    end
                end
                
                LOAD_INPUT_TILE: begin
                    // 生成输入数据的DDR地址
                    ddr_addr <= input_base_addr + 
                               (tile_h_idx * tile_h * total_w + 
                                tile_w_idx * tile_w) * tile_ic;
                    
                    if (transfer_count < transfers_per_tile) begin
                        ddr_read_req <= 1;
                        if (ddr_read_valid) begin
                            sram_write_en <= 1;
                            sram_write_data <= ddr_read_data;
                            sram_addr <= transfer_count;
                            transfer_count <= transfer_count + 1;
                        end
                    end
                end
                
                LOAD_WEIGHT_TILE: begin
                    // 类似地加载权重数据
                    // 省略具体实现
                end
                
                WAIT_COMPUTE: begin
                    tile_ready <= 1;
                    current_tile_h <= tile_h_idx;
                    current_tile_w <= tile_w_idx;
                end
                
                STORE_OUTPUT_TILE: begin
                    // 存储输出数据回DDR
                    // 省略具体实现
                end
                
                NEXT_TILE: begin
                    tile_ready <= 0;
                    // 更新tile索引
                    if (tile_w_idx < (total_w / tile_w - 1)) begin
                        tile_w_idx <= tile_w_idx + 1;
                    end else begin
                        tile_w_idx <= 0;
                        if (tile_h_idx < (total_h / tile_h - 1)) begin
                            tile_h_idx <= tile_h_idx + 1;
                        end else begin
                            // 所有tile处理完成
                            dma_busy <= 0;
                        end
                    end
                end
            endcase
        end
    end
    
    // 次态逻辑
    always @(*) begin
        next_state = state;
        
        case (state)
            IDLE: begin
                if (config_valid) next_state = LOAD_INPUT_TILE;
            end
            
            LOAD_INPUT_TILE: begin
                if (transfer_count >= transfers_per_tile) begin
                    next_state = LOAD_WEIGHT_TILE;
                end
            end
            
            LOAD_WEIGHT_TILE: begin
                // 权重加载完成后等待计算
                next_state = WAIT_COMPUTE;
            end
            
            WAIT_COMPUTE: begin
                // 收到计算完成信号后存储输出
                next_state = STORE_OUTPUT_TILE;
            end
            
            STORE_OUTPUT_TILE: begin
                // 输出存储完成后处理下一个tile
                next_state = NEXT_TILE;
            end
            
            NEXT_TILE: begin
                if (dma_busy) begin
                    next_state = LOAD_INPUT_TILE;
                end else begin
                    next_state = IDLE;
                end
            end
        endcase
    end
endmodule

// 分块策略分析（概念说明，不是RTL）
// 编译器会根据以下因素计算最优分块参数：
// 1. 片上SRAM容量
// 2. 数据复用机会
// 3. DDR带宽限制
// 4. 计算与访存的重叠

// 典型的分块策略：
// - 输入特征图：尽量保持空间局部性
// - 权重：考虑多个输入tile的复用
// - 输出：最小化部分和的存储
            </div>

            <h3>11.3 功耗优化</h3>
            
            <p>功耗是NPU设计的关键约束，特别是在边缘和移动设备上。功耗优化需要从架构、电路到系统级别的全方位考虑。</p>

            <h4>11.3.1 动态功耗管理</h4>
            <div class="code-block">
// 多级功耗管理控制器
module PowerManagementUnit #(
    parameter NUM_CLUSTERS = 8,
    parameter NUM_CORES_PER_CLUSTER = 4
)(
    input wire clk,
    input wire rst_n,
    
    // 工作负载监控
    input wire [NUM_CLUSTERS-1:0] cluster_active,
    input wire [NUM_CLUSTERS-1:0][NUM_CORES_PER_CLUSTER-1:0] core_active,
    input wire [7:0] global_utilization,  // 0-100%
    
    // DVFS控制
    output reg [2:0] voltage_level,       // 0-7级电压
    output reg [2:0] frequency_level,     // 0-7级频率
    
    // 电源门控
    output reg [NUM_CLUSTERS-1:0] cluster_power_gate,
    output reg [NUM_CLUSTERS-1:0][NUM_CORES_PER_CLUSTER-1:0] core_clock_gate,
    
    // 性能计数器
    output reg [31:0] total_energy,
    output reg [31:0] active_cycles
);
    
    // DVFS查找表
    reg [7:0] voltage_table [7:0];  // mV/10
    reg [7:0] freq_table [7:0];     // MHz/10
    
    initial begin
        // 电压表（0.6V-1.0V）
        voltage_table[0] = 60;   // 0.6V
        voltage_table[1] = 65;
        voltage_table[2] = 70;
        voltage_table[3] = 75;
        voltage_table[4] = 80;
        voltage_table[5] = 85;
        voltage_table[6] = 90;
        voltage_table[7] = 100;  // 1.0V
        
        // 频率表（100MHz-800MHz）
        freq_table[0] = 10;      // 100MHz
        freq_table[1] = 20;
        freq_table[2] = 30;
        freq_table[3] = 40;
        freq_table[4] = 50;
        freq_table[5] = 60;
        freq_table[6] = 70;
        freq_table[7] = 80;      // 800MHz
    end
    
    // 功耗状态机
    reg [2:0] power_state;
    localparam ACTIVE = 3'b000;
    localparam THROTTLE = 3'b001;
    localparam IDLE = 3'b010;
    localparam SLEEP = 3'b011;
    localparam DEEP_SLEEP = 3'b100;
    
    // 负载历史记录（用于预测）
    reg [7:0] load_history [15:0];
    reg [3:0] history_ptr;
    reg [7:0] avg_load;
    
    // 计算平均负载
    integer i;
    always @(posedge clk) begin
        if (!rst_n) begin
            history_ptr <= 0;
            avg_load <= 0;
        end else begin
            load_history[history_ptr] <= global_utilization;
            history_ptr <= history_ptr + 1;
            
            // 计算移动平均
            avg_load <= 0;
            for (i = 0; i < 16; i = i + 1) begin
                avg_load <= avg_load + (load_history[i] >> 4);
            end
        end
    end
    
    // DVFS控制逻辑
    always @(posedge clk) begin
        if (!rst_n) begin
            voltage_level <= 3'b111;  // 最高性能
            frequency_level <= 3'b111;
            power_state <= ACTIVE;
        end else begin
            case (power_state)
                ACTIVE: begin
                    if (avg_load < 20) begin
                        power_state <= IDLE;
                    end else if (avg_load > 90) begin
                        // 提升性能
                        if (voltage_level < 7) begin
                            voltage_level <= voltage_level + 1;
                            frequency_level <= frequency_level + 1;
                        end
                    end else if (avg_load < 50) begin
                        // 降低性能以节能
                        if (voltage_level > 3) begin
                            voltage_level <= voltage_level - 1;
                            frequency_level <= frequency_level - 1;
                        end
                    end
                end
                
                IDLE: begin
                    if (avg_load > 30) begin
                        power_state <= ACTIVE;
                    end else if (avg_load < 10) begin
                        power_state <= SLEEP;
                        voltage_level <= 3'b010;
                        frequency_level <= 3'b010;
                    end
                end
                
                SLEEP: begin
                    if (avg_load > 20) begin
                        power_state <= IDLE;
                        voltage_level <= 3'b100;
                        frequency_level <= 3'b100;
                    end else if (avg_load == 0) begin
                        power_state <= DEEP_SLEEP;
                        voltage_level <= 3'b000;
                        frequency_level <= 3'b000;
                    end
                end
                
                DEEP_SLEEP: begin
                    if (|cluster_active) begin
                        power_state <= IDLE;
                        voltage_level <= 3'b100;
                        frequency_level <= 3'b100;
                    end
                end
            endcase
        end
    end
    
    // 电源门控控制
    genvar c, p;
    generate
        for (c = 0; c < NUM_CLUSTERS; c = c + 1) begin : cluster_ctrl
            always @(posedge clk) begin
                if (!rst_n) begin
                    cluster_power_gate[c] <= 1'b0;
                end else begin
                    // 簇级电源门控（需要较长时间空闲）
                    if (!cluster_active[c] && power_state == SLEEP) begin
                        cluster_power_gate[c] <= 1'b1;
                    end else begin
                        cluster_power_gate[c] <= 1'b0;
                    end
                end
            end
            
            // 核心级时钟门控（快速响应）
            for (p = 0; p < NUM_CORES_PER_CLUSTER; p = p + 1) begin : core_ctrl
                always @(posedge clk) begin
                    if (!rst_n) begin
                        core_clock_gate[c][p] <= 1'b0;
                    end else begin
                        core_clock_gate[c][p] <= !core_active[c][p];
                    end
                end
            end
        end
    endgenerate
    
    // 能量统计
    reg [15:0] instant_power;
    always @(posedge clk) begin
        if (!rst_n) begin
            total_energy <= 0;
            active_cycles <= 0;
            instant_power <= 0;
        end else begin
            // 简化的功耗模型：P = CV²f
            instant_power <= (voltage_table[voltage_level] * voltage_table[voltage_level] * 
                            freq_table[frequency_level]) >> 8;
            
            // 根据活跃单元调整
            instant_power <= instant_power * global_utilization / 100;
            
            // 累加总能量
            total_energy <= total_energy + instant_power;
            
            if (power_state == ACTIVE) begin
                active_cycles <= active_cycles + 1;
            end
        end
    end
endmodule
            </div>

            <h4>11.3.2 静态功耗优化 - 多阈值电压技术</h4>
            <div class="info-box">
                <p><strong>多阈值电压（Multi-Vth）技术：</strong>这是在物理设计阶段使用的静态功耗优化技术。通过在芯片中混合使用不同阈值电压的标准单元，在满足时序要求的同时最小化漏电功耗。</p>
            </div>
            <div class="code-block">
// 多阈值电压优化原理（概念说明）
// 注意：这不是一个硬件模块，而是EDA工具在物理设计时的优化策略

不同Vth单元的特性对比：
┌─────────┬──────────┬──────────┬──────────┬──────────┐
│ Vth类型  │ 阈值电压  │ 速度     │ 漏电功耗  │ 应用场景  │
├─────────┼──────────┼──────────┼──────────┼──────────┤
│   LVT   │   低     │   快     │    高    │ 关键路径  │
│   RVT   │   中     │   中     │    中    │ 一般路径  │
│   HVT   │   高     │   慢     │    低    │ 非关键路径│
└─────────┴──────────┴──────────┴──────────┴──────────┘

// 在物理设计脚本中的应用（Synopsys DC示例）
# 定义多Vt库
set_attribute [get_libs */LVT] default_threshold_voltage_group LVT
set_attribute [get_libs */RVT] default_threshold_voltage_group RVT
set_attribute [get_libs */HVT] default_threshold_voltage_group HVT

# 设置优化约束
set_multi_vth_constraint -lvt_percentage 10  # LVT单元不超过10%
set_multi_vth_constraint -hvt_percentage 60  # HVT单元至少60%

# 优化策略
# 1. 综合工具首先满足时序要求
# 2. 在时序裕量允许的范围内，尽量使用HVT单元
# 3. 只在关键路径上使用LVT单元

# 结果：在相同性能下，漏电功耗可降低30-50%
            </div>
            
            <div class="warning-box">
                <p><strong>重要区别：</strong>多阈值电压优化是在芯片设计时由EDA工具完成的，一旦芯片制造完成，每个晶体管的Vth就固定了。这与DVFS（动态电压频率调节）等运行时功耗管理技术有本质区别。</p>
            </div>
            
            <h4>11.3.3 数据通路功耗优化</h4>
            <div class="code-block">
// 低功耗数据通路设计
module LowPowerDatapath #(
    parameter DATA_WIDTH = 8,
    parameter NUM_LANES = 16
)(
    input wire clk,
    input wire rst_n,
    
    // 输入数据
    input wire [NUM_LANES-1:0][DATA_WIDTH-1:0] data_in,
    input wire [NUM_LANES-1:0] data_valid,
    
    // 输出
    output reg [NUM_LANES-1:0][DATA_WIDTH-1:0] data_out,
    output reg [NUM_LANES-1:0] data_out_valid
);
    
    // 操作数隔离寄存器
    reg [NUM_LANES-1:0][DATA_WIDTH-1:0] isolated_data;
    reg [NUM_LANES-1:0] lane_active;
    
    // 数据编码（减少翻转）
    reg [NUM_LANES-1:0][DATA_WIDTH-1:0] encoded_data;
    reg [NUM_LANES-1:0] invert_flag;
    
    genvar lane;
    generate
        for (lane = 0; lane < NUM_LANES; lane = lane + 1) begin : lane_process
            // 计算汉明距离
            wire [3:0] hamming_dist;
            assign hamming_dist = 
                (data_in[lane][0] ^ isolated_data[lane][0]) +
                (data_in[lane][1] ^ isolated_data[lane][1]) +
                (data_in[lane][2] ^ isolated_data[lane][2]) +
                (data_in[lane][3] ^ isolated_data[lane][3]) +
                (data_in[lane][4] ^ isolated_data[lane][4]) +
                (data_in[lane][5] ^ isolated_data[lane][5]) +
                (data_in[lane][6] ^ isolated_data[lane][6]) +
                (data_in[lane][7] ^ isolated_data[lane][7]);
            
            // 总线反转编码
            always @(posedge clk) begin
                if (!rst_n) begin
                    encoded_data[lane] <= 0;
                    invert_flag[lane] <= 0;
                end else if (data_valid[lane]) begin
                    if (hamming_dist > 4) begin
                        // 反转数据以减少翻转
                        encoded_data[lane] <= ~data_in[lane];
                        invert_flag[lane] <= 1'b1;
                    end else begin
                        encoded_data[lane] <= data_in[lane];
                        invert_flag[lane] <= 1'b0;
                    end
                end
            end
            
            // 操作数隔离
            always @(posedge clk) begin
                if (!rst_n) begin
                    isolated_data[lane] <= 0;
                    lane_active[lane] <= 0;
                end else begin
                    if (data_valid[lane]) begin
                        isolated_data[lane] <= encoded_data[lane];
                        lane_active[lane] <= 1'b1;
                    end else begin
                        // 保持之前的值，避免不必要的翻转
                        isolated_data[lane] <= isolated_data[lane];
                        lane_active[lane] <= 1'b0;
                    end
                end
            end
            
            // 输出解码
            always @(posedge clk) begin
                if (!rst_n) begin
                    data_out[lane] <= 0;
                    data_out_valid[lane] <= 0;
                end else begin
                    if (lane_active[lane]) begin
                        // 根据反转标志恢复数据
                        data_out[lane] <= invert_flag[lane] ? 
                                        ~isolated_data[lane] : isolated_data[lane];
                        data_out_valid[lane] <= 1'b1;
                    end else begin
                        data_out_valid[lane] <= 1'b0;
                    end
                end
            end
        end
    endgenerate
endmodule
            </div>

            <h3>11.4 稀疏计算加速</h3>
            
            <p>神经网络中存在大量的稀疏性（零值），利用这种稀疏性可以显著减少计算量和功耗。硬件级的稀疏计算加速是NPU优化的重要方向。</p>
            
            <h4>11.4.1 稀疏检测与跳过</h4>
            <div class="code-block">
// 稀疏计算加速器
module SparseAccelerator #(
    parameter DATA_WIDTH = 8,
    parameter MATRIX_SIZE = 16,
    parameter SPARSITY_THRESHOLD = 0.5
)(
    input wire clk,
    input wire rst_n,
    
    // 稀疏矩阵输入（CSR格式）
    input wire [DATA_WIDTH-1:0] values[0:255],      // 非零值
    input wire [7:0] col_indices[0:255],            // 列索引
    input wire [8:0] row_ptr[0:MATRIX_SIZE],        // 行指针
    input wire [8:0] nnz,                           // 非零元素数量
    
    // 密集向量输入
    input wire [DATA_WIDTH-1:0] vector[0:MATRIX_SIZE-1],
    
    // 输出
    output reg [31:0] result[0:MATRIX_SIZE-1],
    output reg compute_done
);
    
    // 稀疏矩阵向量乘法（SpMV）实现
    reg [8:0] current_row;
    reg [8:0] value_idx;
    reg [2:0] state;
    
    localparam IDLE = 3'b000;
    localparam LOAD_ROW = 3'b001;
    localparam COMPUTE = 3'b010;
    localparam STORE = 3'b011;
    localparam DONE = 3'b100;
    
    // 计算单元
    reg [31:0] accumulator;
    wire [15:0] mult_result;
    
    // 零值跳过逻辑
    wire is_zero_value = (values[value_idx] == 0);
    wire is_zero_vector = (vector[col_indices[value_idx]] == 0);
    wire skip_computation = is_zero_value || is_zero_vector;
    
    // 乘法器（只在非零时激活）
    assign mult_result = skip_computation ? 16'd0 : 
                        values[value_idx] * vector[col_indices[value_idx]];
    
    always @(posedge clk) begin
        if (!rst_n) begin
            state <= IDLE;
            current_row <= 0;
            value_idx <= 0;
            compute_done <= 0;
        end else begin
            case (state)
                IDLE: begin
                    if (nnz > 0) begin
                        state <= LOAD_ROW;
                        current_row <= 0;
                        value_idx <= row_ptr[0];
                        accumulator <= 0;
                    end
                end
                
                LOAD_ROW: begin
                    if (current_row < MATRIX_SIZE) begin
                        accumulator <= 0;
                        state <= COMPUTE;
                    end else begin
                        state <= DONE;
                    end
                end
                
                COMPUTE: begin
                    if (value_idx < row_ptr[current_row + 1]) begin
                        if (!skip_computation) begin
                            // 只在非零时累加
                            accumulator <= accumulator + mult_result;
                        end
                        value_idx <= value_idx + 1;
                    end else begin
                        state <= STORE;
                    end
                end
                
                STORE: begin
                    result[current_row] <= accumulator;
                    current_row <= current_row + 1;
                    if (current_row + 1 < MATRIX_SIZE) begin
                        value_idx <= row_ptr[current_row + 1];
                        state <= LOAD_ROW;
                    end else begin
                        state <= DONE;
                    end
                end
                
                DONE: begin
                    compute_done <= 1;
                    state <= IDLE;
                end
            endcase
        end
    end
    
    // 性能计数器
    reg [31:0] total_operations;
    reg [31:0] skipped_operations;
    
    always @(posedge clk) begin
        if (!rst_n) begin
            total_operations <= 0;
            skipped_operations <= 0;
        end else if (state == COMPUTE) begin
            total_operations <= total_operations + 1;
            if (skip_computation) begin
                skipped_operations <= skipped_operations + 1;
            end
        end
    end
    
    // 稀疏度统计
    wire [31:0] sparsity_percentage = (skipped_operations * 100) / total_operations;
    
endmodule

// 零值跳过MAC单元
module ZeroSkippingMAC #(
    parameter DATA_WIDTH = 8
)(
    input wire clk,
    input wire rst_n,
    input wire enable,
    
    input wire [DATA_WIDTH-1:0] weight,
    input wire [DATA_WIDTH-1:0] activation,
    input wire [31:0] accumulator_in,
    
    output reg [31:0] accumulator_out,
    output reg valid_out,
    output reg operation_skipped
);
    
    // 零检测
    wire weight_is_zero = (weight == 0);
    wire activation_is_zero = (activation == 0);
    wire skip_mac = weight_is_zero || activation_is_zero;
    
    // MAC操作
    wire [2*DATA_WIDTH-1:0] product = weight * activation;
    
    always @(posedge clk) begin
        if (!rst_n) begin
            accumulator_out <= 0;
            valid_out <= 0;
            operation_skipped <= 0;
        end else if (enable) begin
            if (skip_mac) begin
                // 跳过计算，直接传递累加器值
                accumulator_out <= accumulator_in;
                operation_skipped <= 1'b1;
            end else begin
                // 执行MAC操作
                accumulator_out <= accumulator_in + product;
                operation_skipped <= 1'b0;
            end
            valid_out <= 1'b1;
        end else begin
            valid_out <= 1'b0;
        end
    end
    
endmodule
            </div>
            
            <h4>11.4.2 稀疏数据格式与硬件支持</h4>
            <p>不同的稀疏格式适合不同的硬件实现和应用场景：</p>
            <ul>
                <li><strong>CSR (Compressed Sparse Row)：</strong>适合行稀疏矩阵，硬件实现简单</li>
                <li><strong>CSC (Compressed Sparse Column)：</strong>适合列稀疏矩阵</li>
                <li><strong>COO (Coordinate)：</strong>最灵活但存储开销大</li>
                <li><strong>Bitmap：</strong>使用位图标记非零位置，适合中等稀疏度</li>
            </ul>
            
            <div class="info-box">
                <p><strong>稀疏加速效果：</strong>在典型的剪枝神经网络中，稀疏度可达90%以上。通过零值跳过，理论上可以减少90%的MAC操作，实际加速比取决于硬件实现的效率和数据访问模式。</p>
            </div>

            <h3>11.5 面积优化</h3>
            
            <p>面积优化直接影响芯片成本。通过资源共享、存储压缩等技术，可以在满足性能要求的前提下显著减小芯片面积。</p>

            <h4>11.5.1 计算单元复用</h4>
            <div class="code-block">
// 可重构计算单元
module ReconfigurableComputeUnit #(
    parameter DATA_WIDTH = 8,
    parameter ACCUM_WIDTH = 32
)(
    input wire clk,
    input wire rst_n,
    
    // 操作模式
    input wire [2:0] op_mode,  // 0:MAC 1:ADD 2:MUL 3:COMP 4:POOL
    
    // 输入数据
    input wire [DATA_WIDTH-1:0] operand_a,
    input wire [DATA_WIDTH-1:0] operand_b,
    input wire [DATA_WIDTH-1:0] operand_c,  // 用于MAC
    input wire [ACCUM_WIDTH-1:0] accumulator_in,
    
    // 输出
    output reg [ACCUM_WIDTH-1:0] result_out,
    output reg result_valid
);
    
    // 共享的算术单元
    reg [DATA_WIDTH*2-1:0] mult_result;
    reg [ACCUM_WIDTH-1:0] add_result;
    reg comparison_result;
    
    // 操作模式定义
    localparam OP_MAC = 3'b000;
    localparam OP_ADD = 3'b001;
    localparam OP_MUL = 3'b010;
    localparam OP_MAX = 3'b011;
    localparam OP_MIN = 3'b100;
    
    // 组合逻辑计算
    always @(*) begin
        mult_result = operand_a * operand_b;
        add_result = accumulator_in + {{(ACCUM_WIDTH-DATA_WIDTH){operand_a[DATA_WIDTH-1]}}, operand_a};
        comparison_result = operand_a > operand_b;
    end
    
    // 流水线寄存器
    reg [2:0] op_mode_r1, op_mode_r2;
    reg [ACCUM_WIDTH-1:0] stage1_result;
    
    // 第一级流水线：执行基本运算
    always @(posedge clk) begin
        if (!rst_n) begin
            stage1_result <= 0;
            op_mode_r1 <= 0;
        end else begin
            op_mode_r1 <= op_mode;
            
            case (op_mode)
                OP_MAC: begin
                    // MAC第一步：乘法
                    stage1_result <= {{(ACCUM_WIDTH-DATA_WIDTH*2){mult_result[DATA_WIDTH*2-1]}}, mult_result};
                end
                
                OP_ADD: begin
                    // 直接加法
                    stage1_result <= add_result;
                end
                
                OP_MUL: begin
                    // 乘法结果扩展
                    stage1_result <= {{(ACCUM_WIDTH-DATA_WIDTH*2){mult_result[DATA_WIDTH*2-1]}}, mult_result};
                end
                
                OP_MAX: begin
                    // 最大值
                    stage1_result <= comparison_result ? 
                        {{(ACCUM_WIDTH-DATA_WIDTH){operand_a[DATA_WIDTH-1]}}, operand_a} :
                        {{(ACCUM_WIDTH-DATA_WIDTH){operand_b[DATA_WIDTH-1]}}, operand_b};
                end
                
                OP_MIN: begin
                    // 最小值
                    stage1_result <= comparison_result ? 
                        {{(ACCUM_WIDTH-DATA_WIDTH){operand_b[DATA_WIDTH-1]}}, operand_b} :
                        {{(ACCUM_WIDTH-DATA_WIDTH){operand_a[DATA_WIDTH-1]}}, operand_a};
                end
                
                default: begin
                    stage1_result <= 0;
                end
            endcase
        end
    end
    
    // 第二级流水线：完成累加或输出
    always @(posedge clk) begin
        if (!rst_n) begin
            result_out <= 0;
            result_valid <= 0;
            op_mode_r2 <= 0;
        end else begin
            op_mode_r2 <= op_mode_r1;
            result_valid <= 1'b1;
            
            case (op_mode_r1)
                OP_MAC: begin
                    // MAC第二步：累加
                    result_out <= stage1_result + accumulator_in;
                end
                
                default: begin
                    // 其他操作直接输出
                    result_out <= stage1_result;
                end
            endcase
        end
    end
endmodule

// 共享计算阵列
module SharedComputeArray #(
    parameter ARRAY_SIZE = 16,
    parameter DATA_WIDTH = 8
)(
    input wire clk,
    input wire rst_n,
    
    // 全局控制
    input wire [2:0] array_mode,  // 0:卷积 1:矩阵乘 2:池化 3:激活
    
    // 数据输入
    input wire [ARRAY_SIZE-1:0][DATA_WIDTH-1:0] input_a,
    input wire [ARRAY_SIZE-1:0][DATA_WIDTH-1:0] input_b,
    input wire [ARRAY_SIZE-1:0][31:0] partial_sums,
    
    // 数据输出
    output wire [ARRAY_SIZE-1:0][31:0] output_results
);
    
    // 模式配置
    reg [2:0] unit_op_mode [ARRAY_SIZE-1:0];
    
    // 根据阵列模式配置单元操作
    always @(*) begin
        case (array_mode)
            3'b000: begin  // 卷积模式
                for (int i = 0; i < ARRAY_SIZE; i++) begin
                    unit_op_mode[i] = 3'b000;  // MAC
                end
            end
            
            3'b001: begin  // 矩阵乘法模式
                for (int i = 0; i < ARRAY_SIZE; i++) begin
                    unit_op_mode[i] = 3'b000;  // MAC
                end
            end
            
            3'b010: begin  // 最大池化
                for (int i = 0; i < ARRAY_SIZE; i++) begin
                    unit_op_mode[i] = 3'b011;  // MAX
                end
            end
            
            3'b011: begin  // ReLU激活
                for (int i = 0; i < ARRAY_SIZE; i++) begin
                    unit_op_mode[i] = 3'b011;  // MAX(x, 0)
                end
            end
            
            default: begin
                for (int i = 0; i < ARRAY_SIZE; i++) begin
                    unit_op_mode[i] = 3'b000;
                end
            end
        endcase
    end
    
    // 实例化共享计算单元
    genvar i;
    generate
        for (i = 0; i < ARRAY_SIZE; i = i + 1) begin : compute_units
            ReconfigurableComputeUnit unit (
                .clk(clk),
                .rst_n(rst_n),
                .op_mode(unit_op_mode[i]),
                .operand_a(input_a[i]),
                .operand_b(input_b[i]),
                .operand_c(8'h0),  // 池化模式下不使用
                .accumulator_in(partial_sums[i]),
                .result_out(output_results[i]),
                .result_valid()
            );
        end
    endgenerate
endmodule
            </div>

            <h4>11.5.2 存储压缩技术</h4>
            <div class="code-block">
// 权重压缩存储单元
module CompressedWeightStorage #(
    parameter WEIGHT_WIDTH = 8,
    parameter BLOCK_SIZE = 16,
    parameter MEMORY_DEPTH = 1024
)(
    input wire clk,
    input wire rst_n,
    
    // 写入接口（压缩）
    input wire write_enable,
    input wire [9:0] write_addr,
    input wire [BLOCK_SIZE-1:0][WEIGHT_WIDTH-1:0] write_data,
    
    // 读取接口（解压）
    input wire read_enable,
    input wire [9:0] read_addr,
    output reg [BLOCK_SIZE-1:0][WEIGHT_WIDTH-1:0] read_data,
    output reg read_valid
);
    
    // 压缩存储格式
    // [元数据(16bit)][压缩数据(变长)]
    // 元数据：[压缩类型(2bit)][块长度(6bit)][零掩码(8bit)]
    
    // 内部存储
    reg [127:0] compressed_memory [MEMORY_DEPTH-1:0];
    reg [15:0] metadata_memory [MEMORY_DEPTH-1:0];
    
    // 压缩逻辑
    reg [1:0] compression_type;
    reg [5:0] compressed_length;
    reg [BLOCK_SIZE-1:0] zero_mask;
    reg [127:0] compressed_data;
    
    // 检测零值
    integer i;
    always @(*) begin
        zero_mask = 0;
        for (i = 0; i < BLOCK_SIZE; i = i + 1) begin
            zero_mask[i] = (write_data[i] == 0);
        end
    end
    
    // 计算非零值数量
    reg [4:0] non_zero_count;
    always @(*) begin
        non_zero_count = 0;
        for (i = 0; i < BLOCK_SIZE; i = i + 1) begin
            if (!zero_mask[i]) non_zero_count = non_zero_count + 1;
        end
    end
    
    // 压缩写入
    always @(posedge clk) begin
        if (!rst_n) begin
            compression_type <= 0;
            compressed_length <= 0;
        end else if (write_enable) begin
            // 选择压缩方案
            if (non_zero_count <= 4) begin
                // 稀疏压缩：只存储非零值和位置
                compression_type <= 2'b00;
                compressed_length <= non_zero_count * (WEIGHT_WIDTH + 4);
                
                // 打包非零值
                compressed_data <= 0;
                for (i = 0; i < BLOCK_SIZE; i = i + 1) begin
                    if (!zero_mask[i]) begin
                        compressed_data <= {compressed_data[119:0], write_data[i]};
                    end
                end
            end else if (non_zero_count == BLOCK_SIZE) begin
                // 无压缩：直接存储
                compression_type <= 2'b01;
                compressed_length <= BLOCK_SIZE * WEIGHT_WIDTH;
                compressed_data <= write_data;
            end else begin
                // 零值压缩：使用掩码
                compression_type <= 2'b10;
                compressed_length <= non_zero_count * WEIGHT_WIDTH;
                
                // 打包非零值
                compressed_data <= 0;
                for (i = 0; i < BLOCK_SIZE; i = i + 1) begin
                    if (!zero_mask[i]) begin
                        compressed_data <= {compressed_data[119:0], write_data[i]};
                    end
                end
            end
            
            // 写入存储
            metadata_memory[write_addr] <= {compression_type, compressed_length, zero_mask[7:0]};
            compressed_memory[write_addr] <= compressed_data;
        end
    end
    
    // 解压读取
    reg [15:0] read_metadata;
    reg [127:0] read_compressed;
    reg [1:0] decomp_type;
    reg [5:0] decomp_length;
    reg [7:0] decomp_zero_mask;
    
    always @(posedge clk) begin
        if (!rst_n) begin
            read_data <= 0;
            read_valid <= 0;
        end else if (read_enable) begin
            // 读取元数据和压缩数据
            read_metadata <= metadata_memory[read_addr];
            read_compressed <= compressed_memory[read_addr];
            read_valid <= 1'b1;
            
            // 解析元数据
            decomp_type <= read_metadata[15:14];
            decomp_length <= read_metadata[13:8];
            decomp_zero_mask <= read_metadata[7:0];
            
            // 根据压缩类型解压
            case (read_metadata[15:14])
                2'b00: begin  // 稀疏压缩
                    // 恢复零值
                    read_data <= 0;
                    // 填充非零值（简化示例）
                end
                
                2'b01: begin  // 无压缩
                    read_data <= read_compressed[BLOCK_SIZE*WEIGHT_WIDTH-1:0];
                end
                
                2'b10: begin  // 零值压缩
                    // 根据掩码恢复
                    read_data <= 0;
                    for (i = 0; i < BLOCK_SIZE; i = i + 1) begin
                        if (!decomp_zero_mask[i]) begin
                            read_data[i] <= read_compressed[WEIGHT_WIDTH-1:0];
                            read_compressed <= read_compressed >> WEIGHT_WIDTH;
                        end
                    end
                end
            endcase
        end else begin
            read_valid <= 0;
        end
    end
endmodule
            </div>

            <div class="exercise">
                <h4>练习 11.1：量化感知训练</h4>
                <div class="question">
                    <p><strong>题目：</strong>设计一个支持量化感知训练（QAT）的前向传播单元，要求：
                    1) 支持FP32训练和INT8推理模式切换
                    2) 实现fake quantization操作
                    3) 支持per-channel量化参数</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：QAT在训练时模拟量化效果但仍用FP32计算。Fake量化：FP32→INT8→FP32的过程。Per-channel意味着每个通道有独立的scale和zero_point。模式切换需要multiplexer选择数据路径。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module QATForwardUnit #(
    parameter NUM_CHANNELS = 64,
    parameter FP_WIDTH = 32,
    parameter INT_WIDTH = 8
)(
    input wire clk,
    input wire rst_n,
    
    // 模式控制
    input wire training_mode,  // 1: 训练, 0: 推理
    
    // FP32输入（训练模式）
    input wire [NUM_CHANNELS-1:0][FP_WIDTH-1:0] fp_input,
    
    // INT8输入（推理模式）
    input wire [NUM_CHANNELS-1:0][INT_WIDTH-1:0] int_input,
    
    // 量化参数（per-channel）
    input wire [NUM_CHANNELS-1:0][15:0] scale,      // Q8.8
    input wire [NUM_CHANNELS-1:0][7:0] zero_point,
    
    // 输出
    output reg [NUM_CHANNELS-1:0][FP_WIDTH-1:0] fp_output,
    output reg [NUM_CHANNELS-1:0][INT_WIDTH-1:0] int_output,
    output reg output_valid
);
    
    // Fake quantization流水线
    reg [NUM_CHANNELS-1:0][FP_WIDTH-1:0] quantized_fp;
    reg [NUM_CHANNELS-1:0][INT_WIDTH-1:0] quantized_int;
    reg stage1_valid, stage2_valid;
    
    genvar ch;
    generate
        for (ch = 0; ch < NUM_CHANNELS; ch = ch + 1) begin : channel_quant
            // 第一级：量化到INT8
            always @(posedge clk) begin
                if (!rst_n) begin
                    quantized_int[ch] <= 0;
                end else if (training_mode) begin
                    // 量化：q = round(x/scale) + zero_point
                    // 简化实现，实际需要浮点除法
                    reg [FP_WIDTH-1:0] scaled_val;
                    scaled_val = fp_input[ch] / scale[ch];
                    
                    // 四舍五入和饱和
                    if (scaled_val + zero_point[ch] > 127) begin
                        quantized_int[ch] <= 8'd127;
                    end else if (scaled_val + zero_point[ch] < -128) begin
                        quantized_int[ch] <= 8'd128;  // -128的补码表示
                    end else begin
                        quantized_int[ch] <= scaled_val + zero_point[ch];
                    end
                end else begin
                    // 推理模式直接使用INT8输入
                    quantized_int[ch] <= int_input[ch];
                end
            end
            
            // 第二级：反量化到FP32（仅训练模式）
            always @(posedge clk) begin
                if (!rst_n) begin
                    quantized_fp[ch] <= 0;
                end else if (stage1_valid && training_mode) begin
                    // 反量化：x = (q - zero_point) * scale
                    quantized_fp[ch] <= (quantized_int[ch] - zero_point[ch]) * scale[ch];
                end
            end
        end
    endgenerate
    
    // 输出选择
    always @(posedge clk) begin
        if (!rst_n) begin
            fp_output <= 0;
            int_output <= 0;
            output_valid <= 0;
        end else begin
            if (training_mode) begin
                fp_output <= quantized_fp;
                int_output <= quantized_int;  // 也输出量化值用于统计
            end else begin
                fp_output <= 0;  // 推理模式不需要FP输出
                int_output <= quantized_int;
            end
            
            output_valid <= stage2_valid;
        end
    end
    
    // 流水线控制
    always @(posedge clk) begin
        if (!rst_n) begin
            stage1_valid <= 0;
            stage2_valid <= 0;
        end else begin
            stage1_valid <= 1'b1;  // 假设输入总是有效
            stage2_valid <= stage1_valid;
        end
    end
endmodule
                        </div>
                    </div>
                </div>
            </div>

            <div class="exercise">
                <h4>练习 11.2：动态数据流优化</h4>
                <div class="question">
                    <p><strong>题目：</strong>实现一个动态数据流控制器，能够根据层类型和数据特征自适应选择最优数据流模式（WS/OS/RS）。考虑：
                    1) 不同层类型的数据复用特征
                    2) 片上存储容量限制
                    3) 数据流切换开销</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：分析不同层类型（1×1卷积适合WS，深度卷积适合OS）。计算每种模式的内存需求和数据复用率。切换开销包括重新配置和数据重排。使用决策表或启发式算法。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module AdaptiveDataflowController #(
    parameter SRAM_SIZE = 512 * 1024,  // 512KB
    parameter PE_ARRAY_DIM = 16
)(
    input wire clk,
    input wire rst_n,
    
    // 层配置
    input wire [3:0] layer_type,  // 0:Conv 1:DW-Conv 2:FC 3:Pool
    input wire [15:0] input_h, input_w, input_c,
    input wire [15:0] output_h, output_w, output_c,
    input wire [3:0] kernel_size,
    input wire [3:0] stride,
    
    // 数据流选择输出
    output reg [1:0] dataflow_mode,  // 0:WS 1:OS 2:RS
    output reg [7:0] tile_config [3:0],  // [H,W,IC,OC]
    output reg config_valid
);
    
    // 数据流模式定义
    localparam WS = 2'b00;  // Weight Stationary
    localparam OS = 2'b01;  // Output Stationary
    localparam RS = 2'b10;  // Row Stationary
    
    // 计算数据复用度
    function [31:0] calc_ws_reuse;
        input [15:0] ih, iw, ic, oc;
        input [3:0] ks;
        begin
            // WS复用度：每个权重被使用ih*iw次
            calc_ws_reuse = ih * iw;
        end
    endfunction
    
    function [31:0] calc_os_reuse;
        input [15:0] ih, iw, ic, oc;
        input [3:0] ks;
        begin
            // OS复用度：每个输出累加ks*ks*ic次
            calc_os_reuse = ks * ks * ic;
        end
    endfunction
    
    function [31:0] calc_rs_reuse;
        input [15:0] ih, iw, ic, oc;
        input [3:0] ks;
        begin
            // RS复用度：综合考虑
            calc_rs_reuse = (ih * iw + ks * ks * ic + oc) / 3;
        end
    endfunction
    
    // 决策状态机
    reg [2:0] decision_state;
    reg [31:0] ws_score, os_score, rs_score;
    
    always @(posedge clk) begin
        if (!rst_n) begin
            decision_state <= 0;
            dataflow_mode <= WS;
            config_valid <= 0;
        end else begin
            case (decision_state)
                3'b000: begin  // 分析层特征
                    case (layer_type)
                        4'b0000: begin  // 标准卷积
                            if (output_c > 256 && kernel_size <= 3) begin
                                // 大量输出通道，小卷积核 -> WS
                                dataflow_mode <= WS;
                            end else if (input_c > 256) begin
                                // 大量输入通道 -> OS
                                dataflow_mode <= OS;
                            end else begin
                                // 平衡情况 -> RS
                                dataflow_mode <= RS;
                            end
                        end
                        
                        4'b0001: begin  // 深度可分离卷积
                            // DW卷积适合OS（输出通道少）
                            dataflow_mode <= OS;
                        end
                        
                        4'b0010: begin  // 全连接层
                            // FC层适合WS（大量权重复用）
                            dataflow_mode <= WS;
                        end
                        
                        4'b0011: begin  // 池化层
                            // 池化无权重，使用OS
                            dataflow_mode <= OS;
                        end
                    endcase
                    decision_state <= 3'b001;
                end
                
                3'b001: begin  // 计算复用度得分
                    ws_score <= calc_ws_reuse(input_h, input_w, input_c, output_c, kernel_size);
                    os_score <= calc_os_reuse(input_h, input_w, input_c, output_c, kernel_size);
                    rs_score <= calc_rs_reuse(input_h, input_w, input_c, output_c, kernel_size);
                    decision_state <= 3'b010;
                end
                
                3'b010: begin  // 选择最优数据流
                    if (ws_score >= os_score && ws_score >= rs_score) begin
                        dataflow_mode <= WS;
                    end else if (os_score >= rs_score) begin
                        dataflow_mode <= OS;
                    end else begin
                        dataflow_mode <= RS;
                    end
                    decision_state <= 3'b011;
                end
                
                3'b011: begin  // 配置分块参数
                    case (dataflow_mode)
                        WS: begin
                            // 权重固定：最大化权重在片上
                            tile_config[0] <= (input_h > 32) ? 32 : input_h;
                            tile_config[1] <= (input_w > 32) ? 32 : input_w;
                            tile_config[2] <= input_c;  // 所有输入通道
                            tile_config[3] <= (output_c > PE_ARRAY_DIM) ? PE_ARRAY_DIM : output_c;
                        end
                        
                        OS: begin
                            // 输出固定：平衡各维度
                            tile_config[0] <= (output_h > 16) ? 16 : output_h;
                            tile_config[1] <= (output_w > 16) ? 16 : output_w;
                            tile_config[2] <= (input_c > 64) ? 64 : input_c;
                            tile_config[3] <= (output_c > 64) ? 64 : output_c;
                        end
                        
                        RS: begin
                            // 行固定：优化行方向复用
                            tile_config[0] <= PE_ARRAY_DIM;
                            tile_config[1] <= (input_w > 64) ? 64 : input_w;
                            tile_config[2] <= (input_c > 32) ? 32 : input_c;
                            tile_config[3] <= (output_c > 32) ? 32 : output_c;
                        end
                    endcase
                    decision_state <= 3'b100;
                end
                
                3'b100: begin  // 完成配置
                    config_valid <= 1'b1;
                    decision_state <= 3'b101;
                end
                
                3'b101: begin  // 等待新请求
                    config_valid <= 1'b0;
                    decision_state <= 3'b000;
                end
            endcase
        end
    end
endmodule
                        </div>
                    </div>
                </div>
            </div>

            <div class="exercise">
                <h4>练习 11.3：层次化功耗管理</h4>
                <div class="question">
                    <p><strong>题目：</strong>设计一个层次化的功耗管理系统，包括：
                    1) 芯片级、簇级、核心级三层功耗控制
                    2) 基于负载预测的DVFS策略
                    3) 细粒度的时钟门控和电源门控
                    4) 功耗预算分配机制</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：层次化管理允许不同粒度的控制。DVFS需要预测未来负载并提前调整。时钟门控在细粒度上节省动态功耗。功耗预算分配需要考虑优先级和性能要求。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module HierarchicalPowerManager #(
    parameter NUM_CLUSTERS = 4,
    parameter CORES_PER_CLUSTER = 8,
    parameter POWER_BUDGET = 10000  // mW
)(
    input wire clk,
    input wire rst_n,
    
    // 性能监控
    input wire [31:0] global_instruction_count,
    input wire [NUM_CLUSTERS-1:0][31:0] cluster_active_cycles,
    input wire [NUM_CLUSTERS-1:0][CORES_PER_CLUSTER-1:0] core_utilization,
    
    // 温度监控
    input wire [7:0] chip_temperature,  // 摄氏度
    input wire [NUM_CLUSTERS-1:0][7:0] cluster_temperature,
    
    // 功耗控制输出
    output reg [3:0] chip_voltage_level,
    output reg [3:0] chip_frequency_level,
    output reg [NUM_CLUSTERS-1:0][3:0] cluster_voltage_level,
    output reg [NUM_CLUSTERS-1:0] cluster_power_gate,
    output reg [NUM_CLUSTERS-1:0][CORES_PER_CLUSTER-1:0] core_clock_gate,
    
    // 功耗统计
    output reg [31:0] estimated_power,
    output reg [NUM_CLUSTERS-1:0][15:0] cluster_power_allocation
);
    
    // 功耗模型参数
    localparam STATIC_POWER_BASE = 100;   // mW
    localparam DYNAMIC_POWER_COEF = 50;  // mW/GHz/V²
    
    // 负载预测
    reg [31:0] load_history [63:0];
    reg [5:0] history_ptr;
    reg [31:0] predicted_load;
    
    // 移动平均负载预测
    integer i;
    always @(posedge clk) begin
        if (!rst_n) begin
            history_ptr <= 0;
            predicted_load <= 0;
        end else begin
            load_history[history_ptr] <= global_instruction_count;
            history_ptr <= history_ptr + 1;
            
            // 计算未来负载（简单线性预测）
            if (history_ptr >= 4) begin
                predicted_load <= load_history[history_ptr-1] + 
                    (load_history[history_ptr-1] - load_history[history_ptr-4]) / 3;
            end
        end
    end
    
    // 温度管理状态机
    reg [2:0] thermal_state;
    localparam THERMAL_NORMAL = 3'b000;
    localparam THERMAL_WARM = 3'b001;
    localparam THERMAL_HOT = 3'b010;
    localparam THERMAL_CRITICAL = 3'b011;
    localparam THERMAL_SHUTDOWN = 3'b100;
    
    always @(posedge clk) begin
        if (!rst_n) begin
            thermal_state <= THERMAL_NORMAL;
        end else begin
            if (chip_temperature > 95) begin
                thermal_state <= THERMAL_SHUTDOWN;
            end else if (chip_temperature > 85) begin
                thermal_state <= THERMAL_CRITICAL;
            end else if (chip_temperature > 75) begin
                thermal_state <= THERMAL_HOT;
            end else if (chip_temperature > 65) begin
                thermal_state <= THERMAL_WARM;
            end else begin
                thermal_state <= THERMAL_NORMAL;
            end
        end
    end
    
    // 芯片级DVFS控制
    reg [31:0] target_performance;
    reg [31:0] power_headroom;
    
    always @(posedge clk) begin
        if (!rst_n) begin
            chip_voltage_level <= 4'b1000;   // 中等电压
            chip_frequency_level <= 4'b1000;  // 中等频率
        end else begin
            // 根据热状态调整
            case (thermal_state)
                THERMAL_SHUTDOWN: begin
                    chip_voltage_level <= 4'b0001;
                    chip_frequency_level <= 4'b0001;
                end
                
                THERMAL_CRITICAL: begin
                    if (chip_voltage_level > 4'b0100) begin
                        chip_voltage_level <= chip_voltage_level - 1;
                        chip_frequency_level <= chip_frequency_level - 1;
                    end
                end
                
                THERMAL_HOT: begin
                    if (chip_voltage_level > 4'b0110) begin
                        chip_voltage_level <= chip_voltage_level - 1;
                        chip_frequency_level <= chip_frequency_level - 1;
                    end
                end
                
                THERMAL_NORMAL: begin
                    // 基于负载预测调整
                    if (predicted_load > target_performance * 110 / 100) begin
                        // 需要提升性能
                        if (chip_voltage_level < 4'b1111 && estimated_power < POWER_BUDGET * 90 / 100) begin
                            chip_voltage_level <= chip_voltage_level + 1;
                            chip_frequency_level <= chip_frequency_level + 1;
                        end
                    end else if (predicted_load < target_performance * 50 / 100) begin
                        // 可以降低功耗
                        if (chip_voltage_level > 4'b0100) begin
                            chip_voltage_level <= chip_voltage_level - 1;
                            chip_frequency_level <= chip_frequency_level - 1;
                        end
                    end
                end
            endcase
        end
    end
    
    // 簇级功耗分配
    reg [31:0] cluster_load [NUM_CLUSTERS-1:0];
    reg [31:0] total_cluster_load;
    
    always @(posedge clk) begin
        if (!rst_n) begin
            for (i = 0; i < NUM_CLUSTERS; i = i + 1) begin
                cluster_power_allocation[i] <= POWER_BUDGET / NUM_CLUSTERS;
                cluster_voltage_level[i] <= 4'b1000;
                cluster_power_gate[i] <= 1'b0;
            end
        end else begin
            // 计算各簇负载
            total_cluster_load = 0;
            for (i = 0; i < NUM_CLUSTERS; i = i + 1) begin
                cluster_load[i] = cluster_active_cycles[i];
                total_cluster_load = total_cluster_load + cluster_load[i];
            end
            
            // 按负载比例分配功耗预算
            for (i = 0; i < NUM_CLUSTERS; i = i + 1) begin
                if (total_cluster_load > 0) begin
                    cluster_power_allocation[i] <= 
                        (POWER_BUDGET - STATIC_POWER_BASE) * cluster_load[i] / total_cluster_load;
                end
                
                // 簇级电源门控
                if (cluster_load[i] == 0 && thermal_state != THERMAL_NORMAL) begin
                    cluster_power_gate[i] <= 1'b1;  // 关闭空闲簇
                end else begin
                    cluster_power_gate[i] <= 1'b0;
                end
                
                // 簇级DVFS
                if (cluster_temperature[i] > 80) begin
                    cluster_voltage_level[i] <= 4'b0110;  // 降温
                end else if (cluster_power_allocation[i] > 3000) begin
                    cluster_voltage_level[i] <= 4'b1111;  // 高性能
                end else if (cluster_power_allocation[i] > 2000) begin
                    cluster_voltage_level[i] <= 4'b1100;  // 中高性能
                end else if (cluster_power_allocation[i] > 1000) begin
                    cluster_voltage_level[i] <= 4'b1000;  // 中等性能
                end else begin
                    cluster_voltage_level[i] <= 4'b0100;  // 低功耗
                end
            end
        end
    end
    
    // 核心级时钟门控
    genvar c, p;
    generate
        for (c = 0; c < NUM_CLUSTERS; c = c + 1) begin : cluster_gen
            for (p = 0; p < CORES_PER_CLUSTER; p = p + 1) begin : core_gen
                always @(posedge clk) begin
                    if (!rst_n) begin
                        core_clock_gate[c][p] <= 1'b0;
                    end else begin
                        // 细粒度时钟门控
                        if (core_utilization[c][p] < 8'd10) begin
                            core_clock_gate[c][p] <= 1'b1;  // 关闭低利用率核心
                        end else begin
                            core_clock_gate[c][p] <= 1'b0;
                        end
                    end
                end
            end
        end
    endgenerate
    
    // 功耗估算
    always @(posedge clk) begin
        if (!rst_n) begin
            estimated_power <= 0;
        end else begin
            estimated_power = STATIC_POWER_BASE;
            
            // 芯片动态功耗
            estimated_power = estimated_power + 
                DYNAMIC_POWER_COEF * chip_frequency_level * 
                chip_voltage_level * chip_voltage_level / 256;
            
            // 各簇功耗
            for (i = 0; i < NUM_CLUSTERS; i = i + 1) begin
                if (!cluster_power_gate[i]) begin
                    estimated_power = estimated_power + 
                        cluster_power_allocation[i] * 
                        cluster_voltage_level[i] * cluster_voltage_level[i] / 256;
                end
            end
        end
    end
endmodule
                        </div>
                    </div>
                </div>
            </div>

            <div class="exercise">
                <h4>练习 11.4：稀疏计算加速器设计</h4>
                <div class="question">
                    <p><strong>题目：</strong>设计一个高效的稀疏计算加速器，支持：
                    1) 动态稀疏检测和零值跳过
                    2) 多种稀疏格式（CSR、COO、Bitmap）
                    3) 稀疏度自适应的负载均衡</p>
                    <p>要求：实现稀疏矩阵乘法（SpMM），对比稠密计算的性能提升，并分析不同稀疏度下的加速效果。</p>
                </div>
                <button class="toggle-answer">显示答案</button>
                <div class="answer" style="display: none;">
                    <div class="code-block">
// 稀疏矩阵乘法加速器
module SparseMatrixMultiplier #(
    parameter DATA_WIDTH = 8,
    parameter MATRIX_DIM = 16,
    parameter MAX_NNZ = 256
)(
    input wire clk,
    input wire rst_n,
    
    // 控制信号
    input wire start,
    input wire [1:0] sparse_format,  // 0:CSR 1:COO 2:Bitmap
    
    // 稀疏矩阵A（CSR格式）
    input wire [DATA_WIDTH-1:0] a_values[MAX_NNZ-1:0],
    input wire [7:0] a_col_idx[MAX_NNZ-1:0],
    input wire [8:0] a_row_ptr[MATRIX_DIM:0],
    
    // 稀疏矩阵B（可以是稠密或稀疏）
    input wire [DATA_WIDTH-1:0] b_matrix[MATRIX_DIM-1:0][MATRIX_DIM-1:0],
    input wire b_is_sparse,
    
    // 输出矩阵C
    output reg [31:0] c_matrix[MATRIX_DIM-1:0][MATRIX_DIM-1:0],
    output reg done
);
    
    // 稀疏度统计
    reg [31:0] zero_count, total_count;
    wire [7:0] sparsity = (zero_count * 100) / total_count;
    
    // 负载均衡单元
    reg [3:0] active_rows[3:0];  // 4个并行处理单元
    reg [3:0] row_assignment[MATRIX_DIM-1:0];
    
    // 根据每行的非零元素数量进行负载均衡
    always @(posedge clk) begin
        if (!rst_n) begin
            for (int i = 0; i < 4; i++) begin
                active_rows[i] <= 0;
            end
        end else if (start) begin
            // 分析每行的计算量
            for (int row = 0; row < MATRIX_DIM; row++) begin
                int nnz_in_row = a_row_ptr[row+1] - a_row_ptr[row];
                
                // 分配到负载最轻的处理单元
                int min_load = 999;
                int selected_unit = 0;
                for (int unit = 0; unit < 4; unit++) begin
                    if (active_rows[unit] < min_load) begin
                        min_load = active_rows[unit];
                        selected_unit = unit;
                    end
                end
                
                row_assignment[row] <= selected_unit;
                active_rows[selected_unit] <= active_rows[selected_unit] + nnz_in_row;
            end
        end
    end
    
    // 并行计算单元
    genvar unit;
    generate
        for (unit = 0; unit < 4; unit = unit + 1) begin : compute_units
            SparseComputeUnit #(
                .DATA_WIDTH(DATA_WIDTH),
                .MATRIX_DIM(MATRIX_DIM)
            ) unit_inst (
                .clk(clk),
                .rst_n(rst_n),
                .unit_id(unit),
                .row_assignment(row_assignment),
                .a_values(a_values),
                .a_col_idx(a_col_idx),
                .a_row_ptr(a_row_ptr),
                .b_matrix(b_matrix),
                .partial_results(c_matrix)
            );
        end
    endgenerate
    
    // 性能监控
    reg [31:0] cycle_count;
    reg [31:0] mac_operations;
    reg [31:0] skipped_operations;
    
    always @(posedge clk) begin
        if (!rst_n || start) begin
            cycle_count <= 0;
            mac_operations <= 0;
            skipped_operations <= 0;
        end else if (!done) begin
            cycle_count <= cycle_count + 1;
        end
    end
    
    // 计算吞吐量和加速比
    wire [31:0] dense_operations = MATRIX_DIM * MATRIX_DIM * MATRIX_DIM;
    wire [31:0] sparse_operations = mac_operations;
    wire [31:0] speedup = (dense_operations * 100) / (sparse_operations > 0 ? sparse_operations : 1);
    
endmodule
                    </div>
                    <p><strong>解析：</strong></p>
                    <ul>
                        <li>稀疏检测：实时统计零值比例，动态调整处理策略</li>
                        <li>负载均衡：根据每行非零元素数量分配到不同处理单元</li>
                        <li>性能监控：统计实际MAC操作数和跳过的操作数</li>
                        <li>格式支持：可扩展支持多种稀疏格式</li>
                        <li>加速效果：在90%稀疏度下，理论加速比可达10倍</li>
                    </ul>
                </div>
            </div>
            
            <div class="exercise">
                <h4>练习 11.5：面积优化的可重构MAC阵列</h4>
                <div class="question">
                    <p><strong>题目：</strong>设计一个面积优化的可重构MAC阵列，要求：
                    1) 支持INT4/INT8/INT16多精度计算
                    2) 可配置为不同的阵列形态（如4×4、2×8、1×16）
                    3) 共享乘法器和加法器资源
                    4) 最小化互连开销</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：INT16乘法器可以拆分为4个INT8或16个INT4乘法器。使用MUX网络重新路由数据。不同形态适合不同的矩阵尺寸。考虑部分积累加的位宽增长。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module ReconfigurableMACArray #(
    parameter MAX_ARRAY_DIM = 16,
    parameter MAX_DATA_WIDTH = 16
)(
    input wire clk,
    input wire rst_n,
    
    // 配置接口
    input wire [1:0] precision_mode,  // 0:INT4 1:INT8 2:INT16
    input wire [1:0] array_mode,      // 0:16x1 1:8x2 2:4x4 3:2x8
    
    // 数据输入
    input wire [MAX_ARRAY_DIM-1:0][MAX_DATA_WIDTH-1:0] input_a,
    input wire [MAX_ARRAY_DIM-1:0][MAX_DATA_WIDTH-1:0] input_b,
    input wire input_valid,
    
    // 输出
    output reg [MAX_ARRAY_DIM-1:0][31:0] output_results,
    output reg output_valid
);
    
    // 基础计算单元（可分解）
    module FlexibleMultiplier (
        input wire [15:0] a,
        input wire [15:0] b,
        input wire [1:0] mode,  // 0:1x16bit 1:2x8bit 2:4x4bit
        output reg [31:0] products [3:0]
    );
        always @(*) begin
            case (mode)
                2'b00: begin  // 1个16位乘法
                    products[0] = a * b;
                    products[1] = 0;
                    products[2] = 0;
                    products[3] = 0;
                end
                
                2'b01: begin  // 2个8位乘法
                    products[0] = {8'h0, a[7:0]} * {8'h0, b[7:0]};
                    products[1] = {8'h0, a[15:8]} * {8'h0, b[15:8]};
                    products[2] = 0;
                    products[3] = 0;
                end
                
                2'b10: begin  // 4个4位乘法
                    products[0] = {12'h0, a[3:0]} * {12'h0, b[3:0]};
                    products[1] = {12'h0, a[7:4]} * {12'h0, b[7:4]};
                    products[2] = {12'h0, a[11:8]} * {12'h0, b[11:8]};
                    products[3] = {12'h0, a[15:12]} * {12'h0, b[15:12]};
                end
            endcase
        end
    endmodule
    
    // 共享乘法器阵列（使用更少的物理乘法器）
    wire [31:0] mult_results [MAX_ARRAY_DIM-1:0][3:0];
    genvar i;
    generate
        for (i = 0; i < MAX_ARRAY_DIM; i = i + 1) begin : mult_array
            FlexibleMultiplier mult_inst (
                .a(input_a[i]),
                .b(input_b[i]),
                .mode(precision_mode),
                .products(mult_results[i])
            );
        end
    endgenerate
    
    // 可重构累加树
    reg [31:0] accum_stage1 [MAX_ARRAY_DIM-1:0];
    reg [31:0] accum_stage2 [MAX_ARRAY_DIM/2-1:0];
    reg [31:0] accum_stage3 [MAX_ARRAY_DIM/4-1:0];
    reg [31:0] accum_stage4 [MAX_ARRAY_DIM/8-1:0];
    
    // 第一级：局部累加
    always @(posedge clk) begin
        if (!rst_n) begin
            for (i = 0; i < MAX_ARRAY_DIM; i = i + 1) begin
                accum_stage1[i] <= 0;
            end
        end else if (input_valid) begin
            case (precision_mode)
                2'b00: begin  // INT16
                    for (i = 0; i < MAX_ARRAY_DIM; i = i + 1) begin
                        accum_stage1[i] <= mult_results[i][0];
                    end
                end
                
                2'b01: begin  // INT8
                    for (i = 0; i < MAX_ARRAY_DIM; i = i + 2) begin
                        accum_stage1[i] <= mult_results[i/2][0];
                        accum_stage1[i+1] <= mult_results[i/2][1];
                    end
                end
                
                2'b10: begin  // INT4
                    for (i = 0; i < MAX_ARRAY_DIM; i = i + 4) begin
                        accum_stage1[i] <= mult_results[i/4][0];
                        accum_stage1[i+1] <= mult_results[i/4][1];
                        accum_stage1[i+2] <= mult_results[i/4][2];
                        accum_stage1[i+3] <= mult_results[i/4][3];
                    end
                end
            endcase
        end
    end
    
    // 可配置的归约网络
    always @(posedge clk) begin
        if (!rst_n) begin
            output_results <= 0;
        end else begin
            case (array_mode)
                2'b00: begin  // 16x1模式
                    // 全部累加为一个结果
                    output_results[0] <= 0;
                    for (i = 0; i < MAX_ARRAY_DIM; i = i + 1) begin
                        output_results[0] <= output_results[0] + accum_stage1[i];
                    end
                    for (i = 1; i < MAX_ARRAY_DIM; i = i + 1) begin
                        output_results[i] <= 0;
                    end
                end
                
                2'b01: begin  // 8x2模式
                    // 分成2组，每组8个
                    output_results[0] <= 0;
                    output_results[1] <= 0;
                    for (i = 0; i < 8; i = i + 1) begin
                        output_results[0] <= output_results[0] + accum_stage1[i];
                        output_results[1] <= output_results[1] + accum_stage1[i+8];
                    end
                    for (i = 2; i < MAX_ARRAY_DIM; i = i + 1) begin
                        output_results[i] <= 0;
                    end
                end
                
                2'b10: begin  // 4x4模式
                    // 分成4组，每组4个
                    for (i = 0; i < 4; i = i + 1) begin
                        output_results[i] <= accum_stage1[i*4] + accum_stage1[i*4+1] + 
                                           accum_stage1[i*4+2] + accum_stage1[i*4+3];
                    end
                    for (i = 4; i < MAX_ARRAY_DIM; i = i + 1) begin
                        output_results[i] <= 0;
                    end
                end
                
                2'b11: begin  // 2x8模式
                    // 分成8组，每组2个
                    for (i = 0; i < 8; i = i + 1) begin
                        output_results[i] <= accum_stage1[i*2] + accum_stage1[i*2+1];
                    end
                    for (i = 8; i < MAX_ARRAY_DIM; i = i + 1) begin
                        output_results[i] <= 0;
                    end
                end
            endcase
        end
    end
    
    // 输出控制
    always @(posedge clk) begin
        if (!rst_n) begin
            output_valid <= 0;
        end else begin
            output_valid <= input_valid;
        end
    end
endmodule
                        </div>
                    </div>
                </div>
            </div>

            <div class="exercise">
                <h4>练习 11.6：综合性能优化</h4>
                <div class="question">
                    <p><strong>题目：</strong>设计一个综合考虑算法、数据流、功耗和面积的NPU优化框架，包括：
                    1) 自动选择最优量化策略
                    2) 动态调整数据流模式
                    3) 实时功耗监控和调节
                    4) 根据工作负载动态分配资源
                    要求给出完整的系统架构和关键模块实现。</p>
                    <details class="hint">
                        <summary>💡 提示</summary>
                        <p>思考方向：构建分层架构：策略层（决策）、执行层（实施）、监控层（反馈）。使用机器学习模型预测最佳配置。实时性能计数器提供反馈。资源分配需要考虑QoS。</p>
                    </details>
                    <button class="toggle-answer">显示答案</button>
                    <div class="answer">
                        <div class="code-block">
module IntegratedNPUOptimizer #(
    parameter NUM_CLUSTERS = 4,
    parameter PE_PER_CLUSTER = 64,
    parameter SRAM_SIZE_KB = 512
)(
    input wire clk,
    input wire rst_n,
    
    // 神经网络模型信息
    input wire [7:0] model_id,
    input wire [15:0] num_layers,
    input wire model_load_start,
    
    // 实时监控输入
    input wire [31:0] current_fps,
    input wire [31:0] target_fps,
    input wire [15:0] power_consumption_mw,
    input wire [15:0] power_budget_mw,
    input wire [7:0] chip_temperature,
    
    // 优化控制输出
    output reg [2:0] quantization_mode,     // 0:FP32 1:FP16 2:INT8 3:INT4
    output reg [1:0] dataflow_mode,         // 0:WS 1:OS 2:RS 3:Adaptive
    output reg [3:0] voltage_level,
    output reg [3:0] frequency_level,
    output reg [NUM_CLUSTERS-1:0] cluster_enable,
    output reg optimization_done
);
    
    // 优化状态机
    reg [3:0] opt_state;
    localparam IDLE = 4'b0000;
    localparam PROFILE = 4'b0001;
    localparam ANALYZE = 4'b0010;
    localparam OPTIMIZE_ALGO = 4'b0011;
    localparam OPTIMIZE_DATAFLOW = 4'b0100;
    localparam OPTIMIZE_POWER = 4'b0101;
    localparam OPTIMIZE_RESOURCE = 4'b0110;
    localparam APPLY = 4'b0111;
    localparam MONITOR = 4'b1000;
    
    // 性能分析结果
    reg [31:0] layer_compute_density [255:0];  // FLOPs/Byte
    reg [31:0] layer_memory_footprint [255:0]; // Bytes
    reg [7:0] layer_precision_loss [255:0];    // 量化后精度损失%
    
    // 优化决策变量
    reg [2:0] best_quant_mode;
    reg [1:0] best_dataflow;
    reg [3:0] best_voltage;
    reg [3:0] best_frequency;
    reg [NUM_CLUSTERS-1:0] best_cluster_config;
    reg [31:0] predicted_performance;
    reg [15:0] predicted_power;
    
    // 性能模型
    function [31:0] estimate_performance;
        input [2:0] quant;
        input [1:0] dataflow;
        input [3:0] voltage;
        input [3:0] freq;
        input [NUM_CLUSTERS-1:0] clusters;
        reg [31:0] compute_throughput;
        reg [31:0] memory_bandwidth;
        reg [31:0] effective_performance;
        begin
            // 计算吞吐量（简化模型）
            case (quant)
                3'b000: compute_throughput = freq * 100;      // FP32
                3'b001: compute_throughput = freq * 200;      // FP16
                3'b010: compute_throughput = freq * 400;      // INT8
                3'b011: compute_throughput = freq * 800;      // INT4
            endcase
            
            // 考虑活跃簇数
            compute_throughput = compute_throughput * $countones(clusters) / NUM_CLUSTERS;
            
            // 数据流效率
            case (dataflow)
                2'b00: memory_bandwidth = compute_throughput * 80 / 100;   // WS
                2'b01: memory_bandwidth = compute_throughput * 85 / 100;   // OS
                2'b10: memory_bandwidth = compute_throughput * 90 / 100;   // RS
                2'b11: memory_bandwidth = compute_throughput * 95 / 100;   // Adaptive
            endcase
            
            estimate_performance = memory_bandwidth;
        end
    endfunction
    
    // 功耗模型
    function [15:0] estimate_power;
        input [3:0] voltage;
        input [3:0] freq;
        input [NUM_CLUSTERS-1:0] clusters;
        reg [15:0] dynamic_power;
        reg [15:0] static_power;
        begin
            // P = CV²f
            dynamic_power = 10 * voltage * voltage * freq / 16;
            dynamic_power = dynamic_power * $countones(clusters) / NUM_CLUSTERS;
            
            // 静态功耗
            static_power = 50 * $countones(clusters);
            
            estimate_power = dynamic_power + static_power;
        end
    endfunction
    
    // 主优化流程
    always @(posedge clk) begin
        if (!rst_n) begin
            opt_state <= IDLE;
            optimization_done <= 0;
            quantization_mode <= 3'b010;  // 默认INT8
            dataflow_mode <= 2'b11;       // 默认自适应
            voltage_level <= 4'b1000;
            frequency_level <= 4'b1000;
            cluster_enable <= {NUM_CLUSTERS{1'b1}};
        end else begin
            case (opt_state)
                IDLE: begin
                    if (model_load_start) begin
                        opt_state <= PROFILE;
                        optimization_done <= 0;
                    end
                end
                
                PROFILE: begin
                    // 分析模型特征（简化示例）
                    // 实际实现需要解析模型结构
                    opt_state <= ANALYZE;
                end
                
                ANALYZE: begin
                    // 分析当前性能差距
                    if (current_fps < target_fps * 90 / 100) begin
                        // 性能不足，需要优化
                        opt_state <= OPTIMIZE_ALGO;
                    end else if (power_consumption_mw > power_budget_mw) begin
                        // 功耗超标
                        opt_state <= OPTIMIZE_POWER;
                    end else begin
                        opt_state <= MONITOR;
                    end
                end
                
                OPTIMIZE_ALGO: begin
                    // 算法优化：选择量化策略
                    if (current_fps < target_fps * 50 / 100) begin
                        // 严重性能不足，使用激进量化
                        best_quant_mode <= 3'b011;  // INT4
                    end else if (current_fps < target_fps * 75 / 100) begin
                        best_quant_mode <= 3'b010;  // INT8
                    end else begin
                        best_quant_mode <= 3'b001;  // FP16
                    end
                    opt_state <= OPTIMIZE_DATAFLOW;
                end
                
                OPTIMIZE_DATAFLOW: begin
                    // 根据模型特征选择数据流
                    // 简化：根据计算密度选择
                    if (layer_compute_density[0] > 100) begin
                        best_dataflow <= 2'b00;  // 计算密集->WS
                    end else if (layer_memory_footprint[0] > SRAM_SIZE_KB * 1024) begin
                        best_dataflow <= 2'b01;  // 内存密集->OS
                    end else begin
                        best_dataflow <= 2'b11;  // 自适应
                    end
                    opt_state <= OPTIMIZE_POWER;
                end
                
                OPTIMIZE_POWER: begin
                    // 功耗优化
                    if (chip_temperature > 85) begin
                        // 温度过高，降频
                        best_voltage <= 4'b0110;
                        best_frequency <= 4'b0110;
                    end else if (power_consumption_mw > power_budget_mw) begin
                        // 功耗超标
                        if (frequency_level > 4'b0100) begin
                            best_frequency <= frequency_level - 1;
                            best_voltage <= voltage_level - 1;
                        end
                    end else if (power_consumption_mw < power_budget_mw * 70 / 100) begin
                        // 功耗余量大，可以提频
                        if (frequency_level < 4'b1110) begin
                            best_frequency <= frequency_level + 1;
                            best_voltage <= voltage_level + 1;
                        end
                    end else begin
                        best_voltage <= voltage_level;
                        best_frequency <= frequency_level;
                    end
                    opt_state <= OPTIMIZE_RESOURCE;
                end
                
                OPTIMIZE_RESOURCE: begin
                    // 资源分配优化
                    predicted_performance = estimate_performance(
                        best_quant_mode, best_dataflow, 
                        best_voltage, best_frequency, 
                        {NUM_CLUSTERS{1'b1}}
                    );
                    
                    predicted_power = estimate_power(
                        best_voltage, best_frequency,
                        {NUM_CLUSTERS{1'b1}}
                    );
                    
                    // 如果功耗还是超标，关闭部分簇
                    if (predicted_power > power_budget_mw) begin
                        best_cluster_config <= {1'b0, {(NUM_CLUSTERS-1){1'b1}}};
                    end else begin
                        best_cluster_config <= {NUM_CLUSTERS{1'b1}};
                    end
                    
                    opt_state <= APPLY;
                end
                
                APPLY: begin
                    // 应用优化配置
                    quantization_mode <= best_quant_mode;
                    dataflow_mode <= best_dataflow;
                    voltage_level <= best_voltage;
                    frequency_level <= best_frequency;
                    cluster_enable <= best_cluster_config;
                    
                    optimization_done <= 1'b1;
                    opt_state <= MONITOR;
                end
                
                MONITOR: begin
                    // 持续监控
                    optimization_done <= 1'b0;
                    
                    // 检测是否需要重新优化
                    if (current_fps < target_fps * 85 / 100 ||
                        power_consumption_mw > power_budget_mw * 110 / 100 ||
                        chip_temperature > 90) begin
                        opt_state <= ANALYZE;
                    end
                end
            endcase
        end
    end
    
    // 性能计数器和统计
    reg [31:0] optimization_count;
    reg [31:0] total_energy_saved;
    reg [15:0] average_fps_improvement;
    
    always @(posedge clk) begin
        if (!rst_n) begin
            optimization_count <= 0;
            total_energy_saved <= 0;
            average_fps_improvement <= 0;
        end else if (opt_state == APPLY) begin
            optimization_count <= optimization_count + 1;
            
            // 计算节能效果
            if (predicted_power < power_consumption_mw) begin
                total_energy_saved <= total_energy_saved + 
                    (power_consumption_mw - predicted_power);
            end
            
            // 更新平均性能提升
            if (predicted_performance > current_fps) begin
                average_fps_improvement <= 
                    (average_fps_improvement * (optimization_count - 1) + 
                     (predicted_performance - current_fps)) / optimization_count;
            end
        end
    end
endmodule
                        </div>
                        <p><strong>解析：</strong></p>
                        <ul>
                            <li>该框架实现了完整的优化循环：监测→分析→优化→应用→监测</li>
                            <li>算法优化根据性能差距自动选择量化精度</li>
                            <li>数据流优化基于模型特征（计算密度、内存占用）选择</li>
                            <li>功耗优化考虑温度、功耗预算和性能需求的平衡</li>
                            <li>资源分配可以动态开关计算簇以满足功耗约束</li>
                            <li>包含性能和功耗预测模型，支持优化前评估</li>
                            <li>提供优化统计，用于长期效果评估</li>
                        </ul>
                    </div>
                </div>
            </div>
        </section>
        
        <!-- 第12章：NPU设计实战 -->
        <section id="chapter12" class="chapter">
            <h2>第12章：NPU设计实战</h2>
            
            <p>欢迎来到NPU设计的综合实战。在前面的章节中，我们已经分别探讨了神经网络的基本原理、硬件加速的核心思想、关键计算单元（如MAC阵列）以及存储架构。本章将扮演一个"总装车间"的角色，带领读者从零开始，经历一个完整的、符合工业界设计流程的边缘计算NPU项目。</p>
            
            <p>我们将不仅仅是展示最终的代码，更重要的是，我们将深入探讨"为什么"这么设计。每一行代码、每一个架构决策背后，都有其性能、功耗、面积（PPA）上的权衡。本章的目标是让读者不仅能看懂一个NPU设计，更能理解其背后的设计哲学和工程实践，从而具备独立设计和评估NPU的能力。让我们从项目的第一步——需求分析开始。</p>

            <h3>12.1 项目需求分析</h3>
            
            <p>所有设计的源头是需求。硬件设计不是凭空创造，而是为了解决特定问题。在开始设计之前，需要明确项目目标、应用场景和关键性能指标。本节将详细分析边缘AI NPU的需求。</p>

            <h4>12.1.1 应用场景定义</h4>
            
            <div class="info-box">
                <h5>什么是边缘AI？</h5>
                <p>边缘AI是相对于云端AI的概念。它将AI计算能力部署在靠近数据源的"边缘"设备上，具有以下优势：</p>
                <ul>
                    <li><strong>低延迟</strong>：无需将数据传输到云端，实时响应（毫秒级）</li>
                    <li><strong>数据隐私</strong>：敏感数据无需离开本地设备</li>
                    <li><strong>低功耗</strong>：专用硬件设计，能效比远超通用处理器</li>
                    <li><strong>网络无关性</strong>：即使没有网络连接也能正常工作</li>
                </ul>
            </div>
            
            <p>我们选择以下四个应用场景作为设计目标，它们代表了不同的工作负载类型和性能要求：</p>
            
            <ul>
                <li><strong>智能摄像头</strong>：
                    <ul>
                        <li>应用：实时目标检测、人脸识别</li>
                        <li>特点：典型CNN应用，对吞吐率（FPS）和延迟要求高</li>
                        <li>挑战：需要处理高分辨率视频流（1080p@30fps）</li>
                    </ul>
                </li>
                <li><strong>智能家居（语音处理）</strong>：
                    <ul>
                        <li>应用：语音识别、自然语言处理</li>
                        <li>特点：可能是RNN或小型Transformer，对实时响应和低功耗待机要求高</li>
                        <li>挑战：需要支持长时间待机，响应延迟<200ms</li>
                    </ul>
                </li>
                <li><strong>工业检测</strong>：
                    <ul>
                        <li>应用：缺陷检测、质量控制</li>
                        <li>特点：对精度和可靠性要求极高，模型可能更复杂</li>
                        <li>挑战：需要支持高精度推理（FP16），错误率<0.1%</li>
                    </ul>
                </li>
                <li><strong>移动设备</strong>：
                    <ul>
                        <li>应用：图像增强、AR/VR处理</li>
                        <li>特点：对能效（电池寿命）的要求是第一位的</li>
                        <li>挑战：功耗预算极其有限（<2W），需要处理多种混合任务</li>
                    </ul>
                </li>
                <li><strong>具身智能</strong>：
                    <ul>
                        <li>应用：机器人感知与控制、自主导航、人机交互</li>
                        <li>特点：需要融合多模态感知（视觉、触觉、力觉）和实时决策</li>
                        <li>挑战：超低延迟控制环路（<10ms），多传感器数据融合，动态环境适应</li>
                    </ul>
                </li>
            </ul>
            
            <p class="highlight-box">
                <strong>设计启示：</strong>这些不同的应用场景会直接影响我们在第2章和第3章学到的不同网络模型（如CNN、Transformer）的选择，并最终决定了我们在12.2节中架构设计的侧重点。一个优秀的NPU设计应该能够灵活地适应这些不同的工作负载。
            </p>

            <h4>12.1.2 性能需求分析</h4>
            
            <p>为了将模糊的应用需求转化为清晰的工程目标，我们需要定义一系列可量化的性能指标（Key Performance Indicators, KPIs）。这就像在建造一座大楼前，必须有明确的图纸，标明高度、承重、面积等。在NPU设计中，这些指标将成为我们后续所有设计、验证和优化工作的"黄金标准"。下面的<code>NPU_Requirements</code>结构体，就是我们将这些需求代码化的第一步，它将作为我们设计和验证的"合同"（Specification as Code）。</p>
            
            <div class="code-block">
// NPU性能需求定义
typedef struct {
    // 算力需求
    uint32_t peak_tops;        // 峰值算力 (TOPS)
    uint32_t sustained_tops;   // 持续算力 (TOPS)
    
    // 功耗约束
    uint16_t tdp_watts;        // 热设计功耗 (W)
    uint16_t idle_mw;          // 待机功耗 (mW)
    
    // 内存需求
    uint32_t sram_size_mb;     // 片上SRAM (MB)
    uint32_t ddr_bandwidth_gb; // DDR带宽 (GB/s)
    
    // 支持的模型
    uint8_t support_cnn;       // CNN支持
    uint8_t support_rnn;       // RNN支持
    uint8_t support_transformer; // Transformer支持
    
    // 精度支持
    uint8_t fp32_support;      // FP32
    uint8_t fp16_support;      // FP16
    uint8_t int8_support;      // INT8
    uint8_t int4_support;      // INT4
} NPU_Requirements;

// 边缘AI NPU需求实例
NPU_Requirements edge_npu_req = {
    .peak_tops = 8,            // 8 TOPS峰值算力
    .sustained_tops = 6,       // 6 TOPS持续算力
    .tdp_watts = 5,            // 5W TDP
    .idle_mw = 100,            // 100mW待机
    .sram_size_mb = 4,         // 4MB片上SRAM
    .ddr_bandwidth_gb = 16,    // 16GB/s DDR带宽
    .support_cnn = 1,          // 支持CNN
    .support_rnn = 1,          // 支持RNN
    .support_transformer = 1,   // 支持Transformer
    .fp32_support = 0,         // 不支持FP32
    .fp16_support = 1,         // 支持FP16
    .int8_support = 1,         // 支持INT8
    .int4_support = 1          // 支持INT4
};
            </div>

            <h4>12.1.3 目标模型分析</h4>
            <div class="code-block">
// 目标模型工作负载分析
module WorkloadAnalyzer #(
    parameter MODEL_COUNT = 8,
    parameter LAYER_MAX = 256
)(
    input wire clk,
    input wire rst_n,
    
    // 模型输入
    input wire [7:0] model_id,
    input wire model_load,
    
    // 层信息输入
    input wire [7:0] layer_type,      // 0:CONV 1:FC 2:POOL 3:ATTN
    input wire [31:0] layer_ops,      // 操作数
    input wire [31:0] layer_params,   // 参数量
    input wire [31:0] layer_activations, // 激活值大小
    
    // 分析输出
    output reg [63:0] total_ops,
    output reg [63:0] total_params,
    output reg [63:0] total_activations,
    output reg [7:0] bottleneck_layer,
    output reg [2:0] bottleneck_type,  // 0:计算 1:内存 2:带宽
    output reg analysis_done
);
    
    // 模型统计存储
    reg [63:0] model_ops [MODEL_COUNT-1:0];
    reg [63:0] model_params [MODEL_COUNT-1:0];
    reg [63:0] model_acts [MODEL_COUNT-1:0];
    
    // 层统计
    reg [7:0] layer_count;
    reg [31:0] layer_compute_intensity [LAYER_MAX-1:0];
    reg [31:0] layer_memory_footprint [LAYER_MAX-1:0];
    reg [31:0] layer_bandwidth_req [LAYER_MAX-1:0];
    
    // 分析状态机
    typedef enum logic [2:0] {
        IDLE,
        COLLECT,
        ANALYZE,
        REPORT
    } analyzer_state_t;
    
    analyzer_state_t state;
    
    // 计算强度分析
    function [31:0] calc_compute_intensity;
        input [31:0] ops, params, acts;
        begin
            // 计算密度 = 操作数 / (参数+激活值)
            calc_compute_intensity = ops / ((params + acts) >> 10); // KB为单位
        end
    endfunction
    
    // 带宽需求分析
    function [31:0] calc_bandwidth_req;
        input [7:0] ltype;
        input [31:0] params, acts;
        begin
            case (ltype)
                8'd0: begin // CONV
                    // 卷积层需要读取权重和输入，写入输出
                    calc_bandwidth_req = (params + acts * 2) >> 20; // MB
                end
                8'd1: begin // FC
                    // 全连接层带宽密集
                    calc_bandwidth_req = (params + acts) >> 20;
                end
                8'd3: begin // ATTN
                    // 注意力层需要大量中间结果存储
                    calc_bandwidth_req = (acts * 4) >> 20; // QKV + output
                end
                default: begin
                    calc_bandwidth_req = acts >> 20;
                end
            endcase
        end
    endfunction
    
    // 主状态机
    always @(posedge clk) begin
        if (!rst_n) begin
            state <= IDLE;
            layer_count <= 0;
            analysis_done <= 0;
            total_ops <= 0;
            total_params <= 0;
            total_activations <= 0;
        end else begin
            case (state)
                IDLE: begin
                    if (model_load) begin
                        state <= COLLECT;
                        layer_count <= 0;
                        analysis_done <= 0;
                    end
                end
                
                COLLECT: begin
                    // 收集层信息
                    layer_compute_intensity[layer_count] <= 
                        calc_compute_intensity(layer_ops, layer_params, layer_activations);
                    layer_memory_footprint[layer_count] <= 
                        (layer_params + layer_activations) >> 20; // MB
                    layer_bandwidth_req[layer_count] <= 
                        calc_bandwidth_req(layer_type, layer_params, layer_activations);
                    
                    // 累计统计
                    total_ops <= total_ops + layer_ops;
                    total_params <= total_params + layer_params;
                    total_activations <= total_activations + layer_activations;
                    
                    layer_count <= layer_count + 1;
                    
                    if (layer_count == LAYER_MAX - 1) begin
                        state <= ANALYZE;
                    end
                end
                
                ANALYZE: begin
                    // 找出瓶颈层
                    reg [31:0] max_compute_req, max_memory_req, max_bandwidth_req;
                    reg [7:0] compute_bottleneck, memory_bottleneck, bandwidth_bottleneck;
                    
                    max_compute_req = 0;
                    max_memory_req = 0;
                    max_bandwidth_req = 0;
                    
                    for (int i = 0; i < layer_count; i++) begin
                        // 计算瓶颈
                        if (layer_ops[i] > max_compute_req) begin
                            max_compute_req = layer_ops[i];
                            compute_bottleneck = i;
                        end
                        
                        // 内存瓶颈
                        if (layer_memory_footprint[i] > max_memory_req) begin
                            max_memory_req = layer_memory_footprint[i];
                            memory_bottleneck = i;
                        end
                        
                        // 带宽瓶颈
                        if (layer_bandwidth_req[i] > max_bandwidth_req) begin
                            max_bandwidth_req = layer_bandwidth_req[i];
                            bandwidth_bottleneck = i;
                        end
                    end
                    
                    // 确定主要瓶颈
                    if (max_compute_req > max_memory_req && max_compute_req > max_bandwidth_req) begin
                        bottleneck_layer <= compute_bottleneck;
                        bottleneck_type <= 3'b000; // 计算瓶颈
                    end else if (max_memory_req > max_bandwidth_req) begin
                        bottleneck_layer <= memory_bottleneck;
                        bottleneck_type <= 3'b001; // 内存瓶颈
                    end else begin
                        bottleneck_layer <= bandwidth_bottleneck;
                        bottleneck_type <= 3'b010; // 带宽瓶颈
                    end
                    
                    state <= REPORT;
                end
                
                REPORT: begin
                    // 保存分析结果
                    model_ops[model_id] <= total_ops;
                    model_params[model_id] <= total_params;
                    model_acts[model_id] <= total_activations;
                    
                    analysis_done <= 1;
                    state <= IDLE;
                end
            endcase
        end
    end
endmodule
            </div>

            <h4>12.1.4 设计约束定义</h4>
            <div class="code-block">
// 设计约束参数
module DesignConstraints;
    // 工艺约束
    parameter PROCESS_NODE = 16;        // 16nm工艺
    parameter VOLTAGE_NOMINAL = 0.8;    // 0.8V标称电压
    parameter FREQ_TARGET = 1000;       // 1GHz目标频率
    
    // 面积约束
    parameter DIE_AREA_MM2 = 25;        // 25mm²芯片面积
    parameter COMPUTE_AREA_PCT = 60;    // 60%用于计算
    parameter SRAM_AREA_PCT = 30;       // 30%用于SRAM
    parameter IO_AREA_PCT = 10;         // 10%用于IO
    
    // 功耗预算
    parameter POWER_COMPUTE = 3.0;      // 3W计算功耗
    parameter POWER_MEMORY = 1.5;       // 1.5W内存功耗
    parameter POWER_IO = 0.5;           // 0.5W IO功耗
    
    // 性能目标
    parameter MAC_UNITS = 2048;         // 2048个MAC单元
    parameter SIMD_WIDTH = 128;         // 128位SIMD宽度
    parameter PIPELINE_DEPTH = 8;       // 8级流水线
    
    // 内存层次
    parameter L1_SIZE_KB = 64;          // 64KB L1缓存
    parameter L2_SIZE_KB = 512;         // 512KB L2缓存
    parameter L3_SIZE_MB = 4;           // 4MB L3缓存
    
    // 接口规格
    parameter PCIE_GEN = 4;             // PCIe Gen4
    parameter PCIE_LANES = 4;           // x4通道
    parameter DDR_TYPE = "LPDDR4";      // LPDDR4内存
    parameter DDR_WIDTH = 64;           // 64位宽度
endmodule
            </div>

            <div class="exercise">
                <h4>练习 1：需求分析与规格定义</h4>
                <p>假设你需要为自动驾驶应用设计一个NPU，该NPU需要实时处理来自多个摄像头的视频流，执行目标检测、语义分割和路径规划。请：</p>
                <ol>
                    <li>定义具体的性能需求（算力、延迟、功耗）</li>
                    <li>分析主要的工作负载特征</li>
                    <li>确定关键的设计约束</li>
                    <li>编写需求规格文档的RTL结构体</li>
                </ol>
                
                <details class="hint">
                    <summary>💡 提示</summary>
                    <p>思考方向：自动驾驶需要实时性（<100ms延迟）、高可靠性、功耗受限（车载<50W）。工作负载包括CNN（检测）、FCN（分割）、RNN（预测）。考虑多模型并行、确定性延迟、功能安全等约束。</p>
                </details>
                <button class="toggle-answer">显示答案</button>
                <div class="answer">
                    <div class="code-block">
// 自动驾驶NPU需求定义
typedef struct {
    // 性能需求
    uint32_t min_fps;          // 最小帧率要求
    uint32_t camera_count;     // 摄像头数量
    uint32_t resolution;       // 处理分辨率
    uint32_t latency_ms;       // 端到端延迟
    
    // 算力需求
    uint32_t detection_tops;   // 目标检测算力
    uint32_t segmentation_tops; // 语义分割算力
    uint32_t planning_tops;    // 路径规划算力
    
    // 功耗约束
    uint16_t max_power_w;      // 最大功耗
    uint16_t typical_power_w;  // 典型功耗
    uint8_t thermal_grade;     // 温度等级
    
    // 可靠性需求
    uint8_t asil_level;        // 汽车安全完整性等级
    uint8_t ecc_support;       // ECC支持
    uint8_t redundancy;        // 冗余设计
} AutomotiveNPU_Spec;

// 具体需求实例
AutomotiveNPU_Spec auto_npu_spec = {
    // 性能需求
    .min_fps = 30,             // 30 FPS最小帧率
    .camera_count = 8,         // 8个摄像头
    .resolution = 1920*1080,   // 1080p分辨率
    .latency_ms = 100,         // 100ms最大延迟
    
    // 算力需求（总计50 TOPS）
    .detection_tops = 20,      // 20 TOPS用于检测
    .segmentation_tops = 20,   // 20 TOPS用于分割
    .planning_tops = 10,       // 10 TOPS用于规划
    
    // 功耗约束
    .max_power_w = 30,         // 30W最大功耗
    .typical_power_w = 20,     // 20W典型功耗
    .thermal_grade = 125,      // 125°C车规级
    
    // 可靠性需求
    .asil_level = 3,           // ASIL-C等级
    .ecc_support = 1,          // 支持ECC
    .redundancy = 2            // 双核冗余
};

// 工作负载特征分析
module AutomotiveWorkloadProfile;
    // YOLO目标检测特征
    parameter YOLO_LAYERS = 53;
    parameter YOLO_GFLOPS = 65;
    parameter YOLO_PARAMS_MB = 250;
    parameter YOLO_BATCH = 8;      // 8路摄像头
    
    // DeepLabV3语义分割特征
    parameter DEEPLAB_LAYERS = 101;
    parameter DEEPLAB_GFLOPS = 120;
    parameter DEEPLAB_PARAMS_MB = 180;
    parameter DEEPLAB_RESOLUTION = 1024;
    
    // 路径规划网络特征
    parameter PLANNING_RNN_LAYERS = 4;
    parameter PLANNING_HIDDEN_SIZE = 512;
    parameter PLANNING_SEQUENCE_LEN = 100;
    
    // 内存需求计算
    parameter TOTAL_PARAMS_MB = YOLO_PARAMS_MB + DEEPLAB_PARAMS_MB + 50;
    parameter ACTIVATION_BUFFER_MB = 512;  // 中间激活值缓存
    parameter TOTAL_SRAM_MB = 16;          // 片上SRAM需求
    
    // 带宽需求计算
    parameter PIXEL_BANDWIDTH_GB = 8 * 1920 * 1080 * 3 * 30 / 1e9; // 11.9 GB/s
    parameter WEIGHT_BANDWIDTH_GB = TOTAL_PARAMS_MB * 30 / 1000;    // 14.1 GB/s
    parameter TOTAL_BANDWIDTH_GB = PIXEL_BANDWIDTH_GB + WEIGHT_BANDWIDTH_GB; // 26 GB/s
endmodule

// 设计约束定义
module AutomotiveDesignConstraints;
    // 安全性约束
    parameter LOCKSTEP_CORES = 1;      // 锁步核心
    parameter ECC_PROTECTION = 1;      // ECC保护
    parameter PARITY_CHECK = 1;        // 奇偶校验
    parameter BIST_SUPPORT = 1;        // 内建自测试
    
    // 实时性约束
    parameter MAX_LATENCY_CYCLES = 100_000_000; // 1GHz下100ms
    parameter DETERMINISTIC_EXEC = 1;   // 确定性执行
    parameter PRIORITY_LEVELS = 4;      // 4级优先级
    
    // 接口约束
    parameter CAMERA_INTERFACES = 8;    // 8路MIPI CSI-2
    parameter CAN_FD_SUPPORT = 1;       // CAN-FD支持
    parameter ETHERNET_AVB = 1;         // 汽车以太网
    
    // 温度和电压范围
    parameter TEMP_MIN = -40;           // -40°C
    parameter TEMP_MAX = 125;           // +125°C
    parameter VDD_MIN = 0.72;           // 0.72V
    parameter VDD_MAX = 0.88;           // 0.88V
endmodule
                    </div>
                    <p><strong>解析：</strong></p>
                    <ul>
                        <li>自动驾驶NPU需要处理多路高分辨率视频，算力需求达50 TOPS</li>
                        <li>实时性要求严格，端到端延迟不超过100ms</li>
                        <li>需要满足汽车安全标准（ASIL-C），包含冗余设计和ECC保护</li>
                        <li>工作温度范围宽（-40°C到+125°C），需要车规级设计</li>
                        <li>带宽需求高（26 GB/s），需要优化内存访问模式</li>
                    </ul>
                </div>
            </div>

            <div class="exercise">
                <h4>练习 2：性能建模与预测</h4>
                <p>基于给定的NPU规格，建立一个性能预测模型，能够：</p>
                <ol>
                    <li>根据硬件配置预测理论峰值性能</li>
                    <li>考虑内存带宽限制的实际性能</li>
                    <li>评估不同工作负载的性能</li>
                </ol>
                
                <details class="hint">
                    <summary>💡 提示</summary>
                    <p>思考方向：理论峰值=MAC数×频率×2。实际性能受限于min(计算性能, 内存带宽/计算强度)。不同层的计算强度不同（FC层高，DW卷积低）。建立roofline模型来预测性能。</p>
                </details>
                <button class="toggle-answer">显示答案</button>
                <div class="answer">
                    <div class="code-block">
module PerformanceModel #(
    parameter MAC_UNITS = 2048,
    parameter FREQUENCY_MHZ = 1000,
    parameter SRAM_SIZE_MB = 4,
    parameter DDR_BANDWIDTH_GB = 16,
    parameter DATA_WIDTH = 8  // INT8
)(
    input wire clk,
    input wire rst_n,
    
    // 工作负载参数
    input wire [31:0] layer_macs,        // MAC操作数
    input wire [31:0] weight_size_kb,    // 权重大小
    input wire [31:0] activation_size_kb, // 激活值大小
    input wire [7:0] reuse_factor,       // 数据重用因子
    
    // 性能预测输出
    output reg [31:0] compute_cycles,
    output reg [31:0] memory_cycles,
    output reg [31:0] total_cycles,
    output reg [15:0] achieved_tops,
    output reg [7:0] efficiency_percent
);
    
    // 计算理论峰值性能
    localparam PEAK_OPS_PER_CYCLE = MAC_UNITS * 2; // 2 ops per MAC
    localparam PEAK_TOPS = PEAK_OPS_PER_CYCLE * FREQUENCY_MHZ / 1000;
    
    // 内存带宽参数
    localparam SRAM_BANDWIDTH_GB = SRAM_SIZE_MB * FREQUENCY_MHZ / 250; // 假设4周期访问
    localparam EFFECTIVE_DDR_BW_GB = DDR_BANDWIDTH_GB * 70 / 100; // 70%效率
    
    // 计算所需周期
    always @(*) begin
        // 计算周期 = MAC操作数 / 每周期MAC数
        compute_cycles = layer_macs / MAC_UNITS;
        
        // 内存周期计算
        reg [31:0] sram_data_kb, ddr_data_kb;
        reg [31:0] sram_cycles, ddr_cycles;
        
        // 估算SRAM可以容纳的数据
        if (weight_size_kb + activation_size_kb <= SRAM_SIZE_MB * 1024) begin
            // 全部在SRAM中
            sram_data_kb = weight_size_kb + activation_size_kb;
            ddr_data_kb = 0;
        end else begin
            // 部分在SRAM，部分需要从DDR读取
            sram_data_kb = SRAM_SIZE_MB * 1024;
            ddr_data_kb = (weight_size_kb + activation_size_kb - sram_data_kb) / reuse_factor;
        end
        
        // 计算内存访问周期
        sram_cycles = (sram_data_kb * 1024) / (SRAM_BANDWIDTH_GB * 1000 * 1000 / FREQUENCY_MHZ);
        ddr_cycles = (ddr_data_kb * 1024) / (EFFECTIVE_DDR_BW_GB * 1000 * 1000 / FREQUENCY_MHZ);
        
        memory_cycles = sram_cycles > ddr_cycles ? sram_cycles : ddr_cycles;
        
        // 总周期取计算和内存的最大值
        total_cycles = compute_cycles > memory_cycles ? compute_cycles : memory_cycles;
        
        // 实际达到的性能
        achieved_tops = (layer_macs * 2 * FREQUENCY_MHZ) / (total_cycles * 1000 * 1000);
        
        // 效率百分比
        efficiency_percent = (achieved_tops * 100) / PEAK_TOPS;
    end
    
    // 性能瓶颈分析
    reg [2:0] bottleneck_type; // 0:计算 1:SRAM带宽 2:DDR带宽
    always @(*) begin
        if (compute_cycles >= memory_cycles) begin
            bottleneck_type = 3'b000; // 计算瓶颈
        end else if (sram_cycles >= ddr_cycles) begin
            bottleneck_type = 3'b001; // SRAM带宽瓶颈
        end else begin
            bottleneck_type = 3'b010; // DDR带宽瓶颈
        end
    end
    
    // 优化建议生成
    reg [127:0] optimization_hint;
    always @(*) begin
        case (bottleneck_type)
            3'b000: optimization_hint = "Compute bound: consider increasing MAC units";
            3'b001: optimization_hint = "SRAM BW bound: optimize data layout and reuse";
            3'b010: optimization_hint = "DDR BW bound: increase on-chip buffer size";
            default: optimization_hint = "Balanced design";
        endcase
    end
endmodule

// 多层网络性能评估
module NetworkPerformanceEvaluator #(
    parameter MAX_LAYERS = 256
)(
    input wire clk,
    input wire rst_n,
    
    // 网络输入
    input wire network_start,
    input wire [7:0] network_id,
    input wire [7:0] num_layers,
    
    // 逐层性能数据
    input wire [31:0] layer_cycles [MAX_LAYERS-1:0],
    input wire [15:0] layer_tops [MAX_LAYERS-1:0],
    
    // 网络级性能输出
    output reg [63:0] total_inference_cycles,
    output reg [31:0] average_tops,
    output reg [7:0] min_efficiency_layer,
    output reg [15:0] inference_latency_ms,
    output reg eval_done
);
    
    // 评估状态机
    reg [2:0] eval_state;
    reg [7:0] layer_idx;
    reg [63:0] cycle_accumulator;
    reg [31:0] tops_accumulator;
    reg [7:0] min_eff_layer;
    reg [15:0] min_efficiency;
    
    always @(posedge clk) begin
        if (!rst_n) begin
            eval_state <= 0;
            eval_done <= 0;
        end else begin
            case (eval_state)
                3'b000: begin // 空闲
                    if (network_start) begin
                        eval_state <= 3'b001;
                        layer_idx <= 0;
                        cycle_accumulator <= 0;
                        tops_accumulator <= 0;
                        min_efficiency <= 16'hFFFF;
                        eval_done <= 0;
                    end
                end
                
                3'b001: begin // 累加层统计
                    if (layer_idx < num_layers) begin
                        cycle_accumulator <= cycle_accumulator + layer_cycles[layer_idx];
                        tops_accumulator <= tops_accumulator + layer_tops[layer_idx];
                        
                        // 跟踪最低效率层
                        if (layer_tops[layer_idx] < min_efficiency) begin
                            min_efficiency <= layer_tops[layer_idx];
                            min_eff_layer <= layer_idx;
                        end
                        
                        layer_idx <= layer_idx + 1;
                    end else begin
                        eval_state <= 3'b010;
                    end
                end
                
                3'b010: begin // 计算网络级指标
                    total_inference_cycles <= cycle_accumulator;
                    average_tops <= tops_accumulator / num_layers;
                    min_efficiency_layer <= min_eff_layer;
                    
                    // 计算推理延迟 (ms)
                    inference_latency_ms <= (cycle_accumulator * 1000) / (1000 * 1000 * 1000); // 假设1GHz
                    
                    eval_done <= 1;
                    eval_state <= 3'b000;
                end
            endcase
        end
    end
endmodule
                    </div>
                    <p><strong>解析：</strong></p>
                    <ul>
                        <li>性能模型考虑了计算能力和内存带宽两个主要因素</li>
                        <li>通过比较计算周期和内存访问周期，识别性能瓶颈</li>
                        <li>数据重用因子反映了算法优化对内存访问的影响</li>
                        <li>网络级评估器可以分析整个模型的性能，找出效率最低的层</li>
                        <li>模型输出包括实际TOPS、效率百分比和优化建议</li>
                    </ul>
                </div>
            </div>

            <h3>12.2 架构设计实践</h3>
            
            <p>基于需求分析，本节将设计NPU的整体架构，包括计算核心、存储层次、互连网络和控制系统。</p>

            <h4>12.2.1 整体架构设计</h4>
            <div class="code-block">
// NPU顶层架构定义
module EdgeNPU_Top #(
    parameter NUM_CLUSTERS = 4,
    parameter MACS_PER_CLUSTER = 512,
    parameter SRAM_SIZE_PER_CLUSTER_KB = 1024,
    parameter GLOBAL_BUFFER_MB = 4
)(
    input wire clk,
    input wire rst_n,
    
    // 主机接口
    input wire pcie_clk,
    input wire [63:0] pcie_data_in,
    output wire [63:0] pcie_data_out,
    input wire pcie_valid,
    output wire pcie_ready,
    
    // DDR接口
    output wire [31:0] ddr_addr,
    inout wire [63:0] ddr_data,
    output wire ddr_wen,
    output wire ddr_ren,
    input wire ddr_ready,
    
    // 状态和控制
    output wire [3:0] npu_state,
    output wire [31:0] performance_counter,
    output wire [15:0] power_state
);
    
    // 全局控制器
    wire [31:0] global_pc;
    wire [127:0] global_instruction;
    wire global_inst_valid;
    
    GlobalController #(
        .INST_CACHE_SIZE_KB(64)
    ) global_ctrl (
        .clk(clk),
        .rst_n(rst_n),
        .pc(global_pc),
        .instruction(global_instruction),
        .inst_valid(global_inst_valid),
        .pcie_cmd_in(pcie_data_in),
        .pcie_cmd_valid(pcie_valid),
        .state_out(npu_state)
    );
    
    // 计算簇阵列
    wire [NUM_CLUSTERS-1:0] cluster_enable;
    wire [NUM_CLUSTERS-1:0] cluster_busy;
    wire [31:0] cluster_results [NUM_CLUSTERS-1:0];
    
    genvar i;
    generate
        for (i = 0; i < NUM_CLUSTERS; i = i + 1) begin : cluster_gen
            ComputeCluster #(
                .CLUSTER_ID(i),
                .NUM_MACS(MACS_PER_CLUSTER),
                .LOCAL_SRAM_KB(SRAM_SIZE_PER_CLUSTER_KB)
            ) cluster (
                .clk(clk),
                .rst_n(rst_n),
                .enable(cluster_enable[i]),
                .instruction(global_instruction),
                .inst_valid(global_inst_valid),
                .busy(cluster_busy[i]),
                .result_out(cluster_results[i]),
                .gl_buffer_read_addr(),
                .gl_buffer_read_data(),
                .gl_buffer_write_addr(),
                .gl_buffer_write_data(),
                .gl_buffer_write_en()
            );
        end
    endgenerate
    
    // 全局缓冲器
    GlobalBuffer #(
        .SIZE_MB(GLOBAL_BUFFER_MB),
        .NUM_BANKS(16),
        .NUM_PORTS(NUM_CLUSTERS * 2)
    ) global_buffer (
        .clk(clk),
        .rst_n(rst_n),
        // 连接到各个簇的读写端口
    );
    
    // NoC互连网络
    NetworkOnChip #(
        .NUM_NODES(NUM_CLUSTERS + 2), // +2 for global buffer and DDR
        .FLIT_WIDTH(128),
        .VC_NUM(4)
    ) noc (
        .clk(clk),
        .rst_n(rst_n)
        // 路由和仲裁逻辑
    );
    
    // DDR控制器
    DDRController #(
        .DATA_WIDTH(64),
        .ADDR_WIDTH(32),
        .BURST_LENGTH(8)
    ) ddr_ctrl (
        .clk(clk),
        .rst_n(rst_n),
        .ddr_clk(clk),
        .addr_out(ddr_addr),
        .data_io(ddr_data),
        .wen(ddr_wen),
        .ren(ddr_ren),
        .ready_in(ddr_ready)
    );
    
    // 电源管理单元
    PowerManagementUnit #(
        .NUM_DOMAINS(NUM_CLUSTERS + 1)
    ) pmu (
        .clk(clk),
        .rst_n(rst_n),
        .activity_level(cluster_busy),
        .power_state(power_state),
        .dvfs_enable(),
        .power_gate_ctrl()
    );
endmodule
            </div>

            <h4>12.2.2 计算簇设计</h4>
            <div class="code-block">
// 优化的计算簇架构 - Verilog版本
module ComputeCluster #(
    parameter CLUSTER_ID = 0,
    parameter NUM_MACS = 512,
    parameter LOCAL_SRAM_KB = 1024,
    parameter PE_ARRAY_DIM = 16,  // 16x16 PE阵列
    parameter PIPELINE_STAGES = 4
)(
    input wire clk,
    input wire rst_n,
    
    // 控制接口
    input wire enable,
    input wire [127:0] instruction,
    input wire inst_valid,
    output reg busy,
    output reg done,
    output reg [31:0] result_out,
    output reg result_valid,
    
    // 全局缓冲器接口 - 流水线化
    output reg [19:0] gl_buffer_read_addr,
    output reg gl_buffer_read_req,
    input wire [255:0] gl_buffer_read_data,
    input wire gl_buffer_read_valid,
    
    output reg [19:0] gl_buffer_write_addr,
    output reg [255:0] gl_buffer_write_data,
    output reg gl_buffer_write_en,
    input wire gl_buffer_write_ack,
    
    // 本地SRAM接口 - 流水线化
    output reg [16:0] local_sram_addr,
    output reg [255:0] local_sram_write_data,
    output reg local_sram_write_en,
    output reg [2:0] local_sram_bank_sel,
    input wire [255:0] local_sram_read_data,
    input wire local_sram_read_valid
);
    
    // 指令解码 - 流水线寄存器
    reg [127:0] instruction_reg;
    reg [7:0] opcode;
    reg [3:0] dataflow_mode;
    reg [7:0] tile_m, tile_n, tile_k;
    reg [15:0] base_addr_a, base_addr_b, base_addr_c;
    reg decode_valid;
    
    // 指令解码流水线
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            instruction_reg <= 128'd0;
            opcode <= 8'd0;
            dataflow_mode <= 4'd0;
            {tile_m, tile_n, tile_k} <= 24'd0;
            {base_addr_a, base_addr_b, base_addr_c} <= 48'd0;
            decode_valid <= 1'b0;
        end else begin
            if (inst_valid && enable) begin
                instruction_reg <= instruction;
                decode_valid <= 1'b1;
            end else begin
                decode_valid <= 1'b0;
            end
            
            // 流水线级别1: 解码基本字段
            if (decode_valid) begin
                opcode <= instruction_reg[127:120];
                dataflow_mode <= instruction_reg[119:116];
            end
            
            // 流水线级别2: 解码地址和维度
            tile_m <= instruction_reg[115:108];
            tile_n <= instruction_reg[107:100];
            tile_k <= instruction_reg[99:92];
            base_addr_a <= instruction_reg[91:76];
            base_addr_b <= instruction_reg[75:60];
            base_addr_c <= instruction_reg[59:44];
        end
    end
    
    // PE阵列信号
    reg [PE_ARRAY_DIM-1:0][7:0] pe_data_in_h_reg;  // 水平输入寄存器
    reg [PE_ARRAY_DIM-1:0][7:0] pe_data_in_v_reg;  // 垂直输入寄存器
    wire [PE_ARRAY_DIM-1:0][PE_ARRAY_DIM-1:0][31:0] pe_results;
    reg pe_array_enable;
    wire pe_array_done;
    
    // 流水线化的PE阵列
    ProcessingElementArray_Pipelined #(
        .ARRAY_DIM(PE_ARRAY_DIM),
        .DATA_WIDTH(8),
        .ACCUM_WIDTH(32),
        .PIPELINE_DEPTH(PIPELINE_STAGES)
    ) pe_array (
        .clk(clk),
        .rst_n(rst_n),
        .enable(pe_array_enable),
        .dataflow_mode(dataflow_mode),
        .data_in_h(pe_data_in_h_reg),
        .data_in_v(pe_data_in_v_reg),
        .results_out(pe_results),
        .done(pe_array_done)
    );
    
    // 本地SRAM与流水线缓冲
    reg [16:0] sram_addr_pipe [PIPELINE_STAGES-1:0];
    reg [255:0] sram_data_pipe [PIPELINE_STAGES-1:0];
    reg sram_pipe_valid [PIPELINE_STAGES-1:0];
    
    integer p;
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            for (p = 0; p < PIPELINE_STAGES; p = p + 1) begin
                sram_addr_pipe[p] <= 17'd0;
                sram_data_pipe[p] <= 256'd0;
                sram_pipe_valid[p] <= 1'b0;
            end
        end else begin
            // 地址流水线
            sram_addr_pipe[0] <= local_sram_addr;
            sram_pipe_valid[0] <= local_sram_write_en;
            for (p = 1; p < PIPELINE_STAGES; p = p + 1) begin
                sram_addr_pipe[p] <= sram_addr_pipe[p-1];
                sram_pipe_valid[p] <= sram_pipe_valid[p-1];
            end
            
            // 数据流水线
            if (local_sram_read_valid) begin
                sram_data_pipe[0] <= local_sram_read_data;
                for (p = 1; p < PIPELINE_STAGES; p = p + 1) begin
                    sram_data_pipe[p] <= sram_data_pipe[p-1];
                end
            end
        end
    end
    
    // 数据编排器 - 流水线化
    reg [7:0] data_buffer_h [PE_ARRAY_DIM-1:0][PIPELINE_STAGES-1:0];
    reg [7:0] data_buffer_v [PE_ARRAY_DIM-1:0][PIPELINE_STAGES-1:0];
    reg data_orch_valid;
    
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            data_orch_valid <= 1'b0;
            for (int i = 0; i < PE_ARRAY_DIM; i++) begin
                for (int j = 0; j < PIPELINE_STAGES; j++) begin
                    data_buffer_h[i][j] <= 8'd0;
                    data_buffer_v[i][j] <= 8'd0;
                end
            end
        end else if (sram_pipe_valid[PIPELINE_STAGES-1]) begin
            // 根据数据流模式编排数据
            case (dataflow_mode)
                4'b0001: begin // Weight Stationary
                    for (int i = 0; i < PE_ARRAY_DIM; i++) begin
                        data_buffer_h[i][0] <= sram_data_pipe[PIPELINE_STAGES-1][i*8+:8];
                        data_buffer_v[i][0] <= sram_data_pipe[PIPELINE_STAGES-1][(i+16)*8+:8];
                    end
                end
                4'b0010: begin // Output Stationary
                    for (int i = 0; i < PE_ARRAY_DIM; i++) begin
                        data_buffer_h[i][0] <= sram_data_pipe[PIPELINE_STAGES-1][(i*2)*8+:8];
                        data_buffer_v[i][0] <= sram_data_pipe[PIPELINE_STAGES-1][(i*2+1)*8+:8];
                    end
                end
                default: begin // Input Stationary
                    for (int i = 0; i < PE_ARRAY_DIM; i++) begin
                        data_buffer_h[i][0] <= sram_data_pipe[PIPELINE_STAGES-1][i*8+:8];
                        data_buffer_v[i][0] <= 8'd0;
                    end
                end
            endcase
            data_orch_valid <= 1'b1;
        end else begin
            data_orch_valid <= 1'b0;
        end
        
        // 数据缓冲器移位
        if (data_orch_valid) begin
            for (int i = 0; i < PE_ARRAY_DIM; i++) begin
                pe_data_in_h_reg[i] <= data_buffer_h[i][0];
                pe_data_in_v_reg[i] <= data_buffer_v[i][0];
                for (int j = 1; j < PIPELINE_STAGES; j++) begin
                    data_buffer_h[i][j-1] <= data_buffer_h[i][j];
                    data_buffer_v[i][j-1] <= data_buffer_v[i][j];
                end
            end
        end
    end
    
    // 簇控制状态机 - 流水线化
    reg [3:0] cluster_state, next_state;
    localparam IDLE = 4'b0000;
    localparam DECODE = 4'b0001;
    localparam FETCH_PREP = 4'b0010;
    localparam FETCH = 4'b0011;
    localparam COMPUTE_PREP = 4'b0100;
    localparam COMPUTE = 4'b0101;
    localparam WRITEBACK_PREP = 4'b0110;
    localparam WRITEBACK = 4'b0111;
    localparam DONE = 4'b1000;
    
    // 计数器和控制信号
    reg [15:0] fetch_counter;
    reg [15:0] compute_counter;
    reg [15:0] writeback_counter;
    reg fetch_complete, compute_complete, writeback_complete;
    
    // 状态机逻辑
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            cluster_state <= IDLE;
        end else begin
            cluster_state <= next_state;
        end
    end
    
    // 下一状态逻辑
    always @(*) begin
        next_state = cluster_state;
        
        case (cluster_state)
            IDLE: begin
                if (enable && inst_valid) begin
                    next_state = DECODE;
                end
            end
            
            DECODE: begin
                if (decode_valid) begin
                    next_state = FETCH_PREP;
                end
            end
            
            FETCH_PREP: begin
                next_state = FETCH;
            end
            
            FETCH: begin
                if (fetch_complete) begin
                    next_state = COMPUTE_PREP;
                end
            end
            
            COMPUTE_PREP: begin
                next_state = COMPUTE;
            end
            
            COMPUTE: begin
                if (compute_complete) begin
                    next_state = WRITEBACK_PREP;
                end
            end
            
            WRITEBACK_PREP: begin
                next_state = WRITEBACK;
            end
            
            WRITEBACK: begin
                if (writeback_complete) begin
                    next_state = DONE;
                end
            end
            
            DONE: begin
                next_state = IDLE;
            end
        endcase
    end
    
    // 输出逻辑和控制信号
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            busy <= 1'b0;
            done <= 1'b0;
            result_valid <= 1'b0;
            pe_array_enable <= 1'b0;
            fetch_counter <= 16'd0;
            compute_counter <= 16'd0;
            writeback_counter <= 16'd0;
            fetch_complete <= 1'b0;
            compute_complete <= 1'b0;
            writeback_complete <= 1'b0;
        end else begin
            done <= (cluster_state == DONE);
            busy <= (cluster_state != IDLE);
            
            case (cluster_state)
                FETCH_PREP: begin
                    fetch_counter <= 16'd0;
                    fetch_complete <= 1'b0;
                    gl_buffer_read_addr <= {CLUSTER_ID[3:0], base_addr_a};
                    gl_buffer_read_req <= 1'b1;
                end
                
                FETCH: begin
                    if (gl_buffer_read_valid) begin
                        local_sram_addr <= fetch_counter;
                        local_sram_write_data <= gl_buffer_read_data;
                        local_sram_write_en <= 1'b1;
                        local_sram_bank_sel <= fetch_counter[2:0];
                        fetch_counter <= fetch_counter + 1;
                        
                        if (fetch_counter >= (tile_m * tile_n + tile_n * tile_k)) begin
                            fetch_complete <= 1'b1;
                            gl_buffer_read_req <= 1'b0;
                        end
                    end else begin
                        local_sram_write_en <= 1'b0;
                    end
                end
                
                COMPUTE_PREP: begin
                    compute_counter <= 16'd0;
                    compute_complete <= 1'b0;
                    pe_array_enable <= 1'b1;
                end
                
                COMPUTE: begin
                    compute_counter <= compute_counter + 1;
                    if (pe_array_done || compute_counter >= (tile_k * PIPELINE_STAGES)) begin
                        compute_complete <= 1'b1;
                        pe_array_enable <= 1'b0;
                    end
                end
                
                WRITEBACK_PREP: begin
                    writeback_counter <= 16'd0;
                    writeback_complete <= 1'b0;
                    result_out <= 32'd0;
                end
                
                WRITEBACK: begin
                    if (writeback_counter < PE_ARRAY_DIM * PE_ARRAY_DIM) begin
                        gl_buffer_write_addr <= {CLUSTER_ID[3:0], base_addr_c} + writeback_counter;
                        gl_buffer_write_data <= {224'd0, pe_results[writeback_counter/PE_ARRAY_DIM][writeback_counter%PE_ARRAY_DIM]};
                        gl_buffer_write_en <= 1'b1;
                        
                        if (gl_buffer_write_ack) begin
                            writeback_counter <= writeback_counter + 1;
                            result_out <= result_out + pe_results[writeback_counter/PE_ARRAY_DIM][writeback_counter%PE_ARRAY_DIM];
                        end
                    end else begin
                        gl_buffer_write_en <= 1'b0;
                        writeback_complete <= 1'b1;
                        result_valid <= 1'b1;
                    end
                end
                
                default: begin
                    gl_buffer_read_req <= 1'b0;
                    gl_buffer_write_en <= 1'b0;
                    local_sram_write_en <= 1'b0;
                    result_valid <= 1'b0;
                end
            endcase
        end
    end
    
endmodule

            </div>
            
            <div class="code-block">
// Chisel版本对比：
import chisel3._
import chisel3.util._

class ComputeCluster(clusterId: Int = 0,
                     numMacs: Int = 512,
                     localSramKB: Int = 1024,
                     peArrayDim: Int = 16) extends Module {
  val io = IO(new Bundle {
    // 控制接口
    val enable = Input(Bool())
    val instruction = Input(UInt(128.W))
    val instValid = Input(Bool())
    val busy = Output(Bool())
    val done = Output(Bool())
    val resultOut = Output(UInt(32.W))
    val resultValid = Output(Bool())
    
    // 全局缓冲器接口
    val glBuffer = new Bundle {
      val readAddr = Output(UInt(20.W))
      val readReq = Output(Bool())
      val readData = Input(UInt(256.W))
      val readValid = Input(Bool())
      val writeAddr = Output(UInt(20.W))
      val writeData = Output(UInt(256.W))
      val writeEn = Output(Bool())
      val writeAck = Input(Bool())
    }
  })
  
  // 状态机定义
  val idle :: decode :: fetchPrep :: fetch :: computePrep :: compute :: writebackPrep :: writeback :: done :: Nil = Enum(9)
  val state = RegInit(idle)
  
  // 指令解码寄存器
  val instructionReg = RegEnable(io.instruction, io.instValid && io.enable)
  val opcode = RegNext(instructionReg(127, 120))
  val dataflowMode = RegNext(instructionReg(119, 116))
  val tileM = RegNext(instructionReg(115, 108))
  val tileN = RegNext(instructionReg(107, 100))
  val tileK = RegNext(instructionReg(99, 92))
  val baseAddrA = RegNext(instructionReg(91, 76))
  val baseAddrB = RegNext(instructionReg(75, 60))
  val baseAddrC = RegNext(instructionReg(59, 44))
  
  // PE阵列实例化
  val peArray = Module(new ProcessingElementArrayPipelined(
    peArrayDim, 8, 32))
  
  // 计数器
  val fetchCounter = RegInit(0.U(16.W))
  val computeCounter = RegInit(0.U(16.W))
  val writebackCounter = RegInit(0.U(16.W))
  
  // 完成标志
  val fetchComplete = RegInit(false.B)
  val computeComplete = RegInit(false.B)
  val writebackComplete = RegInit(false.B)
  
  // 状态机转换
  switch(state) {
    is(idle) {
      when(io.enable && io.instValid) {
        state := decode
      }
    }
    is(decode) {
      state := fetchPrep
    }
    is(fetchPrep) {
      fetchCounter := 0.U
      fetchComplete := false.B
      state := fetch
    }
    is(fetch) {
      when(fetchComplete) {
        state := computePrep
      }
    }
    is(computePrep) {
      computeCounter := 0.U
      computeComplete := false.B
      state := compute
    }
    is(compute) {
      when(computeComplete) {
        state := writebackPrep
      }
    }
    is(writebackPrep) {
      writebackCounter := 0.U
      writebackComplete := false.B
      state := writeback
    }
    is(writeback) {
      when(writebackComplete) {
        state := done
      }
    }
    is(done) {
      state := idle
    }
  }
  
  // Fetch逻辑
  when(state === fetch) {
    io.glBuffer.readReq := true.B
    io.glBuffer.readAddr := Cat(clusterId.U(4.W), baseAddrA) + fetchCounter
    
    when(io.glBuffer.readValid) {
      fetchCounter := fetchCounter + 1.U
      when(fetchCounter >= (tileM * tileN + tileN * tileK)) {
        fetchComplete := true.B
      }
    }
  }.otherwise {
    io.glBuffer.readReq := false.B
  }
  
  // Compute逻辑
  peArray.io.enable := state === compute
  peArray.io.dataflowMode := dataflowMode
  
  when(state === compute) {
    computeCounter := computeCounter + 1.U
    when(peArray.io.done || computeCounter >= (tileK * 4.U)) {
      computeComplete := true.B
    }
  }
  
  // Writeback逻辑
  when(state === writeback) {
    io.glBuffer.writeEn := true.B
    io.glBuffer.writeAddr := Cat(clusterId.U(4.W), baseAddrC) + writebackCounter
    io.glBuffer.writeData := peArray.io.results(writebackCounter)
    
    when(io.glBuffer.writeAck) {
      writebackCounter := writebackCounter + 1.U
      when(writebackCounter >= (peArrayDim * peArrayDim).U) {
        writebackComplete := true.B
      }
    }
  }.otherwise {
    io.glBuffer.writeEn := false.B
  }
  
  // 输出
  io.busy := state =/= idle
  io.done := state === done
  io.resultValid := state === done
  io.resultOut := RegEnable(
    peArray.io.results.reduce(_ + _),
    state === writebackPrep
  )
}
            </div>
            
            <div class="code-block">
// 可重构PE阵列
module ProcessingElementArray #(
    parameter ARRAY_DIM = 16,
    parameter DATA_WIDTH = 8,
    parameter ACCUM_WIDTH = 32
)(
    input wire clk,
    input wire rst_n,
    input wire enable,
    input wire [3:0] dataflow_mode,
    
    // 数据输入
    input wire [ARRAY_DIM-1:0][DATA_WIDTH-1:0] data_in_h,
    input wire [ARRAY_DIM-1:0][DATA_WIDTH-1:0] data_in_v,
    
    // 结果输出
    output wire [ARRAY_DIM-1:0][ARRAY_DIM-1:0][ACCUM_WIDTH-1:0] results_out
);
    
    // 数据流模式
    localparam WS_MODE = 4'b0000;  // Weight Stationary
    localparam OS_MODE = 4'b0001;  // Output Stationary
    localparam IS_MODE = 4'b0010;  // Input Stationary
    localparam RS_MODE = 4'b0011;  // Row Stationary
    
    // PE间连接
    wire [ARRAY_DIM-1:0][ARRAY_DIM-1:0][DATA_WIDTH-1:0] h_links;
    wire [ARRAY_DIM-1:0][ARRAY_DIM-1:0][DATA_WIDTH-1:0] v_links;
    wire [ARRAY_DIM-1:0][ARRAY_DIM-1:0][ACCUM_WIDTH-1:0] partial_sums;
    
    // 生成PE阵列
    genvar row, col;
    generate
        for (row = 0; row < ARRAY_DIM; row = row + 1) begin : pe_row
            for (col = 0; col < ARRAY_DIM; col = col + 1) begin : pe_col
                ProcessingElement #(
                    .DATA_WIDTH(DATA_WIDTH),
                    .ACCUM_WIDTH(ACCUM_WIDTH)
                ) pe (
                    .clk(clk),
                    .rst_n(rst_n),
                    .enable(enable),
                    .mode(dataflow_mode),
                    
                    // 数据输入
                    .data_in_h(col == 0 ? data_in_h[row] : h_links[row][col-1]),
                    .data_in_v(row == 0 ? data_in_v[col] : v_links[row-1][col]),
                    
                    // 数据输出
                    .data_out_h(h_links[row][col]),
                    .data_out_v(v_links[row][col]),
                    
                    // 部分和
                    .partial_sum_in(partial_sums[row][col]),
                    .result_out(results_out[row][col])
                );
            end
        end
    endgenerate
endmodule
            </div>

            <h4>12.2.3 存储层次设计</h4>
            <div class="code-block">
// 分层存储系统
module HierarchicalMemorySystem #(
    parameter L0_SIZE_KB = 2,      // PE本地寄存器
    parameter L1_SIZE_KB = 64,     // 簇内共享L1
    parameter L2_SIZE_KB = 1024,   // 簇私有L2
    parameter L3_SIZE_MB = 4       // 全局共享L3
)(
    input wire clk,
    input wire rst_n,
    
    // PE访问接口
    input wire [511:0] pe_read_req,      // 512个PE的读请求
    input wire [511:0][15:0] pe_read_addr,
    output wire [511:0][7:0] pe_read_data,
    output wire [511:0] pe_read_valid,
    
    // DMA接口
    input wire dma_req,
    input wire [31:0] dma_src_addr,
    input wire [31:0] dma_dst_addr,
    input wire [15:0] dma_length,
    output wire dma_done,
    
    // DDR接口
    output wire [31:0] ddr_addr,
    output wire ddr_read_en,
    input wire [255:0] ddr_read_data,
    input wire ddr_read_valid
);
    
    // L0寄存器文件（每个PE）
    genvar pe_id;
    generate
        for (pe_id = 0; pe_id < 512; pe_id = pe_id + 1) begin : l0_gen
            RegFile #(
                .SIZE_BYTES(L0_SIZE_KB * 1024),
                .DATA_WIDTH(8)
            ) l0_rf (
                .clk(clk),
                .read_addr(pe_read_addr[pe_id][7:0]),
                .read_data(l0_data[pe_id]),
                .write_addr(l0_write_addr[pe_id]),
                .write_data(l0_write_data[pe_id]),
                .write_en(l0_write_en[pe_id])
            );
        end
    endgenerate
    
    // L1缓存（簇内共享）
    wire [15:0] l1_req_addr [15:0];  // 16个L1 bank
    wire [15:0] l1_req_valid;
    wire [15:0][63:0] l1_resp_data;
    wire [15:0] l1_resp_valid;
    
    genvar bank;
    generate
        for (bank = 0; bank < 16; bank = bank + 1) begin : l1_gen
            L1Cache #(
                .SIZE_KB(L1_SIZE_KB / 16),
                .LINE_SIZE(64),
                .ASSOCIATIVITY(4)
            ) l1_bank (
                .clk(clk),
                .rst_n(rst_n),
                .req_addr(l1_req_addr[bank]),
                .req_valid(l1_req_valid[bank]),
                .resp_data(l1_resp_data[bank]),
                .resp_valid(l1_resp_valid[bank]),
                .miss_addr(l1_miss_addr[bank]),
                .miss_valid(l1_miss_valid[bank])
            );
        end
    endgenerate
    
    // L1仲裁器和路由
    L1Arbiter #(
        .NUM_PE(512),
        .NUM_BANKS(16)
    ) l1_arbiter (
        .clk(clk),
        .rst_n(rst_n),
        .pe_requests(pe_read_req),
        .pe_addresses(pe_read_addr),
        .bank_grant(l1_req_valid),
        .bank_addresses(l1_req_addr)
    );
    
    // L2缓存（簇私有）
    L2Cache #(
        .SIZE_KB(L2_SIZE_KB),
        .LINE_SIZE(256),
        .ASSOCIATIVITY(8),
        .NUM_BANKS(8)
    ) l2_cache (
        .clk(clk),
        .rst_n(rst_n),
        // L1 miss处理
        .l1_miss_addr(l1_miss_addr_merged),
        .l1_miss_valid(|l1_miss_valid),
        .l1_fill_data(l2_to_l1_data),
        .l1_fill_valid(l2_to_l1_valid),
        // L3接口
        .l3_req_addr(l2_to_l3_addr),
        .l3_req_valid(l2_to_l3_valid),
        .l3_resp_data(l3_to_l2_data),
        .l3_resp_valid(l3_to_l2_valid)
    );
    
    // L3全局缓存
    L3GlobalBuffer #(
        .SIZE_MB(L3_SIZE_MB),
        .LINE_SIZE(512),
        .NUM_PORTS(4),  // 4个簇
        .NUM_BANKS(16)
    ) l3_buffer (
        .clk(clk),
        .rst_n(rst_n),
        // 簇接口
        .cluster_req_addr(l2_to_l3_addr_all),
        .cluster_req_valid(l2_to_l3_valid_all),
        .cluster_resp_data(l3_to_l2_data_all),
        .cluster_resp_valid(l3_to_l2_valid_all),
        // DDR接口
        .ddr_req_addr(ddr_addr),
        .ddr_req_valid(ddr_read_en),
        .ddr_resp_data(ddr_read_data),
        .ddr_resp_valid(ddr_read_valid),
        // DMA接口
        .dma_req(dma_req),
        .dma_src_addr(dma_src_addr),
        .dma_dst_addr(dma_dst_addr),
        .dma_length(dma_length),
        .dma_done(dma_done)
    );
    
    // 预取引擎
    PrefetchEngine #(
        .PREFETCH_DEGREE(4),
        .PATTERN_TABLE_SIZE(256)
    ) prefetcher (
        .clk(clk),
        .rst_n(rst_n),
        .access_addr(pe_read_addr),
        .access_valid(pe_read_req),
        .prefetch_addr(prefetch_addr),
        .prefetch_valid(prefetch_valid)
    );
endmodule

// 智能缓存替换策略
module AdaptiveCacheReplacement #(
    parameter CACHE_WAYS = 8,
    parameter HISTORY_BITS = 4
)(
    input wire clk,
    input wire rst_n,
    
    // 访问信息
    input wire access_valid,
    input wire [2:0] access_way,
    input wire [1:0] access_type,  // 0:权重 1:激活 2:部分和
    
    // 替换决策
    input wire replace_req,
    output reg [2:0] victim_way,
    output reg victim_valid
);
    
    // 每路的元数据
    reg [CACHE_WAYS-1:0][HISTORY_BITS-1:0] access_history;
    reg [CACHE_WAYS-1:0][1:0] data_type;
    reg [CACHE_WAYS-1:0][15:0] reuse_counter;
    reg [CACHE_WAYS-1:0] dead_prediction;
    
    // 更新访问历史
    always @(posedge clk) begin
        if (!rst_n) begin
            access_history <= 0;
            reuse_counter <= 0;
        end else if (access_valid) begin
            // 更新LRU位
            access_history[access_way] <= {HISTORY_BITS{1'b1}};
            for (int i = 0; i < CACHE_WAYS; i++) begin
                if (i != access_way && access_history[i] > 0) begin
                    access_history[i] <= access_history[i] - 1;
                end
            end
            
            // 更新重用计数
            reuse_counter[access_way] <= reuse_counter[access_way] + 1;
            data_type[access_way] <= access_type;
        end
    end
    
    // 死亡预测逻辑
    always @(posedge clk) begin
        for (int i = 0; i < CACHE_WAYS; i++) begin
            // 权重数据通常重用度高
            if (data_type[i] == 2'b00) begin
                dead_prediction[i] <= 0;
            end
            // 激活值重用度取决于层类型
            else if (data_type[i] == 2'b01) begin
                dead_prediction[i] <= (reuse_counter[i] < 2);
            end
            // 部分和通常只使用一次
            else if (data_type[i] == 2'b10) begin
                dead_prediction[i] <= 1;
            end
        end
    end
    
    // 选择替换牺牲者
    always @(*) begin
        victim_valid = 0;
        victim_way = 0;
        
        if (replace_req) begin
            // 优先替换预测为死亡的行
            for (int i = 0; i < CACHE_WAYS; i++) begin
                if (dead_prediction[i]) begin
                    victim_way = i;
                    victim_valid = 1;
                    break;
                end
            end
            
            // 如果没有死亡预测，使用LRU
            if (!victim_valid) begin
                reg [HISTORY_BITS-1:0] min_history = {HISTORY_BITS{1'b1}};
                for (int i = 0; i < CACHE_WAYS; i++) begin
                    if (access_history[i] < min_history) begin
                        min_history = access_history[i];
                        victim_way = i;
                    end
                end
                victim_valid = 1;
            end
        end
    end
endmodule
            </div>

            <div class="exercise">
                <h4>练习 3：架构优化设计</h4>
                <p>基于上述NPU架构，进行以下优化设计：</p>
                <ol>
                    <li>设计一个支持稀疏计算的PE阵列，能够跳过零值计算</li>
                    <li>实现一个自适应的NoC路由算法，根据网络拥塞动态调整路径</li>
                    <li>设计一个混合精度计算单元，支持INT4/INT8/FP16动态切换</li>
                </ol>
                
                <details class="hint">
                    <summary>💡 提示</summary>
                    <p>思考方向：1) 稀疏计算需要零检测和索引管理，考虑压缩格式（CSR/CSC）。2) 自适应路由需要监控各链路负载，使用备选路径。3) 混合精度需要可配置的数据通路和位宽转换逻辑。</p>
                </details>
                <button class="toggle-answer">显示答案</button>
                <div class="answer">
                    <div class="code-block">
// 稀疏感知PE阵列
module SparsePEArray #(
    parameter ARRAY_DIM = 16,
    parameter DATA_WIDTH = 8,
    parameter SPARSE_THRESHOLD = 10  // 稀疏度阈值
)(
    input wire clk,
    input wire rst_n,
    
    // 稀疏数据输入
    input wire [ARRAY_DIM-1:0][DATA_WIDTH-1:0] weight_values,
    input wire [ARRAY_DIM-1:0] weight_valid,  // 非零标志
    input wire [ARRAY_DIM-1:0][DATA_WIDTH-1:0] activation_values,
    input wire [ARRAY_DIM-1:0] activation_valid,
    
    // 压缩索引
    input wire [ARRAY_DIM-1:0][3:0] weight_indices,
    input wire [ARRAY_DIM-1:0][3:0] activation_indices,
    
    // 输出
    output reg [ARRAY_DIM-1:0][31:0] sparse_results,
    output reg [ARRAY_DIM-1:0] result_valid
);
    
    // 稀疏度检测
    reg [7:0] weight_sparsity, activation_sparsity;
    always @(*) begin
        weight_sparsity = 0;
        activation_sparsity = 0;
        for (int i = 0; i < ARRAY_DIM; i++) begin
            if (!weight_valid[i]) weight_sparsity = weight_sparsity + 1;
            if (!activation_valid[i]) activation_sparsity = activation_sparsity + 1;
        end
    end
    
    // 动态选择计算模式
    wire sparse_mode = (weight_sparsity > SPARSE_THRESHOLD) || 
                       (activation_sparsity > SPARSE_THRESHOLD);
    
    // 稀疏计算引擎
    genvar pe_idx;
    generate
        for (pe_idx = 0; pe_idx < ARRAY_DIM; pe_idx = pe_idx + 1) begin : sparse_pe
            SparsePE #(
                .DATA_WIDTH(DATA_WIDTH)
            ) spe (
                .clk(clk),
                .rst_n(rst_n),
                .sparse_mode(sparse_mode),
                // 稠密输入
                .dense_weight(weight_values[pe_idx]),
                .dense_activation(activation_values[pe_idx]),
                // 稀疏输入
                .sparse_weight_val(weight_values[pe_idx]),
                .sparse_weight_idx(weight_indices[pe_idx]),
                .sparse_weight_valid(weight_valid[pe_idx]),
                .sparse_act_val(activation_values[pe_idx]),
                .sparse_act_idx(activation_indices[pe_idx]),
                .sparse_act_valid(activation_valid[pe_idx]),
                // 输出
                .result(sparse_results[pe_idx]),
                .result_valid(result_valid[pe_idx])
            );
        end
    endgenerate
    
    // 零值跳过控制器
    ZeroSkipController #(
        .ARRAY_DIM(ARRAY_DIM)
    ) skip_ctrl (
        .clk(clk),
        .rst_n(rst_n),
        .data_valid(weight_valid & activation_valid),
        .skip_enable(sparse_mode),
        .compute_enable(pe_compute_en)
    );
endmodule

// 自适应NoC路由
module AdaptiveRouter #(
    parameter NODE_ID = 0,
    parameter NETWORK_WIDTH = 4,
    parameter NETWORK_HEIGHT = 4,
    parameter FLIT_WIDTH = 128,
    parameter VC_NUM = 4
)(
    input wire clk,
    input wire rst_n,
    
    // 输入端口（5个方向：N,S,E,W,Local）
    input wire [4:0][FLIT_WIDTH-1:0] in_flits,
    input wire [4:0] in_valid,
    output wire [4:0] in_ready,
    
    // 输出端口
    output reg [4:0][FLIT_WIDTH-1:0] out_flits,
    output reg [4:0] out_valid,
    input wire [4:0] out_ready,
    
    // 拥塞信息
    input wire [4:0][7:0] congestion_level,
    output wire [7:0] local_congestion
);
    
    // 提取目标地址
    wire [7:0] dest_x[4:0], dest_y[4:0];
    genvar port;
    generate
        for (port = 0; port < 5; port = port + 1) begin : dest_extract
            assign dest_x[port] = in_flits[port][7:0];
            assign dest_y[port] = in_flits[port][15:8];
        end
    endgenerate
    
    // 计算最短路径
    reg [2:0] preferred_port[4:0];
    reg [2:0] alternate_port[4:0];
    
    always @(*) begin
        for (int i = 0; i < 5; i++) begin
            // XY路由作为基础
            if (dest_x[i] > NODE_ID % NETWORK_WIDTH) begin
                preferred_port[i] = 3'd2; // East
            end else if (dest_x[i] < NODE_ID % NETWORK_WIDTH) begin
                preferred_port[i] = 3'd3; // West
            end else if (dest_y[i] > NODE_ID / NETWORK_WIDTH) begin
                preferred_port[i] = 3'd0; // North
            end else if (dest_y[i] < NODE_ID / NETWORK_WIDTH) begin
                preferred_port[i] = 3'd1; // South
            end else begin
                preferred_port[i] = 3'd4; // Local
            end
            
            // 计算备选路径（YX路由）
            if (dest_y[i] > NODE_ID / NETWORK_WIDTH) begin
                alternate_port[i] = 3'd0; // North
            end else if (dest_y[i] < NODE_ID / NETWORK_WIDTH) begin
                alternate_port[i] = 3'd1; // South
            end else if (dest_x[i] > NODE_ID % NETWORK_WIDTH) begin
                alternate_port[i] = 3'd2; // East
            end else if (dest_x[i] < NODE_ID % NETWORK_WIDTH) begin
                alternate_port[i] = 3'd3; // West
            end else begin
                alternate_port[i] = 3'd4; // Local
            end
        end
    end
    
    // 自适应路由决策
    reg [2:0] selected_port[4:0];
    always @(*) begin
        for (int i = 0; i < 5; i++) begin
            // 比较拥塞程度
            if (congestion_level[preferred_port[i]] < 
                congestion_level[alternate_port[i]] + 8'd32) begin
                // 优选路径拥塞不严重，使用优选
                selected_port[i] = preferred_port[i];
            end else begin
                // 优选路径拥塞，使用备选
                selected_port[i] = alternate_port[i];
            end
        end
    end
    
    // 仲裁和交叉开关
    wire [4:0][4:0] request_matrix;  // request_matrix[i][j]: 输入i请求输出j
    wire [4:0][4:0] grant_matrix;
    
    genvar in_p, out_p;
    generate
        for (in_p = 0; in_p < 5; in_p = in_p + 1) begin : req_gen
            for (out_p = 0; out_p < 5; out_p = out_p + 1) begin : req_out
                assign request_matrix[in_p][out_p] = 
                    in_valid[in_p] && (selected_port[in_p] == out_p);
            end
        end
    endgenerate
    
    // Round-Robin仲裁器
    RoundRobinArbiter #(
        .NUM_PORTS(5)
    ) arbiter[4:0] (
        .clk(clk),
        .rst_n(rst_n),
        .requests(request_matrix),
        .grants(grant_matrix)
    );
    
    // 输出多路复用
    always @(posedge clk) begin
        if (!rst_n) begin
            out_valid <= 0;
        end else begin
            for (int out_p = 0; out_p < 5; out_p++) begin
                out_valid[out_p] <= 0;
                for (int in_p = 0; in_p < 5; in_p++) begin
                    if (grant_matrix[in_p][out_p]) begin
                        out_flits[out_p] <= in_flits[in_p];
                        out_valid[out_p] <= 1;
                    end
                end
            end
        end
    end
    
    // 本地拥塞度计算
    reg [7:0] buffer_occupancy[4:0];
    assign local_congestion = (buffer_occupancy[0] + buffer_occupancy[1] + 
                              buffer_occupancy[2] + buffer_occupancy[3] + 
                              buffer_occupancy[4]) / 5;
endmodule

// 混合精度计算单元
module MixedPrecisionUnit #(
    parameter MAX_WIDTH = 16  // 最大支持FP16
)(
    input wire clk,
    input wire rst_n,
    
    // 操作数输入
    input wire [MAX_WIDTH-1:0] operand_a,
    input wire [MAX_WIDTH-1:0] operand_b,
    input wire [31:0] accumulator,
    
    // 精度控制
    input wire [1:0] precision_mode,  // 00:INT4 01:INT8 10:FP16
    input wire [2:0] operation,       // 000:MAC 001:ADD 010:MUL
    
    // 输出
    output reg [31:0] result,
    output reg overflow,
    output reg underflow
);
    
    // 精度模式定义
    localparam INT4_MODE = 2'b00;
    localparam INT8_MODE = 2'b01;
    localparam FP16_MODE = 2'b10;
    
    // INT4计算单元（可以并行计算4个）
    wire [3:0] int4_a[3:0], int4_b[3:0];
    wire [7:0] int4_results[3:0];
    
    genvar i;
    generate
        for (i = 0; i < 4; i = i + 1) begin : int4_extract
            assign int4_a[i] = operand_a[i*4 +: 4];
            assign int4_b[i] = operand_b[i*4 +: 4];
            
            // INT4 MAC
            wire [7:0] int4_prod = $signed(int4_a[i]) * $signed(int4_b[i]);
            assign int4_results[i] = int4_prod;
        end
    endgenerate
    
    // INT8计算单元（可以并行计算2个）
    wire [7:0] int8_a[1:0], int8_b[1:0];
    wire [15:0] int8_results[1:0];
    
    generate
        for (i = 0; i < 2; i = i + 1) begin : int8_calc
            assign int8_a[i] = operand_a[i*8 +: 8];
            assign int8_b[i] = operand_b[i*8 +: 8];
            
            // INT8 MAC
            wire [15:0] int8_prod = $signed(int8_a[i]) * $signed(int8_b[i]);
            assign int8_results[i] = int8_prod;
        end
    endgenerate
    
    // FP16计算单元
    wire [15:0] fp16_a = operand_a[15:0];
    wire [15:0] fp16_b = operand_b[15:0];
    wire [31:0] fp16_result;
    
    FP16MAC fp16_mac (
        .a(fp16_a),
        .b(fp16_b),
        .c(accumulator),
        .result(fp16_result),
        .overflow(fp16_overflow),
        .underflow(fp16_underflow)
    );
    
    // 结果选择和累加
    always @(posedge clk) begin
        if (!rst_n) begin
            result <= 0;
            overflow <= 0;
            underflow <= 0;
        end else begin
            case (precision_mode)
                INT4_MODE: begin
                    // INT4模式：4路并行
                    result <= accumulator + 
                             $signed(int4_results[0]) + 
                             $signed(int4_results[1]) + 
                             $signed(int4_results[2]) + 
                             $signed(int4_results[3]);
                    overflow <= 0;
                    underflow <= 0;
                end
                
                INT8_MODE: begin
                    // INT8模式：2路并行
                    result <= accumulator + 
                             $signed(int8_results[0]) + 
                             $signed(int8_results[1]);
                    overflow <= 0;
                    underflow <= 0;
                end
                
                FP16_MODE: begin
                    // FP16模式：单路
                    result <= fp16_result;
                    overflow <= fp16_overflow;
                    underflow <= fp16_underflow;
                end
                
                default: begin
                    result <= accumulator;
                end
            endcase
        end
    end
    
    // 动态精度选择逻辑
    reg [1:0] auto_precision;
    reg [31:0] value_range;
    
    always @(*) begin
        // 根据数值范围自动选择精度
        value_range = (operand_a > operand_b) ? operand_a : operand_b;
        
        if (value_range < 16) begin
            auto_precision = INT4_MODE;  // 小数值用INT4
        end else if (value_range < 256) begin
            auto_precision = INT8_MODE;  // 中等数值用INT8
        end else begin
            auto_precision = FP16_MODE;  // 大数值用FP16
        end
    end
endmodule
                    </div>
                    <p><strong>解析：</strong></p>
                    <ul>
                        <li>稀疏PE阵列通过检测零值分布，动态切换计算模式，跳过零值MAC操作</li>
                        <li>自适应路由器基于实时拥塞信息选择XY或YX路由，避免热点</li>
                        <li>混合精度单元支持INT4/INT8/FP16，INT4模式下可4路并行提高吞吐量</li>
                        <li>包含自动精度选择逻辑，根据数值范围动态调整精度</li>
                        <li>这些优化可以显著提升NPU的能效和灵活性</li>
                    </ul>
                </div>
            </div>

            <h3>12.3 RTL实现与验证</h3>
            
            <p>本节将展示关键模块的RTL实现细节，并建立完整的验证环境。</p>

            <h4>12.3.1 MAC单元RTL实现</h4>
            <div class="code-block">
// 高性能MAC单元实现 - 改进版（严格遵循可综合规范）
module HighPerformanceMAC #(
    parameter DATA_WIDTH = 8,
    parameter ACCUM_WIDTH = 32,
    parameter PIPELINE_STAGES = 3
)(
    input wire clk,
    input wire rst_n,
    
    // 输入接口
    input wire signed [DATA_WIDTH-1:0] a,
    input wire signed [DATA_WIDTH-1:0] b,
    input wire signed [ACCUM_WIDTH-1:0] c,
    input wire valid_in,
    input wire [1:0] mode,  // 00:MAC 01:MUL 10:ADD 11:BYPASS
    
    // 输出接口
    output reg signed [ACCUM_WIDTH-1:0] result,
    output reg valid_out,
    output reg overflow
);
    
    // 确保所有内部信号声明
    wire signed [2*DATA_WIDTH-1:0] mult_result_comb;
    reg signed [ACCUM_WIDTH-1:0] add_result_next;
    reg overflow_next;
    
    // 流水线寄存器
    reg signed [DATA_WIDTH-1:0] a_r1, b_r1;
    reg signed [ACCUM_WIDTH-1:0] c_r1, c_r2;
    reg [1:0] mode_r1, mode_r2;
    reg valid_r1, valid_r2;
    
    // 乘法结果
    reg signed [2*DATA_WIDTH-1:0] mult_result;
    reg signed [ACCUM_WIDTH-1:0] mult_extended;
    
    // 第一级：输入寄存
    always @(posedge clk) begin
        if (!rst_n) begin
            a_r1 <= 0;
            b_r1 <= 0;
            c_r1 <= 0;
            mode_r1 <= 0;
            valid_r1 <= 0;
        end else begin
            a_r1 <= a;
            b_r1 <= b;
            c_r1 <= c;
            mode_r1 <= mode;
            valid_r1 <= valid_in;
        end
    end
    
    // 组合逻辑计算乘法结果
    assign mult_result_comb = a_r1 * b_r1;
    
    // 第二级：乘法结果寄存（使用非阻塞赋值）
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            mult_result <= '0;
            c_r2 <= '0;
            mode_r2 <= 2'b00;
            valid_r2 <= 1'b0;
        end else begin
            mult_result <= mult_result_comb;
            c_r2 <= c_r1;
            mode_r2 <= mode_r1;
            valid_r2 <= valid_r1;
        end
    end
    
    // 符号扩展
    always @(*) begin
        mult_extended = {{(ACCUM_WIDTH-2*DATA_WIDTH){mult_result[2*DATA_WIDTH-1]}}, 
                        mult_result};
    end
    
    // 组合逻辑计算下一个结果
    always @(*) begin
        // 先给所有输出赋默认值，避免锁存器
        add_result_next = result;
        overflow_next = 1'b0;
        
        case (mode_r2)
            2'b00: begin  // MAC
                {overflow_next, add_result_next} = {mult_extended[ACCUM_WIDTH-1], mult_extended} + 
                                                   {c_r2[ACCUM_WIDTH-1], c_r2};
            end
            2'b01: begin  // MUL only
                add_result_next = mult_extended;
                overflow_next = 1'b0;
            end
            2'b10: begin  // ADD only
                add_result_next = c_r2 + {{(ACCUM_WIDTH-DATA_WIDTH){a_r1[DATA_WIDTH-1]}}, a_r1};
                overflow_next = 1'b0;
            end
            2'b11: begin  // BYPASS
                add_result_next = c_r2;
                overflow_next = 1'b0;
            end
            default: begin  // 确保完备性
                add_result_next = c_r2;
                overflow_next = 1'b0;
            end
        endcase
    end
    
    // 第三级：结果寄存
    always @(posedge clk or negedge rst_n) begin
        if (!rst_n) begin
            result <= '0;
            valid_out <= 1'b0;
            overflow <= 1'b0;
        end else begin
            result <= add_result_next;
            valid_out <= valid_r2;
            overflow <= overflow_next;
        end
    end
    
    // 断言检查
    // synthesis translate_off
    always @(posedge clk) begin
        if (valid_in && valid_r1 && valid_r2) begin
            assert(valid_out) else $error("Pipeline stall detected");
        end
    end
    // synthesis translate_on
endmodule

// 脉动阵列实现
module SystolicArray #(
    parameter ARRAY_SIZE = 16,
    parameter DATA_WIDTH = 8
)(
    input wire clk,
    input wire rst_n,
    
    // 权重加载接口
    input wire weight_load,
    input wire [ARRAY_SIZE-1:0][ARRAY_SIZE-1:0][DATA_WIDTH-1:0] weights,
    
    // 数据流接口
    input wire [ARRAY_SIZE-1:0][DATA_WIDTH-1:0] input_data,
    input wire input_valid,
    
    // 输出接口
    output wire [ARRAY_SIZE-1:0][31:0] output_data,
    output wire [ARRAY_SIZE-1:0] output_valid
);
    
    // PE间连接
    wire [ARRAY_SIZE:0][ARRAY_SIZE:0][DATA_WIDTH-1:0] h_data;
    wire [ARRAY_SIZE:0][ARRAY_SIZE:0][31:0] v_data;
    wire [ARRAY_SIZE:0][ARRAY_SIZE:0] h_valid, v_valid;
    
    // 边界连接
    genvar i;
    generate
        for (i = 0; i < ARRAY_SIZE; i = i + 1) begin : boundary
            // 左边界输入
            assign h_data[i][0] = input_data[i];
            assign h_valid[i][0] = input_valid;
            
            // 上边界输入（部分和初始化为0）
            assign v_data[0][i] = 32'h0;
            assign v_valid[0][i] = 1'b1;
            
            // 下边界输出
            assign output_data[i] = v_data[ARRAY_SIZE][i];
            assign output_valid[i] = v_valid[ARRAY_SIZE][i];
        end
    endgenerate
    
    // PE阵列实例化
    genvar row, col;
    generate
        for (row = 0; row < ARRAY_SIZE; row = row + 1) begin : pe_row
            for (col = 0; col < ARRAY_SIZE; col = col + 1) begin : pe_col
                SystolicPE #(
                    .DATA_WIDTH(DATA_WIDTH)
                ) pe (
                    .clk(clk),
                    .rst_n(rst_n),
                    
                    // 权重接口
                    .weight_load(weight_load),
                    .weight_in(weights[row][col]),
                    
                    // 水平数据流（激活值）
                    .h_data_in(h_data[row][col]),
                    .h_valid_in(h_valid[row][col]),
                    .h_data_out(h_data[row][col+1]),
                    .h_valid_out(h_valid[row][col+1]),
                    
                    // 垂直数据流（部分和）
                    .v_data_in(v_data[row][col]),
                    .v_valid_in(v_valid[row][col]),
                    .v_data_out(v_data[row+1][col]),
                    .v_valid_out(v_valid[row+1][col])
                );
            end
        end
    endgenerate
endmodule

// 脉动PE单元
module SystolicPE #(
    parameter DATA_WIDTH = 8
)(
    input wire clk,
    input wire rst_n,
    
    // 权重接口
    input wire weight_load,
    input wire [DATA_WIDTH-1:0] weight_in,
    
    // 水平数据流
    input wire [DATA_WIDTH-1:0] h_data_in,
    input wire h_valid_in,
    output reg [DATA_WIDTH-1:0] h_data_out,
    output reg h_valid_out,
    
    // 垂直数据流
    input wire [31:0] v_data_in,
    input wire v_valid_in,
    output reg [31:0] v_data_out,
    output reg v_valid_out
);
    
    // 权重寄存器
    reg [DATA_WIDTH-1:0] weight_reg;
    
    // 权重加载
    always @(posedge clk) begin
        if (!rst_n) begin
            weight_reg <= 0;
        end else if (weight_load) begin
            weight_reg <= weight_in;
        end
    end
    
    // MAC计算
    wire [31:0] mac_result;
    wire mac_valid;
    
    HighPerformanceMAC #(
        .DATA_WIDTH(DATA_WIDTH),
        .ACCUM_WIDTH(32),
        .PIPELINE_STAGES(1)
    ) mac_unit (
        .clk(clk),
        .rst_n(rst_n),
        .a(h_data_in),
        .b(weight_reg),
        .c(v_data_in),
        .valid_in(h_valid_in & v_valid_in),
        .mode(2'b00),  // MAC mode
        .result(mac_result),
        .valid_out(mac_valid),
        .overflow()
    );
    
    // 数据传递
    always @(posedge clk) begin
        if (!rst_n) begin
            h_data_out <= 0;
            h_valid_out <= 0;
            v_data_out <= 0;
            v_valid_out <= 0;
        end else begin
            // 水平传递（激活值）
            h_data_out <= h_data_in;
            h_valid_out <= h_valid_in;
            
            // 垂直传递（部分和）
            v_data_out <= mac_result;
            v_valid_out <= mac_valid;
        end
    end
endmodule
            </div>

            <h4>12.3.2 UVM验证环境</h4>
            <div class="code-block">
// 改进的UVM测试环境 - 完整的自校验和覆盖率驱动
class npu_env extends uvm_env;
    `uvm_component_utils(npu_env)
    
    // 环境组件
    npu_agent           input_agent;
    npu_agent           output_agent;
    npu_scoreboard      scoreboard;
    npu_coverage        coverage;
    npu_ref_model       ref_model;
    npu_assertion_monitor assertion_mon;  // 新增：断言监测器
    npu_performance_monitor perf_mon;     // 新增：性能监测器
    
    // 配置对象
    npu_env_config      env_cfg;
    
    function new(string name = "npu_env", uvm_component parent = null);
        super.new(name, parent);
    endfunction
    
    function void build_phase(uvm_phase phase);
        super.build_phase(phase);
        
        // 获取配置
        if (!uvm_config_db#(npu_env_config)::get(this, "", "env_cfg", env_cfg))
            `uvm_fatal("ENV", "Failed to get env_cfg")
        
        // 创建代理
        input_agent = npu_agent::type_id::create("input_agent", this);
        output_agent = npu_agent::type_id::create("output_agent", this);
        
        // 创建记分板和覆盖率
        scoreboard = npu_scoreboard::type_id::create("scoreboard", this);
        coverage = npu_coverage::type_id::create("coverage", this);
        ref_model = npu_ref_model::type_id::create("ref_model", this);
        
        // 配置代理
        input_agent.is_active = UVM_ACTIVE;
        output_agent.is_active = UVM_PASSIVE;
    endfunction
    
    function void connect_phase(uvm_phase phase);
        super.connect_phase(phase);
        
        // 连接TLM端口
        input_agent.monitor.ap.connect(ref_model.input_fifo.analysis_export);
        input_agent.monitor.ap.connect(coverage.analysis_export);
        
        ref_model.output_ap.connect(scoreboard.expected_fifo.analysis_export);
        output_agent.monitor.ap.connect(scoreboard.actual_fifo.analysis_export);
    endfunction
endclass

// NPU代理
class npu_agent extends uvm_agent;
    `uvm_component_utils(npu_agent)
    
    npu_driver      driver;
    npu_monitor     monitor;
    npu_sequencer   sequencer;
    
    function new(string name = "npu_agent", uvm_component parent = null);
        super.new(name, parent);
    endfunction
    
    function void build_phase(uvm_phase phase);
        super.build_phase(phase);
        
        monitor = npu_monitor::type_id::create("monitor", this);
        
        if (is_active == UVM_ACTIVE) begin
            driver = npu_driver::type_id::create("driver", this);
            sequencer = npu_sequencer::type_id::create("sequencer", this);
        end
    endfunction
    
    function void connect_phase(uvm_phase phase);
        super.connect_phase(phase);
        
        if (is_active == UVM_ACTIVE) begin
            driver.seq_item_port.connect(sequencer.seq_item_export);
        end
    endfunction
endclass

// 增强的NPU事务 - 支持更多约束和灵活性
class npu_transaction extends uvm_sequence_item;
    `uvm_object_utils(npu_transaction)
    
    // 事务类型
    typedef enum {CONV, FC, POOL, ACTIVATION, SPARSE_CONV, DEPTHWISE} op_type_e;
    rand op_type_e op_type;
    
    // 数据字段
    rand bit [7:0] input_data[];
    rand bit [7:0] weight_data[];
    rand bit [31:0] output_data[];
    
    // 配置参数
    rand int input_height, input_width, input_channels;
    rand int output_height, output_width, output_channels;
    rand int kernel_size, stride, padding;
    rand int sparsity_ratio;  // 新增：稀疏度
    rand bit use_bias;        // 新增：是否使用偏置
    rand bit [2:0] precision_mode; // 新增：INT4/INT8/FP16
    
    // 增强的约束 - 更接近实际应用
    constraint data_size_c {
        input_data.size() == input_height * input_width * input_channels;
        if (op_type == DEPTHWISE) {
            weight_data.size() == kernel_size * kernel_size * input_channels;
        } else {
            weight_data.size() == kernel_size * kernel_size * input_channels * output_channels;
        }
        output_data.size() == output_height * output_width * output_channels;
    }
    
    constraint dimension_c {
        input_height inside {[8:256]};
        input_width inside {[8:256]};
        input_channels inside {[16:512]};
        output_channels inside {[16:512]};
        kernel_size inside {1, 3, 5, 7};
        stride inside {1, 2};
        padding inside {[0:3]};
        
        // 输出尺寸计算约束
        output_height == (input_height + 2*padding - kernel_size) / stride + 1;
        output_width == (input_width + 2*padding - kernel_size) / stride + 1;
        
        // 稀疏度约束
        sparsity_ratio inside {[0:90]}; // 0-90%稀疏度
        
        // 精度模式约束
        precision_mode inside {[0:2]}; // 0:INT4, 1:INT8, 2:FP16
    }
    
    // 稀疏数据生成约束
    constraint sparsity_c {
        if (op_type == SPARSE_CONV) {
            // 根据稀疏度比例设置零值
            foreach (weight_data[i]) {
                (sparsity_ratio > 50) -> (weight_data[i] dist {0 := sparsity_ratio, [1:255] := 100-sparsity_ratio});
            }
        }
    }
    
    function new(string name = "npu_transaction");
        super.new(name);
    endfunction
    
    function void do_copy(uvm_object rhs);
        npu_transaction tr;
        super.do_copy(rhs);
        $cast(tr, rhs);
        op_type = tr.op_type;
        input_data = tr.input_data;
        weight_data = tr.weight_data;
        output_data = tr.output_data;
    endfunction
endclass

// 增强的约束随机测试序列
class constrained_random_sequence extends uvm_sequence#(npu_transaction);
    `uvm_object_utils(constrained_random_sequence)
    
    // 可配置参数
    rand int num_transactions = 1000;
    rand bit enable_sparse = 1;
    rand bit enable_mixed_precision = 1;
    
    function new(string name = "constrained_random_sequence");
        super.new(name);
    endfunction
    
    task body();
        npu_transaction tr;
        
        // 随机生成多种类型的事务
        repeat(num_transactions) begin
            tr = npu_transaction::type_id::create("tr");
            start_item(tr);
            
            // 复杂的约束随机化
            assert(tr.randomize() with {
                // 操作类型分布
                op_type dist {CONV := 40, FC := 20, POOL := 10, 
                             ACTIVATION := 10, SPARSE_CONV := 15, DEPTHWISE := 5};
                
                // 根据操作类型调整参数
                if (op_type == CONV || op_type == SPARSE_CONV) {
                    kernel_size dist {1 := 10, 3 := 60, 5 := 20, 7 := 10};
                    stride dist {1 := 70, 2 := 30};
                }
                
                if (op_type == POOL) {
                    kernel_size inside {2, 3};
                    stride == kernel_size; // 无重叠池化
                }
                
                // 精度模式随机化
                if (enable_mixed_precision) {
                    precision_mode dist {0 := 30, 1 := 50, 2 := 20}; // INT4:30%, INT8:50%, FP16:20%
                } else {
                    precision_mode == 1; // 仅INT8
                }
                
                // 稀疏度控制
                if (enable_sparse && op_type == SPARSE_CONV) {
                    sparsity_ratio dist {[0:30] := 20, [31:70] := 60, [71:90] := 20};
                } else {
                    sparsity_ratio == 0;
                }
            }) else `uvm_error("RAND", "Randomization failed");
            
            finish_item(tr);
        end
    endtask
endclass

// 增强的参考模型 - 位精确性能模型
class npu_ref_model extends uvm_component;
    `uvm_component_utils(npu_ref_model)
    
    uvm_tlm_analysis_fifo#(npu_transaction) input_fifo;
    uvm_analysis_port#(npu_transaction) output_ap;
    
    // 性能统计
    int total_operations = 0;
    int sparse_operations_skipped = 0;
    real average_sparsity = 0.0;
    
    // 配置
    bit enable_performance_modeling = 1;
    bit enable_precision_modeling = 1;
    
    function new(string name = "npu_ref_model", uvm_component parent = null);
        super.new(name, parent);
        input_fifo = new("input_fifo", this);
        output_ap = new("output_ap", this);
    endfunction
    
    task run_phase(uvm_phase phase);
        npu_transaction input_tr, output_tr;
        
        forever begin
            input_fifo.get(input_tr);
            
            // 克隆事务
            $cast(output_tr, input_tr.clone());
            
            // 根据操作类型计算期望输出
            case (input_tr.op_type)
                npu_transaction::CONV: compute_conv(input_tr, output_tr);
                npu_transaction::FC: compute_fc(input_tr, output_tr);
                npu_transaction::POOL: compute_pool(input_tr, output_tr);
                npu_transaction::ACTIVATION: compute_activation(input_tr, output_tr);
            endcase
            
            // 发送期望输出
            output_ap.write(output_tr);
        end
    endtask
    
    // 卷积计算
    function void compute_conv(npu_transaction input_tr, output npu_transaction output_tr);
        int in_idx, w_idx, out_idx;
        int h, w, c, k_h, k_w, oc;
        int in_h, in_w;
        int accumulator;
        
        // 清空输出
        foreach (output_tr.output_data[i])
            output_tr.output_data[i] = 0;
        
        // 执行卷积
        for (h = 0; h < output_tr.output_height; h++) begin
            for (w = 0; w < output_tr.output_width; w++) begin
                for (oc = 0; oc < output_tr.output_channels; oc++) begin
                    accumulator = 0;
                    
                    for (k_h = 0; k_h < input_tr.kernel_size; k_h++) begin
                        for (k_w = 0; k_w < input_tr.kernel_size; k_w++) begin
                            for (c = 0; c < input_tr.input_channels; c++) begin
                                in_h = h * input_tr.stride - input_tr.padding + k_h;
                                in_w = w * input_tr.stride - input_tr.padding + k_w;
                                
                                if (in_h >= 0 && in_h < input_tr.input_height &&
                                    in_w >= 0 && in_w < input_tr.input_width) begin
                                    
                                    in_idx = (in_h * input_tr.input_width + in_w) * 
                                            input_tr.input_channels + c;
                                    w_idx = ((k_h * input_tr.kernel_size + k_w) * 
                                            input_tr.input_channels + c) * 
                                            output_tr.output_channels + oc;
                                    
                                    accumulator += input_tr.input_data[in_idx] * 
                                                  input_tr.weight_data[w_idx];
                                end
                            end
                        end
                    end
                    
                    out_idx = (h * output_tr.output_width + w) * 
                             output_tr.output_channels + oc;
                    output_tr.output_data[out_idx] = accumulator;
                end
            end
        end
    endfunction
endclass
            </div>

            <h4>12.3.3 性能验证与分析</h4>
            <div class="code-block">
// 性能监控模块
module PerformanceMonitor #(
    parameter NUM_COUNTERS = 16,
    parameter COUNTER_WIDTH = 48
)(
    input wire clk,
    input wire rst_n,
    
    // 事件输入
    input wire mac_valid,
    input wire cache_hit,
    input wire cache_miss,
    input wire ddr_read_valid,
    input wire ddr_write_valid,
    input wire [3:0] active_clusters,
    
    // 控制接口
    input wire [3:0] counter_select,
    output reg [COUNTER_WIDTH-1:0] counter_value,
    
    // 性能指标输出
    output reg [31:0] ops_per_second,
    output reg [31:0] bandwidth_utilization,
    output reg [31:0] cache_hit_rate,
    output reg [31:0] power_efficiency
);
    
    // 性能计数器
    reg [COUNTER_WIDTH-1:0] perf_counters [NUM_COUNTERS-1:0];
    
    // 计数器定义
    localparam CNT_CYCLES = 0;
    localparam CNT_MAC_OPS = 1;
    localparam CNT_CACHE_HITS = 2;
    localparam CNT_CACHE_MISSES = 3;
    localparam CNT_DDR_READS = 4;
    localparam CNT_DDR_WRITES = 5;
    localparam CNT_ACTIVE_CYCLES = 6;
    
    // 更新计数器
    always @(posedge clk) begin
        if (!rst_n) begin
            for (int i = 0; i < NUM_COUNTERS; i++)
                perf_counters[i] <= 0;
        end else begin
            // 周期计数
            perf_counters[CNT_CYCLES] <= perf_counters[CNT_CYCLES] + 1;
            
            // MAC操作计数
            if (mac_valid)
                perf_counters[CNT_MAC_OPS] <= perf_counters[CNT_MAC_OPS] + 1;
            
            // 缓存统计
            if (cache_hit)
                perf_counters[CNT_CACHE_HITS] <= perf_counters[CNT_CACHE_HITS] + 1;
            if (cache_miss)
                perf_counters[CNT_CACHE_MISSES] <= perf_counters[CNT_CACHE_MISSES] + 1;
            
            // DDR访问统计
            if (ddr_read_valid)
                perf_counters[CNT_DDR_READS] <= perf_counters[CNT_DDR_READS] + 1;
            if (ddr_write_valid)
                perf_counters[CNT_DDR_WRITES] <= perf_counters[CNT_DDR_WRITES] + 1;
            
            // 活跃周期统计
            if (|active_clusters)
                perf_counters[CNT_ACTIVE_CYCLES] <= perf_counters[CNT_ACTIVE_CYCLES] + 1;
        end
    end
    
    // 性能指标计算
    reg [31:0] sample_counter;
    localparam SAMPLE_PERIOD = 1000000; // 1M cycles
    
    always @(posedge clk) begin
        if (!rst_n) begin
            sample_counter <= 0;
            ops_per_second <= 0;
            bandwidth_utilization <= 0;
            cache_hit_rate <= 0;
            power_efficiency <= 0;
        end else begin
            sample_counter <= sample_counter + 1;
            
            if (sample_counter == SAMPLE_PERIOD) begin
                sample_counter <= 0;
                
                // 计算OPS (假设1GHz时钟)
                ops_per_second <= (perf_counters[CNT_MAC_OPS] * 1000);
                
                // 带宽利用率 (假设峰值16GB/s，每次传输32B)
                bandwidth_utilization <= ((perf_counters[CNT_DDR_READS] + 
                                         perf_counters[CNT_DDR_WRITES]) * 32 * 100) / 
                                        (16 * SAMPLE_PERIOD / 1000);
                
                // 缓存命中率
                if (perf_counters[CNT_CACHE_HITS] + perf_counters[CNT_CACHE_MISSES] > 0)
                    cache_hit_rate <= (perf_counters[CNT_CACHE_HITS] * 100) / 
                                     (perf_counters[CNT_CACHE_HITS] + 
                                      perf_counters[CNT_CACHE_MISSES]);
                
                // 功耗效率 (GOPS/W，假设)
                power_efficiency <= ops_per_second / 5000; // 假设5W功耗
                
                // 重置统计计数器
                for (int i = 1; i < NUM_COUNTERS; i++)
                    perf_counters[i] <= 0;
            end
        end
    end
    
    // 读取计数器
    always @(*) begin
        counter_value = perf_counters[counter_select];
    end
endmodule

// 功能覆盖率收集
class npu_coverage extends uvm_subscriber#(npu_transaction);
    `uvm_component_utils(npu_coverage)
    
    // 覆盖率组
    covergroup operation_cg;
        // 操作类型覆盖
        op_type_cp: coverpoint trans.op_type {
            bins conv = {npu_transaction::CONV};
            bins fc = {npu_transaction::FC};
            bins pool = {npu_transaction::POOL};
            bins act = {npu_transaction::ACTIVATION};
        }
        
        // 卷积核大小覆盖
        kernel_size_cp: coverpoint trans.kernel_size {
            bins small = {1};
            bins medium = {3};
            bins large = {5, 7};
        }
        
        // 通道数覆盖
        channels_cp: coverpoint trans.input_channels {
            bins low = {[16:63]};
            bins medium = {[64:255]};
            bins high = {[256:512]};
        }
        
        // 交叉覆盖
        op_kernel_cross: cross op_type_cp, kernel_size_cp {
            ignore_bins invalid = binsof(op_type_cp.fc) || 
                                 binsof(op_type_cp.pool);
        }
    endgroup
    
    // 性能覆盖
    covergroup performance_cg;
        // MAC利用率
        mac_utilization_cp: coverpoint get_mac_utilization() {
            bins low = {[0:25]};
            bins medium = {[26:75]};
            bins high = {[76:100]};
        }
        
        // 内存带宽利用率
        memory_bandwidth_cp: coverpoint get_memory_bandwidth() {
            bins low = {[0:30]};
            bins medium = {[31:70]};
            bins high = {[71:100]};
        }
    endgroup
    
    npu_transaction trans;
    
    function new(string name = "npu_coverage", uvm_component parent = null);
        super.new(name, parent);
        operation_cg = new();
        performance_cg = new();
    endfunction
    
    function void write(npu_transaction t);
        trans = t;
        operation_cg.sample();
        performance_cg.sample();
    endfunction
    
    function int get_mac_utilization();
        // 从DUT获取MAC利用率
        return 80; // 示例值
    endfunction
    
    function int get_memory_bandwidth();
        // 从DUT获取内存带宽利用率
        return 65; // 示例值
    endfunction
endclass
            </div>

            <div class="exercise">
                <h4>练习 4：验证方案设计</h4>
                <p>设计一个完整的NPU验证方案，包括：</p>
                <ol>
                    <li>针对Transformer模型的专用测试序列</li>
                    <li>压力测试场景，验证极限性能</li>
                    <li>功耗验证环境，确保满足TDP要求</li>
                </ol>
                
                <button class="toggle-answer">显示答案</button>
                <div class="answer">
                    <div class="code-block">
// Transformer测试序列
class transformer_test_sequence extends uvm_sequence#(npu_transaction);
    `uvm_object_utils(transformer_test_sequence)
    
    // Transformer参数
    int seq_length = 512;
    int hidden_dim = 768;
    int num_heads = 12;
    int batch_size = 1;
    
    function new(string name = "transformer_test_sequence");
        super.new(name);
    endfunction
    
    task body();
        // 生成自注意力测试
        generate_self_attention_test();
        
        // 生成前馈网络测试
        generate_ffn_test();
        
        // 生成完整Transformer层测试
        generate_full_transformer_test();
    endtask
    
    task generate_self_attention_test();
        npu_transaction tr;
        
        // Q, K, V矩阵乘法
        repeat(3) begin
            tr = npu_transaction::type_id::create("tr");
            start_item(tr);
            
            assert(tr.randomize() with {
                op_type == npu_transaction::FC;
                input_height == seq_length;
                input_width == hidden_dim;
                input_channels == 1;
                output_height == seq_length;
                output_width == hidden_dim;
                output_channels == 1;
            });
            
            finish_item(tr);
        end
        
        // QK^T矩阵乘法
        tr = npu_transaction::type_id::create("tr");
        start_item(tr);
        
        assert(tr.randomize() with {
            op_type == npu_transaction::FC;
            input_height == seq_length;
            input_width == hidden_dim / num_heads;
            output_height == seq_length;
            output_width == seq_length;
        });
        
        finish_item(tr);
        
        // Softmax (使用activation操作)
        tr = npu_transaction::type_id::create("tr");
        start_item(tr);
        
        assert(tr.randomize() with {
            op_type == npu_transaction::ACTIVATION;
            input_height == seq_length;
            input_width == seq_length;
        });
        
        finish_item(tr);
    endtask
    
    task generate_ffn_test();
        npu_transaction tr;
        
        // 第一个线性层 (扩展维度)
        tr = npu_transaction::type_id::create("tr");
        start_item(tr);
        
        assert(tr.randomize() with {
            op_type == npu_transaction::FC;
            input_width == hidden_dim;
            output_width == hidden_dim * 4;
        });
        
        finish_item(tr);
        
        // GELU激活
        tr = npu_transaction::type_id::create("tr");
        start_item(tr);
        
        assert(tr.randomize() with {
            op_type == npu_transaction::ACTIVATION;
            input_width == hidden_dim * 4;
        });
        
        finish_item(tr);
        
        // 第二个线性层 (压缩维度)
        tr = npu_transaction::type_id::create("tr");
        start_item(tr);
        
        assert(tr.randomize() with {
            op_type == npu_transaction::FC;
            input_width == hidden_dim * 4;
            output_width == hidden_dim;
        });
        
        finish_item(tr);
    endtask
endclass

// 压力测试环境
class stress_test extends uvm_test;
    `uvm_component_utils(stress_test)
    
    npu_env env;
    
    function new(string name = "stress_test", uvm_component parent = null);
        super.new(name, parent);
    endfunction
    
    function void build_phase(uvm_phase phase);
        super.build_phase(phase);
        env = npu_env::type_id::create("env", this);
    endfunction
    
    task run_phase(uvm_phase phase);
        stress_sequence seq;
        
        phase.raise_objection(this);
        
        // 运行压力测试序列
        seq = stress_sequence::type_id::create("seq");
        seq.start(env.input_agent.sequencer);
        
        // 等待所有事务完成
        #100000ns;
        
        phase.drop_objection(this);
    endtask
endclass

// 压力测试序列
class stress_sequence extends uvm_sequence#(npu_transaction);
    `uvm_object_utils(stress_sequence)
    
    function new(string name = "stress_sequence");
        super.new(name);
    endfunction
    
    task body();
        npu_transaction tr;
        
        // 并发生成多个大规模计算任务
        fork
            // 线程1: 大尺寸卷积
            begin
                repeat(50) begin
                    tr = npu_transaction::type_id::create("tr1");
                    start_item(tr);
                    assert(tr.randomize() with {
                        op_type == npu_transaction::CONV;
                        input_height == 224;
                        input_width == 224;
                        input_channels == 256;
                        output_channels == 512;
                        kernel_size == 3;
                    });
                    finish_item(tr);
                end
            end
            
            // 线程2: 大规模全连接
            begin
                repeat(30) begin
                    tr = npu_transaction::type_id::create("tr2");
                    start_item(tr);
                    assert(tr.randomize() with {
                        op_type == npu_transaction::FC;
                        input_width == 4096;
                        output_width == 4096;
                    });
                    finish_item(tr);
                end
            end
            
            // 线程3: 混合操作
            begin
                repeat(100) begin
                    tr = npu_transaction::type_id::create("tr3");
                    start_item(tr);
                    assert(tr.randomize());
                    finish_item(tr);
                end
            end
        join
    endtask
endclass

// 功耗验证模块
module PowerVerification #(
    parameter VOLTAGE_LEVELS = 8,
    parameter FREQ_LEVELS = 8
)(
    input wire clk,
    input wire rst_n,
    
    // DUT功耗相关信号
    input wire [2:0] voltage_level,
    input wire [2:0] frequency_level,
    input wire [3:0] active_clusters,
    input wire [15:0] mac_activity,
    input wire [15:0] memory_activity,
    
    // 功耗测量
    output reg [31:0] instant_power_mw,
    output reg [31:0] average_power_mw,
    output reg [31:0] peak_power_mw,
    output reg tdp_violation
);
    
    // 功耗查找表 (mW)
    reg [15:0] voltage_power_table [VOLTAGE_LEVELS-1:0];
    reg [15:0] frequency_power_table [FREQ_LEVELS-1:0];
    
    // 初始化功耗表
    initial begin
        // 电压功耗表 (二次关系)
        voltage_power_table[0] = 500;   // 0.6V
        voltage_power_table[1] = 800;   // 0.65V
        voltage_power_table[2] = 1200;  // 0.7V
        voltage_power_table[3] = 1700;  // 0.75V
        voltage_power_table[4] = 2300;  // 0.8V
        voltage_power_table[5] = 3000;  // 0.85V
        voltage_power_table[6] = 3800;  // 0.9V
        voltage_power_table[7] = 4700;  // 0.95V
        
        // 频率功耗表 (线性关系)
        frequency_power_table[0] = 100;   // 250MHz
        frequency_power_table[1] = 200;   // 500MHz
        frequency_power_table[2] = 300;   // 625MHz
        frequency_power_table[3] = 400;   // 750MHz
        frequency_power_table[4] = 500;   // 875MHz
        frequency_power_table[5] = 600;   // 1000MHz
        frequency_power_table[6] = 700;   // 1125MHz
        frequency_power_table[7] = 800;   // 1250MHz
    end
    
    // 计算瞬时功耗
    reg [31:0] static_power, dynamic_power;
    reg [31:0] compute_power, memory_power;
    
    always @(posedge clk) begin
        if (!rst_n) begin
            instant_power_mw <= 0;
            static_power <= 0;
            dynamic_power <= 0;
        end else begin
            // 静态功耗
            static_power = voltage_power_table[voltage_level] * active_clusters / 4;
            
            // 动态功耗
            compute_power = (mac_activity * frequency_power_table[frequency_level]) >> 8;
            memory_power = (memory_activity * voltage_power_table[voltage_level]) >> 10;
            dynamic_power = compute_power + memory_power;
            
            // 总功耗
            instant_power_mw <= static_power + dynamic_power;
        end
    end
    
    // 计算平均功耗
    reg [39:0] power_accumulator;
    reg [31:0] sample_count;
    
    always @(posedge clk) begin
        if (!rst_n) begin
            power_accumulator <= 0;
            sample_count <= 0;
            average_power_mw <= 0;
            peak_power_mw <= 0;
        end else begin
            power_accumulator <= power_accumulator + instant_power_mw;
            sample_count <= sample_count + 1;
            
            // 每1000个周期更新平均值
            if (sample_count[9:0] == 0) begin
                average_power_mw <= power_accumulator / 1000;
                power_accumulator <= 0;
            end
            
            // 更新峰值
            if (instant_power_mw > peak_power_mw) begin
                peak_power_mw <= instant_power_mw;
            end
        end
    end
    
    // TDP违规检测
    localparam TDP_LIMIT_MW = 5000; // 5W TDP
    
    always @(posedge clk) begin
        if (!rst_n) begin
            tdp_violation <= 0;
        end else begin
            tdp_violation <= (average_power_mw > TDP_LIMIT_MW);
        end
    end
    
    // 断言检查
    // synthesis translate_off
    property tdp_check;
        @(posedge clk) disable iff (!rst_n)
        average_power_mw <= TDP_LIMIT_MW;
    endproperty
    
    assert property(tdp_check) else
        $error("TDP violation: average power %0d mW exceeds limit %0d mW", 
               average_power_mw, TDP_LIMIT_MW);
    
    property power_state_transition;
        @(posedge clk) disable iff (!rst_n)
        ($changed(voltage_level) || $changed(frequency_level)) |-> 
        ##[1:100] $stable(instant_power_mw);
    endproperty
    
    assert property(power_state_transition) else
        $error("Power state transition not stable");
    // synthesis translate_on
endmodule
                    </div>
                    <p><strong>解析：</strong></p>
                    <ul>
                        <li>Transformer测试序列覆盖了自注意力、前馈网络等关键操作</li>
                        <li>压力测试通过并发执行多种大规模计算任务，验证NPU极限性能</li>
                        <li>功耗验证模块实时监测瞬时功耗、平均功耗和峰值功耗</li>
                        <li>包含TDP违规检测和功耗状态转换的断言检查</li>
                        <li>通过查找表模拟不同电压频率下的功耗特性</li>
                    </ul>
                </div>
            </div>

            <h3>12.4 综合与后端实现</h3>
            
            <p>本节将介绍NPU的逻辑综合、物理设计和后端实现流程。</p>

            <h4>12.4.1 逻辑综合</h4>
            <div class="code-block">
# 改进的Design Compiler综合脚本 - 更接近工业实践
# npu_synthesis_enhanced.tcl

# 设置库路径和工艺库
set TECH_NODE "16nm"
set search_path ". /tools/libraries/$TECH_NODE ./rtl ./include"
set target_library "${TECH_NODE}_hvt.db ${TECH_NODE}_svt.db ${TECH_NODE}_lvt.db"
set link_library "* $target_library"
set symbol_library "${TECH_NODE}.sdb"

# 设置TLU+文件用于精确的RC提取
set_tlu_plus_files -max_tluplus /tools/libraries/$TECH_NODE/tluplus/maxTLU+ \
                   -min_tluplus /tools/libraries/$TECH_NODE/tluplus/minTLU+ \
                   -tech2itf_map /tools/libraries/$TECH_NODE/tech2itf.map

# 读取设计文件
set RTL_LIST {
    ./rtl/npu_top.v
    ./rtl/compute_cluster.v
    ./rtl/pe_array.v
    ./rtl/memory_system.v
    ./rtl/noc_router.v
    ./rtl/sparse_accelerator.v
    ./rtl/power_management.v
}

analyze -format verilog $RTL_LIST
elaborate EdgeNPU_Top -parameters "NUM_CLUSTERS=4,MACS_PER_CLUSTER=512"
current_design EdgeNPU_Top
link

# 检查设计一致性
check_design -summary
report_design > reports/design_check.rpt

# ===========================================
# 时序约束 - 多模式多角(MMMC)
# ===========================================

# 主时钟定义
create_clock -period 1.0 -name sys_clk [get_ports clk]
create_clock -period 0.8 -name noc_clk [get_ports noc_clk]

# 时钟不确定性 - 考虑抖动和偏移
set_clock_uncertainty -setup 0.05 [get_clocks sys_clk]
set_clock_uncertainty -hold 0.03 [get_clocks sys_clk]
set_clock_transition 0.08 [get_clocks sys_clk]

# 虚拟时钟用于DFT
create_clock -period 10.0 -name test_clk [get_ports test_clk]

# 输入输出延迟 - 基于系统级时序预算
# 输入延迟 = Tco(上游芯片) + Tpcb(板级走线) + Tmargin
set INPUT_DELAY_MAX 0.3
set INPUT_DELAY_MIN 0.1
set_input_delay -clock sys_clk -max $INPUT_DELAY_MAX [remove_from_collection [all_inputs] [get_ports {clk rst_n}]]
set_input_delay -clock sys_clk -min $INPUT_DELAY_MIN [remove_from_collection [all_inputs] [get_ports {clk rst_n}]]

# 输出延迟 = Tsu(下游芯片) + Tpcb + Tmargin  
set OUTPUT_DELAY_MAX 0.25
set OUTPUT_DELAY_MIN 0.05
set_output_delay -clock sys_clk -max $OUTPUT_DELAY_MAX [all_outputs]
set_output_delay -clock sys_clk -min $OUTPUT_DELAY_MIN [all_outputs]

# 异步路径和多周期路径
set_false_path -from [get_clocks sys_clk] -to [get_clocks noc_clk]
set_false_path -from [get_clocks noc_clk] -to [get_clocks sys_clk]
set_false_path -from [get_ports rst_n] -to [all_registers]

# MAC阵列的多周期路径
set_multicycle_path -setup 2 -from [get_pins mac_array/*/mult_reg*] -to [get_pins mac_array/*/acc_reg*]
set_multicycle_path -hold 1 -from [get_pins mac_array/*/mult_reg*] -to [get_pins mac_array/*/acc_reg*]

# 设置面积和功耗约束
set_max_area 25000000  # 25mm²
set_max_dynamic_power 3.0  # 3W动态功耗
set_max_leakage_power 0.5  # 0.5W泄漏功耗

# 多阈值电压优化
set_multi_vth_constraint -lvth_percentage 10 \
                        -hvth_percentage 60

# 时钟门控插入
set_clock_gating_style -sequential_cell latch \
                      -positive_edge_logic {and} \
                      -negative_edge_logic {or} \
                      -control_point before \
                      -control_signal scan_enable

insert_clock_gating

# 设置优化策略
set_optimize_registers true
set_boundary_optimization true
set compile_ultra_ungroup_dw false

# ===========================================
# 综合策略和优化
# ===========================================

# 启用高级优化选项
set_app_var compile_enable_register_merging true
set_app_var compile_seqmap_enable_output_inversion true
set_app_var placer_channel_detect_mode true

# 时序驱动综合配置
set_app_var compile_timing_high_effort true
set_app_var psynopt_area_recovery_high_effort true

# 开始综合 - 分阶段进行
echo "========== Starting Synthesis =========="
date

# 第一阶段：高级综合
compile_ultra -no_autoungroup -no_boundary_optimization

# 第二阶段：寄存器优化
optimize_registers -print_critical_loop

# 第三阶段：增量优化
compile_ultra -incremental -scan

# ===========================================
# DFT插入
# ===========================================

# 设置DFT配置
set_dft_configuration -scan_style muxed_scan \
                     -test_mode_port test_mode \
                     -scan_enable_port scan_enable

# 定义扫描链
set_scan_configuration -chain_count 16 \
                      -clock_mixing mix_clocks \
                      -add_lockup true \
                      -test_mode test_mode

# 插入DFT结构
insert_dft

# ===========================================
# 最终优化和报告
# ===========================================

# 最终时序优化
optimize_netlist -area

# 生成详细报告
echo "========== Generating Reports =========="

# 时序报告
report_timing -delay_type max -nworst 1 -max_paths 100 -sort_by group > reports/setup_timing.rpt
report_timing -delay_type min -nworst 1 -max_paths 100 -sort_by group > reports/hold_timing.rpt
report_clock -skew -attribute > reports/clock_report.rpt

# 面积和功耗报告  
report_area -hierarchy -physical > reports/area_physical.rpt
report_power -analysis_effort high -verbose > reports/power_analysis.rpt
report_saif > reports/switching_activity.rpt

# 约束违例报告
report_constraint -all_violators -verbose > reports/all_violations.rpt
report_timing -loops > reports/timing_loops.rpt

# QoR报告
report_qor > reports/qor_summary.rpt

# DFT报告
report_dft > reports/dft_summary.rpt
report_scan_chain > reports/scan_chains.rpt

# ===========================================
# 输出文件
# ===========================================

# 保存设计
write_file -format ddc -hierarchy -output results/npu_top.ddc

# 输出网表
change_names -rules verilog -hierarchy
write_file -format verilog -hierarchy -output netlists/npu_top_synth.v

# 输出约束
write_sdc -nosplit constraints/npu_top_final.sdc

# 输出延迟文件
write_sdf delays/npu_top_max.sdf -context verilog
write_sdf delays/npu_top_min.sdf -context verilog -min_view

# 输出形式验证文件
set_svf -off

date
echo "========== Synthesis Complete =========="
            </div>

            <h4>12.4.2 物理设计</h4>
            <div class="code-block">
# 改进的Innovus物理设计脚本 - 多模式多角(MMMC)和迭代优化
# npu_physical_design_enhanced.tcl

# ===========================================
# MMMC设置
# ===========================================

# 定义工艺角
create_library_set -name SS_125C -timing {/tools/libs/16nm/ss_125c.lib} \
                   -si {/tools/libs/16nm/ss_125c.cdb}
create_library_set -name TT_25C -timing {/tools/libs/16nm/tt_25c.lib} \
                   -si {/tools/libs/16nm/tt_25c.cdb}  
create_library_set -name FF_M40C -timing {/tools/libs/16nm/ff_m40c.lib} \
                   -si {/tools/libs/16nm/ff_m40c.cdb}

# 定义RC角
create_rc_corner -name RC_worst -cap_table /tools/tech/16nm/capTbl_worst \
                 -T 125 -preRoute_res 1.2 -preRoute_cap 1.2 \
                 -postRoute_res 1.2 -postRoute_cap 1.2
create_rc_corner -name RC_typ -cap_table /tools/tech/16nm/capTbl_typ \
                 -T 25 -preRoute_res 1 -preRoute_cap 1 \
                 -postRoute_res 1 -postRoute_cap 1
create_rc_corner -name RC_best -cap_table /tools/tech/16nm/capTbl_best \
                 -T -40 -preRoute_res 0.8 -preRoute_cap 0.8 \
                 -postRoute_res 0.8 -postRoute_cap 0.8

# 定义延迟角
create_delay_corner -name DC_max -library_set SS_125C -rc_corner RC_worst
create_delay_corner -name DC_typ -library_set TT_25C -rc_corner RC_typ  
create_delay_corner -name DC_min -library_set FF_M40C -rc_corner RC_best

# 定义约束模式
create_constraint_mode -name FUNC -sdc_files {./constraints/npu_func.sdc}
create_constraint_mode -name TEST -sdc_files {./constraints/npu_test.sdc}

# 定义分析视图
create_analysis_view -name av_func_max -constraint_mode FUNC -delay_corner DC_max
create_analysis_view -name av_func_typ -constraint_mode FUNC -delay_corner DC_typ
create_analysis_view -name av_func_min -constraint_mode FUNC -delay_corner DC_min
create_analysis_view -name av_test_max -constraint_mode TEST -delay_corner DC_max

set_analysis_view -setup {av_func_max av_test_max} -hold {av_func_min}

# ===========================================
# 设计初始化
# ===========================================

# 读取设计
init_design -netlist ./netlists/npu_top_synth.v \
           -top EdgeNPU_Top \
           -lef {/tools/tech/16nm/tech.lef /tools/libs/16nm/cells.lef} \
           -mmmc_file ./scripts/mmmc.tcl \
           -powerNet {VDD} \
           -groundNet {VSS}

# 全局变量设置
setDesignMode -process 16
setUsefulSkew true
setOptMode -usefulSkew true -preserveAllSequential false
setNanoRouteMode -routeInsertAntennaDiode true -routeAntennaCellName ANTENNA

# ===========================================
# Floorplan规划
# ===========================================

# 计算芯片尺寸 - 基于利用率和面积估算
set CORE_UTILIZATION 0.7
set CORE_ASPECT_RATIO 1.0
set CORE_MARGIN 10

floorPlan -site core_site -r $CORE_ASPECT_RATIO $CORE_UTILIZATION \
          $CORE_MARGIN $CORE_MARGIN $CORE_MARGIN $CORE_MARGIN

# 创建电压域
createVoltageArea -name CORE_PD -coordinate {500 500 4500 4500} \
                  -powerDomain PD_CORE -netNames {VDD VSS}
createVoltageArea -name AON_PD -coordinate {100 100 500 4900} \
                  -powerDomain PD_AON -netNames {VDDAON VSSAON}

# SRAM宏单元的自动化布局
# 定义宏单元列表
set sram_macros [get_cells -hierarchical -filter "ref_name=~SRAM*"]

# 创建Macro放置组 - 确保对齐和间距
createMacroArray -macros $sram_macros \
                 -rows 2 -cols 2 \
                 -xSpace 100 -ySpace 100 \
                 -site core_site

# 为SRAM创建框区和Halo
foreach macro $sram_macros {
    createHaloFromPin -allBlock -topleft 20 20 -bottomright 20 20
    createRouteBlk -layer {M1 M2 M3} -box [getObjBBox $macro] -exceptPGNet
}

# 计算簇的分区规划
set cluster_width 800
set cluster_height 800
set cluster_spacing 50

for {set i 0} {$i < 4} {incr i} {
    set x [expr 1000 + $i * ($cluster_width + $cluster_spacing)]
    set y 1000
    
    createRegion cluster_${i}_region $x $y \
                 [expr $x + $cluster_width] [expr $y + $cluster_height]
    
    assignInstToRegion [get_cells compute_cluster_${i}/*] cluster_${i}_region
    
    # 为每个簇设置密度约束
    setPlaceMode -region cluster_${i}_region -density 0.85
}

# IO规划
loadIoFile ./scripts/io_assignment.io

# ===========================================
# 电源规划 - 考虑功耗密度和IR Drop
# ===========================================

# 计算电源需求
set POWER_BUDGET 5.0 ;# 5W TDP
set VDD_VOLTAGE 0.8  ;# 0.8V
set CURRENT_TOTAL [expr $POWER_BUDGET / $VDD_VOLTAGE]
set IR_DROP_TARGET 0.05 ;# 5% IR drop

# 全局电源网格创建
# 电源环 - 顶层金属
addRing -nets {VDD VSS} -type core_rings \
        -layer {top M9 bottom M9 left M10 right M10} \
        -width {top 30 bottom 30 left 30 right 30} \
        -spacing {top 10 bottom 10 left 10 right 10} \
        -offset {top 5 bottom 5 left 5 right 5} \
        -center 1

# 分层电源条带规划
# M10 - 主要水平电源条带
addStripe -nets {VDD VSS} -layer M10 -direction horizontal \
          -width 20 -spacing 10 -set_to_set_distance 200 \
          -start_offset 100 -stop_offset 100 \
          -extend_to design_boundary

# M9 - 主要垂直电源条带  
addStripe -nets {VDD VSS} -layer M9 -direction vertical \
          -width 20 -spacing 10 -set_to_set_distance 200 \
          -start_offset 100 -stop_offset 100 \
          -extend_to design_boundary

# M8 - 次级水平电源条带
addStripe -nets {VDD VSS} -layer M8 -direction horizontal \
          -width 10 -spacing 5 -set_to_set_distance 100 \
          -start_offset 50 -stop_offset 50 \
          -extend_to design_boundary

# 针对高功耗区域的加密电源网格
# MAC阵列区域 - 需要更密集的电源网格
foreach region [get_db regions cluster_*_region] {
    selectInst [get_db $region .insts]
    
    addStripe -nets {VDD VSS} -layer M7 -direction vertical \
              -width 5 -spacing 2.5 -set_to_set_distance 25 \
              -area [get_db $region .bbox]
    
    addStripe -nets {VDD VSS} -layer M6 -direction horizontal \
              -width 5 -spacing 2.5 -set_to_set_distance 25 \
              -area [get_db $region .bbox]
}

# Via阵列优化 - 减少层间电阻
setViaGenMode -optimize_cross_via true \
              -optimize_via_on_routing_track true \
              -viarule_preference generated

# 标准单元电源轨连接
sroute -connect {blockPin padPin corePin floatingStripe} \
       -layerChangeRange {M1 M10} \
       -blockPinTarget {nearestTarget} \
       -deleteExistingRoutes \
       -allowJogging 1 \
       -crossoverViaLayerRange {M1 M10} \
       -allowLayerChange 1 \
       -nets {VDD VSS}

# 电源分析
analyzeRail -type ir
report_rail -type ir > reports/ir_drop_initial.rpt

# 标准单元电源轨
sroute -connect {blockPin padPin padRing corePin floatingStripe} \
       -layerChangeRange {M1 M10} -blockPinTarget {nearestTarget} \
       -padPinPortConnect {allPort oneGeom} -padPinTarget {nearestTarget} \
       -corePinTarget {firstAfterRowEnd} -floatingStripeTarget {blockring padring ring stripe ringpin blockpin followpin} \
       -allowJogging 1 -crossoverViaLayerRange {M1 M10} \
       -nets {VDD VSS}

# ===========================================
# 布局优化 - 迭代式
# ===========================================

# 布局前设置
setPlaceMode -reset
setPlaceMode -congEffort high \
             -timingDriven true \
             -modulePlan true \
             -clkGateAware true \
             -powerDriven true \
             -ignoreScan false \
             -reorderScan true \
             -ignoreSpare false \
             -placeIOPins false \
             -moduleAwareSpare true \
             -preserveRouting false \
             -rmAffectedRouting false \
             -checkRoute false \
             -swapEEQ false

# 设置布局密度目标
setPlaceMode -uniformDensity true -maxDensity 0.85

# 阶段1：全局布局
place_global_opt

# 拥塞分析
reportCongestion -hotSpot -overflow -includeBlockage > reports/congestion_global.rpt

# 阶段2：详细布局
setOptMode -fixCap true -fixTran true -fixFanoutLoad true
placeDesign -incremental -timingDriven

# 阶段3：布局后优化
optDesign -prePlaceOpt

# 扫描链重排
scanReorder

# ===========================================
# 时钟树综合(CTS) - 使用CCOpt
# ===========================================

# 设置CCOpt选项
set_ccopt_property buffer_cells {CKBUF_X16M CKBUF_X20M CKBUF_X24M}
set_ccopt_property inverter_cells {CKINV_X16M CKINV_X20M CKINV_X24M}
set_ccopt_property clock_gating_cells {CKLHQD_X2M CKLHQD_X4M}
set_ccopt_property target_skew 0.02
set_ccopt_property target_insertion_delay 0.3

# 创建时钟树规范
create_ccopt_clock_tree_spec -file ccopt.spec \
                             -immediate

# 设置时钟树约束
set_ccopt_property -clock_tree sys_clk routing_rule clk_rule
set_ccopt_property -clock_tree sys_clk max_fanout 32
set_ccopt_property -clock_tree sys_clk max_transition 0.08

# 执行CTS
ccopt_design -cts

# CTS后报告
report_ccopt_clock_trees -summary > reports/cts_summary.rpt
report_ccopt_skew_groups > reports/cts_skew.rpt

# ===========================================
# 后CTS优化
# ===========================================

# 修复保持时间违例
optDesign -postCTS -hold

# 有用偏移优化
setOptMode -usefulSkew true
optDesign -postCTS -setup

# 布线
setNanoRouteMode -quiet -timingEngine {}
setNanoRouteMode -quiet -routeWithTimingDriven 1
setNanoRouteMode -quiet -routeWithSiDriven 1
setNanoRouteMode -quiet -routeTopRoutingLayer 10
setNanoRouteMode -quiet -routeBottomRoutingLayer 1
setNanoRouteMode -quiet -drouteEndIteration 10
setNanoRouteMode -quiet -routeWithTimingDriven true
setNanoRouteMode -quiet -routeWithSiDriven true

routeDesign -globalDetail

# 后布线优化
optDesign -postRoute -hold

# 填充单元插入
addFiller -cell {FILL1 FILL2 FILL4 FILL8} -prefix FILLER

# DRC/LVS修复
fixVia -minCut
fixMetalFill

# SI分析和修复
setDelayCalMode -engine default -siAware true
setAnalysisMode -analysisType onChipVariation
timeDesign -postRoute -pathReports -drvReports -slackReports -numPaths 50 -prefix postRoute -outDir timingReports

# 功耗分析
report_power -outfile reports/final_power.rpt

# 输出设计
saveDesign final_design.enc
defOut -floorplan -netlist -routing npu_final.def
            </div>

            <h4>12.4.3 时序收敛与签核</h4>
            <div class="code-block">
# PrimeTime时序签核脚本
# timing_signoff.tcl

# 读取设计
read_verilog ./netlists/npu_final.v
current_design EdgeNPU_Top
link_design

# 读取寄生参数
read_parasitics -format SPEF ./spef/npu_final.spef

# 设置操作条件
set_operating_conditions -analysis_type on_chip_variation

# 定义时钟
create_clock -period 1.0 [get_ports clk]
set_clock_uncertainty -setup 0.05 [get_clocks clk]
set_clock_uncertainty -hold 0.03 [get_clocks clk]
set_clock_transition 0.08 [get_clocks clk]

# AOCV设置
set_aocvm_mode manual
read_aocvm 16nm_aocvm.table

# CPPR分析
set timing_remove_clock_reconvergence_pessimism true

# 多模式多角分析
# 定义角
create_scenario -name func_ss_125c
set_operating_conditions SS_125C
set_voltage 0.72 -object_list VDD

create_scenario -name func_ff_m40c
set_operating_conditions FF_M40C
set_voltage 0.88 -object_list VDD

# 执行时序分析
update_timing -full
report_timing -delay_type max -nworst 1 -max_paths 1000 > timing_setup.rpt
report_timing -delay_type min -nworst 1 -max_paths 1000 > timing_hold.rpt

# 时序违规分析
report_constraint -all_violators > violations.rpt

# 功耗分析
set power_enable_analysis true
set power_analysis_mode averaged

read_saif ./saif/npu_vectors.saif -strip_path testbench/dut
update_power
report_power -hierarchy > power_signoff.rpt

# ECO修复脚本生成
write_changes -format icctcl -output eco_fixes.tcl

# 时序模型生成
extract_model -output ./models/npu_timing.lib -format liberty \
              -timing -power -test

# 生成最终报告
report_design > design_summary.rpt
report_clock_timing -type summary > clock_summary.rpt
report_analysis_coverage > coverage.rpt
            </div>

            <h4>12.4.4 DFT与可测试性设计</h4>
            <div class="code-block">
// DFT控制器
module DFTController (
    input wire clk,
    input wire rst_n,
    
    // 测试模式控制
    input wire test_mode,
    input wire scan_enable,
    input wire mbist_mode,
    
    // 扫描链接口
    input wire scan_in,
    output wire scan_out,
    
    // MBIST接口
    output wire mbist_start,
    output wire mbist_done,
    output wire mbist_fail,
    
    // JTAG接口
    input wire tck,
    input wire tms,
    input wire tdi,
    output wire tdo,
    input wire trst_n
);
    
    // 扫描链配置
    localparam NUM_SCAN_CHAINS = 16;
    localparam SCAN_LENGTH = 10000;
    
    // 扫描链多路复用
    wire [NUM_SCAN_CHAINS-1:0] chain_scan_in;
    wire [NUM_SCAN_CHAINS-1:0] chain_scan_out;
    
    // 扫描链分配
    genvar i;
    generate
        for (i = 0; i < NUM_SCAN_CHAINS; i = i + 1) begin : scan_chain
            assign chain_scan_in[i] = (i == 0) ? scan_in : chain_scan_out[i-1];
        end
    endgenerate
    assign scan_out = chain_scan_out[NUM_SCAN_CHAINS-1];
    
    // MBIST控制器
    MBISTController #(
        .NUM_MEMORIES(32),
        .ADDR_WIDTH(18),
        .DATA_WIDTH(256)
    ) mbist_ctrl (
        .clk(clk),
        .rst_n(rst_n),
        .mbist_mode(mbist_mode),
        .start(mbist_start),
        .done(mbist_done),
        .fail(mbist_fail),
        // 内存接口连接
        .mem_en(),
        .mem_we(),
        .mem_addr(),
        .mem_wdata(),
        .mem_rdata()
    );
    
    // JTAG TAP控制器
    JTAGController jtag_ctrl (
        .tck(tck),
        .tms(tms),
        .tdi(tdi),
        .tdo(tdo),
        .trst_n(trst_n),
        // 内部寄存器访问
        .reg_addr(),
        .reg_data(),
        .reg_we()
    );
    
    // ATPG测试点插入
    // 提高可测试性的观察点和控制点
    reg [31:0] test_point_observe;
    reg [31:0] test_point_control;
    
    always @(posedge clk) begin
        if (test_mode) begin
            // 在测试模式下激活测试点
            test_point_observe <= internal_hard_to_observe_signals;
            internal_hard_to_control_signals <= test_point_control;
        end
    end
endmodule

// MBIST算法实现
module MBISTController #(
    parameter NUM_MEMORIES = 32,
    parameter ADDR_WIDTH = 18,
    parameter DATA_WIDTH = 256
)(
    input wire clk,
    input wire rst_n,
    input wire mbist_mode,
    input wire start,
    output reg done,
    output reg fail,
    
    // 内存接口
    output reg [NUM_MEMORIES-1:0] mem_en,
    output reg [NUM_MEMORIES-1:0] mem_we,
    output reg [ADDR_WIDTH-1:0] mem_addr,
    output reg [DATA_WIDTH-1:0] mem_wdata,
    input wire [DATA_WIDTH-1:0] mem_rdata [NUM_MEMORIES-1:0]
);
    
    // MBIST状态机
    typedef enum logic [3:0] {
        IDLE,
        MARCH_C_W0,    // March C- Write 0
        MARCH_C_R0W1,  // March C- Read 0, Write 1
        MARCH_C_R1W0,  // March C- Read 1, Write 0
        MARCH_C_R0,    // March C- Read 0
        CHECKERBOARD,  // Checkerboard测试
        ADDRESS_DECODE, // 地址解码测试
        RETENTION,     // 数据保持测试
        REPORT
    } mbist_state_t;
    
    mbist_state_t state;
    reg [7:0] current_memory;
    reg [ADDR_WIDTH-1:0] current_addr;
    reg [DATA_WIDTH-1:0] expected_data;
    reg [31:0] error_count;
    reg [7:0] failing_memory;
    reg [ADDR_WIDTH-1:0] failing_addr;
    
    // March C-算法实现
    always @(posedge clk) begin
        if (!rst_n) begin
            state <= IDLE;
            done <= 0;
            fail <= 0;
            error_count <= 0;
        end else if (mbist_mode) begin
            case (state)
                IDLE: begin
                    if (start) begin
                        state <= MARCH_C_W0;
                        current_memory <= 0;
                        current_addr <= 0;
                        error_count <= 0;
                        done <= 0;
                        fail <= 0;
                    end
                end
                
                MARCH_C_W0: begin
                    // 向所有地址写0
                    mem_en[current_memory] <= 1;
                    mem_we[current_memory] <= 1;
                    mem_addr <= current_addr;
                    mem_wdata <= {DATA_WIDTH{1'b0}};
                    
                    if (current_addr == {ADDR_WIDTH{1'b1}}) begin
                        if (current_memory == NUM_MEMORIES - 1) begin
                            state <= MARCH_C_R0W1;
                            current_memory <= 0;
                            current_addr <= 0;
                        end else begin
                            current_memory <= current_memory + 1;
                            current_addr <= 0;
                        end
                    end else begin
                        current_addr <= current_addr + 1;
                    end
                end
                
                MARCH_C_R0W1: begin
                    // 读0写1，地址递增
                    if (mem_we[current_memory]) begin
                        // 写周期
                        mem_wdata <= {DATA_WIDTH{1'b1}};
                    end else begin
                        // 读周期
                        mem_we[current_memory] <= 0;
                        expected_data <= {DATA_WIDTH{1'b0}};
                        
                        if (mem_rdata[current_memory] !== expected_data) begin
                            error_count <= error_count + 1;
                            failing_memory <= current_memory;
                            failing_addr <= current_addr;
                        end
                        
                        // 准备写1
                        mem_we[current_memory] <= 1;
                    end
                    
                    // 地址和内存推进逻辑...
                end
                
                // 其他测试模式实现...
                
                REPORT: begin
                    done <= 1;
                    fail <= (error_count > 0);
                    state <= IDLE;
                end
            endcase
        end
    end
endmodule

# DFT插入脚本
# dft_insertion.tcl

# 设置DFT配置
set_dft_configuration -scan_style muxed_scan
set_scan_configuration -chain_count 16
set_scan_configuration -clock_mixing mix_edges

# 定义测试模式
define_test_mode functional -usage scan
define_test_mode mbist -usage mbist_mode

# 扫描链插入
set_scan_path chain1 -view spec -scan_data_in scan_in_1 -scan_data_out scan_out_1
set_scan_path chain2 -view spec -scan_data_in scan_in_2 -scan_data_out scan_out_2
# ... 更多扫描链

# 插入测试结构
insert_dft

# MBIST插入
insert_mbist -memory_instances {sram_*} -algorithm march_c

# 测试点插入
set_test_point_configuration -control_points 100 -observe_points 200
insert_test_points -random

# 生成测试协议
write_test_protocol -output test_protocol.spf

# ATPG向量生成
set_atpg_options -capture_cycles 4 -patterns 10000
run_atpg -auto

# 故障覆盖率报告
report_dft -scan > reports/dft_scan.rpt
report_dft -test_coverage > reports/test_coverage.rpt
write_test -format stil -output patterns/npu_test.stil
            </div>

            <div class="exercise">
                <h4>练习 5：后端优化挑战</h4>
                <p>针对以下后端实现挑战，提出解决方案：</p>
                <ol>
                    <li>在16nm工艺下，如何优化NPU的功耗密度，避免热点？</li>
                    <li>设计一个时钟域交叉(CDC)验证方案</li>
                    <li>实现一个针对NPU特点的自定义单元库</li>
                </ol>
                
                <button class="toggle-answer">显示答案</button>
                <div class="answer">
                    <div class="code-block">
// 热点缓解设计
module ThermalManagement (
    input wire clk,
    input wire rst_n,
    
    // 温度传感器输入
    input wire [7:0] temp_sensors [15:0],
    
    // 功耗控制输出
    output reg [3:0] cluster_throttle,
    output reg [2:0] voltage_adjust,
    output reg [2:0] frequency_adjust,
    
    // 任务迁移控制
    output reg task_migration_req,
    output reg [3:0] migration_src_cluster,
    output reg [3:0] migration_dst_cluster
);
    
    // 温度阈值定义
    localparam TEMP_NORMAL = 70;    // 70°C
    localparam TEMP_WARNING = 85;   // 85°C
    localparam TEMP_CRITICAL = 95;  // 95°C
    localparam TEMP_SHUTDOWN = 105; // 105°C
    
    // 热点检测
    reg [3:0] hotspot_cluster;
    reg [7:0] max_temp;
    reg [7:0] avg_temp;
    
    always @(*) begin
        // 找出最热的簇
        max_temp = 0;
        hotspot_cluster = 0;
        avg_temp = 0;
        
        for (int i = 0; i < 16; i++) begin
            avg_temp = avg_temp + temp_sensors[i];
            if (temp_sensors[i] > max_temp) begin
                max_temp = temp_sensors[i];
                hotspot_cluster = i[3:0];
            end
        end
        avg_temp = avg_temp >> 4; // 除以16
    end
    
    // 热管理状态机
    typedef enum logic [2:0] {
        THERMAL_IDLE,
        THERMAL_MONITOR,
        THERMAL_THROTTLE,
        THERMAL_MIGRATE,
        THERMAL_EMERGENCY
    } thermal_state_t;
    
    thermal_state_t thermal_state;
    
    // 功耗密度均衡算法
    reg [7:0] power_density_map [15:0];
    reg [3:0] coolest_cluster;
    
    always @(posedge clk) begin
        if (!rst_n) begin
            thermal_state <= THERMAL_IDLE;
            cluster_throttle <= 4'b0000;
            voltage_adjust <= 3'b100;  // 标称电压
            frequency_adjust <= 3'b100; // 标称频率
            task_migration_req <= 0;
        end else begin
            case (thermal_state)
                THERMAL_IDLE: begin
                    thermal_state <= THERMAL_MONITOR;
                end
                
                THERMAL_MONITOR: begin
                    if (max_temp > TEMP_SHUTDOWN) begin
                        thermal_state <= THERMAL_EMERGENCY;
                    end else if (max_temp > TEMP_CRITICAL) begin
                        thermal_state <= THERMAL_THROTTLE;
                    end else if (max_temp > TEMP_WARNING) begin
                        // 检查是否需要任务迁移
                        if (find_coolest_cluster() < TEMP_NORMAL) begin
                            thermal_state <= THERMAL_MIGRATE;
                        end else begin
                            thermal_state <= THERMAL_THROTTLE;
                        end
                    end
                end
                
                THERMAL_THROTTLE: begin
                    // 降低热点簇的性能
                    cluster_throttle[hotspot_cluster[1:0]] <= 1;
                    
                    // 全局降频降压
                    if (voltage_adjust > 3'b001) begin
                        voltage_adjust <= voltage_adjust - 1;
                        frequency_adjust <= frequency_adjust - 1;
                    end
                    
                    thermal_state <= THERMAL_MONITOR;
                end
                
                THERMAL_MIGRATE: begin
                    // 请求任务迁移
                    task_migration_req <= 1;
                    migration_src_cluster <= hotspot_cluster;
                    migration_dst_cluster <= coolest_cluster;
                    
                    if (task_migration_ack) begin
                        task_migration_req <= 0;
                        thermal_state <= THERMAL_MONITOR;
                    end
                end
                
                THERMAL_EMERGENCY: begin
                    // 紧急关闭热点簇
                    cluster_throttle <= 4'b1111;
                    voltage_adjust <= 3'b001;  // 最低电压
                    frequency_adjust <= 3'b001; // 最低频率
                    
                    if (max_temp < TEMP_CRITICAL) begin
                        thermal_state <= THERMAL_MONITOR;
                    end
                end
            endcase
        end
    end
    
    // 功耗密度计算
    function [3:0] find_coolest_cluster;
        reg [7:0] min_temp;
        reg [3:0] coolest_idx;
        begin
            min_temp = 8'hFF;
            coolest_idx = 0;
            
            for (int i = 0; i < 16; i++) begin
                if (temp_sensors[i] < min_temp && !cluster_throttle[i[1:0]]) begin
                    min_temp = temp_sensors[i];
                    coolest_idx = i[3:0];
                end
            end
            
            find_coolest_cluster = coolest_idx;
        end
    endfunction
endmodule

// CDC验证环境
module CDCVerification (
    // 源时钟域
    input wire clk_src,
    input wire rst_src_n,
    input wire [31:0] data_src,
    input wire valid_src,
    output wire ready_src,
    
    // 目标时钟域
    input wire clk_dst,
    input wire rst_dst_n,
    output wire [31:0] data_dst,
    output wire valid_dst,
    input wire ready_dst
);
    
    // 格雷码同步器
    GrayCodeSync #(
        .WIDTH(32)
    ) gray_sync (
        .clk_src(clk_src),
        .rst_src_n(rst_src_n),
        .data_src(data_src),
        .clk_dst(clk_dst),
        .rst_dst_n(rst_dst_n),
        .data_dst(data_gray_sync)
    );
    
    // 双触发器同步器
    reg valid_sync_1, valid_sync_2;
    always @(posedge clk_dst) begin
        if (!rst_dst_n) begin
            valid_sync_1 <= 0;
            valid_sync_2 <= 0;
        end else begin
            valid_sync_1 <= valid_src;
            valid_sync_2 <= valid_sync_1;
        end
    end
    
    // 异步FIFO
    AsyncFIFO #(
        .DATA_WIDTH(32),
        .ADDR_WIDTH(4)
    ) async_fifo (
        .wr_clk(clk_src),
        .wr_rst_n(rst_src_n),
        .wr_data(data_src),
        .wr_en(valid_src),
        .wr_full(fifo_full),
        
        .rd_clk(clk_dst),
        .rd_rst_n(rst_dst_n),
        .rd_data(data_dst),
        .rd_en(ready_dst),
        .rd_empty(fifo_empty)
    );
    
    assign ready_src = !fifo_full;
    assign valid_dst = !fifo_empty;
    
    // CDC协议检查器
    // synthesis translate_off
    property cdc_handshake_check;
        @(posedge clk_src) disable iff (!rst_src_n)
        valid_src && !ready_src |=> valid_src;
    endproperty
    
    assert property(cdc_handshake_check) else
        $error("CDC: Source dropped valid during backpressure");
    
    property cdc_data_stability;
        @(posedge clk_src) disable iff (!rst_src_n)
        valid_src && !ready_src |=> $stable(data_src);
    endproperty
    
    assert property(cdc_data_stability) else
        $error("CDC: Data changed while valid was high");
    // synthesis translate_on
endmodule

// NPU专用标准单元库
module NPUCustomCells;
    
    // 高性能8位乘法器单元
    module MAC8x8_HP (
        input wire [7:0] a,
        input wire [7:0] b,
        input wire [15:0] c,
        output wire [15:0] result
    );
        // 优化的Wallace树乘法器
        wire [15:0] partial_products [7:0];
        wire [15:0] mult_result;
        
        // Booth编码减少部分积
        BoothEncoder booth_enc (
            .multiplicand(a),
            .multiplier(b),
            .partial_products(partial_products)
        );
        
        // Wallace树归约
        WallaceTree wallace (
            .partial_products(partial_products),
            .product(mult_result)
        );
        
        // 最终加法器（Kogge-Stone）
        KoggeStoneAdder #(16) final_adder (
            .a(mult_result),
            .b(c),
            .sum(result)
        );
    endmodule
    
    // 低功耗SRAM位单元
    module SRAM_BitCell_LP (
        input wire wl,      // 字线
        input wire bl,      // 位线
        input wire blb,     // 位线反
        inout wire q,       // 存储节点
        inout wire qb       // 存储节点反
    );
        // 6T SRAM单元，优化漏电
        tranif1 pass1 (q, bl, wl);
        tranif1 pass2 (qb, blb, wl);
        
        // 交叉耦合反相器，使用高阈值晶体管
        pmos #(1) p1 (q, vdd, qb);
        nmos #(1) n1 (q, gnd, qb);
        pmos #(1) p2 (qb, vdd, q);
        nmos #(1) n2 (qb, gnd, q);
    endmodule
    
    // 时钟门控单元
    module ClockGate_NPU (
        input wire clk,
        input wire enable,
        input wire scan_enable,
        output wire gated_clk
    );
        reg latch_out;
        
        // 低电平锁存器
        always @(*) begin
            if (!clk)
                latch_out <= enable || scan_enable;
        end
        
        // AND门输出
        assign gated_clk = clk && latch_out;
        
        // 保持时间检查
        // synthesis translate_off
        always @(posedge clk) begin
            assert($stable(enable)) else
                $error("Clock gate enable changed during high phase");
        end
        // synthesis translate_on
    endmodule
    
    // 优化的低延迟互连单元 - Verilog版本
    module NPU_Interconnect_Cell #(
        parameter DATA_WIDTH = 8,
        parameter SEL_WIDTH = 4,
        parameter PIPELINE_STAGES = 2
    )(
        input wire clk,
        input wire rst_n,
        input wire [DATA_WIDTH-1:0] data_in,
        input wire [SEL_WIDTH-1:0] sel,
        input wire valid_in,
        output reg [DATA_WIDTH-1:0] data_out,
        output reg valid_out
    );
        // 流水线寄存器
        reg [DATA_WIDTH-1:0] data_reg [PIPELINE_STAGES-1:0];
        reg [SEL_WIDTH-1:0] sel_reg [PIPELINE_STAGES-1:0];
        reg valid_reg [PIPELINE_STAGES-1:0];
        
        // 中间结果寄存器
        reg [DATA_WIDTH-1:0] rotated_data;
        reg [DATA_WIDTH-1:0] mux_result;
        
        // 第一级流水线：输入寄存
        always @(posedge clk or negedge rst_n) begin
            if (!rst_n) begin
                data_reg[0] <= {DATA_WIDTH{1'b0}};
                sel_reg[0] <= {SEL_WIDTH{1'b0}};
                valid_reg[0] <= 1'b0;
            end else begin
                data_reg[0] <= data_in;
                sel_reg[0] <= sel;
                valid_reg[0] <= valid_in;
            end
        end
        
        // 第二级流水线：部分选择逻辑
        always @(posedge clk or negedge rst_n) begin
            if (!rst_n) begin
                data_reg[1] <= {DATA_WIDTH{1'b0}};
                sel_reg[1] <= {SEL_WIDTH{1'b0}};
                valid_reg[1] <= 1'b0;
                rotated_data <= {DATA_WIDTH{1'b0}};
            end else if (valid_reg[0]) begin
                data_reg[1] <= data_reg[0];
                sel_reg[1] <= sel_reg[0];
                valid_reg[1] <= valid_reg[0];
                
                // 使用二级MUX树优化时序
                case (sel_reg[0][1:0])
                    2'b00: rotated_data <= data_reg[0];
                    2'b01: rotated_data <= {data_reg[0][DATA_WIDTH-2:0], data_reg[0][DATA_WIDTH-1]};
                    2'b10: rotated_data <= {data_reg[0][DATA_WIDTH-3:0], data_reg[0][DATA_WIDTH-1:DATA_WIDTH-2]};
                    2'b11: rotated_data <= {data_reg[0][DATA_WIDTH-4:0], data_reg[0][DATA_WIDTH-1:DATA_WIDTH-3]};
                endcase
            end else begin
                valid_reg[1] <= 1'b0;
            end
        end
        
        // 第三级流水线：完成选择
        always @(posedge clk or negedge rst_n) begin
            if (!rst_n) begin
                mux_result <= {DATA_WIDTH{1'b0}};
                valid_out <= 1'b0;
            end else if (valid_reg[1]) begin
                // 第二级MUX
                case (sel_reg[1][3:2])
                    2'b00: mux_result <= rotated_data;
                    2'b01: mux_result <= {rotated_data[DATA_WIDTH-5:0], rotated_data[DATA_WIDTH-1:DATA_WIDTH-4]};
                    2'b10: mux_result <= {rotated_data[DATA_WIDTH-6:0], rotated_data[DATA_WIDTH-1:DATA_WIDTH-5]};
                    2'b11: mux_result <= {rotated_data[DATA_WIDTH-7:0], rotated_data[DATA_WIDTH-1:DATA_WIDTH-6]};
                endcase
                valid_out <= valid_reg[1];
            end else begin
                valid_out <= 1'b0;
            end
        end
        
        // 输出寄存器
        always @(posedge clk or negedge rst_n) begin
            if (!rst_n) begin
                data_out <= {DATA_WIDTH{1'b0}};
            end else begin
                data_out <= mux_result;
            end
        end
        
    endmodule
endmodule
                    </div>
                    
                    <div class="code-block">
// Chisel版本对比：
import chisel3._
import chisel3.util._

class NPUInterconnectCell(dataWidth: Int = 8,
                         selWidth: Int = 4,
                         pipelineStages: Int = 2) extends Module {
  val io = IO(new Bundle {
    val dataIn = Input(UInt(dataWidth.W))
    val sel = Input(UInt(selWidth.W))
    val validIn = Input(Bool())
    val dataOut = Output(UInt(dataWidth.W))
    val validOut = Output(Bool())
  })
  
  // 流水线寄存器
  val dataReg = Reg(Vec(pipelineStages, UInt(dataWidth.W)))
  val selReg = Reg(Vec(pipelineStages, UInt(selWidth.W)))
  val validReg = RegInit(VecInit(Seq.fill(pipelineStages)(false.B)))
  
  // 第一级：输入寄存
  dataReg(0) := io.dataIn
  selReg(0) := io.sel
  validReg(0) := io.validIn
  
  // 第二级：部分旋转
  val rotatedData = RegInit(0.U(dataWidth.W))
  
  when(validReg(0)) {
    dataReg(1) := dataReg(0)
    selReg(1) := selReg(0)
    validReg(1) := validReg(0)
    
    // 一级MUX
    rotatedData := MuxCase(dataReg(0), Seq(
      (selReg(0)(1, 0) === 0.U) -> dataReg(0),
      (selReg(0)(1, 0) === 1.U) -> Cat(dataReg(0)(dataWidth-2, 0), dataReg(0)(dataWidth-1)),
      (selReg(0)(1, 0) === 2.U) -> Cat(dataReg(0)(dataWidth-3, 0), dataReg(0)(dataWidth-1, dataWidth-2)),
      (selReg(0)(1, 0) === 3.U) -> Cat(dataReg(0)(dataWidth-4, 0), dataReg(0)(dataWidth-1, dataWidth-3))
    ))
  }.otherwise {
    validReg(1) := false.B
  }
  
  // 第三级：完成选择
  val muxResult = RegInit(0.U(dataWidth.W))
  
  when(validReg(1)) {
    // 二级MUX
    muxResult := MuxCase(rotatedData, Seq(
      (selReg(1)(3, 2) === 0.U) -> rotatedData,
      (selReg(1)(3, 2) === 1.U) -> Cat(rotatedData(dataWidth-5, 0), rotatedData(dataWidth-1, dataWidth-4)),
      (selReg(1)(3, 2) === 2.U) -> Cat(rotatedData(dataWidth-6, 0), rotatedData(dataWidth-1, dataWidth-5)),
      (selReg(1)(3, 2) === 3.U) -> Cat(rotatedData(dataWidth-7, 0), rotatedData(dataWidth-1, dataWidth-6))
    ))
  }
  
  io.dataOut := RegNext(muxResult)
  io.validOut := RegNext(validReg(1))
}
                    </div>
                    <p><strong>解析：</strong></p>
                    <ul>
                        <li>热管理模块通过温度传感器监控各簇温度，支持降频、任务迁移等策略</li>
                        <li>CDC验证包含格雷码同步、异步FIFO和协议检查断言</li>
                        <li>自定义单元库包含优化的MAC单元、低功耗SRAM、时钟门控等</li>
                        <li>采用Wallace树和Kogge-Stone加法器优化关键路径</li>
                        <li>通过高阈值晶体管和时钟门控降低静态功耗</li>
                    </ul>
                </div>
            </div>

            <h3>综合项目练习</h3>
            
            <div class="exercise">
                <h4>项目：完整NPU设计实现</h4>
                <p>基于本章所学内容，完成一个面向边缘AI的NPU完整设计，要求：</p>
                <ol>
                    <li>支持ResNet-50和BERT-Base模型的高效推理</li>
                    <li>峰值算力8 TOPS，功耗不超过5W</li>
                    <li>支持INT8/INT4量化和稀疏计算</li>
                    <li>包含完整的验证环境和后端实现</li>
                    <li>达到90%以上的测试覆盖率</li>
                </ol>
                
                <p>项目交付物：</p>
                <ul>
                    <li>架构设计文档</li>
                    <li>RTL代码（Verilog/SystemVerilog）</li>
                    <li>UVM验证环境</li>
                    <li>综合脚本和时序报告</li>
                    <li>物理设计数据（DEF/GDS）</li>
                    <li>功耗和性能分析报告</li>
                </ul>
                
                <button class="toggle-answer">显示答案</button>
                <div class="answer">
                    <p><strong>项目实施指南：</strong></p>
                    
                    <h5>1. 架构设计阶段（第1-2周）</h5>
                    <div class="code-block">
// 顶层架构参数定义
module EdgeAI_NPU_Config;
    // 系统配置
    parameter NUM_CLUSTERS = 4;
    parameter MACS_PER_CLUSTER = 512;  // 总计2048 MACs
    parameter SYSTOLIC_ARRAY_SIZE = 16;  // 16x16 systolic array per cluster
    
    // 存储层次
    parameter L1_BUFFER_KB = 64;      // 每个cluster的L1缓存
    parameter L2_BUFFER_MB = 4;       // 共享L2缓存
    parameter DRAM_BANDWIDTH_GB = 32; // 外部内存带宽
    
    // 数据精度支持
    parameter SUPPORT_INT8 = 1;
    parameter SUPPORT_INT4 = 1;
    parameter SUPPORT_MIXED_PRECISION = 1;
    
    // 稀疏计算
    parameter SPARSITY_SUPPORT = 1;
    parameter MIN_SPARSITY_GRANULARITY = 4; // 4x4块稀疏
    
    // 功耗目标
    parameter TARGET_FREQ_MHZ = 1000;
    parameter TARGET_POWER_W = 5.0;
endmodule

// 性能建模框架
class PerformanceModel {
    // ResNet-50性能估算
    float estimate_resnet50_fps() {
        float total_ops = 3.8e9;  // ResNet-50 FLOPs
        float mac_efficiency = 0.85;  // 考虑数据传输开销
        float sparsity_speedup = 1.3; // 30%稀疏度带来的加速
        
        float peak_ops = NUM_CLUSTERS * MACS_PER_CLUSTER * 2 * TARGET_FREQ_MHZ * 1e6;
        float effective_ops = peak_ops * mac_efficiency * sparsity_speedup;
        
        return effective_ops / total_ops;
    }
    
    // BERT-Base性能估算
    float estimate_bert_latency(int seq_length) {
        float attention_ops = 12 * seq_length * seq_length * 768 * 4;
        float ffn_ops = 12 * seq_length * 768 * 3072 * 2;
        float total_ops = attention_ops + ffn_ops;
        
        // 考虑内存带宽限制
        float compute_time = total_ops / (8e12 * 0.7); // 70%利用率
        float memory_time = estimate_memory_bound_time();
        
        return max(compute_time, memory_time);
    }
}
</div>
                    
                    <h5>2. RTL设计实现（第3-6周）</h5>
                    <div class="code-block">
// 计算簇顶层设计
module ComputeCluster #(
    parameter CLUSTER_ID = 0,
    parameter NUM_PES = 256,
    parameter ARRAY_SIZE = 16,
    parameter WEIGHT_BUFFER_KB = 32,
    parameter ACTIVATION_BUFFER_KB = 32
)(
    input wire clk,
    input wire rst_n,
    
    // NoC接口
    input wire [511:0] noc_data_in,
    input wire noc_valid_in,
    output wire noc_ready_out,
    
    output wire [511:0] noc_data_out,
    output wire noc_valid_out,
    input wire noc_ready_in,
    
    // 控制接口
    input wire [31:0] config_data,
    input wire config_valid,
    input wire start_compute,
    output wire compute_done,
    
    // 性能监控
    output wire [63:0] perf_counters [7:0]
);
    
    // 内部模块实例化
    // Weight Stationary Systolic Array
    SystolicArray_WS #(
        .ARRAY_SIZE(ARRAY_SIZE),
        .DATA_WIDTH(8),
        .SUPPORT_INT4(1)
    ) systolic_array (
        .clk(clk),
        .rst_n(rst_n),
        .weights(weight_data),
        .activations(activation_data),
        .partial_sums_in(ps_in),
        .partial_sums_out(ps_out),
        .config(array_config),
        .compute_enable(array_enable)
    );
    
    // 稀疏计算加速器
    SparseAccelerator #(
        .NUM_ENGINES(16),
        .BLOCK_SIZE(4)
    ) sparse_acc (
        .clk(clk),
        .rst_n(rst_n),
        .sparse_weights(sparse_weight_data),
        .sparse_indices(sparse_indices),
        .dense_activations(activation_data),
        .results(sparse_results),
        .sparse_enable(sparse_mode)
    );
    
    // 本地存储管理
    LocalMemorySystem #(
        .WEIGHT_BUFFER_SIZE(WEIGHT_BUFFER_KB * 1024),
        .ACTIVATION_BUFFER_SIZE(ACTIVATION_BUFFER_KB * 1024),
        .NUM_BANKS(16)
    ) local_mem (
        .clk(clk),
        .rst_n(rst_n),
        .weight_addr(weight_addr),
        .weight_data(weight_data),
        .weight_we(weight_we),
        .activation_addr(activation_addr),
        .activation_data(activation_data),
        .activation_we(activation_we)
    );
    
    // DMA控制器
    DMAController dma_ctrl (
        .clk(clk),
        .rst_n(rst_n),
        .noc_interface(noc_if),
        .local_mem_interface(mem_if),
        .transfer_config(dma_config),
        .start_transfer(dma_start),
        .transfer_done(dma_done)
    );
    
    // 流水线控制器
    PipelineController pipeline_ctrl (
        .clk(clk),
        .rst_n(rst_n),
        .layer_config(layer_config),
        .start_layer(start_compute),
        .layer_done(compute_done),
        .array_control(array_ctrl),
        .memory_control(mem_ctrl),
        .dma_control(dma_ctrl)
    );
endmodule
</div>
                    
                    <h5>3. 验证环境开发（第4-7周，与RTL并行）</h5>
                    <div class="code-block">
// 增强的UVM验证环境
class npu_test_base extends uvm_test;
    `uvm_component_utils(npu_test_base)
    
    npu_env env;
    npu_config cfg;
    
    // 测试场景配置
    rand int num_layers;
    rand layer_config_t layer_configs[];
    rand bit enable_sparsity;
    rand bit enable_mixed_precision;
    
    constraint test_constraints {
        num_layers inside {[1:50]};  // ResNet-50级别
        layer_configs.size() == num_layers;
        foreach(layer_configs[i]) {
            layer_configs[i].layer_type inside {CONV, FC, ATTENTION};
            if (layer_configs[i].layer_type == CONV) {
                layer_configs[i].kernel_size inside {1, 3, 5, 7};
                layer_configs[i].stride inside {1, 2};
            }
        }
    }
    
    function void build_phase(uvm_phase phase);
        super.build_phase(phase);
        
        // 创建配置
        cfg = npu_config::type_id::create("cfg");
        cfg.num_clusters = 4;
        cfg.enable_coverage = 1;
        cfg.enable_scoreboard = 1;
        cfg.enable_performance_monitor = 1;
        
        // 设置配置
        uvm_config_db#(npu_config)::set(this, "env", "cfg", cfg);
        
        // 创建环境
        env = npu_env::type_id::create("env", this);
    endfunction
    
    task run_phase(uvm_phase phase);
        npu_sequence seq;
        
        phase.raise_objection(this);
        
        // 运行测试序列
        seq = npu_sequence::type_id::create("seq");
        seq.num_transactions = 1000;
        seq.randomize();
        seq.start(env.agent.sequencer);
        
        // 等待DUT空闲
        wait_for_idle();
        
        // 检查结果
        check_test_results();
        
        phase.drop_objection(this);
    endtask
endclass

// ResNet-50专项测试
class resnet50_test extends npu_test_base;
    `uvm_component_utils(resnet50_test)
    
    function void build_phase(uvm_phase phase);
        super.build_phase(phase);
        
        // 配置ResNet-50层
        num_layers = 50;
        layer_configs = new[num_layers];
        
        // Conv1: 7x7, stride 2
        layer_configs[0].layer_type = CONV;
        layer_configs[0].in_channels = 3;
        layer_configs[0].out_channels = 64;
        layer_configs[0].kernel_size = 7;
        layer_configs[0].stride = 2;
        
        // 后续层配置...
    endfunction
    
    task run_phase(uvm_phase phase);
        resnet50_sequence seq;
        real start_time, end_time;
        
        phase.raise_objection(this);
        
        // 记录开始时间
        start_time = $realtime;
        
        // 运行ResNet-50推理
        seq = resnet50_sequence::type_id::create("seq");
        seq.batch_size = 1;
        seq.image_size = 224;
        seq.start(env.agent.sequencer);
        
        // 记录结束时间
        end_time = $realtime;
        
        // 性能分析
        `uvm_info("PERF", $sformatf("ResNet-50 inference time: %0.2f ms", 
                  (end_time - start_time) / 1000000), UVM_LOW)
        
        // 验证精度
        check_inference_accuracy();
        
        phase.drop_objection(this);
    endtask
endclass
</div>
                    
                    <h5>4. 综合与时序优化（第8-9周）</h5>
                    <div class="code-block">
# 增强的综合脚本 - 包含功耗优化
# power_aware_synthesis.tcl

# 读取UPF文件
read_power_intent -upf ./upf/npu_power_intent.upf

# 设置功耗优化选项
set_dynamic_optimization true
set_leakage_optimization true

# 多Vt策略
set_attribute [get_lib_cells */LVT] dont_use false
set_attribute [get_lib_cells */RVT] dont_use false  
set_attribute [get_lib_cells */HVT] dont_use false

# 设置功耗约束
set_max_total_power 5.0 W
set_max_leakage_power 0.5 W

# 关键路径约束
group_path -name CLK2Q -from [all_registers] -to [all_outputs]
group_path -name REG2REG -from [all_registers] -to [all_registers]
group_path -name IN2REG -from [all_inputs] -to [all_registers]

set_critical_range 0.1 [current_design]

# 运行综合
compile_ultra -no_autoungroup -no_boundary_optimization

# 增量优化
optimize_registers -print_critical_loop
optimize_netlist -area

# 功耗优化
optimize_power -effort high -include {leakage dynamic}

# 生成报告
report_power -hierarchy > reports/power_report.txt
report_timing -max_paths 100 -nworst 10 > reports/timing_report.txt
report_area -hierarchy > reports/area_report.txt
report_qor > reports/qor_report.txt

# 检查设计规则
check_design -summary
check_timing -include {no_clock no_input_delay}
</div>
                    
                    <h5>5. 物理设计实现（第10-12周）</h5>
                    <div class="code-block">
# 自动化物理设计流程
# auto_pnr_flow.tcl

# 定义检查点和迭代优化
proc run_pnr_with_checkpoints {} {
    global design_name
    
    # Floorplan阶段
    source scripts/floorplan.tcl
    timeDesign -prePlace -prefix ${design_name}_preplace
    
    if {[get_metric timing.setup.wns] < -0.1} {
        # Floorplan优化
        optimize_floorplan_for_timing
    }
    
    # Placement阶段
    placeDesign -concurrent_optimization
    timeDesign -preCTS -prefix ${design_name}_prects
    
    # 检查placement质量
    if {[check_placement_quality] == "FAIL"} {
        # 重新placement，调整参数
        deleteAllGlobalNets
        placeDesign -congestion_effort high -timing_driven
    }
    
    # CTS阶段
    create_ccopt_clock_tree_spec
    ccopt_design -cts
    timeDesign -postCTS -prefix ${design_name}_postcts
    
    # Route阶段
    routeDesign -globalDetail
    
    # 迭代优化
    set iteration 0
    while {[get_metric timing.setup.wns] < 0 && $iteration < 5} {
        optDesign -postRoute -setup -drv
        incr iteration
    }
    
    # 最终优化
    optDesign -postRoute -hold
    
    # 添加填充单元
    addFiller -cell {FILL1 FILL2 FILL4 FILL8} -prefix FILLER
    
    # 金属填充
    addMetalFill -layer {1 2 3 4 5 6} -minDensity 0.20 -maxDensity 0.80
}

# 功耗网格优化
proc optimize_power_grid {} {
    # 分析IR drop
    analyze_power_grid -net {VDD VSS}
    
    # 识别热点
    set hotspots [identify_ir_hotspots -threshold 50mV]
    
    foreach hotspot $hotspots {
        # 局部加强电源网格
        add_power_stripes -area $hotspot -layer M6 -width 2.0
    }
    
    # 重新分析
    analyze_power_grid -net {VDD VSS} -report power_grid_final.rpt
}
</div>
                    
                    <h5>6. 测试与部署（第13-14周）</h5>
                    <div class="code-block">
// 芯片测试程序
class NPU_TestProgram {
    // 结构测试
    void run_structural_tests() {
        // 扫描链测试
        scan_test_controller.run_atpg_patterns();
        
        // MBIST测试
        mbist_controller.test_all_memories();
        
        // 边界扫描测试
        jtag_controller.run_boundary_scan();
    }
    
    // 功能测试
    void run_functional_tests() {
        // 基本功能测试
        test_single_mac_operation();
        test_systolic_array_operation();
        test_memory_subsystem();
        test_noc_communication();
        
        // 复杂场景测试
        test_conv2d_layers();
        test_fully_connected_layers();
        test_attention_mechanism();
        
        // 边界条件测试
        test_maximum_throughput();
        test_minimum_latency();
        test_power_modes();
    }
    
    // 性能验证
    void validate_performance() {
        PerformanceResults results;
        
        // ResNet-50测试
        results.resnet50_fps = benchmark_resnet50();
        assert(results.resnet50_fps >= 30);  // 目标: 30 FPS
        
        // BERT测试
        results.bert_latency = benchmark_bert_base();
        assert(results.bert_latency <= 10);  // 目标: <10ms
        
        // 功耗测试
        results.avg_power = measure_average_power();
        assert(results.avg_power <= 5.0);  // 目标: ≤5W
        
        generate_performance_report(results);
    }
}

// 软件SDK示例
class EdgeNPU_SDK {
    // 模型部署API
    NPUModel* deploy_model(const string& model_path) {
        // 加载模型
        auto model = load_onnx_model(model_path);
        
        // 图优化
        optimize_graph(model);
        
        // 量化
        quantize_model(model, QuantizationMode::INT8);
        
        // 编译到NPU指令
        auto compiled = compile_for_npu(model);
        
        return compiled;
    }
    
    // 推理API
    Tensor inference(NPUModel* model, const Tensor& input) {
        // 分配设备内存
        auto d_input = allocate_device_memory(input.size());
        auto d_output = allocate_device_memory(model->output_size());
        
        // 数据传输
        copy_to_device(input, d_input);
        
        // 执行推理
        npu_runtime.execute(model, d_input, d_output);
        
        // 获取结果
        Tensor output;
        copy_from_device(d_output, output);
        
        return output;
    }
};
</div>
                    
                    <h5>7. 项目交付与文档（第14周）</h5>
                    <ul>
                        <li><strong>设计文档</strong>：
                            <ul>
                                <li>架构规格说明书（包含性能模型和功耗分析）</li>
                                <li>微架构设计文档（详细的模块划分和接口定义）</li>
                                <li>验证计划和覆盖率报告</li>
                                <li>PPA（功耗、性能、面积）分析报告</li>
                            </ul>
                        </li>
                        <li><strong>代码交付</strong>：
                            <ul>
                                <li>RTL源码（含详细注释）</li>
                                <li>UVM验证环境</li>
                                <li>综合和物理设计脚本</li>
                                <li>SDK和编译器</li>
                            </ul>
                        </li>
                        <li><strong>测试报告</strong>：
                            <ul>
                                <li>功能测试报告（覆盖率>95%）</li>
                                <li>性能基准测试结果</li>
                                <li>功耗测试数据</li>
                                <li>可靠性分析</li>
                            </ul>
                        </li>
                    </ul>
                    
                    <h5>关键设计决策与权衡：</h5>
                    <ol>
                        <li><strong>数据流选择</strong>：Weight Stationary在边缘场景下能最大化权重重用，减少外部内存访问</li>
                        <li><strong>精度策略</strong>：INT8为主，INT4用于非关键层，混合精度提升灵活性</li>
                        <li><strong>稀疏支持</strong>：4x4块稀疏在硬件复杂度和加速效果间取得平衡</li>
                        <li><strong>内存层次</strong>：两级缓存设计，L1靠近计算单元，L2实现跨簇共享</li>
                        <li><strong>功耗优化</strong>：多电压域、动态时钟门控、细粒度电源管理</li>
                        <li><strong>可测试性</strong>：完整的DFT设计，支持量产测试需求</li>
                    </ol>
                </div>
            </div>
        </section>
        
        <section id="conclusion">
            <h2>总结与展望</h2>
            
            <h3>NPU技术发展趋势</h3>
            <p>通过本教程的学习，我们深入了解了NPU从架构设计到芯片实现的完整流程。展望未来，NPU技术将在以下几个方向持续演进：</p>
            
            <div class="info-box">
                <h4>1. 架构创新</h4>
                <ul>
                    <li><strong>存算一体化</strong>：将计算单元与存储深度融合，突破冯·诺依曼瓶颈</li>
                    <li><strong>可重构计算</strong>：支持动态架构调整，适应不同AI工作负载</li>
                    <li><strong>近数据计算</strong>：在数据产生和存储的地方进行计算，减少数据移动</li>
                    <li><strong>量子-经典混合</strong>：结合量子计算优势，加速特定AI算法</li>
                </ul>
            </div>
            
            <div class="info-box">
                <h4>2. 工艺与封装</h4>
                <ul>
                    <li><strong>3D堆叠技术</strong>：垂直集成计算和存储，大幅提升带宽密度</li>
                    <li><strong>Chiplet生态</strong>：标准化接口推动模块化设计和快速创新</li>
                    <li><strong>先进节点</strong>：2nm及以下工艺带来的机遇与挑战</li>
                    <li><strong>新型器件</strong>：忆阻器、自旋电子器件等新型计算元件</li>
                </ul>
            </div>
            
            <div class="info-box">
                <h4>3. 软件与算法协同</h4>
                <ul>
                    <li><strong>编译器优化</strong>：更智能的图优化和硬件映射策略</li>
                    <li><strong>自动化设计</strong>：AI驱动的芯片设计和优化</li>
                    <li><strong>软硬件协同设计</strong>：算法与架构的深度融合</li>
                    <li><strong>开源生态</strong>：推动NPU技术的普及和创新</li>
                </ul>
            </div>
            
            <h3>学习资源推荐</h3>
            
            <h4>📚 推荐书籍</h4>
            <ul>
                <li>《Efficient Processing of Deep Neural Networks》- Vivienne Sze等</li>
                <li>《Computer Architecture: A Quantitative Approach》- Hennessy & Patterson</li>
                <li>《Deep Learning》- Ian Goodfellow等</li>
                <li>《CMOS VLSI Design》- Weste & Harris</li>
            </ul>
            
            <h4>📝 学术论文</h4>
            <ul>
                <li>EIE: Efficient Inference Engine on Compressed Deep Neural Network</li>
                <li>In-Datacenter Performance Analysis of a Tensor Processing Unit</li>
                <li>Eyeriss: An Energy-Efficient Reconfigurable Accelerator</li>
                <li>DaDianNao: A Machine-Learning Supercomputer</li>
            </ul>
            
            <h4>🛠 开源项目</h4>
            <ul>
                <li><strong>NVDLA</strong>：NVIDIA深度学习加速器开源项目</li>
                <li><strong>VTA</strong>：Versatile Tensor Accelerator (TVM项目)</li>
                <li><strong>Gemmini</strong>：Berkeley的开源DNN加速器生成器</li>
                <li><strong>SCALE-Sim</strong>：Systolic阵列性能模拟器</li>
            </ul>
            
            <h4>💻 在线课程</h4>
            <ul>
                <li>MIT 6.888: Hardware Architecture for Deep Learning</li>
                <li>Stanford CS217: Hardware Accelerators for Machine Learning</li>
                <li>Cornell ECE5745: Complex Digital ASIC Design</li>
                <li>ETH Zurich: Digital Design and Computer Architecture</li>
            </ul>
            
            <h4>🔧 开发工具</h4>
            <div class="code-block">
# EDA工具
- Synopsys: Design Compiler, IC Compiler II, PrimeTime
- Cadence: Genus, Innovus, Tempus
- Mentor: Calibre, Tessent

# 开源工具
- Verilator: 开源Verilog仿真器
- OpenROAD: 开源数字芯片设计流程
- Yosys: 开源综合工具
- Magic: 开源版图工具

# AI框架
- TensorFlow Lite: 边缘AI推理框架
- ONNX Runtime: 跨平台推理引擎
- Apache TVM: 深度学习编译器
- MLIR: 多级中间表示
            </div>
            
            <h3>职业发展建议</h3>
            
            <p>NPU设计是一个交叉学科领域，需要掌握多方面的知识和技能：</p>
            
            <div class="exercise">
                <h4>技能发展路线图</h4>
                <ol>
                    <li><strong>基础阶段（0-2年）</strong>
                        <ul>
                            <li>掌握数字电路设计基础</li>
                            <li>熟悉Verilog/SystemVerilog</li>
                            <li>理解计算机体系结构</li>
                            <li>学习深度学习基础知识</li>
                        </ul>
                    </li>
                    <li><strong>进阶阶段（2-5年）</strong>
                        <ul>
                            <li>深入理解NPU架构设计</li>
                            <li>掌握UVM验证方法学</li>
                            <li>参与完整芯片项目</li>
                            <li>了解后端设计流程</li>
                        </ul>
                    </li>
                    <li><strong>专家阶段（5年+）</strong>
                        <ul>
                            <li>领导架构定义和创新</li>
                            <li>优化PPA（功耗、性能、面积）</li>
                            <li>推动软硬件协同设计</li>
                            <li>参与行业标准制定</li>
                        </ul>
                    </li>
                </ol>
            </div>
            
            <h3>结语</h3>
            
            <p>NPU作为AI时代的核心基础设施，正在深刻改变着计算范式。从云端数据中心到边缘设备，从自动驾驶到智能手机，NPU无处不在。希望通过本教程的学习，你能够：</p>
            
            <ul>
                <li>建立对NPU完整的认知体系</li>
                <li>掌握NPU设计的核心技术</li>
                <li>具备独立设计NPU的能力</li>
                <li>为AI芯片创新贡献力量</li>
            </ul>
            
            <p class="highlight-box">
                记住，芯片设计既是一门科学，也是一门艺术。它需要严谨的工程思维，也需要创新的设计理念。在追求极致性能的同时，不要忘记考虑实际应用的需求。祝你在NPU设计的道路上不断进步，创造出改变世界的AI芯片！
            </p>
            
            <div class="info-box" style="text-align: center; margin-top: 40px;">
                <p><strong>感谢阅读本教程！</strong></p>
                <p>如有问题或建议，欢迎通过GitHub Issues反馈</p>
                <p>让我们一起推动AI芯片技术的发展！</p>
            </div>
        </section>
        
    </div>

    <script>
        // JavaScript for collapsible answers
        function toggleAnswer(button) {
            const answer = button.nextElementSibling;
            if (answer.classList.contains('show')) {
                answer.classList.remove('show');
                button.textContent = '显示答案';
            } else {
                answer.classList.add('show');
                button.textContent = '隐藏答案';
            }
        }

        // Add event listeners to all toggle buttons
        document.addEventListener('DOMContentLoaded', function() {
            const toggleButtons = document.querySelectorAll('.toggle-answer');
            toggleButtons.forEach(button => {
                button.addEventListener('click', function() {
                    toggleAnswer(this);
                });
            });
        });

        // Smooth scrolling for navigation links
        document.querySelectorAll('nav a').forEach(anchor => {
            anchor.addEventListener('click', function(e) {
                e.preventDefault();
                const target = document.querySelector(this.getAttribute('href'));
                if (target) {
                    target.scrollIntoView({
                        behavior: 'smooth',
                        block: 'start'
                    });
                }
            });
        });
    </script>
</body>
</html>