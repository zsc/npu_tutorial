## 第3章：NPU系统架构

在前两章中，我们了解了NPU的基本概念和神经网络计算的基础知识。从本章开始，我们将深入探讨NPU的架构设计。在众多NPU架构中，**脉动阵列（Systolic Array）**凭借其规则的结构、高效的数据复用和优秀的可扩展性，成为了现代NPU设计的一种流行选择。Google TPU、Tesla FSD芯片等知名NPU都采用了脉动阵列作为其计算核心。

因此，在接下来的几章中，我们将以脉动阵列架构为核心展开讨论。本章将介绍NPU的整体系统架构，第4章将深入脉动阵列的计算核心设计，第5章将探讨如何为脉动阵列设计高效的存储系统。需要强调的是，虽然我们以脉动阵列为例，但**许多设计原则和优化思想同样适用于其他架构**，如Groq的数据流架构（Dataflow Architecture）。两种架构都追求规则的数据流动、高效的并行计算和最小化的内存访问开销，只是在具体实现方式上有所不同。通过深入理解脉动阵列，我们可以掌握NPU设计的核心思想——如何通过规则的数据流动模式实现高效的并行计算。

### 3.1 整体架构设计

#### 3.1.1 NPU系统组成

现代NPU系统通常包含以下核心组件：

NPU系统架构层次：
┌─────────────────────────────────────────┐
│          Host Interface (PCIe/AXI)       │
├─────────────────────────────────────────┤
│         Command Processor & Scheduler    │
├─────────────────────────────────────────┤
│  ┌─────────┐  ┌─────────┐  ┌─────────┐ │
│  │ Compute │  │ Memory  │  │  DMA    │ │
│  │ Cluster │  │ System  │  │ Engine  │ │
│  └─────────┘  └─────────┘  └─────────┘ │
├─────────────────────────────────────────┤
│         On-chip Interconnect (NoC)      │
├─────────────────────────────────────────┤
│         External Memory Interface        │
└─────────────────────────────────────────┘
