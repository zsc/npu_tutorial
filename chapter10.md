# ç¬¬10ç« ï¼šè½¯ä»¶æ ˆä¸ç¼–è¯‘ä¼˜åŒ–

## <a name="101"></a>10.1 NPUè½¯ä»¶æ ˆæ¶æ„

### 10.1.1 è½¯ä»¶æ ˆçš„é‡è¦æ€§

NPUçš„ç¡¬ä»¶æ€§èƒ½å†å¼ºï¼Œä¹Ÿéœ€è¦ä¼˜ç§€çš„è½¯ä»¶æ ˆæ‰èƒ½å……åˆ†å‘æŒ¥ã€‚è½¯ä»¶æ ˆæ˜¯è¿æ¥ä¸Šå±‚AIæ¡†æ¶å’Œåº•å±‚ç¡¬ä»¶çš„æ¡¥æ¢ï¼Œå®ƒå†³å®šäº†ç¡¬ä»¶æ€§èƒ½èƒ½å¤Ÿè¢«å‘æŒ¥åˆ°ä»€ä¹ˆç¨‹åº¦ã€‚

"ç¡¬ä»¶å®šä¹‰äº†æ€§èƒ½çš„ä¸Šé™ï¼Œè€Œè½¯ä»¶å†³å®šäº†èƒ½è¾¾åˆ°è¿™ä¸ªä¸Šé™çš„å¤šå°‘ã€‚"è¿™å¥è¯å®Œç¾è¯ é‡Šäº†NPUè½¯ä»¶æ ˆçš„é‡è¦æ€§ã€‚Googleçš„ç ”ç©¶è¡¨æ˜ï¼Œé€šè¿‡ä¼˜åŒ–TPUçš„ç¼–è¯‘å™¨ï¼Œä»–ä»¬åœ¨ä¸æ”¹å˜ç¡¬ä»¶çš„æƒ…å†µä¸‹å°†æŸäº›å·¥ä½œè´Ÿè½½çš„æ€§èƒ½æå‡äº†2.8å€ã€‚

### 10.1.2 åˆ†å±‚æ¶æ„è®¾è®¡

ç°ä»£NPUè½¯ä»¶æ ˆé‡‡ç”¨åˆ†å±‚æ¶æ„ï¼Œæ¯ä¸€å±‚ä¸“æ³¨äºç‰¹å®šçš„ä¼˜åŒ–ç›®æ ‡ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      AI Frameworks (TensorFlow/PyTorch) â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         Graph Representation            â”‚
â”‚         (ONNX, TorchScript)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         High-Level IR (HIR)            â”‚
â”‚     (Graph Optimization Pass)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         Mid-Level IR (MIR)             â”‚
â”‚    (Operator Fusion, Tiling)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         Low-Level IR (LIR)             â”‚
â”‚   (Memory Allocation, Scheduling)      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚      Code Generation Backend           â”‚
â”‚    (NPU Instruction Generation)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         Runtime Library                â”‚
â”‚    (Execution, Memory Management)      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         NPU Hardware                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 10.1.3 å…³é”®ç»„ä»¶åŠŸèƒ½

æ¯ä¸ªè½¯ä»¶æ ˆç»„ä»¶éƒ½æ‰¿æ‹…ç€ç‰¹å®šçš„èŒè´£ï¼š

> **ğŸ“‹ è½¯ä»¶æ ˆæ ¸å¿ƒç»„ä»¶**
>
> - **å‰ç«¯è§£æå™¨ï¼š** æ”¯æŒå¤šç§æ¡†æ¶æ¨¡å‹æ ¼å¼ï¼Œè½¬æ¢ä¸ºç»Ÿä¸€çš„å†…éƒ¨è¡¨ç¤º
> - **å›¾ä¼˜åŒ–å™¨ï¼š** æ‰§è¡Œç®—å­èåˆã€å¸¸é‡æŠ˜å ã€æ­»ä»£ç æ¶ˆé™¤ç­‰ä¼˜åŒ–
> - **é‡åŒ–å·¥å…·ï¼š** æ”¯æŒè®­ç»ƒåé‡åŒ–å’Œé‡åŒ–æ„ŸçŸ¥è®­ç»ƒ
> - **å†…å­˜åˆ†é…å™¨ï¼š** ä¼˜åŒ–ç‰‡ä¸Šå†…å­˜ä½¿ç”¨ï¼Œæœ€å°åŒ–æ•°æ®æ¬ç§»
> - **æŒ‡ä»¤è°ƒåº¦å™¨ï¼š** ç”Ÿæˆé«˜æ•ˆçš„æŒ‡ä»¤åºåˆ—ï¼Œæœ€å¤§åŒ–ç¡¬ä»¶åˆ©ç”¨ç‡
> - **è¿è¡Œæ—¶ç³»ç»Ÿï¼š** ç®¡ç†ä»»åŠ¡æ‰§è¡Œã€å†…å­˜ç®¡ç†ã€å¤šæ ¸è°ƒåº¦

### 10.1.4 ä¸­é—´è¡¨ç¤ºï¼ˆIRï¼‰è®¾è®¡

ä¸­é—´è¡¨ç¤ºæ˜¯ç°ä»£AIç¼–è¯‘å™¨çš„çµé­‚ï¼ŒNPUç¼–è¯‘å™¨é€šå¸¸é‡‡ç”¨å¤šå±‚IRè®¾è®¡ï¼š

```cpp
// å¤šå±‚IRæ¶æ„ç¤ºä¾‹
// 1. Graph IR - é«˜å±‚è®¡ç®—å›¾è¡¨ç¤º
class GraphIR {
    // èŠ‚ç‚¹è¡¨ç¤ºç®—å­
    struct Node {
        string op_type;        // "Conv2D", "MatMul", "Add", etc.
        vector<Tensor> inputs;
        vector<Tensor> outputs;
        map<string, Attribute> attrs;  // kernel_size, stride, etc.
    };
    
    // è¾¹è¡¨ç¤ºæ•°æ®æµ
    struct Edge {
        Node* src;
        Node* dst;
        int src_output_idx;
        int dst_input_idx;
    };
};

// 2. Tensor IR - å¼ é‡ç¨‹åºè¡¨ç¤º
class TensorIR {
    // ç±»ä¼¼TVMçš„å¼ é‡è¡¨è¾¾å¼
    Tensor conv2d_tir(Tensor input, Tensor weight) {
        // å®šä¹‰è®¡ç®—ç»´åº¦
        auto N = input.shape[0];
        auto H = input.shape[1];
        auto W = input.shape[2];
        auto C = input.shape[3];
        auto K = weight.shape[0];
        
        // å®šä¹‰è¾“å‡ºå¼ é‡
        Tensor output({N, H-2, W-2, K});
        
        // å®šä¹‰è®¡ç®—
        output(n, h, w, k) = sum(
            input(n, h+rh, w+rw, c) * weight(k, rh, rw, c),
            {rh, rw, c}  // reduction axes
        );
        
        return output;
    }
};

// 3. Hardware IR - ç¡¬ä»¶æŒ‡ä»¤è¡¨ç¤º
class HardwareIR {
    enum OpCode {
        LOAD_WEIGHT,    // åŠ è½½æƒé‡åˆ°ç‰‡ä¸Š
        LOAD_ACT,       // åŠ è½½æ¿€æ´»å€¼
        COMPUTE_MAC,    // MACé˜µåˆ—è®¡ç®—
        STORE_RESULT,   // å­˜å‚¨ç»“æœ
        SYNC            // åŒæ­¥æŒ‡ä»¤
    };
    
    struct Instruction {
        OpCode opcode;
        vector<int> operands;
        map<string, int> config;  // ç¡¬ä»¶é…ç½®å‚æ•°
    };
};
```

> **ğŸ’¡ ä¸ºä»€ä¹ˆéœ€è¦å¤šå±‚IRï¼Ÿ**
>
> - **Graph IRï¼š** é€‚åˆåšå›¾çº§åˆ«ä¼˜åŒ–ï¼Œå¦‚ç®—å­èåˆã€å¸¸é‡æŠ˜å ã€æ­»ä»£ç æ¶ˆé™¤
> - **Tensor IRï¼š** é€‚åˆåšç®—å­å†…éƒ¨ä¼˜åŒ–ï¼Œå¦‚å¾ªç¯å˜æ¢ã€å‘é‡åŒ–ã€å†…å­˜è®¿é—®ä¼˜åŒ–
> - **Hardware IRï¼š** è´´è¿‘ç¡¬ä»¶ï¼Œä¾¿äºæŒ‡ä»¤è°ƒåº¦ã€å¯„å­˜å™¨åˆ†é…ã€ç¡¬ä»¶ç‰¹æ€§åˆ©ç”¨
>
> ç°ä»£æ¡†æ¶å¦‚**MLIRï¼ˆMulti-Level IRï¼‰**æä¾›äº†æ„å»ºå¤šå±‚IRçš„åŸºç¡€è®¾æ–½ï¼Œè¢«Googleã€Intelç­‰å…¬å¸å¹¿æ³›é‡‡ç”¨ã€‚

## <a name="102"></a>10.2 è®¡ç®—å›¾ä¼˜åŒ–

### 10.2.1 ç®—å­èåˆæŠ€æœ¯

ç®—å­èåˆæ˜¯æå‡NPUæ€§èƒ½æœ€æœ‰æ•ˆçš„ä¼˜åŒ–æŠ€æœ¯ä¹‹ä¸€ï¼Œé€šè¿‡å°†å¤šä¸ªç‹¬ç«‹çš„è®¡ç®—æ“ä½œåˆå¹¶ä¸ºä¸€ä¸ªå¤åˆæ“ä½œï¼Œå‡å°‘å†…å­˜è®¿é—®æ¬¡æ•°ã€‚

```python
# ç®—å­èåˆç¤ºä¾‹ï¼šConv + BN + ReLUèåˆ
# åŸå§‹è®¡ç®—å›¾
class OriginalGraph:
    def forward(self, x):
        # å·ç§¯æ“ä½œ
        conv_out = self.conv2d(x)  # éœ€è¦å†™å›å†…å­˜
        # æ‰¹å½’ä¸€åŒ–
        bn_out = self.batch_norm(conv_out)  # éœ€è¦è¯»å†™å†…å­˜
        # æ¿€æ´»å‡½æ•°
        relu_out = self.relu(bn_out)  # éœ€è¦è¯»å†™å†…å­˜
        return relu_out

# èåˆåçš„è®¡ç®—å›¾
class FusedGraph:
    def forward(self, x):
        # èåˆçš„ç®—å­ï¼Œä¸€æ¬¡å†…å­˜è¯»å†™å®Œæˆä¸‰ä¸ªæ“ä½œ
        return self.conv_bn_relu_fused(x)

# èåˆå®ç°ï¼ˆä¼ªä»£ç ï¼‰
def conv_bn_relu_fused(input, conv_weight, bn_params):
    # åœ¨NPUå†…éƒ¨å®Œæˆæ‰€æœ‰è®¡ç®—
    for (oc in output_channels):
        for (oh, ow in output_positions):
            # å·ç§¯è®¡ç®—
            acc = 0
            for (ic, kh, kw in kernel):
                acc += input[ic][oh+kh][ow+kw] * conv_weight[oc][ic][kh][kw]
            
            # BNè®¡ç®—ï¼ˆåœ¨çº¿èåˆï¼‰
            acc = (acc - bn_mean[oc]) / sqrt(bn_var[oc] + eps)
            acc = acc * bn_scale[oc] + bn_bias[oc]
            
            # ReLUè®¡ç®—
            output[oc][oh][ow] = max(0, acc)
    
    return output
```

### 10.2.2 ç®—å­èåˆçš„ç±»å‹ä¸é™åˆ¶

```cpp
// ä¸åŒç±»å‹çš„ç®—å­èåˆæ¨¡å¼
// 1. å‚ç›´èåˆï¼ˆVertical Fusionï¼‰- å°†element-wiseæ“ä½œèå…¥è®¡ç®—å¯†é›†å‹æ“ä½œ
class VerticalFusion {
    // èåˆå‰ï¼šConv -> Add(bias) -> BN -> ReLU
    void unfused_forward(Tensor input) {
        Tensor conv_out = conv2d(input, weight);      // å†™å›DDR
        Tensor bias_out = add(conv_out, bias);        // è¯»å†™DDR
        Tensor bn_out = batch_norm(bias_out);         // è¯»å†™DDR
        Tensor relu_out = relu(bn_out);               // è¯»å†™DDR
        return relu_out;
    }
    
    // èåˆåï¼šæ‰€æœ‰æ“ä½œåœ¨ç‰‡ä¸Šå®Œæˆ
    void fused_forward(Tensor input) {
        // ä¸€æ¬¡æ€§å®Œæˆæ‰€æœ‰è®¡ç®—ï¼Œåªå†™æœ€ç»ˆç»“æœ
        return conv_bias_bn_relu_fused(input, weight, bias, bn_params);
    }
};

// 2. æ°´å¹³èåˆï¼ˆHorizontal Fusionï¼‰- åˆå¹¶ç›¸åŒç±»å‹çš„å¹¶è¡Œæ“ä½œ
class HorizontalFusion {
    // èåˆå‰ï¼šå¤šä¸ªå°çŸ©é˜µä¹˜æ³•åˆ†åˆ«æ‰§è¡Œ
    void unfused_multi_matmul(vector<Tensor> A_list, vector<Tensor> B_list) {
        vector<Tensor> results;
        for (int i = 0; i < A_list.size(); i++) {
            results.push_back(matmul(A_list[i], B_list[i]));
        }
        return results;
    }
    
    // èåˆåï¼šæ‰“åŒ…æˆä¸€ä¸ªå¤§çŸ©é˜µä¹˜æ³•
    void fused_batched_matmul(vector<Tensor> A_list, vector<Tensor> B_list) {
        Tensor A_packed = pack_tensors(A_list);  // [batch, M, K]
        Tensor B_packed = pack_tensors(B_list);  // [batch, K, N]
        Tensor C_packed = batched_matmul(A_packed, B_packed);
        return unpack_tensors(C_packed);
    }
};

// 3. èåˆçš„é™åˆ¶æ¡ä»¶
bool can_fuse(Node* node1, Node* node2) {
    // æ£€æŸ¥æ•°æ®ä¾èµ–
    if (has_external_dependency(node1, node2)) {
        return false;  // ä¸­é—´ç»“æœè¢«å…¶ä»–èŠ‚ç‚¹ä½¿ç”¨
    }
    
    // æ£€æŸ¥å†…å­˜é™åˆ¶
    size_t fused_memory = estimate_memory(node1) + estimate_memory(node2);
    if (fused_memory > on_chip_memory_size) {
        return false;  // èåˆåè¶…å‡ºç‰‡ä¸Šå†…å­˜
    }
    
    // æ£€æŸ¥ç¡¬ä»¶æ”¯æŒ
    if (!hardware_supports_fused_op(node1->op_type, node2->op_type)) {
        return false;  // ç¡¬ä»¶æ²¡æœ‰å¯¹åº”çš„èåˆæŒ‡ä»¤
    }
    
    // æ£€æŸ¥æ•°å€¼ç¨³å®šæ€§
    if (fusion_affects_numerical_stability(node1, node2)) {
        return false;  // èåˆå¯èƒ½å¯¼è‡´ç²¾åº¦æŸå¤±
    }
    
    return true;
}
```

> **âš ï¸ ç®—å­èåˆçš„æƒè¡¡**
>
> **æ”¶ç›Šï¼š** å‡å°‘å†…å­˜è®¿é—®ã€é™ä½å¸¦å®½å‹åŠ›ã€å‡å°‘kernelå¯åŠ¨å¼€é”€
>
> **ä»£ä»·ï¼š** å¢åŠ ä»£ç å¤æ‚åº¦ã€å¯èƒ½é™ä½ç¡¬ä»¶åˆ©ç”¨ç‡ã€é™åˆ¶å¹¶è¡Œåº¦
>
> **åŸåˆ™ï¼š** ä¼˜å…ˆèåˆå†…å­˜å—é™ï¼ˆmemory-boundï¼‰çš„æ“ä½œï¼Œè®¡ç®—å—é™ï¼ˆcompute-boundï¼‰çš„æ“ä½œè°¨æ…èåˆ

## <a name="103"></a>10.3 å†…å­˜ä¼˜åŒ–æŠ€æœ¯

### 10.3.1 å†…å­˜åˆ†é…ç­–ç•¥

NPUçš„ç‰‡ä¸Šå†…å­˜é€šå¸¸æœ‰é™ä¸”æ˜‚è´µï¼Œé«˜æ•ˆçš„å†…å­˜ç®¡ç†æ˜¯æ€§èƒ½ä¼˜åŒ–çš„å…³é”®ã€‚

```cpp
class NPUMemoryAllocator {
    // å†…å­˜æ± ç®¡ç†
    struct MemoryPool {
        size_t total_size;
        size_t free_size;
        std::vector<MemoryBlock> free_blocks;
        std::map<void*, MemoryBlock> allocated_blocks;
    };
    
    // ä¸åŒç±»å‹çš„å†…å­˜æ± 
    MemoryPool weight_memory;      // æƒé‡ä¸“ç”¨å†…å­˜
    MemoryPool activation_memory;  // æ¿€æ´»å€¼å†…å­˜
    MemoryPool scratch_memory;     // ä¸´æ—¶è®¡ç®—å†…å­˜
    
public:
    // æ™ºèƒ½å†…å­˜åˆ†é…
    void* allocate(size_t size, MemoryType type, AlignmentRequirement align) {
        // é€‰æ‹©åˆé€‚çš„å†…å­˜æ± 
        MemoryPool& pool = select_pool(type);
        
        // å°è¯•å¤ç”¨ç°æœ‰å†…å­˜å—
        auto reusable_block = find_reusable_block(pool, size, align);
        if (reusable_block != nullptr) {
            return reusable_block;
        }
        
        // åˆ†é…æ–°å†…å­˜å—
        return allocate_new_block(pool, size, align);
    }
    
    // å†…å­˜ç”Ÿå‘½å‘¨æœŸåˆ†æ
    void analyze_memory_lifetime(ComputeGraph& graph) {
        std::map<Tensor*, std::pair<int, int>> lifetimes;
        
        // åˆ†ææ¯ä¸ªtensorçš„ç”Ÿå‘½å‘¨æœŸ
        for (int i = 0; i < graph.nodes.size(); i++) {
            auto& node = graph.nodes[i];
            
            // è¾“å…¥tensorç”Ÿå‘½å‘¨æœŸå¼€å§‹
            for (auto& input : node.inputs) {
                if (lifetimes.find(input) == lifetimes.end()) {
                    lifetimes[input].first = i;
                }
                lifetimes[input].second = i;  // æ›´æ–°ç»“æŸæ—¶é—´
            }
            
            // è¾“å‡ºtensorç”Ÿå‘½å‘¨æœŸå¼€å§‹
            for (auto& output : node.outputs) {
                lifetimes[output].first = i;
            }
        }
        
        // åŸºäºç”Ÿå‘½å‘¨æœŸè¿›è¡Œå†…å­˜å¤ç”¨
        schedule_memory_reuse(lifetimes);
    }
    
private:
    void schedule_memory_reuse(const std::map<Tensor*, std::pair<int, int>>& lifetimes) {
        // ä½¿ç”¨åŒºé—´è°ƒåº¦ç®—æ³•ä¼˜åŒ–å†…å­˜å¤ç”¨
        std::vector<std::pair<Tensor*, std::pair<int, int>>> sorted_tensors(
            lifetimes.begin(), lifetimes.end());
        
        // æŒ‰ç”Ÿå‘½å‘¨æœŸç»“æŸæ—¶é—´æ’åº
        std::sort(sorted_tensors.begin(), sorted_tensors.end(),
            [](const auto& a, const auto& b) {
                return a.second.second < b.second.second;
            });
        
        // åˆ†é…å†…å­˜æ§½ä½
        std::vector<int> memory_slots;
        for (auto& [tensor, lifetime] : sorted_tensors) {
            int slot = find_available_slot(memory_slots, lifetime.first);
            assign_tensor_to_slot(tensor, slot);
            memory_slots[slot] = lifetime.second;
        }
    }
};
```

### 10.3.2 æ•°æ®å¸ƒå±€ä¼˜åŒ–

```cpp
// æ•°æ®å¸ƒå±€å˜æ¢ä¼˜åŒ–
class DataLayoutOptimizer {
    // å¸¸è§çš„æ•°æ®å¸ƒå±€æ ¼å¼
    enum LayoutFormat {
        NCHW,    // é€‚åˆGPUè®¡ç®—
        NHWC,    // é€‚åˆç§»åŠ¨ç«¯NPU
        NC4HW4,  // 4é€šé“å¯¹é½æ ¼å¼
        NC8HW8,  // 8é€šé“å¯¹é½æ ¼å¼
        NCHW_TO_NC4HW4  // å¸ƒå±€è½¬æ¢
    };
    
    // ä¸ºæ¯ä¸ªæ“ä½œé€‰æ‹©æœ€ä¼˜å¸ƒå±€
    LayoutFormat select_optimal_layout(OpType op, HardwareSpec hw) {
        switch (op) {
            case CONV2D:
                if (hw.has_winograd_support) {
                    return select_winograd_layout(hw);
                } else if (hw.vector_width == 4) {
                    return NC4HW4;
                } else if (hw.vector_width == 8) {
                    return NC8HW8;
                }
                break;
                
            case MATMUL:
                // çŸ©é˜µä¹˜æ³•åå¥½è¡Œä¸»åºæˆ–åˆ—ä¸»åº
                return hw.prefers_row_major ? ROW_MAJOR : COL_MAJOR;
                
            case ELEMENTWISE:
                // é€å…ƒç´ æ“ä½œåå¥½è¿ç»­å†…å­˜å¸ƒå±€
                return CONTIGUOUS;
        }
        return NCHW;  // é»˜è®¤å¸ƒå±€
    }
    
    // å¸ƒå±€è½¬æ¢çš„ä»£ä»·ä¼°è®¡
    float estimate_layout_conversion_cost(LayoutFormat from, LayoutFormat to, 
                                        TensorShape shape) {
        // è®¡ç®—æ•°æ®é‡æ’çš„å†…å­˜è®¿é—®ä»£ä»·
        size_t total_elements = shape.total_elements();
        
        if (is_simple_transpose(from, to)) {
            // ç®€å•è½¬ç½®ï¼š2å€å†…å­˜è®¿é—®
            return total_elements * 2 * sizeof(float);
        } else if (requires_padding(from, to)) {
            // éœ€è¦å¡«å……ï¼šé¢å¤–çš„å†…å­˜å’Œè®¡ç®—å¼€é”€
            float padding_ratio = calculate_padding_ratio(from, to, shape);
            return total_elements * (1 + padding_ratio) * 2 * sizeof(float);
        } else {
            // å¤æ‚é‡æ’ï¼šå¯èƒ½éœ€è¦å¤šæ¬¡pass
            return total_elements * 4 * sizeof(float);
        }
    }
    
    // å…¨å±€å¸ƒå±€ä¼˜åŒ–
    void optimize_global_layout(ComputeGraph& graph) {
        // æ„å»ºå¸ƒå±€ä¼ æ’­å›¾
        std::map<Node*, LayoutFormat> node_layouts;
        std::map<Edge*, float> conversion_costs;
        
        // ä¸ºæ¯ä¸ªèŠ‚ç‚¹é€‰æ‹©å€™é€‰å¸ƒå±€
        for (auto& node : graph.nodes) {
            auto candidates = get_layout_candidates(node);
            node_layouts[&node] = select_best_layout(candidates);
        }
        
        // æœ€å°åŒ–æ€»çš„è½¬æ¢ä»£ä»·
        optimize_conversion_costs(graph, node_layouts, conversion_costs);
        
        // æ’å…¥å¿…è¦çš„å¸ƒå±€è½¬æ¢èŠ‚ç‚¹
        insert_layout_conversion_nodes(graph, node_layouts);
    }
};
```

## <a name="104"></a>10.4 æŒ‡ä»¤è°ƒåº¦ä¸ä»£ç ç”Ÿæˆ

### 10.4.1 æŒ‡ä»¤çº§å¹¶è¡Œè°ƒåº¦

NPUæŒ‡ä»¤è°ƒåº¦çš„æ ¸å¿ƒç›®æ ‡æ˜¯æœ€å¤§åŒ–ç¡¬ä»¶èµ„æºåˆ©ç”¨ç‡ï¼Œé€šè¿‡åˆç†å®‰æ’æŒ‡ä»¤æ‰§è¡Œé¡ºåºæ¥éšè—å»¶è¿Ÿå¹¶å‘æŒ¥å¹¶è¡Œè®¡ç®—èƒ½åŠ›ã€‚

```cpp
// NPUæŒ‡ä»¤è°ƒåº¦å™¨æ ¸å¿ƒå®ç°
class NPUInstructionScheduler {
    struct InstructionInfo {
        int id;
        InstrType type;
        std::vector<int> operands;
        int result_reg;
        int latency;
        std::set<int> dependencies;
    };
    
    // ç¡¬ä»¶èµ„æºæ¨¡å‹
    struct HardwareModel {
        int mac_units = 256;        // MACå•å…ƒæ•°é‡
        int load_units = 8;         // åŠ è½½å•å…ƒ
        int store_units = 4;        // å­˜å‚¨å•å…ƒ
        int vector_width = 16;      // å‘é‡å®½åº¦
    };
    
public:
    // åˆ—è¡¨è°ƒåº¦ç®—æ³•
    std::vector<int> list_schedule(std::vector<InstructionInfo>& instructions) {
        std::vector<int> scheduled_order;
        std::set<int> ready_list;
        std::map<int, int> completion_time;
        int current_cycle = 0;
        
        // åˆå§‹åŒ–ready_list
        for (auto& instr : instructions) {
            if (instr.dependencies.empty()) {
                ready_list.insert(instr.id);
            }
        }
        
        while (!ready_list.empty() || !has_running_instructions()) {
            // é€‰æ‹©ä¼˜å…ˆçº§æœ€é«˜çš„æŒ‡ä»¤
            if (!ready_list.empty()) {
                int selected = select_highest_priority_instruction(ready_list);
                schedule_instruction(selected, current_cycle);
                ready_list.erase(selected);
                scheduled_order.push_back(selected);
            }
            
            // æ›´æ–°å®Œæˆçš„æŒ‡ä»¤
            update_completed_instructions(current_cycle, ready_list);
            current_cycle++;
        }
        
        return scheduled_order;
    }
    
private:
    int calculate_priority(int instr_id) {
        // è®¡ç®—æŒ‡ä»¤ä¼˜å…ˆçº§ï¼ˆè¶Šå¤§è¶Šé«˜ï¼‰
        int critical_path_length = calculate_critical_path(instr_id);
        int resource_pressure = calculate_resource_pressure(instr_id);
        int data_locality = calculate_data_locality(instr_id);
        
        return critical_path_length * 10 + resource_pressure * 5 + data_locality;
    }
};
```

### 10.4.2 è½¯ä»¶æµæ°´çº¿æŠ€æœ¯

```cpp
// è½¯ä»¶æµæ°´çº¿å®ç°
class SoftwarePipelining {
    struct LoopInfo {
        std::vector<InstructionInfo> body;
        int iteration_count;
        std::vector<int> loop_carried_deps;  // å¾ªç¯æºå¸¦ä¾èµ–
    };
    
public:
    // æ¨¡è°ƒåº¦ç®—æ³•å®ç°
    ScheduleResult modulo_schedule(const LoopInfo& loop) {
        // 1. è®¡ç®—MII (Minimum Initiation Interval)
        int resource_mii = calculate_resource_mii(loop.body);
        int recurrence_mii = calculate_recurrence_mii(loop.loop_carried_deps);
        int mii = std::max(resource_mii, recurrence_mii);
        
        // 2. å°è¯•åœ¨ä¸åŒIIä¸‹è°ƒåº¦
        for (int ii = mii; ii <= mii * 2; ii++) {
            auto result = try_schedule_with_ii(loop, ii);
            if (result.success) {
                return result;
            }
        }
        
        // 3. è°ƒåº¦å¤±è´¥ï¼Œå›é€€åˆ°å±•å¼€
        return fallback_to_unrolling(loop);
    }
    
private:
    int calculate_resource_mii(const std::vector<InstructionInfo>& instructions) {
        std::map<InstrType, int> usage_count;
        for (const auto& instr : instructions) {
            usage_count[instr.type]++;
        }
        
        int max_mii = 1;
        max_mii = std::max(max_mii, 
            (usage_count[COMPUTE_INSTR] + hw_model.mac_units - 1) / hw_model.mac_units);
        max_mii = std::max(max_mii,
            (usage_count[LOAD_INSTR] + hw_model.load_units - 1) / hw_model.load_units);
        
        return max_mii;
    }
};
```

### 10.4.3 ä»£ç ç”Ÿæˆåç«¯

```cpp
// NPUæ±‡ç¼–ä»£ç ç”Ÿæˆ
class NPUCodeGenerator {
    // æŒ‡ä»¤ç¼–ç 
    struct NPUInstruction {
        uint8_t opcode;
        uint8_t dst_reg;
        uint8_t src1_reg;
        uint8_t src2_reg;
        uint16_t immediate;
        uint8_t flags;
    };
    
public:
    std::string generate_assembly(const IR& intermediate_rep) {
        std::stringstream asm_code;
        
        // å‡½æ•°åºè¨€
        asm_code << ".section .text\n";
        asm_code << ".global " << intermediate_rep.function_name << "\n";
        asm_code << intermediate_rep.function_name << ":\n";
        
        // å¯„å­˜å™¨åˆ†é…
        auto reg_allocation = allocate_registers(intermediate_rep);
        
        // ç”ŸæˆæŒ‡ä»¤åºåˆ—
        for (const auto& stmt : intermediate_rep.statements) {
            asm_code << generate_statement(stmt, reg_allocation);
        }
        
        // å‡½æ•°å°¾å£°
        asm_code << "    ret\n";
        
        return asm_code.str();
    }
    
private:
    std::string generate_conv2d_instruction(const ConvStatement& stmt) {
        std::stringstream code;
        code << "    # 2Då·ç§¯æŒ‡ä»¤ç”Ÿæˆ\n";
        code << "    cfg_mac_array " << stmt.kernel_h << ", " << stmt.kernel_w << "\n";
        code << "    load_weight w" << stmt.weight_reg << ", [" << stmt.weight_addr << "]\n";
        code << "    load_input a" << stmt.input_reg << ", [" << stmt.input_addr << "]\n";
        code << "    mac_compute a" << stmt.input_reg << ", w" << stmt.weight_reg 
             << ", acc" << stmt.output_reg << "\n";
        code << "    store_result acc" << stmt.output_reg << ", [" << stmt.output_addr << "]\n";
        return code.str();
    }
    
    std::map<int, int> allocate_registers(const IR& ir) {
        // ç®€åŒ–çš„å›¾ç€è‰²å¯„å­˜å™¨åˆ†é…
        std::map<int, int> allocation;
        std::vector<std::set<int>> interference_graph(ir.virtual_regs.size());
        
        // æ„å»ºå†²çªå›¾
        build_interference_graph(ir, interference_graph);
        
        // å›¾ç€è‰²ç®—æ³•
        auto coloring = graph_coloring(interference_graph, hw_model.num_registers);
        
        // å¤„ç†æº¢å‡º
        if (coloring.has_spills) {
            handle_register_spills(ir, coloring.spilled_regs);
        }
        
        return coloring.allocation;
    }
};
```

## <a name="105"></a>10.5 é‡åŒ–ä¸ç²¾åº¦ä¼˜åŒ–

### 10.5.1 é‡åŒ–ç­–ç•¥é€‰æ‹©

NPUé‡åŒ–æŠ€æœ¯çš„æ ¸å¿ƒæ˜¯åœ¨ä¿æŒæ¨¡å‹ç²¾åº¦çš„å‰æä¸‹ï¼Œæœ€å¤§åŒ–ç¡¬ä»¶è®¡ç®—æ•ˆç‡å’Œå†…å­˜åˆ©ç”¨ç‡ã€‚

> **ğŸ¯ é‡åŒ–ç­–ç•¥å¯¹æ¯”**
> 
> | é‡åŒ–ç±»å‹ | ç²¾åº¦ä¿æŒ | ç¡¬ä»¶æ•ˆç‡ | å®ç°å¤æ‚åº¦ | é€‚ç”¨åœºæ™¯ |
> |---------|---------|---------|-----------|---------|
> | FP16é‡åŒ– | 99.5%+ | ä¸­ç­‰ | ä½ | è®­ç»ƒæ¨ç† |
> | INT8é‡åŒ– | 98%+ | é«˜ | ä¸­ç­‰ | æ¨ç†ä¼˜åŒ– |
> | INT4é‡åŒ– | 95%+ | å¾ˆé«˜ | é«˜ | è¾¹ç¼˜éƒ¨ç½² |
> | æ··åˆç²¾åº¦ | 99%+ | é«˜ | é«˜ | å¤§æ¨¡å‹æ¨ç† |

```python
# é‡åŒ–ç­–ç•¥é€‰æ‹©æ¡†æ¶
class QuantizationStrategySelector:
    def __init__(self, model, target_hardware, accuracy_threshold=0.98):
        self.model = model
        self.target_hardware = target_hardware
        self.accuracy_threshold = accuracy_threshold
        
    def select_optimal_strategy(self):
        # æ¨¡å‹æ•æ„Ÿæ€§åˆ†æ
        sensitivity_analysis = self.analyze_layer_sensitivity()
        
        # ç¡¬ä»¶çº¦æŸåˆ†æ
        hardware_constraints = self.analyze_hardware_constraints()
        
        # ç­–ç•¥ç©ºé—´æœç´¢
        strategy = self.search_strategy_space(sensitivity_analysis, hardware_constraints)
        
        return strategy
    
    def analyze_layer_sensitivity(self):
        """åˆ†ææ¯å±‚å¯¹é‡åŒ–çš„æ•æ„Ÿæ€§"""
        sensitivity_map = {}
        baseline_accuracy = self.evaluate_model(self.model)
        
        for layer_name, layer in self.model.named_modules():
            if self.is_quantizable_layer(layer):
                # å•ç‹¬é‡åŒ–æµ‹è¯•
                test_model = self.quantize_single_layer(self.model, layer_name, 'int8')
                quantized_accuracy = self.evaluate_model(test_model)
                sensitivity_map[layer_name] = baseline_accuracy - quantized_accuracy
                
        return sensitivity_map
```

### 10.5.2 åŠ¨æ€é‡åŒ–æŠ€æœ¯

```python
# åŠ¨æ€é‡åŒ–å®ç°
class DynamicQuantization:
    def __init__(self, calibration_data, quantization_scheme='symmetric'):
        self.calibration_data = calibration_data
        self.quantization_scheme = quantization_scheme
        self.activation_observers = {}
        
    def calibrate_activation_ranges(self, model):
        """æ ¡å‡†æ¿€æ´»å€¼èŒƒå›´"""
        model.eval()
        
        # æ³¨å†Œè§‚å¯Ÿå™¨
        for name, module in model.named_modules():
            if isinstance(module, (nn.Conv2d, nn.Linear)):
                self.activation_observers[name] = ActivationObserver()
                module.register_forward_hook(
                    lambda module, input, output, name=name: 
                    self.activation_observers[name].observe(output)
                )
        
        # æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
        with torch.no_grad():
            for data, _ in self.calibration_data:
                model(data)
        
        # è®¡ç®—é‡åŒ–å‚æ•°
        quantization_params = {}
        for name, observer in self.activation_observers.items():
            if self.quantization_scheme == 'symmetric':
                abs_max = max(abs(observer.min_val), abs(observer.max_val))
                scale = abs_max / 127.0
                zero_point = 0
            else:  # asymmetric
                scale = (observer.max_val - observer.min_val) / 255.0
                zero_point = int(-observer.min_val / scale)
                
            quantization_params[name] = {'scale': scale, 'zero_point': zero_point}
        
        return quantization_params
```

## <a name="106"></a>10.6 æ€§èƒ½åˆ†æå·¥å…·

### 10.6.1 ç¼–è¯‘å™¨æ€§èƒ½åˆ†æå™¨

```python
# NPUç¼–è¯‘å™¨æ€§èƒ½åˆ†æå™¨
class NPUCompilerProfiler:
    def __init__(self):
        self.metrics = {
            'compile_time': {},
            'memory_usage': {},
            'optimization_effects': {},
            'hardware_utilization': {}
        }
        
    def profile_compilation_pipeline(self, model, optimization_passes):
        """åˆ†æç¼–è¯‘æµæ°´çº¿æ€§èƒ½"""
        import time
        import psutil
        
        total_start_time = time.time()
        
        for pass_name, optimization_pass in optimization_passes.items():
            # æµ‹é‡å•ä¸ªpassçš„æ—¶é—´å’Œå†…å­˜
            start_time = time.time()
            start_memory = psutil.Process().memory_info().rss
            
            # æ‰§è¡Œä¼˜åŒ–pass
            optimized_model = optimization_pass(model)
            
            end_time = time.time()
            end_memory = psutil.Process().memory_info().rss
            
            # è®°å½•æŒ‡æ ‡
            self.metrics['compile_time'][pass_name] = end_time - start_time
            self.metrics['memory_usage'][pass_name] = end_memory - start_memory
            
            # åˆ†æä¼˜åŒ–æ•ˆæœ
            self.analyze_optimization_effect(model, optimized_model, pass_name)
            
            model = optimized_model
        
        self.metrics['total_compile_time'] = time.time() - total_start_time
        return model
    
    def analyze_optimization_effect(self, original, optimized, pass_name):
        """åˆ†æä¼˜åŒ–æ•ˆæœ"""
        effects = {
            'instruction_count_reduction': self.count_instructions(original) - self.count_instructions(optimized),
            'memory_access_reduction': self.estimate_memory_accesses(original) - self.estimate_memory_accesses(optimized),
            'parallelism_improvement': self.estimate_parallelism(optimized) - self.estimate_parallelism(original)
        }
        self.metrics['optimization_effects'][pass_name] = effects
        
    def generate_performance_report(self):
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        report = []
        report.append("=== NPUç¼–è¯‘å™¨æ€§èƒ½æŠ¥å‘Š ===\n")
        
        # ç¼–è¯‘æ—¶é—´åˆ†æ
        report.append("ç¼–è¯‘æ—¶é—´åˆ†æ:")
        for pass_name, time_cost in self.metrics['compile_time'].items():
            report.append(f"  {pass_name}: {time_cost:.3f}s")
        
        # ä¼˜åŒ–æ•ˆæœåˆ†æ
        report.append("\nä¼˜åŒ–æ•ˆæœåˆ†æ:")
        for pass_name, effects in self.metrics['optimization_effects'].items():
            report.append(f"  {pass_name}:")
            for metric, value in effects.items():
                report.append(f"    {metric}: {value}")
        
        return "\n".join(report)
```

### 10.6.2 è¿è¡Œæ—¶æ€§èƒ½ç›‘æ§

```cpp
// NPUè¿è¡Œæ—¶æ€§èƒ½ç›‘æ§å™¨
class NPURuntimeProfiler {
    struct PerformanceCounters {
        uint64_t total_cycles;
        uint64_t compute_cycles;
        uint64_t memory_stall_cycles;
        uint64_t cache_hits;
        uint64_t cache_misses;
        uint64_t instructions_executed;
    };
    
    PerformanceCounters counters;
    
public:
    void start_profiling() {
        reset_counters();
        enable_hardware_counters();
    }
    
    ProfileReport stop_profiling() {
        disable_hardware_counters();
        return analyze_performance();
    }
    
private:
    ProfileReport analyze_performance() {
        ProfileReport report;
        
        // è®¡ç®—å…³é”®æŒ‡æ ‡
        report.compute_utilization = 
            (double)counters.compute_cycles / counters.total_cycles * 100;
            
        report.memory_efficiency = 
            (double)counters.cache_hits / (counters.cache_hits + counters.cache_misses) * 100;
            
        report.ipc = 
            (double)counters.instructions_executed / counters.total_cycles;
        
        // è¯†åˆ«æ€§èƒ½ç“¶é¢ˆ
        if (report.compute_utilization < 50) {
            report.bottleneck = "è®¡ç®—å•å…ƒåˆ©ç”¨ç‡ä½";
            report.suggestions.push_back("å¢åŠ ç®—å­èåˆ");
            report.suggestions.push_back("ä¼˜åŒ–æ•°æ®å¹¶è¡Œåº¦");
        }
        
        if (report.memory_efficiency < 80) {
            report.bottleneck = "å†…å­˜è®¿é—®æ•ˆç‡ä½";
            report.suggestions.push_back("ä¼˜åŒ–æ•°æ®å¸ƒå±€");
            report.suggestions.push_back("å¢åŠ æ•°æ®é‡ç”¨");
        }
        
        return report;
    }
};
```

## <a name="107"></a>10.7 ä¹ é¢˜ä¸å®è·µ

<details>
<summary><strong>ç»ƒä¹ é¢˜10.1ï¼šè½¯ä»¶æ ˆæ¶æ„è®¾è®¡</strong></summary>

**é¢˜ç›®ï¼š** è®¾è®¡ä¸€ä¸ªæ”¯æŒå¤šç§AIæ¡†æ¶ï¼ˆTensorFlowã€PyTorchã€ONNXï¼‰çš„NPUè½¯ä»¶æ ˆï¼Œè¯´æ˜å„å±‚çš„èŒè´£å’Œæ¥å£è®¾è®¡ã€‚

**å‚è€ƒç­”æ¡ˆï¼š**

```python
# NPUè½¯ä»¶æ ˆæ¶æ„è®¾è®¡
class NPUSoftwareStack:
    def __init__(self):
        self.frontend_parsers = {
            'tensorflow': TensorFlowParser(),
            'pytorch': PyTorchParser(), 
            'onnx': ONNXParser()
        }
        self.optimizer = GraphOptimizer()
        self.code_generator = NPUCodeGenerator()
        self.runtime = NPURuntime()
    
    def compile_model(self, model, framework):
        # 1. å‰ç«¯è§£æ
        graph = self.frontend_parsers[framework].parse(model)
        
        # 2. å›¾ä¼˜åŒ–
        optimized_graph = self.optimizer.optimize(graph)
        
        # 3. ä»£ç ç”Ÿæˆ
        npu_code = self.code_generator.generate(optimized_graph)
        
        return npu_code
```

**å…³é”®è®¾è®¡åŸåˆ™ï¼š**
- ç»Ÿä¸€çš„å†…éƒ¨è¡¨ç¤ºï¼ˆIRï¼‰
- æ¨¡å—åŒ–çš„ä¼˜åŒ–pass
- ç¡¬ä»¶æŠ½è±¡å±‚
- å¯æ‰©å±•çš„æ¡†æ¶æ”¯æŒ

</details>

<details>
<summary><strong>ç»ƒä¹ é¢˜10.2ï¼šç®—å­èåˆä¼˜åŒ–</strong></summary>

**é¢˜ç›®ï¼š** å®ç°ä¸€ä¸ªç®—å­èåˆå™¨ï¼Œèƒ½å¤Ÿè‡ªåŠ¨è¯†åˆ«å’ŒèåˆConv2D+BatchNorm+ReLUæ¨¡å¼ã€‚

**å‚è€ƒç­”æ¡ˆï¼š**

```cpp
class OperatorFusionPass {
public:
    bool tryFuseConvBnRelu(ComputeGraph& graph, Node* conv_node) {
        if (conv_node->op_type != "Conv2D") return false;
        
        // æ£€æŸ¥æ¨¡å¼ï¼šConv2D -> BatchNorm -> ReLU
        auto bn_node = findSingleConsumer(conv_node, "BatchNorm");
        if (!bn_node) return false;
        
        auto relu_node = findSingleConsumer(bn_node, "ReLU");
        if (!relu_node) return false;
        
        // åˆ›å»ºèåˆèŠ‚ç‚¹
        auto fused_node = createFusedNode("ConvBnRelu", {
            conv_node->inputs,
            bn_node->bn_params,
            relu_node->relu_params
        });
        
        // æ›¿æ¢åŸæœ‰èŠ‚ç‚¹
        replaceNodesWithFused(graph, {conv_node, bn_node, relu_node}, fused_node);
        
        return true;
    }
};
```

**è¯„åˆ†æ ‡å‡†ï¼š**
- æ¨¡å¼è¯†åˆ«å‡†ç¡®æ€§ (30%)
- æ•°æ®ä¾èµ–æ£€æŸ¥ (25%)
- èåˆå®ç°æ­£ç¡®æ€§ (25%)
- æ€§èƒ½ä¼˜åŒ–æ•ˆæœ (20%)

</details>

<details>
<summary><strong>ç»ƒä¹ é¢˜10.3ï¼šå†…å­˜åˆ†é…ä¼˜åŒ–</strong></summary>

**é¢˜ç›®ï¼š** è®¾è®¡ä¸€ä¸ªå†…å­˜åˆ†é…å™¨ï¼Œä½¿ç”¨ç”Ÿå‘½å‘¨æœŸåˆ†ææ¥æœ€å°åŒ–å†…å­˜ä½¿ç”¨ã€‚

**å‚è€ƒç­”æ¡ˆï¼š**

```cpp
class LifetimeAwareAllocator {
    struct TensorLifetime {
        int birth_time;    // ç¬¬ä¸€æ¬¡ä½¿ç”¨
        int death_time;    // æœ€åä¸€æ¬¡ä½¿ç”¨
        size_t size;
    };
    
public:
    std::map<Tensor*, void*> allocate_tensors(
        const std::vector<TensorLifetime>& lifetimes) {
        
        // æŒ‰æ­»äº¡æ—¶é—´æ’åº
        auto sorted_tensors = lifetimes;
        std::sort(sorted_tensors.begin(), sorted_tensors.end(),
            [](const auto& a, const auto& b) {
                return a.death_time < b.death_time;
            });
        
        std::vector<MemorySlot> memory_slots;
        std::map<Tensor*, void*> allocation;
        
        for (const auto& tensor : sorted_tensors) {
            // å¯»æ‰¾å¯å¤ç”¨çš„å†…å­˜æ§½
            int slot_idx = findAvailableSlot(memory_slots, tensor.birth_time, tensor.size);
            
            if (slot_idx == -1) {
                // åˆ†é…æ–°æ§½
                memory_slots.push_back({tensor.size, tensor.death_time});
                allocation[tensor.tensor_ptr] = allocate_new_memory(tensor.size);
            } else {
                // å¤ç”¨ç°æœ‰æ§½
                memory_slots[slot_idx].end_time = tensor.death_time;
                allocation[tensor.tensor_ptr] = memory_slots[slot_idx].memory_ptr;
            }
        }
        
        return allocation;
    }
};
```

**å†…å­˜å¤ç”¨æ•ˆæœï¼š**
- å…¸å‹æ¨¡å‹å†…å­˜èŠ‚çœï¼š40-60%
- é€‚ç”¨äºæ¨ç†åœºæ™¯çš„å†…å­˜ä¼˜åŒ–

</details>

<details>
<summary><strong>ç»ƒä¹ é¢˜10.4ï¼šæŒ‡ä»¤è°ƒåº¦ç®—æ³•</strong></summary>

**é¢˜ç›®ï¼š** å®ç°ä¸€ä¸ªè€ƒè™‘ç¡¬ä»¶èµ„æºçº¦æŸçš„æŒ‡ä»¤è°ƒåº¦å™¨ã€‚

**å‚è€ƒç­”æ¡ˆï¼š**

è°ƒåº¦å™¨éœ€è¦è€ƒè™‘ï¼š
1. **èµ„æºçº¦æŸ**ï¼šMACå•å…ƒã€å†…å­˜å¸¦å®½ã€å¯„å­˜å™¨æ–‡ä»¶
2. **æ•°æ®ä¾èµ–**ï¼šRAWã€WARã€WAWä¾èµ–å…³ç³»
3. **å»¶è¿Ÿéšè—**ï¼šä½¿ç”¨è½¯ä»¶æµæ°´çº¿æŠ€æœ¯

```cpp
class ResourceConstrainedScheduler {
    struct ResourceUsage {
        int mac_units_used = 0;
        int memory_ports_used = 0;
        int registers_used = 0;
    };
    
public:
    std::vector<int> schedule_instructions(
        const std::vector<Instruction>& instructions,
        const HardwareModel& hw_model) {
        
        std::vector<int> schedule;
        std::priority_queue<int> ready_queue;
        ResourceUsage current_usage;
        
        // åˆå§‹åŒ–ready queue
        for (int i = 0; i < instructions.size(); i++) {
            if (all_dependencies_satisfied(instructions[i])) {
                ready_queue.push(calculate_priority(instructions[i]));
            }
        }
        
        while (!ready_queue.empty()) {
            int instr_id = ready_queue.top();
            ready_queue.pop();
            
            if (can_schedule_instruction(instructions[instr_id], current_usage, hw_model)) {
                schedule.push_back(instr_id);
                update_resource_usage(current_usage, instructions[instr_id]);
                update_ready_queue(ready_queue, instr_id);
            }
        }
        
        return schedule;
    }
};
```

</details>

<details>
<summary><strong>ç»ƒä¹ é¢˜10.5ï¼šé‡åŒ–ç­–ç•¥é€‰æ‹©</strong></summary>

**é¢˜ç›®ï¼š** è®¾è®¡ä¸€ä¸ªè‡ªé€‚åº”é‡åŒ–ç­–ç•¥ï¼Œæ ¹æ®å±‚çš„æ•æ„Ÿæ€§é€‰æ‹©åˆé€‚çš„é‡åŒ–ç²¾åº¦ã€‚

**å‚è€ƒç­”æ¡ˆï¼š**

```python
class AdaptiveQuantizationStrategy:
    def __init__(self, accuracy_threshold=0.02):
        self.accuracy_threshold = accuracy_threshold
        self.bit_width_options = [16, 8, 4]
        
    def select_layer_quantization(self, model, calibration_data):
        layer_strategies = {}
        
        for layer_name, layer in model.named_modules():
            if self.is_quantizable_layer(layer):
                # æµ‹è¯•ä¸åŒç²¾åº¦çš„å½±å“
                best_strategy = self.find_optimal_precision(
                    model, layer_name, calibration_data)
                layer_strategies[layer_name] = best_strategy
                
        return layer_strategies
    
    def find_optimal_precision(self, model, layer_name, data):
        baseline_accuracy = self.evaluate_model(model, data)
        
        for bits in self.bit_width_options:
            quantized_model = self.quantize_layer(model, layer_name, bits)
            accuracy = self.evaluate_model(quantized_model, data)
            accuracy_drop = baseline_accuracy - accuracy
            
            if accuracy_drop <= self.accuracy_threshold:
                return {'bits': bits, 'accuracy_drop': accuracy_drop}
                
        # å¦‚æœéƒ½ä¸æ»¡è¶³ï¼Œé€‰æ‹©æœ€é«˜ç²¾åº¦
        return {'bits': 16, 'accuracy_drop': 0}
```

**å…³é”®è€ƒè™‘å› ç´ ï¼š**
- å±‚æ•æ„Ÿæ€§åˆ†æ
- ç¡¬ä»¶æ”¯æŒçš„ç²¾åº¦
- è®¡ç®—å’Œå­˜å‚¨å¼€é”€æƒè¡¡

</details>

<details>
<summary><strong>ç»ƒä¹ é¢˜10.6ï¼šç¼–è¯‘å™¨æ€§èƒ½åˆ†æ</strong></summary>

**é¢˜ç›®ï¼š** è®¾è®¡ä¸€ä¸ªç¼–è¯‘å™¨æ€§èƒ½åˆ†æå·¥å…·ï¼Œè¯†åˆ«ç¼–è¯‘è¿‡ç¨‹ä¸­çš„ç“¶é¢ˆã€‚

**å‚è€ƒç­”æ¡ˆï¼š**

```python
class CompilerProfiler:
    def __init__(self):
        self.pass_timings = {}
        self.memory_usage = {}
        self.optimization_effects = {}
        
    def profile_compilation(self, model, optimization_passes):
        total_start = time.time()
        
        for pass_name, pass_func in optimization_passes.items():
            # æ€§èƒ½è®¡æ—¶
            start_time = time.time()
            start_memory = self.get_memory_usage()
            
            # æ‰§è¡Œä¼˜åŒ–pass
            optimized_model = pass_func(model)
            
            # è®°å½•æŒ‡æ ‡
            end_time = time.time()
            end_memory = self.get_memory_usage()
            
            self.pass_timings[pass_name] = end_time - start_time
            self.memory_usage[pass_name] = end_memory - start_memory
            
            # åˆ†æä¼˜åŒ–æ•ˆæœ
            self.analyze_optimization_effect(model, optimized_model, pass_name)
            model = optimized_model
            
        return self.generate_report()
    
    def generate_report(self):
        # è¯†åˆ«æœ€è€—æ—¶çš„pass
        slowest_pass = max(self.pass_timings.items(), key=lambda x: x[1])
        
        # è¯†åˆ«å†…å­˜ä½¿ç”¨æœ€å¤šçš„pass
        memory_heavy_pass = max(self.memory_usage.items(), key=lambda x: x[1])
        
        return {
            'total_time': sum(self.pass_timings.values()),
            'bottleneck_pass': slowest_pass[0],
            'memory_heavy_pass': memory_heavy_pass[0],
            'optimization_summary': self.optimization_effects
        }
```

</details>

<details>
<summary><strong>ç»ƒä¹ é¢˜10.7ï¼šå¤šçº§IRè½¬æ¢</strong></summary>

**é¢˜ç›®ï¼š** å®ç°ä¸€ä¸ªå¤šçº§IRè½¬æ¢æ¡†æ¶ï¼Œæ”¯æŒä»é«˜çº§è®¡ç®—å›¾åˆ°ç¡¬ä»¶æŒ‡ä»¤çš„è½¬æ¢ã€‚

**å‚è€ƒç­”æ¡ˆï¼š**

```cpp
class MultiLevelIRConverter {
public:
    HardwareIR convert_to_hardware_ir(const GraphIR& graph_ir) {
        // 1. Graph IR -> Tensor IR
        TensorIR tensor_ir = graph_to_tensor_ir(graph_ir);
        
        // 2. Tensor IRä¼˜åŒ–
        tensor_ir = optimize_tensor_ir(tensor_ir);
        
        // 3. Tensor IR -> Hardware IR
        HardwareIR hw_ir = tensor_to_hardware_ir(tensor_ir);
        
        // 4. Hardware IRä¼˜åŒ–
        hw_ir = optimize_hardware_ir(hw_ir);
        
        return hw_ir;
    }
    
private:
    TensorIR graph_to_tensor_ir(const GraphIR& graph) {
        TensorIR result;
        
        for (const auto& node : graph.nodes) {
            switch (node.op_type) {
                case CONV2D:
                    result.add_compute(create_conv2d_compute(node));
                    break;
                case MATMUL:
                    result.add_compute(create_matmul_compute(node));
                    break;
                // å…¶ä»–ç®—å­...
            }
        }
        
        return result;
    }
    
    HardwareIR tensor_to_hardware_ir(const TensorIR& tensor_ir) {
        HardwareIR hw_ir;
        
        for (const auto& compute : tensor_ir.computes) {
            // å¾ªç¯å±•å¼€å’Œå‘é‡åŒ–
            auto unrolled = unroll_loops(compute);
            auto vectorized = vectorize_compute(unrolled);
            
            // ç”Ÿæˆç¡¬ä»¶æŒ‡ä»¤
            auto instructions = generate_hw_instructions(vectorized);
            hw_ir.add_instructions(instructions);
        }
        
        return hw_ir;
    }
};
```

**è½¬æ¢è¦ç‚¹ï¼š**
- ä¿æŒè¯­ä¹‰ç­‰ä»·æ€§
- é€æ­¥é™ä½æŠ½è±¡å±‚æ¬¡
- æ¯å±‚éƒ½æœ‰ç‰¹å®šçš„ä¼˜åŒ–æœºä¼š

</details>

<details>
<summary><strong>ç»ƒä¹ é¢˜10.8ï¼šè½¯ä»¶æ ˆé›†æˆæµ‹è¯•</strong></summary>

**é¢˜ç›®ï¼š** è®¾è®¡ä¸€ä¸ªç«¯åˆ°ç«¯çš„è½¯ä»¶æ ˆæµ‹è¯•æ¡†æ¶ï¼ŒéªŒè¯ä»æ¨¡å‹è¾“å…¥åˆ°NPUæ‰§è¡Œçš„æ­£ç¡®æ€§ã€‚

**å‚è€ƒç­”æ¡ˆï¼š**

```python
class NPUSoftwareStackTester:
    def __init__(self, npu_compiler, npu_runtime):
        self.compiler = npu_compiler
        self.runtime = npu_runtime
        self.test_models = self.load_test_models()
        
    def run_end_to_end_tests(self):
        test_results = {}
        
        for model_name, (model, test_data, expected_output) in self.test_models.items():
            print(f"æµ‹è¯•æ¨¡å‹: {model_name}")
            
            try:
                # 1. ç¼–è¯‘æ¨¡å‹
                compiled_model = self.compiler.compile(model)
                
                # 2. åœ¨NPUä¸Šæ‰§è¡Œ
                npu_output = self.runtime.execute(compiled_model, test_data)
                
                # 3. ç²¾åº¦éªŒè¯
                accuracy = self.compare_outputs(npu_output, expected_output)
                
                # 4. æ€§èƒ½æµ‹è¯•
                performance = self.measure_performance(compiled_model, test_data)
                
                test_results[model_name] = {
                    'accuracy': accuracy,
                    'performance': performance,
                    'status': 'PASS' if accuracy > 0.99 else 'FAIL'
                }
                
            except Exception as e:
                test_results[model_name] = {
                    'status': 'ERROR',
                    'error': str(e)
                }
        
        return test_results
    
    def compare_outputs(self, npu_output, expected_output, tolerance=1e-5):
        diff = np.abs(npu_output - expected_output)
        relative_error = np.mean(diff / (np.abs(expected_output) + 1e-8))
        return 1.0 - relative_error  # è½¬æ¢ä¸ºå‡†ç¡®ç‡
        
    def measure_performance(self, compiled_model, test_data):
        # é¢„çƒ­
        for _ in range(10):
            self.runtime.execute(compiled_model, test_data)
            
        # æ€§èƒ½æµ‹è¯•
        start_time = time.time()
        for _ in range(100):
            self.runtime.execute(compiled_model, test_data)
        end_time = time.time()
        
        avg_latency = (end_time - start_time) / 100
        throughput = 1.0 / avg_latency
        
        return {
            'latency_ms': avg_latency * 1000,
            'throughput_fps': throughput
        }
```

**æµ‹è¯•è¦†ç›–èŒƒå›´ï¼š**
- åŠŸèƒ½æ­£ç¡®æ€§éªŒè¯
- æ•°å€¼ç²¾åº¦æ£€æŸ¥
- æ€§èƒ½åŸºå‡†æµ‹è¯•
- é”™è¯¯å¤„ç†éªŒè¯

</details>